2021-07-21 06:56:55,689 - mmdet - INFO - Distributed training: False
2021-07-21 06:56:55,689 - mmdet - INFO - MMDetection Version: 1.0.0+c7b294a
2021-07-21 06:56:55,689 - mmdet - INFO - Config:
# model settings
model = dict(
    type='SOLOv2',
    pretrained='torchvision://resnet50',
    backbone=dict(
        type='ResNet',
        depth=50,
        num_stages=4,
        out_indices=(0, 1, 2, 3),  # C2, C3, C4, C5
        frozen_stages=1,
        style='pytorch'),
    neck=dict(
        type='FPN',
        in_channels=[256, 512, 1024, 2048],
        out_channels=256,
        start_level=0,
        num_outs=5),
    bbox_head=dict(
        type='SOLOv2Head',
        num_classes=2,
        in_channels=256,
        stacked_convs=4,
        seg_feat_channels=512,
        strides=[8, 8, 16, 32, 32],
        # scale_ranges=((1, 96), (48, 192), (96, 384), (192, 768), (384, 2048)),
        scale_ranges=((1, 376), (188, 752), (752, 1400)),
        sigma=0.2,
        num_grids=[40, 36, 24, 16, 12],
        ins_out_channels=256,
        loss_ins=dict(
            type='DiceLoss',
            use_sigmoid=True,
            loss_weight=3.0),
        loss_cate=dict(
            type='FocalLoss',
            use_sigmoid=True,
            gamma=2.0,
            alpha=0.25,
            loss_weight=1.0)),
    mask_feat_head=dict(
        type='MaskFeatHead',
        in_channels=256,
        out_channels=128,
        start_level=0,
        end_level=3,
        num_classes=256,
        norm_cfg=dict(type='GN', num_groups=32, requires_grad=True)),
)
# training and testing settings
train_cfg = dict()
test_cfg = dict(
    nms_pre=500,
    score_thr=0.1,
    mask_thr=0.5,
    update_thr=0.05,
    kernel='gaussian',  # gaussian/linear
    sigma=2.0,
    max_per_img=100)
# dataset settings
dataset_type = 'CocoDataset'
data_root = 'data/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),
    dict(type='Resize',
         img_scale=[(1333, 800), (1333, 768), (1333, 736),
                    (1333, 704), (1333, 672), (1333, 640)],
         multiscale_mode='value',
         keep_ratio=True),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(type='Normalize', **img_norm_cfg),
    dict(type='Pad', size_divisor=32),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks']),
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(1333, 800),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(type='Normalize', **img_norm_cfg),
            dict(type='Pad', size_divisor=32),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img']),
        ])
]
data = dict(
    imgs_per_gpu=2,
    workers_per_gpu=2,
    train=dict(
        type=dataset_type,
        ann_file=data_root + 'annotation/merge/merge_train_coco.json',
        img_prefix=data_root + 'road/train/',
        pipeline=train_pipeline),
    val=dict(
        type=dataset_type,
        ann_file=data_root + 'annotation/merge/merge_val_coco.json',
        img_prefix=data_root + 'road/val/',
        pipeline=test_pipeline),
    test=dict(
        type=dataset_type,
        ann_file=data_root + 'annotation/merge/merge_val_coco.json',
        img_prefix=data_root + 'road/val/',
        pipeline=test_pipeline))
# optimizer
optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0001)
optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))
# learning policy
lr_config = dict(
    policy='step',
    warmup='linear',
    warmup_iters=500,
    warmup_ratio=0.01,
    step=[27, 33])
checkpoint_config = dict(interval=1)
# yapf:disable
log_config = dict(
    interval=50,
    hooks=[
        dict(type='TextLoggerHook'),
        # dict(type='TensorboardLoggerHook')
    ])
# yapf:enable
# runtime settings
total_epochs = 36
device_ids = range(8)
dist_params = dict(backend='nccl')
log_level = 'INFO'
# work_dir = './work_dirs/solov2_release_r50_fpn_8gpu_3x'
work_dir = './work_dirs/solov2_release_r50_fpn_8gpu_3x_scale'
load_from = None
resume_from = None
workflow = [('train', 1)]
# workflow = [('train', 1), ('val', 1)]

2021-07-21 06:56:56,080 - mmdet - INFO - load model from: torchvision://resnet50
2021-07-21 06:57:00,143 - mmdet - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: backbone.conv1.weight, backbone.bn1.weight, backbone.bn1.bias, backbone.bn1.running_mean, backbone.bn1.running_var, backbone.bn1.num_batches_tracked, backbone.layer1.0.conv1.weight, backbone.layer1.0.bn1.weight, backbone.layer1.0.bn1.bias, backbone.layer1.0.bn1.running_mean, backbone.layer1.0.bn1.running_var, backbone.layer1.0.bn1.num_batches_tracked, backbone.layer1.0.conv2.weight, backbone.layer1.0.bn2.weight, backbone.layer1.0.bn2.bias, backbone.layer1.0.bn2.running_mean, backbone.layer1.0.bn2.running_var, backbone.layer1.0.bn2.num_batches_tracked, backbone.layer1.0.conv3.weight, backbone.layer1.0.bn3.weight, backbone.layer1.0.bn3.bias, backbone.layer1.0.bn3.running_mean, backbone.layer1.0.bn3.running_var, backbone.layer1.0.bn3.num_batches_tracked, backbone.layer1.0.downsample.0.weight, backbone.layer1.0.downsample.1.weight, backbone.layer1.0.downsample.1.bias, backbone.layer1.0.downsample.1.running_mean, backbone.layer1.0.downsample.1.running_var, backbone.layer1.0.downsample.1.num_batches_tracked, backbone.layer1.1.conv1.weight, backbone.layer1.1.bn1.weight, backbone.layer1.1.bn1.bias, backbone.layer1.1.bn1.running_mean, backbone.layer1.1.bn1.running_var, backbone.layer1.1.bn1.num_batches_tracked, backbone.layer1.1.conv2.weight, backbone.layer1.1.bn2.weight, backbone.layer1.1.bn2.bias, backbone.layer1.1.bn2.running_mean, backbone.layer1.1.bn2.running_var, backbone.layer1.1.bn2.num_batches_tracked, backbone.layer1.1.conv3.weight, backbone.layer1.1.bn3.weight, backbone.layer1.1.bn3.bias, backbone.layer1.1.bn3.running_mean, backbone.layer1.1.bn3.running_var, backbone.layer1.1.bn3.num_batches_tracked, backbone.layer1.2.conv1.weight, backbone.layer1.2.bn1.weight, backbone.layer1.2.bn1.bias, backbone.layer1.2.bn1.running_mean, backbone.layer1.2.bn1.running_var, backbone.layer1.2.bn1.num_batches_tracked, backbone.layer1.2.conv2.weight, backbone.layer1.2.bn2.weight, backbone.layer1.2.bn2.bias, backbone.layer1.2.bn2.running_mean, backbone.layer1.2.bn2.running_var, backbone.layer1.2.bn2.num_batches_tracked, backbone.layer1.2.conv3.weight, backbone.layer1.2.bn3.weight, backbone.layer1.2.bn3.bias, backbone.layer1.2.bn3.running_mean, backbone.layer1.2.bn3.running_var, backbone.layer1.2.bn3.num_batches_tracked, backbone.layer2.0.conv1.weight, backbone.layer2.0.bn1.weight, backbone.layer2.0.bn1.bias, backbone.layer2.0.bn1.running_mean, backbone.layer2.0.bn1.running_var, backbone.layer2.0.bn1.num_batches_tracked, backbone.layer2.0.conv2.weight, backbone.layer2.0.bn2.weight, backbone.layer2.0.bn2.bias, backbone.layer2.0.bn2.running_mean, backbone.layer2.0.bn2.running_var, backbone.layer2.0.bn2.num_batches_tracked, backbone.layer2.0.conv3.weight, backbone.layer2.0.bn3.weight, backbone.layer2.0.bn3.bias, backbone.layer2.0.bn3.running_mean, backbone.layer2.0.bn3.running_var, backbone.layer2.0.bn3.num_batches_tracked, backbone.layer2.0.downsample.0.weight, backbone.layer2.0.downsample.1.weight, backbone.layer2.0.downsample.1.bias, backbone.layer2.0.downsample.1.running_mean, backbone.layer2.0.downsample.1.running_var, backbone.layer2.0.downsample.1.num_batches_tracked, backbone.layer2.1.conv1.weight, backbone.layer2.1.bn1.weight, backbone.layer2.1.bn1.bias, backbone.layer2.1.bn1.running_mean, backbone.layer2.1.bn1.running_var, backbone.layer2.1.bn1.num_batches_tracked, backbone.layer2.1.conv2.weight, backbone.layer2.1.bn2.weight, backbone.layer2.1.bn2.bias, backbone.layer2.1.bn2.running_mean, backbone.layer2.1.bn2.running_var, backbone.layer2.1.bn2.num_batches_tracked, backbone.layer2.1.conv3.weight, backbone.layer2.1.bn3.weight, backbone.layer2.1.bn3.bias, backbone.layer2.1.bn3.running_mean, backbone.layer2.1.bn3.running_var, backbone.layer2.1.bn3.num_batches_tracked, backbone.layer2.2.conv1.weight, backbone.layer2.2.bn1.weight, backbone.layer2.2.bn1.bias, backbone.layer2.2.bn1.running_mean, backbone.layer2.2.bn1.running_var, backbone.layer2.2.bn1.num_batches_tracked, backbone.layer2.2.conv2.weight, backbone.layer2.2.bn2.weight, backbone.layer2.2.bn2.bias, backbone.layer2.2.bn2.running_mean, backbone.layer2.2.bn2.running_var, backbone.layer2.2.bn2.num_batches_tracked, backbone.layer2.2.conv3.weight, backbone.layer2.2.bn3.weight, backbone.layer2.2.bn3.bias, backbone.layer2.2.bn3.running_mean, backbone.layer2.2.bn3.running_var, backbone.layer2.2.bn3.num_batches_tracked, backbone.layer2.3.conv1.weight, backbone.layer2.3.bn1.weight, backbone.layer2.3.bn1.bias, backbone.layer2.3.bn1.running_mean, backbone.layer2.3.bn1.running_var, backbone.layer2.3.bn1.num_batches_tracked, backbone.layer2.3.conv2.weight, backbone.layer2.3.bn2.weight, backbone.layer2.3.bn2.bias, backbone.layer2.3.bn2.running_mean, backbone.layer2.3.bn2.running_var, backbone.layer2.3.bn2.num_batches_tracked, backbone.layer2.3.conv3.weight, backbone.layer2.3.bn3.weight, backbone.layer2.3.bn3.bias, backbone.layer2.3.bn3.running_mean, backbone.layer2.3.bn3.running_var, backbone.layer2.3.bn3.num_batches_tracked, backbone.layer3.0.conv1.weight, backbone.layer3.0.bn1.weight, backbone.layer3.0.bn1.bias, backbone.layer3.0.bn1.running_mean, backbone.layer3.0.bn1.running_var, backbone.layer3.0.bn1.num_batches_tracked, backbone.layer3.0.conv2.weight, backbone.layer3.0.bn2.weight, backbone.layer3.0.bn2.bias, backbone.layer3.0.bn2.running_mean, backbone.layer3.0.bn2.running_var, backbone.layer3.0.bn2.num_batches_tracked, backbone.layer3.0.conv3.weight, backbone.layer3.0.bn3.weight, backbone.layer3.0.bn3.bias, backbone.layer3.0.bn3.running_mean, backbone.layer3.0.bn3.running_var, backbone.layer3.0.bn3.num_batches_tracked, backbone.layer3.0.downsample.0.weight, backbone.layer3.0.downsample.1.weight, backbone.layer3.0.downsample.1.bias, backbone.layer3.0.downsample.1.running_mean, backbone.layer3.0.downsample.1.running_var, backbone.layer3.0.downsample.1.num_batches_tracked, backbone.layer3.1.conv1.weight, backbone.layer3.1.bn1.weight, backbone.layer3.1.bn1.bias, backbone.layer3.1.bn1.running_mean, backbone.layer3.1.bn1.running_var, backbone.layer3.1.bn1.num_batches_tracked, backbone.layer3.1.conv2.weight, backbone.layer3.1.bn2.weight, backbone.layer3.1.bn2.bias, backbone.layer3.1.bn2.running_mean, backbone.layer3.1.bn2.running_var, backbone.layer3.1.bn2.num_batches_tracked, backbone.layer3.1.conv3.weight, backbone.layer3.1.bn3.weight, backbone.layer3.1.bn3.bias, backbone.layer3.1.bn3.running_mean, backbone.layer3.1.bn3.running_var, backbone.layer3.1.bn3.num_batches_tracked, backbone.layer3.2.conv1.weight, backbone.layer3.2.bn1.weight, backbone.layer3.2.bn1.bias, backbone.layer3.2.bn1.running_mean, backbone.layer3.2.bn1.running_var, backbone.layer3.2.bn1.num_batches_tracked, backbone.layer3.2.conv2.weight, backbone.layer3.2.bn2.weight, backbone.layer3.2.bn2.bias, backbone.layer3.2.bn2.running_mean, backbone.layer3.2.bn2.running_var, backbone.layer3.2.bn2.num_batches_tracked, backbone.layer3.2.conv3.weight, backbone.layer3.2.bn3.weight, backbone.layer3.2.bn3.bias, backbone.layer3.2.bn3.running_mean, backbone.layer3.2.bn3.running_var, backbone.layer3.2.bn3.num_batches_tracked, backbone.layer3.3.conv1.weight, backbone.layer3.3.bn1.weight, backbone.layer3.3.bn1.bias, backbone.layer3.3.bn1.running_mean, backbone.layer3.3.bn1.running_var, backbone.layer3.3.bn1.num_batches_tracked, backbone.layer3.3.conv2.weight, backbone.layer3.3.bn2.weight, backbone.layer3.3.bn2.bias, backbone.layer3.3.bn2.running_mean, backbone.layer3.3.bn2.running_var, backbone.layer3.3.bn2.num_batches_tracked, backbone.layer3.3.conv3.weight, backbone.layer3.3.bn3.weight, backbone.layer3.3.bn3.bias, backbone.layer3.3.bn3.running_mean, backbone.layer3.3.bn3.running_var, backbone.layer3.3.bn3.num_batches_tracked, backbone.layer3.4.conv1.weight, backbone.layer3.4.bn1.weight, backbone.layer3.4.bn1.bias, backbone.layer3.4.bn1.running_mean, backbone.layer3.4.bn1.running_var, backbone.layer3.4.bn1.num_batches_tracked, backbone.layer3.4.conv2.weight, backbone.layer3.4.bn2.weight, backbone.layer3.4.bn2.bias, backbone.layer3.4.bn2.running_mean, backbone.layer3.4.bn2.running_var, backbone.layer3.4.bn2.num_batches_tracked, backbone.layer3.4.conv3.weight, backbone.layer3.4.bn3.weight, backbone.layer3.4.bn3.bias, backbone.layer3.4.bn3.running_mean, backbone.layer3.4.bn3.running_var, backbone.layer3.4.bn3.num_batches_tracked, backbone.layer3.5.conv1.weight, backbone.layer3.5.bn1.weight, backbone.layer3.5.bn1.bias, backbone.layer3.5.bn1.running_mean, backbone.layer3.5.bn1.running_var, backbone.layer3.5.bn1.num_batches_tracked, backbone.layer3.5.conv2.weight, backbone.layer3.5.bn2.weight, backbone.layer3.5.bn2.bias, backbone.layer3.5.bn2.running_mean, backbone.layer3.5.bn2.running_var, backbone.layer3.5.bn2.num_batches_tracked, backbone.layer3.5.conv3.weight, backbone.layer3.5.bn3.weight, backbone.layer3.5.bn3.bias, backbone.layer3.5.bn3.running_mean, backbone.layer3.5.bn3.running_var, backbone.layer3.5.bn3.num_batches_tracked, backbone.layer4.0.conv1.weight, backbone.layer4.0.bn1.weight, backbone.layer4.0.bn1.bias, backbone.layer4.0.bn1.running_mean, backbone.layer4.0.bn1.running_var, backbone.layer4.0.bn1.num_batches_tracked, backbone.layer4.0.conv2.weight, backbone.layer4.0.bn2.weight, backbone.layer4.0.bn2.bias, backbone.layer4.0.bn2.running_mean, backbone.layer4.0.bn2.running_var, backbone.layer4.0.bn2.num_batches_tracked, backbone.layer4.0.conv3.weight, backbone.layer4.0.bn3.weight, backbone.layer4.0.bn3.bias, backbone.layer4.0.bn3.running_mean, backbone.layer4.0.bn3.running_var, backbone.layer4.0.bn3.num_batches_tracked, backbone.layer4.0.downsample.0.weight, backbone.layer4.0.downsample.1.weight, backbone.layer4.0.downsample.1.bias, backbone.layer4.0.downsample.1.running_mean, backbone.layer4.0.downsample.1.running_var, backbone.layer4.0.downsample.1.num_batches_tracked, backbone.layer4.1.conv1.weight, backbone.layer4.1.bn1.weight, backbone.layer4.1.bn1.bias, backbone.layer4.1.bn1.running_mean, backbone.layer4.1.bn1.running_var, backbone.layer4.1.bn1.num_batches_tracked, backbone.layer4.1.conv2.weight, backbone.layer4.1.bn2.weight, backbone.layer4.1.bn2.bias, backbone.layer4.1.bn2.running_mean, backbone.layer4.1.bn2.running_var, backbone.layer4.1.bn2.num_batches_tracked, backbone.layer4.1.conv3.weight, backbone.layer4.1.bn3.weight, backbone.layer4.1.bn3.bias, backbone.layer4.1.bn3.running_mean, backbone.layer4.1.bn3.running_var, backbone.layer4.1.bn3.num_batches_tracked, backbone.layer4.2.conv1.weight, backbone.layer4.2.bn1.weight, backbone.layer4.2.bn1.bias, backbone.layer4.2.bn1.running_mean, backbone.layer4.2.bn1.running_var, backbone.layer4.2.bn1.num_batches_tracked, backbone.layer4.2.conv2.weight, backbone.layer4.2.bn2.weight, backbone.layer4.2.bn2.bias, backbone.layer4.2.bn2.running_mean, backbone.layer4.2.bn2.running_var, backbone.layer4.2.bn2.num_batches_tracked, backbone.layer4.2.conv3.weight, backbone.layer4.2.bn3.weight, backbone.layer4.2.bn3.bias, backbone.layer4.2.bn3.running_mean, backbone.layer4.2.bn3.running_var, backbone.layer4.2.bn3.num_batches_tracked, neck.lateral_convs.0.conv.weight, neck.lateral_convs.0.conv.bias, neck.lateral_convs.1.conv.weight, neck.lateral_convs.1.conv.bias, neck.lateral_convs.2.conv.weight, neck.lateral_convs.2.conv.bias, neck.lateral_convs.3.conv.weight, neck.lateral_convs.3.conv.bias, neck.fpn_convs.0.conv.weight, neck.fpn_convs.0.conv.bias, neck.fpn_convs.1.conv.weight, neck.fpn_convs.1.conv.bias, neck.fpn_convs.2.conv.weight, neck.fpn_convs.2.conv.bias, neck.fpn_convs.3.conv.weight, neck.fpn_convs.3.conv.bias, mask_feat_head.convs_all_levels.0.conv0.conv.weight, mask_feat_head.convs_all_levels.0.conv0.gn.weight, mask_feat_head.convs_all_levels.0.conv0.gn.bias, mask_feat_head.convs_all_levels.1.conv0.conv.weight, mask_feat_head.convs_all_levels.1.conv0.gn.weight, mask_feat_head.convs_all_levels.1.conv0.gn.bias, mask_feat_head.convs_all_levels.2.conv0.conv.weight, mask_feat_head.convs_all_levels.2.conv0.gn.weight, mask_feat_head.convs_all_levels.2.conv0.gn.bias, mask_feat_head.convs_all_levels.2.conv1.conv.weight, mask_feat_head.convs_all_levels.2.conv1.gn.weight, mask_feat_head.convs_all_levels.2.conv1.gn.bias, mask_feat_head.convs_all_levels.3.conv0.conv.weight, mask_feat_head.convs_all_levels.3.conv0.gn.weight, mask_feat_head.convs_all_levels.3.conv0.gn.bias, mask_feat_head.convs_all_levels.3.conv1.conv.weight, mask_feat_head.convs_all_levels.3.conv1.gn.weight, mask_feat_head.convs_all_levels.3.conv1.gn.bias, mask_feat_head.convs_all_levels.3.conv2.conv.weight, mask_feat_head.convs_all_levels.3.conv2.gn.weight, mask_feat_head.convs_all_levels.3.conv2.gn.bias, mask_feat_head.conv_pred.0.conv.weight, mask_feat_head.conv_pred.0.gn.weight, mask_feat_head.conv_pred.0.gn.bias, bbox_head.cate_convs.0.conv.weight, bbox_head.cate_convs.0.gn.weight, bbox_head.cate_convs.0.gn.bias, bbox_head.cate_convs.1.conv.weight, bbox_head.cate_convs.1.gn.weight, bbox_head.cate_convs.1.gn.bias, bbox_head.cate_convs.2.conv.weight, bbox_head.cate_convs.2.gn.weight, bbox_head.cate_convs.2.gn.bias, bbox_head.cate_convs.3.conv.weight, bbox_head.cate_convs.3.gn.weight, bbox_head.cate_convs.3.gn.bias, bbox_head.kernel_convs.0.conv.weight, bbox_head.kernel_convs.0.gn.weight, bbox_head.kernel_convs.0.gn.bias, bbox_head.kernel_convs.1.conv.weight, bbox_head.kernel_convs.1.gn.weight, bbox_head.kernel_convs.1.gn.bias, bbox_head.kernel_convs.2.conv.weight, bbox_head.kernel_convs.2.gn.weight, bbox_head.kernel_convs.2.gn.bias, bbox_head.kernel_convs.3.conv.weight, bbox_head.kernel_convs.3.gn.weight, bbox_head.kernel_convs.3.gn.bias, bbox_head.solo_cate.weight, bbox_head.solo_cate.bias, bbox_head.solo_kernel.weight, bbox_head.solo_kernel.bias

missing keys in source state_dict: conv1.weight, bn1.weight, bn1.bias, bn1.running_mean, bn1.running_var, layer1.0.conv1.weight, layer1.0.bn1.weight, layer1.0.bn1.bias, layer1.0.bn1.running_mean, layer1.0.bn1.running_var, layer1.0.conv2.weight, layer1.0.bn2.weight, layer1.0.bn2.bias, layer1.0.bn2.running_mean, layer1.0.bn2.running_var, layer1.0.conv3.weight, layer1.0.bn3.weight, layer1.0.bn3.bias, layer1.0.bn3.running_mean, layer1.0.bn3.running_var, layer1.0.downsample.0.weight, layer1.0.downsample.1.weight, layer1.0.downsample.1.bias, layer1.0.downsample.1.running_mean, layer1.0.downsample.1.running_var, layer1.1.conv1.weight, layer1.1.bn1.weight, layer1.1.bn1.bias, layer1.1.bn1.running_mean, layer1.1.bn1.running_var, layer1.1.conv2.weight, layer1.1.bn2.weight, layer1.1.bn2.bias, layer1.1.bn2.running_mean, layer1.1.bn2.running_var, layer1.1.conv3.weight, layer1.1.bn3.weight, layer1.1.bn3.bias, layer1.1.bn3.running_mean, layer1.1.bn3.running_var, layer1.2.conv1.weight, layer1.2.bn1.weight, layer1.2.bn1.bias, layer1.2.bn1.running_mean, layer1.2.bn1.running_var, layer1.2.conv2.weight, layer1.2.bn2.weight, layer1.2.bn2.bias, layer1.2.bn2.running_mean, layer1.2.bn2.running_var, layer1.2.conv3.weight, layer1.2.bn3.weight, layer1.2.bn3.bias, layer1.2.bn3.running_mean, layer1.2.bn3.running_var, layer2.0.conv1.weight, layer2.0.bn1.weight, layer2.0.bn1.bias, layer2.0.bn1.running_mean, layer2.0.bn1.running_var, layer2.0.conv2.weight, layer2.0.bn2.weight, layer2.0.bn2.bias, layer2.0.bn2.running_mean, layer2.0.bn2.running_var, layer2.0.conv3.weight, layer2.0.bn3.weight, layer2.0.bn3.bias, layer2.0.bn3.running_mean, layer2.0.bn3.running_var, layer2.0.downsample.0.weight, layer2.0.downsample.1.weight, layer2.0.downsample.1.bias, layer2.0.downsample.1.running_mean, layer2.0.downsample.1.running_var, layer2.1.conv1.weight, layer2.1.bn1.weight, layer2.1.bn1.bias, layer2.1.bn1.running_mean, layer2.1.bn1.running_var, layer2.1.conv2.weight, layer2.1.bn2.weight, layer2.1.bn2.bias, layer2.1.bn2.running_mean, layer2.1.bn2.running_var, layer2.1.conv3.weight, layer2.1.bn3.weight, layer2.1.bn3.bias, layer2.1.bn3.running_mean, layer2.1.bn3.running_var, layer2.2.conv1.weight, layer2.2.bn1.weight, layer2.2.bn1.bias, layer2.2.bn1.running_mean, layer2.2.bn1.running_var, layer2.2.conv2.weight, layer2.2.bn2.weight, layer2.2.bn2.bias, layer2.2.bn2.running_mean, layer2.2.bn2.running_var, layer2.2.conv3.weight, layer2.2.bn3.weight, layer2.2.bn3.bias, layer2.2.bn3.running_mean, layer2.2.bn3.running_var, layer2.3.conv1.weight, layer2.3.bn1.weight, layer2.3.bn1.bias, layer2.3.bn1.running_mean, layer2.3.bn1.running_var, layer2.3.conv2.weight, layer2.3.bn2.weight, layer2.3.bn2.bias, layer2.3.bn2.running_mean, layer2.3.bn2.running_var, layer2.3.conv3.weight, layer2.3.bn3.weight, layer2.3.bn3.bias, layer2.3.bn3.running_mean, layer2.3.bn3.running_var, layer3.0.conv1.weight, layer3.0.bn1.weight, layer3.0.bn1.bias, layer3.0.bn1.running_mean, layer3.0.bn1.running_var, layer3.0.conv2.weight, layer3.0.bn2.weight, layer3.0.bn2.bias, layer3.0.bn2.running_mean, layer3.0.bn2.running_var, layer3.0.conv3.weight, layer3.0.bn3.weight, layer3.0.bn3.bias, layer3.0.bn3.running_mean, layer3.0.bn3.running_var, layer3.0.downsample.0.weight, layer3.0.downsample.1.weight, layer3.0.downsample.1.bias, layer3.0.downsample.1.running_mean, layer3.0.downsample.1.running_var, layer3.1.conv1.weight, layer3.1.bn1.weight, layer3.1.bn1.bias, layer3.1.bn1.running_mean, layer3.1.bn1.running_var, layer3.1.conv2.weight, layer3.1.bn2.weight, layer3.1.bn2.bias, layer3.1.bn2.running_mean, layer3.1.bn2.running_var, layer3.1.conv3.weight, layer3.1.bn3.weight, layer3.1.bn3.bias, layer3.1.bn3.running_mean, layer3.1.bn3.running_var, layer3.2.conv1.weight, layer3.2.bn1.weight, layer3.2.bn1.bias, layer3.2.bn1.running_mean, layer3.2.bn1.running_var, layer3.2.conv2.weight, layer3.2.bn2.weight, layer3.2.bn2.bias, layer3.2.bn2.running_mean, layer3.2.bn2.running_var, layer3.2.conv3.weight, layer3.2.bn3.weight, layer3.2.bn3.bias, layer3.2.bn3.running_mean, layer3.2.bn3.running_var, layer3.3.conv1.weight, layer3.3.bn1.weight, layer3.3.bn1.bias, layer3.3.bn1.running_mean, layer3.3.bn1.running_var, layer3.3.conv2.weight, layer3.3.bn2.weight, layer3.3.bn2.bias, layer3.3.bn2.running_mean, layer3.3.bn2.running_var, layer3.3.conv3.weight, layer3.3.bn3.weight, layer3.3.bn3.bias, layer3.3.bn3.running_mean, layer3.3.bn3.running_var, layer3.4.conv1.weight, layer3.4.bn1.weight, layer3.4.bn1.bias, layer3.4.bn1.running_mean, layer3.4.bn1.running_var, layer3.4.conv2.weight, layer3.4.bn2.weight, layer3.4.bn2.bias, layer3.4.bn2.running_mean, layer3.4.bn2.running_var, layer3.4.conv3.weight, layer3.4.bn3.weight, layer3.4.bn3.bias, layer3.4.bn3.running_mean, layer3.4.bn3.running_var, layer3.5.conv1.weight, layer3.5.bn1.weight, layer3.5.bn1.bias, layer3.5.bn1.running_mean, layer3.5.bn1.running_var, layer3.5.conv2.weight, layer3.5.bn2.weight, layer3.5.bn2.bias, layer3.5.bn2.running_mean, layer3.5.bn2.running_var, layer3.5.conv3.weight, layer3.5.bn3.weight, layer3.5.bn3.bias, layer3.5.bn3.running_mean, layer3.5.bn3.running_var, layer4.0.conv1.weight, layer4.0.bn1.weight, layer4.0.bn1.bias, layer4.0.bn1.running_mean, layer4.0.bn1.running_var, layer4.0.conv2.weight, layer4.0.bn2.weight, layer4.0.bn2.bias, layer4.0.bn2.running_mean, layer4.0.bn2.running_var, layer4.0.conv3.weight, layer4.0.bn3.weight, layer4.0.bn3.bias, layer4.0.bn3.running_mean, layer4.0.bn3.running_var, layer4.0.downsample.0.weight, layer4.0.downsample.1.weight, layer4.0.downsample.1.bias, layer4.0.downsample.1.running_mean, layer4.0.downsample.1.running_var, layer4.1.conv1.weight, layer4.1.bn1.weight, layer4.1.bn1.bias, layer4.1.bn1.running_mean, layer4.1.bn1.running_var, layer4.1.conv2.weight, layer4.1.bn2.weight, layer4.1.bn2.bias, layer4.1.bn2.running_mean, layer4.1.bn2.running_var, layer4.1.conv3.weight, layer4.1.bn3.weight, layer4.1.bn3.bias, layer4.1.bn3.running_mean, layer4.1.bn3.running_var, layer4.2.conv1.weight, layer4.2.bn1.weight, layer4.2.bn1.bias, layer4.2.bn1.running_mean, layer4.2.bn1.running_var, layer4.2.conv2.weight, layer4.2.bn2.weight, layer4.2.bn2.bias, layer4.2.bn2.running_mean, layer4.2.bn2.running_var, layer4.2.conv3.weight, layer4.2.bn3.weight, layer4.2.bn3.bias, layer4.2.bn3.running_mean, layer4.2.bn3.running_var

2021-07-21 06:57:00,445 - mmdet - INFO - Start running, host: root@efe7fbebbac3, work_dir: /home/zq/work/SOLO/work_dirs/solov2_release_r50_fpn_8gpu_3x_scale
2021-07-21 06:57:00,446 - mmdet - INFO - workflow: [('train', 1)], max: 36 epochs
loading annotations into memory...
Done (t=0.02s)
creating index...
index created!
{'type': 'CocoDataset', 'ann_file': 'data/annotation/merge/merge_train_coco.json', 'img_prefix': 'data/road/train/', 'pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'LoadAnnotations', 'with_bbox': True, 'with_mask': True}, {'type': 'Resize', 'img_scale': [(1333, 800), (1333, 768), (1333, 736), (1333, 704), (1333, 672), (1333, 640)], 'multiscale_mode': 'value', 'keep_ratio': True}, {'type': 'RandomFlip', 'flip_ratio': 0.5}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'DefaultFormatBundle'}, {'type': 'Collect', 'keys': ['img', 'gt_bboxes', 'gt_labels', 'gt_masks']}]}
/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:2494: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
2021-07-21 06:57:15,564 - mmdet - INFO - Epoch [1][50/673]	lr: 0.00107, eta: 2:01:49, time: 0.302, data_time: 0.019, memory: 4413, loss_ins: 1.0080, loss_cate: 0.7716, loss: 1.7797
2021-07-21 06:57:30,343 - mmdet - INFO - Epoch [1][100/673]	lr: 0.00206, eta: 2:00:12, time: 0.296, data_time: 0.014, memory: 4413, loss_ins: 0.9417, loss_cate: 0.6939, loss: 1.6356
2021-07-21 06:57:45,134 - mmdet - INFO - Epoch [1][150/673]	lr: 0.00305, eta: 1:59:32, time: 0.296, data_time: 0.013, memory: 4415, loss_ins: 0.7403, loss_cate: 0.6951, loss: 1.4354
2021-07-21 06:57:59,765 - mmdet - INFO - Epoch [1][200/673]	lr: 0.00404, eta: 1:58:46, time: 0.293, data_time: 0.013, memory: 4415, loss_ins: 0.7736, loss_cate: 0.6433, loss: 1.4170
2021-07-21 06:58:14,550 - mmdet - INFO - Epoch [1][250/673]	lr: 0.00503, eta: 1:58:27, time: 0.296, data_time: 0.013, memory: 4415, loss_ins: 0.8445, loss_cate: 0.9482, loss: 1.7927
2021-07-21 06:58:29,400 - mmdet - INFO - Epoch [1][300/673]	lr: 0.00602, eta: 1:58:14, time: 0.297, data_time: 0.012, memory: 4415, loss_ins: 0.8046, loss_cate: 0.6215, loss: 1.4262
2021-07-21 06:58:44,150 - mmdet - INFO - Epoch [1][350/673]	lr: 0.00701, eta: 1:57:54, time: 0.295, data_time: 0.012, memory: 4415, loss_ins: 0.7121, loss_cate: 0.9433, loss: 1.6553
2021-07-21 06:58:58,873 - mmdet - INFO - Epoch [1][400/673]	lr: 0.00800, eta: 1:57:34, time: 0.294, data_time: 0.012, memory: 4415, loss_ins: 0.6069, loss_cate: 0.5919, loss: 1.1989
2021-07-21 06:59:13,458 - mmdet - INFO - Epoch [1][450/673]	lr: 0.00899, eta: 1:57:08, time: 0.292, data_time: 0.012, memory: 4415, loss_ins: 0.5058, loss_cate: 0.5232, loss: 1.0290
2021-07-21 06:59:28,329 - mmdet - INFO - Epoch [1][500/673]	lr: 0.00998, eta: 1:56:57, time: 0.297, data_time: 0.012, memory: 4415, loss_ins: 0.6633, loss_cate: 0.5230, loss: 1.1862
2021-07-21 06:59:43,361 - mmdet - INFO - Epoch [1][550/673]	lr: 0.01000, eta: 1:56:53, time: 0.301, data_time: 0.013, memory: 4415, loss_ins: 0.6573, loss_cate: 0.5682, loss: 1.2255
2021-07-21 06:59:58,355 - mmdet - INFO - Epoch [1][600/673]	lr: 0.01000, eta: 1:56:45, time: 0.300, data_time: 0.012, memory: 4415, loss_ins: 0.4284, loss_cate: 0.5288, loss: 0.9572
2021-07-21 07:00:13,206 - mmdet - INFO - Epoch [1][650/673]	lr: 0.01000, eta: 1:56:31, time: 0.297, data_time: 0.012, memory: 4415, loss_ins: 0.5878, loss_cate: 0.4903, loss: 1.0781
2021-07-21 07:00:35,745 - mmdet - INFO - Epoch [2][50/673]	lr: 0.01000, eta: 1:52:45, time: 0.307, data_time: 0.019, memory: 4415, loss_ins: 0.7268, loss_cate: 0.7320, loss: 1.4588
2021-07-21 07:00:51,000 - mmdet - INFO - Epoch [2][100/673]	lr: 0.01000, eta: 1:52:57, time: 0.305, data_time: 0.013, memory: 4415, loss_ins: 0.8709, loss_cate: 5.1532, loss: 6.0241
2021-07-21 07:01:06,034 - mmdet - INFO - Epoch [2][150/673]	lr: 0.01000, eta: 1:52:59, time: 0.301, data_time: 0.012, memory: 4415, loss_ins: 0.7148, loss_cate: 0.6890, loss: 1.4038
2021-07-21 07:01:21,218 - mmdet - INFO - Epoch [2][200/673]	lr: 0.01000, eta: 1:53:03, time: 0.304, data_time: 0.014, memory: 4415, loss_ins: 0.7646, loss_cate: 0.5298, loss: 1.2944
2021-07-21 07:01:36,514 - mmdet - INFO - Epoch [2][250/673]	lr: 0.01000, eta: 1:53:08, time: 0.306, data_time: 0.014, memory: 4415, loss_ins: 0.5460, loss_cate: 0.5171, loss: 1.0631
2021-07-21 07:01:51,727 - mmdet - INFO - Epoch [2][300/673]	lr: 0.01000, eta: 1:53:09, time: 0.304, data_time: 0.014, memory: 4415, loss_ins: 0.6022, loss_cate: 0.4850, loss: 1.0871
2021-07-21 07:02:06,462 - mmdet - INFO - Epoch [2][350/673]	lr: 0.01000, eta: 1:52:57, time: 0.295, data_time: 0.013, memory: 4415, loss_ins: 0.4591, loss_cate: 0.4685, loss: 0.9276
2021-07-21 07:02:21,555 - mmdet - INFO - Epoch [2][400/673]	lr: 0.01000, eta: 1:52:53, time: 0.302, data_time: 0.014, memory: 4415, loss_ins: 0.6242, loss_cate: 0.4564, loss: 1.0805
2021-07-21 07:02:36,657 - mmdet - INFO - Epoch [2][450/673]	lr: 0.01000, eta: 1:52:49, time: 0.302, data_time: 0.013, memory: 4415, loss_ins: 0.6618, loss_cate: 0.4538, loss: 1.1156
2021-07-21 07:02:51,731 - mmdet - INFO - Epoch [2][500/673]	lr: 0.01000, eta: 1:52:42, time: 0.301, data_time: 0.013, memory: 4415, loss_ins: 0.6602, loss_cate: 0.4755, loss: 1.1357
2021-07-21 07:03:06,848 - mmdet - INFO - Epoch [2][550/673]	lr: 0.01000, eta: 1:52:36, time: 0.302, data_time: 0.013, memory: 4415, loss_ins: 0.5637, loss_cate: 0.4273, loss: 0.9909
2021-07-21 07:03:21,558 - mmdet - INFO - Epoch [2][600/673]	lr: 0.01000, eta: 1:52:22, time: 0.294, data_time: 0.012, memory: 4415, loss_ins: 0.4840, loss_cate: 0.4245, loss: 0.9084
2021-07-21 07:03:36,620 - mmdet - INFO - Epoch [2][650/673]	lr: 0.01000, eta: 1:52:14, time: 0.301, data_time: 0.013, memory: 4415, loss_ins: 0.5045, loss_cate: 0.4411, loss: 0.9456
2021-07-21 07:03:59,310 - mmdet - INFO - Epoch [3][50/673]	lr: 0.01000, eta: 1:50:11, time: 0.306, data_time: 0.018, memory: 4415, loss_ins: 0.4635, loss_cate: 0.4270, loss: 0.8905
2021-07-21 07:04:14,440 - mmdet - INFO - Epoch [3][100/673]	lr: 0.01000, eta: 1:50:07, time: 0.303, data_time: 0.014, memory: 4415, loss_ins: 0.5885, loss_cate: 0.4192, loss: 1.0076
2021-07-21 07:04:29,523 - mmdet - INFO - Epoch [3][150/673]	lr: 0.01000, eta: 1:50:01, time: 0.302, data_time: 0.013, memory: 4415, loss_ins: 0.6236, loss_cate: 0.4203, loss: 1.0439
2021-07-21 07:04:44,500 - mmdet - INFO - Epoch [3][200/673]	lr: 0.01000, eta: 1:49:53, time: 0.300, data_time: 0.013, memory: 4415, loss_ins: 0.4881, loss_cate: 0.4015, loss: 0.8896
2021-07-21 07:04:59,610 - mmdet - INFO - Epoch [3][250/673]	lr: 0.01000, eta: 1:49:47, time: 0.302, data_time: 0.014, memory: 4415, loss_ins: 0.6357, loss_cate: 0.4184, loss: 1.0542
2021-07-21 07:05:14,664 - mmdet - INFO - Epoch [3][300/673]	lr: 0.01000, eta: 1:49:39, time: 0.301, data_time: 0.014, memory: 4415, loss_ins: 0.6015, loss_cate: 0.4140, loss: 1.0156
2021-07-21 07:05:29,917 - mmdet - INFO - Epoch [3][350/673]	lr: 0.01000, eta: 1:49:34, time: 0.305, data_time: 0.012, memory: 4415, loss_ins: 0.5964, loss_cate: 0.3922, loss: 0.9886
2021-07-21 07:05:45,134 - mmdet - INFO - Epoch [3][400/673]	lr: 0.01000, eta: 1:49:27, time: 0.304, data_time: 0.014, memory: 4415, loss_ins: 0.5918, loss_cate: 0.4328, loss: 1.0246
2021-07-21 07:05:59,780 - mmdet - INFO - Epoch [3][450/673]	lr: 0.01000, eta: 1:49:13, time: 0.293, data_time: 0.012, memory: 4415, loss_ins: 0.5424, loss_cate: 0.4111, loss: 0.9535
2021-07-21 07:06:14,984 - mmdet - INFO - Epoch [3][500/673]	lr: 0.01000, eta: 1:49:06, time: 0.304, data_time: 0.013, memory: 4415, loss_ins: 0.6398, loss_cate: 0.3859, loss: 1.0257
2021-07-21 07:06:30,017 - mmdet - INFO - Epoch [3][550/673]	lr: 0.01000, eta: 1:48:56, time: 0.301, data_time: 0.013, memory: 4415, loss_ins: 0.6017, loss_cate: 0.4236, loss: 1.0253
2021-07-21 07:06:44,684 - mmdet - INFO - Epoch [3][600/673]	lr: 0.01000, eta: 1:48:42, time: 0.293, data_time: 0.012, memory: 4415, loss_ins: 0.4723, loss_cate: 0.4256, loss: 0.8979
2021-07-21 07:06:59,709 - mmdet - INFO - Epoch [3][650/673]	lr: 0.01000, eta: 1:48:31, time: 0.301, data_time: 0.012, memory: 4415, loss_ins: 0.5962, loss_cate: 0.3917, loss: 0.9880
2021-07-21 07:07:22,679 - mmdet - INFO - Epoch [4][50/673]	lr: 0.01000, eta: 1:47:07, time: 0.309, data_time: 0.019, memory: 4415, loss_ins: 0.6101, loss_cate: 0.3771, loss: 0.9871
2021-07-21 07:07:37,960 - mmdet - INFO - Epoch [4][100/673]	lr: 0.01000, eta: 1:47:00, time: 0.306, data_time: 0.014, memory: 4415, loss_ins: 0.6228, loss_cate: 0.3676, loss: 0.9904
2021-07-21 07:07:53,089 - mmdet - INFO - Epoch [4][150/673]	lr: 0.01000, eta: 1:46:52, time: 0.303, data_time: 0.013, memory: 4415, loss_ins: 0.5988, loss_cate: 0.3958, loss: 0.9946
2021-07-21 07:08:08,017 - mmdet - INFO - Epoch [4][200/673]	lr: 0.01000, eta: 1:46:41, time: 0.299, data_time: 0.012, memory: 4415, loss_ins: 0.4405, loss_cate: 0.4215, loss: 0.8620
2021-07-21 07:08:23,255 - mmdet - INFO - Epoch [4][250/673]	lr: 0.01000, eta: 1:46:34, time: 0.305, data_time: 0.014, memory: 4415, loss_ins: 0.5176, loss_cate: 0.3612, loss: 0.8788
2021-07-21 07:08:26,868 - mmdet - INFO - Distributed training: False
2021-07-21 07:08:26,868 - mmdet - INFO - MMDetection Version: 1.0.0+c7b294a
2021-07-21 07:08:26,868 - mmdet - INFO - Config:
# model settings
model = dict(
    type='SOLOv2',
    pretrained='torchvision://resnet50',
    backbone=dict(
        type='ResNet',
        depth=50,
        num_stages=4,
        out_indices=(0, 1, 2, 3),  # C2, C3, C4, C5
        frozen_stages=1,
        style='pytorch'),
    neck=dict(
        type='FPN',
        in_channels=[256, 512, 1024, 2048],
        out_channels=256,
        start_level=0,
        num_outs=5),
    bbox_head=dict(
        type='SOLOv2Head',
        num_classes=2,
        in_channels=256,
        stacked_convs=4,
        seg_feat_channels=512,
        strides=[8, 8, 16, 32, 32],
        scale_ranges=((1, 96), (48, 192), (96, 384), (192, 768), (384, 2048)),
        # scale_ranges=((1, 376), (188, 752), (752, 1400)),
        sigma=0.2,
        num_grids=[40, 36, 24, 16, 12],
        ins_out_channels=256,
        loss_ins=dict(
            type='DiceLoss',
            use_sigmoid=True,
            # loss_weight=3.0),
            loss_weight=10.0),
        loss_cate=dict(
            type='FocalLoss',
            use_sigmoid=True,
            gamma=2.0,
            alpha=0.25,
            loss_weight=1.0)),
    mask_feat_head=dict(
        type='MaskFeatHead',
        in_channels=256,
        out_channels=128,
        start_level=0,
        end_level=3,
        num_classes=256,
        norm_cfg=dict(type='GN', num_groups=32, requires_grad=True)),
)
# training and testing settings
train_cfg = dict()
test_cfg = dict(
    nms_pre=500,
    score_thr=0.1,
    mask_thr=0.5,
    update_thr=0.05,
    kernel='gaussian',  # gaussian/linear
    sigma=2.0,
    max_per_img=100)
# dataset settings
dataset_type = 'CocoDataset'
data_root = 'data/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),
    dict(type='Resize',
         img_scale=[(1333, 800), (1333, 768), (1333, 736),
                    (1333, 704), (1333, 672), (1333, 640)],
         multiscale_mode='value',
         keep_ratio=True),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(type='Normalize', **img_norm_cfg),
    dict(type='Pad', size_divisor=32),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks']),
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(1333, 800),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(type='Normalize', **img_norm_cfg),
            dict(type='Pad', size_divisor=32),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img']),
        ])
]
data = dict(
    imgs_per_gpu=2,
    workers_per_gpu=2,
    train=dict(
        type=dataset_type,
        ann_file=data_root + 'annotation/merge/merge_train_coco.json',
        img_prefix=data_root + 'road/train/',
        pipeline=train_pipeline),
    val=dict(
        type=dataset_type,
        ann_file=data_root + 'annotation/merge/merge_val_coco.json',
        img_prefix=data_root + 'road/val/',
        pipeline=test_pipeline),
    test=dict(
        type=dataset_type,
        ann_file=data_root + 'annotation/merge/merge_val_coco.json',
        img_prefix=data_root + 'road/val/',
        pipeline=test_pipeline))
# optimizer
optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0001)
optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))
# learning policy
lr_config = dict(
    policy='step',
    warmup='linear',
    warmup_iters=500,
    warmup_ratio=0.01,
    step=[27, 33])
checkpoint_config = dict(interval=1)
# yapf:disable
log_config = dict(
    interval=50,
    hooks=[
        dict(type='TextLoggerHook'),
        # dict(type='TensorboardLoggerHook')
    ])
# yapf:enable
# runtime settings
total_epochs = 36
device_ids = range(8)
dist_params = dict(backend='nccl')
log_level = 'INFO'
# work_dir = './work_dirs/solov2_release_r50_fpn_8gpu_3x'
# work_dir = './work_dirs/solov2_release_r50_fpn_8gpu_3x_scale'
work_dir = './work_dirs/solov2_release_r50_fpn_8gpu_3x_weight'
load_from = None
resume_from = None
workflow = [('train', 1)]
# workflow = [('train', 1), ('val', 1)]

2021-07-21 07:08:27,263 - mmdet - INFO - load model from: torchvision://resnet50
2021-07-21 07:08:30,489 - mmdet - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: backbone.conv1.weight, backbone.bn1.weight, backbone.bn1.bias, backbone.bn1.running_mean, backbone.bn1.running_var, backbone.bn1.num_batches_tracked, backbone.layer1.0.conv1.weight, backbone.layer1.0.bn1.weight, backbone.layer1.0.bn1.bias, backbone.layer1.0.bn1.running_mean, backbone.layer1.0.bn1.running_var, backbone.layer1.0.bn1.num_batches_tracked, backbone.layer1.0.conv2.weight, backbone.layer1.0.bn2.weight, backbone.layer1.0.bn2.bias, backbone.layer1.0.bn2.running_mean, backbone.layer1.0.bn2.running_var, backbone.layer1.0.bn2.num_batches_tracked, backbone.layer1.0.conv3.weight, backbone.layer1.0.bn3.weight, backbone.layer1.0.bn3.bias, backbone.layer1.0.bn3.running_mean, backbone.layer1.0.bn3.running_var, backbone.layer1.0.bn3.num_batches_tracked, backbone.layer1.0.downsample.0.weight, backbone.layer1.0.downsample.1.weight, backbone.layer1.0.downsample.1.bias, backbone.layer1.0.downsample.1.running_mean, backbone.layer1.0.downsample.1.running_var, backbone.layer1.0.downsample.1.num_batches_tracked, backbone.layer1.1.conv1.weight, backbone.layer1.1.bn1.weight, backbone.layer1.1.bn1.bias, backbone.layer1.1.bn1.running_mean, backbone.layer1.1.bn1.running_var, backbone.layer1.1.bn1.num_batches_tracked, backbone.layer1.1.conv2.weight, backbone.layer1.1.bn2.weight, backbone.layer1.1.bn2.bias, backbone.layer1.1.bn2.running_mean, backbone.layer1.1.bn2.running_var, backbone.layer1.1.bn2.num_batches_tracked, backbone.layer1.1.conv3.weight, backbone.layer1.1.bn3.weight, backbone.layer1.1.bn3.bias, backbone.layer1.1.bn3.running_mean, backbone.layer1.1.bn3.running_var, backbone.layer1.1.bn3.num_batches_tracked, backbone.layer1.2.conv1.weight, backbone.layer1.2.bn1.weight, backbone.layer1.2.bn1.bias, backbone.layer1.2.bn1.running_mean, backbone.layer1.2.bn1.running_var, backbone.layer1.2.bn1.num_batches_tracked, backbone.layer1.2.conv2.weight, backbone.layer1.2.bn2.weight, backbone.layer1.2.bn2.bias, backbone.layer1.2.bn2.running_mean, backbone.layer1.2.bn2.running_var, backbone.layer1.2.bn2.num_batches_tracked, backbone.layer1.2.conv3.weight, backbone.layer1.2.bn3.weight, backbone.layer1.2.bn3.bias, backbone.layer1.2.bn3.running_mean, backbone.layer1.2.bn3.running_var, backbone.layer1.2.bn3.num_batches_tracked, backbone.layer2.0.conv1.weight, backbone.layer2.0.bn1.weight, backbone.layer2.0.bn1.bias, backbone.layer2.0.bn1.running_mean, backbone.layer2.0.bn1.running_var, backbone.layer2.0.bn1.num_batches_tracked, backbone.layer2.0.conv2.weight, backbone.layer2.0.bn2.weight, backbone.layer2.0.bn2.bias, backbone.layer2.0.bn2.running_mean, backbone.layer2.0.bn2.running_var, backbone.layer2.0.bn2.num_batches_tracked, backbone.layer2.0.conv3.weight, backbone.layer2.0.bn3.weight, backbone.layer2.0.bn3.bias, backbone.layer2.0.bn3.running_mean, backbone.layer2.0.bn3.running_var, backbone.layer2.0.bn3.num_batches_tracked, backbone.layer2.0.downsample.0.weight, backbone.layer2.0.downsample.1.weight, backbone.layer2.0.downsample.1.bias, backbone.layer2.0.downsample.1.running_mean, backbone.layer2.0.downsample.1.running_var, backbone.layer2.0.downsample.1.num_batches_tracked, backbone.layer2.1.conv1.weight, backbone.layer2.1.bn1.weight, backbone.layer2.1.bn1.bias, backbone.layer2.1.bn1.running_mean, backbone.layer2.1.bn1.running_var, backbone.layer2.1.bn1.num_batches_tracked, backbone.layer2.1.conv2.weight, backbone.layer2.1.bn2.weight, backbone.layer2.1.bn2.bias, backbone.layer2.1.bn2.running_mean, backbone.layer2.1.bn2.running_var, backbone.layer2.1.bn2.num_batches_tracked, backbone.layer2.1.conv3.weight, backbone.layer2.1.bn3.weight, backbone.layer2.1.bn3.bias, backbone.layer2.1.bn3.running_mean, backbone.layer2.1.bn3.running_var, backbone.layer2.1.bn3.num_batches_tracked, backbone.layer2.2.conv1.weight, backbone.layer2.2.bn1.weight, backbone.layer2.2.bn1.bias, backbone.layer2.2.bn1.running_mean, backbone.layer2.2.bn1.running_var, backbone.layer2.2.bn1.num_batches_tracked, backbone.layer2.2.conv2.weight, backbone.layer2.2.bn2.weight, backbone.layer2.2.bn2.bias, backbone.layer2.2.bn2.running_mean, backbone.layer2.2.bn2.running_var, backbone.layer2.2.bn2.num_batches_tracked, backbone.layer2.2.conv3.weight, backbone.layer2.2.bn3.weight, backbone.layer2.2.bn3.bias, backbone.layer2.2.bn3.running_mean, backbone.layer2.2.bn3.running_var, backbone.layer2.2.bn3.num_batches_tracked, backbone.layer2.3.conv1.weight, backbone.layer2.3.bn1.weight, backbone.layer2.3.bn1.bias, backbone.layer2.3.bn1.running_mean, backbone.layer2.3.bn1.running_var, backbone.layer2.3.bn1.num_batches_tracked, backbone.layer2.3.conv2.weight, backbone.layer2.3.bn2.weight, backbone.layer2.3.bn2.bias, backbone.layer2.3.bn2.running_mean, backbone.layer2.3.bn2.running_var, backbone.layer2.3.bn2.num_batches_tracked, backbone.layer2.3.conv3.weight, backbone.layer2.3.bn3.weight, backbone.layer2.3.bn3.bias, backbone.layer2.3.bn3.running_mean, backbone.layer2.3.bn3.running_var, backbone.layer2.3.bn3.num_batches_tracked, backbone.layer3.0.conv1.weight, backbone.layer3.0.bn1.weight, backbone.layer3.0.bn1.bias, backbone.layer3.0.bn1.running_mean, backbone.layer3.0.bn1.running_var, backbone.layer3.0.bn1.num_batches_tracked, backbone.layer3.0.conv2.weight, backbone.layer3.0.bn2.weight, backbone.layer3.0.bn2.bias, backbone.layer3.0.bn2.running_mean, backbone.layer3.0.bn2.running_var, backbone.layer3.0.bn2.num_batches_tracked, backbone.layer3.0.conv3.weight, backbone.layer3.0.bn3.weight, backbone.layer3.0.bn3.bias, backbone.layer3.0.bn3.running_mean, backbone.layer3.0.bn3.running_var, backbone.layer3.0.bn3.num_batches_tracked, backbone.layer3.0.downsample.0.weight, backbone.layer3.0.downsample.1.weight, backbone.layer3.0.downsample.1.bias, backbone.layer3.0.downsample.1.running_mean, backbone.layer3.0.downsample.1.running_var, backbone.layer3.0.downsample.1.num_batches_tracked, backbone.layer3.1.conv1.weight, backbone.layer3.1.bn1.weight, backbone.layer3.1.bn1.bias, backbone.layer3.1.bn1.running_mean, backbone.layer3.1.bn1.running_var, backbone.layer3.1.bn1.num_batches_tracked, backbone.layer3.1.conv2.weight, backbone.layer3.1.bn2.weight, backbone.layer3.1.bn2.bias, backbone.layer3.1.bn2.running_mean, backbone.layer3.1.bn2.running_var, backbone.layer3.1.bn2.num_batches_tracked, backbone.layer3.1.conv3.weight, backbone.layer3.1.bn3.weight, backbone.layer3.1.bn3.bias, backbone.layer3.1.bn3.running_mean, backbone.layer3.1.bn3.running_var, backbone.layer3.1.bn3.num_batches_tracked, backbone.layer3.2.conv1.weight, backbone.layer3.2.bn1.weight, backbone.layer3.2.bn1.bias, backbone.layer3.2.bn1.running_mean, backbone.layer3.2.bn1.running_var, backbone.layer3.2.bn1.num_batches_tracked, backbone.layer3.2.conv2.weight, backbone.layer3.2.bn2.weight, backbone.layer3.2.bn2.bias, backbone.layer3.2.bn2.running_mean, backbone.layer3.2.bn2.running_var, backbone.layer3.2.bn2.num_batches_tracked, backbone.layer3.2.conv3.weight, backbone.layer3.2.bn3.weight, backbone.layer3.2.bn3.bias, backbone.layer3.2.bn3.running_mean, backbone.layer3.2.bn3.running_var, backbone.layer3.2.bn3.num_batches_tracked, backbone.layer3.3.conv1.weight, backbone.layer3.3.bn1.weight, backbone.layer3.3.bn1.bias, backbone.layer3.3.bn1.running_mean, backbone.layer3.3.bn1.running_var, backbone.layer3.3.bn1.num_batches_tracked, backbone.layer3.3.conv2.weight, backbone.layer3.3.bn2.weight, backbone.layer3.3.bn2.bias, backbone.layer3.3.bn2.running_mean, backbone.layer3.3.bn2.running_var, backbone.layer3.3.bn2.num_batches_tracked, backbone.layer3.3.conv3.weight, backbone.layer3.3.bn3.weight, backbone.layer3.3.bn3.bias, backbone.layer3.3.bn3.running_mean, backbone.layer3.3.bn3.running_var, backbone.layer3.3.bn3.num_batches_tracked, backbone.layer3.4.conv1.weight, backbone.layer3.4.bn1.weight, backbone.layer3.4.bn1.bias, backbone.layer3.4.bn1.running_mean, backbone.layer3.4.bn1.running_var, backbone.layer3.4.bn1.num_batches_tracked, backbone.layer3.4.conv2.weight, backbone.layer3.4.bn2.weight, backbone.layer3.4.bn2.bias, backbone.layer3.4.bn2.running_mean, backbone.layer3.4.bn2.running_var, backbone.layer3.4.bn2.num_batches_tracked, backbone.layer3.4.conv3.weight, backbone.layer3.4.bn3.weight, backbone.layer3.4.bn3.bias, backbone.layer3.4.bn3.running_mean, backbone.layer3.4.bn3.running_var, backbone.layer3.4.bn3.num_batches_tracked, backbone.layer3.5.conv1.weight, backbone.layer3.5.bn1.weight, backbone.layer3.5.bn1.bias, backbone.layer3.5.bn1.running_mean, backbone.layer3.5.bn1.running_var, backbone.layer3.5.bn1.num_batches_tracked, backbone.layer3.5.conv2.weight, backbone.layer3.5.bn2.weight, backbone.layer3.5.bn2.bias, backbone.layer3.5.bn2.running_mean, backbone.layer3.5.bn2.running_var, backbone.layer3.5.bn2.num_batches_tracked, backbone.layer3.5.conv3.weight, backbone.layer3.5.bn3.weight, backbone.layer3.5.bn3.bias, backbone.layer3.5.bn3.running_mean, backbone.layer3.5.bn3.running_var, backbone.layer3.5.bn3.num_batches_tracked, backbone.layer4.0.conv1.weight, backbone.layer4.0.bn1.weight, backbone.layer4.0.bn1.bias, backbone.layer4.0.bn1.running_mean, backbone.layer4.0.bn1.running_var, backbone.layer4.0.bn1.num_batches_tracked, backbone.layer4.0.conv2.weight, backbone.layer4.0.bn2.weight, backbone.layer4.0.bn2.bias, backbone.layer4.0.bn2.running_mean, backbone.layer4.0.bn2.running_var, backbone.layer4.0.bn2.num_batches_tracked, backbone.layer4.0.conv3.weight, backbone.layer4.0.bn3.weight, backbone.layer4.0.bn3.bias, backbone.layer4.0.bn3.running_mean, backbone.layer4.0.bn3.running_var, backbone.layer4.0.bn3.num_batches_tracked, backbone.layer4.0.downsample.0.weight, backbone.layer4.0.downsample.1.weight, backbone.layer4.0.downsample.1.bias, backbone.layer4.0.downsample.1.running_mean, backbone.layer4.0.downsample.1.running_var, backbone.layer4.0.downsample.1.num_batches_tracked, backbone.layer4.1.conv1.weight, backbone.layer4.1.bn1.weight, backbone.layer4.1.bn1.bias, backbone.layer4.1.bn1.running_mean, backbone.layer4.1.bn1.running_var, backbone.layer4.1.bn1.num_batches_tracked, backbone.layer4.1.conv2.weight, backbone.layer4.1.bn2.weight, backbone.layer4.1.bn2.bias, backbone.layer4.1.bn2.running_mean, backbone.layer4.1.bn2.running_var, backbone.layer4.1.bn2.num_batches_tracked, backbone.layer4.1.conv3.weight, backbone.layer4.1.bn3.weight, backbone.layer4.1.bn3.bias, backbone.layer4.1.bn3.running_mean, backbone.layer4.1.bn3.running_var, backbone.layer4.1.bn3.num_batches_tracked, backbone.layer4.2.conv1.weight, backbone.layer4.2.bn1.weight, backbone.layer4.2.bn1.bias, backbone.layer4.2.bn1.running_mean, backbone.layer4.2.bn1.running_var, backbone.layer4.2.bn1.num_batches_tracked, backbone.layer4.2.conv2.weight, backbone.layer4.2.bn2.weight, backbone.layer4.2.bn2.bias, backbone.layer4.2.bn2.running_mean, backbone.layer4.2.bn2.running_var, backbone.layer4.2.bn2.num_batches_tracked, backbone.layer4.2.conv3.weight, backbone.layer4.2.bn3.weight, backbone.layer4.2.bn3.bias, backbone.layer4.2.bn3.running_mean, backbone.layer4.2.bn3.running_var, backbone.layer4.2.bn3.num_batches_tracked, neck.lateral_convs.0.conv.weight, neck.lateral_convs.0.conv.bias, neck.lateral_convs.1.conv.weight, neck.lateral_convs.1.conv.bias, neck.lateral_convs.2.conv.weight, neck.lateral_convs.2.conv.bias, neck.lateral_convs.3.conv.weight, neck.lateral_convs.3.conv.bias, neck.fpn_convs.0.conv.weight, neck.fpn_convs.0.conv.bias, neck.fpn_convs.1.conv.weight, neck.fpn_convs.1.conv.bias, neck.fpn_convs.2.conv.weight, neck.fpn_convs.2.conv.bias, neck.fpn_convs.3.conv.weight, neck.fpn_convs.3.conv.bias, mask_feat_head.convs_all_levels.0.conv0.conv.weight, mask_feat_head.convs_all_levels.0.conv0.gn.weight, mask_feat_head.convs_all_levels.0.conv0.gn.bias, mask_feat_head.convs_all_levels.1.conv0.conv.weight, mask_feat_head.convs_all_levels.1.conv0.gn.weight, mask_feat_head.convs_all_levels.1.conv0.gn.bias, mask_feat_head.convs_all_levels.2.conv0.conv.weight, mask_feat_head.convs_all_levels.2.conv0.gn.weight, mask_feat_head.convs_all_levels.2.conv0.gn.bias, mask_feat_head.convs_all_levels.2.conv1.conv.weight, mask_feat_head.convs_all_levels.2.conv1.gn.weight, mask_feat_head.convs_all_levels.2.conv1.gn.bias, mask_feat_head.convs_all_levels.3.conv0.conv.weight, mask_feat_head.convs_all_levels.3.conv0.gn.weight, mask_feat_head.convs_all_levels.3.conv0.gn.bias, mask_feat_head.convs_all_levels.3.conv1.conv.weight, mask_feat_head.convs_all_levels.3.conv1.gn.weight, mask_feat_head.convs_all_levels.3.conv1.gn.bias, mask_feat_head.convs_all_levels.3.conv2.conv.weight, mask_feat_head.convs_all_levels.3.conv2.gn.weight, mask_feat_head.convs_all_levels.3.conv2.gn.bias, mask_feat_head.conv_pred.0.conv.weight, mask_feat_head.conv_pred.0.gn.weight, mask_feat_head.conv_pred.0.gn.bias, bbox_head.cate_convs.0.conv.weight, bbox_head.cate_convs.0.gn.weight, bbox_head.cate_convs.0.gn.bias, bbox_head.cate_convs.1.conv.weight, bbox_head.cate_convs.1.gn.weight, bbox_head.cate_convs.1.gn.bias, bbox_head.cate_convs.2.conv.weight, bbox_head.cate_convs.2.gn.weight, bbox_head.cate_convs.2.gn.bias, bbox_head.cate_convs.3.conv.weight, bbox_head.cate_convs.3.gn.weight, bbox_head.cate_convs.3.gn.bias, bbox_head.kernel_convs.0.conv.weight, bbox_head.kernel_convs.0.gn.weight, bbox_head.kernel_convs.0.gn.bias, bbox_head.kernel_convs.1.conv.weight, bbox_head.kernel_convs.1.gn.weight, bbox_head.kernel_convs.1.gn.bias, bbox_head.kernel_convs.2.conv.weight, bbox_head.kernel_convs.2.gn.weight, bbox_head.kernel_convs.2.gn.bias, bbox_head.kernel_convs.3.conv.weight, bbox_head.kernel_convs.3.gn.weight, bbox_head.kernel_convs.3.gn.bias, bbox_head.solo_cate.weight, bbox_head.solo_cate.bias, bbox_head.solo_kernel.weight, bbox_head.solo_kernel.bias

missing keys in source state_dict: conv1.weight, bn1.weight, bn1.bias, bn1.running_mean, bn1.running_var, layer1.0.conv1.weight, layer1.0.bn1.weight, layer1.0.bn1.bias, layer1.0.bn1.running_mean, layer1.0.bn1.running_var, layer1.0.conv2.weight, layer1.0.bn2.weight, layer1.0.bn2.bias, layer1.0.bn2.running_mean, layer1.0.bn2.running_var, layer1.0.conv3.weight, layer1.0.bn3.weight, layer1.0.bn3.bias, layer1.0.bn3.running_mean, layer1.0.bn3.running_var, layer1.0.downsample.0.weight, layer1.0.downsample.1.weight, layer1.0.downsample.1.bias, layer1.0.downsample.1.running_mean, layer1.0.downsample.1.running_var, layer1.1.conv1.weight, layer1.1.bn1.weight, layer1.1.bn1.bias, layer1.1.bn1.running_mean, layer1.1.bn1.running_var, layer1.1.conv2.weight, layer1.1.bn2.weight, layer1.1.bn2.bias, layer1.1.bn2.running_mean, layer1.1.bn2.running_var, layer1.1.conv3.weight, layer1.1.bn3.weight, layer1.1.bn3.bias, layer1.1.bn3.running_mean, layer1.1.bn3.running_var, layer1.2.conv1.weight, layer1.2.bn1.weight, layer1.2.bn1.bias, layer1.2.bn1.running_mean, layer1.2.bn1.running_var, layer1.2.conv2.weight, layer1.2.bn2.weight, layer1.2.bn2.bias, layer1.2.bn2.running_mean, layer1.2.bn2.running_var, layer1.2.conv3.weight, layer1.2.bn3.weight, layer1.2.bn3.bias, layer1.2.bn3.running_mean, layer1.2.bn3.running_var, layer2.0.conv1.weight, layer2.0.bn1.weight, layer2.0.bn1.bias, layer2.0.bn1.running_mean, layer2.0.bn1.running_var, layer2.0.conv2.weight, layer2.0.bn2.weight, layer2.0.bn2.bias, layer2.0.bn2.running_mean, layer2.0.bn2.running_var, layer2.0.conv3.weight, layer2.0.bn3.weight, layer2.0.bn3.bias, layer2.0.bn3.running_mean, layer2.0.bn3.running_var, layer2.0.downsample.0.weight, layer2.0.downsample.1.weight, layer2.0.downsample.1.bias, layer2.0.downsample.1.running_mean, layer2.0.downsample.1.running_var, layer2.1.conv1.weight, layer2.1.bn1.weight, layer2.1.bn1.bias, layer2.1.bn1.running_mean, layer2.1.bn1.running_var, layer2.1.conv2.weight, layer2.1.bn2.weight, layer2.1.bn2.bias, layer2.1.bn2.running_mean, layer2.1.bn2.running_var, layer2.1.conv3.weight, layer2.1.bn3.weight, layer2.1.bn3.bias, layer2.1.bn3.running_mean, layer2.1.bn3.running_var, layer2.2.conv1.weight, layer2.2.bn1.weight, layer2.2.bn1.bias, layer2.2.bn1.running_mean, layer2.2.bn1.running_var, layer2.2.conv2.weight, layer2.2.bn2.weight, layer2.2.bn2.bias, layer2.2.bn2.running_mean, layer2.2.bn2.running_var, layer2.2.conv3.weight, layer2.2.bn3.weight, layer2.2.bn3.bias, layer2.2.bn3.running_mean, layer2.2.bn3.running_var, layer2.3.conv1.weight, layer2.3.bn1.weight, layer2.3.bn1.bias, layer2.3.bn1.running_mean, layer2.3.bn1.running_var, layer2.3.conv2.weight, layer2.3.bn2.weight, layer2.3.bn2.bias, layer2.3.bn2.running_mean, layer2.3.bn2.running_var, layer2.3.conv3.weight, layer2.3.bn3.weight, layer2.3.bn3.bias, layer2.3.bn3.running_mean, layer2.3.bn3.running_var, layer3.0.conv1.weight, layer3.0.bn1.weight, layer3.0.bn1.bias, layer3.0.bn1.running_mean, layer3.0.bn1.running_var, layer3.0.conv2.weight, layer3.0.bn2.weight, layer3.0.bn2.bias, layer3.0.bn2.running_mean, layer3.0.bn2.running_var, layer3.0.conv3.weight, layer3.0.bn3.weight, layer3.0.bn3.bias, layer3.0.bn3.running_mean, layer3.0.bn3.running_var, layer3.0.downsample.0.weight, layer3.0.downsample.1.weight, layer3.0.downsample.1.bias, layer3.0.downsample.1.running_mean, layer3.0.downsample.1.running_var, layer3.1.conv1.weight, layer3.1.bn1.weight, layer3.1.bn1.bias, layer3.1.bn1.running_mean, layer3.1.bn1.running_var, layer3.1.conv2.weight, layer3.1.bn2.weight, layer3.1.bn2.bias, layer3.1.bn2.running_mean, layer3.1.bn2.running_var, layer3.1.conv3.weight, layer3.1.bn3.weight, layer3.1.bn3.bias, layer3.1.bn3.running_mean, layer3.1.bn3.running_var, layer3.2.conv1.weight, layer3.2.bn1.weight, layer3.2.bn1.bias, layer3.2.bn1.running_mean, layer3.2.bn1.running_var, layer3.2.conv2.weight, layer3.2.bn2.weight, layer3.2.bn2.bias, layer3.2.bn2.running_mean, layer3.2.bn2.running_var, layer3.2.conv3.weight, layer3.2.bn3.weight, layer3.2.bn3.bias, layer3.2.bn3.running_mean, layer3.2.bn3.running_var, layer3.3.conv1.weight, layer3.3.bn1.weight, layer3.3.bn1.bias, layer3.3.bn1.running_mean, layer3.3.bn1.running_var, layer3.3.conv2.weight, layer3.3.bn2.weight, layer3.3.bn2.bias, layer3.3.bn2.running_mean, layer3.3.bn2.running_var, layer3.3.conv3.weight, layer3.3.bn3.weight, layer3.3.bn3.bias, layer3.3.bn3.running_mean, layer3.3.bn3.running_var, layer3.4.conv1.weight, layer3.4.bn1.weight, layer3.4.bn1.bias, layer3.4.bn1.running_mean, layer3.4.bn1.running_var, layer3.4.conv2.weight, layer3.4.bn2.weight, layer3.4.bn2.bias, layer3.4.bn2.running_mean, layer3.4.bn2.running_var, layer3.4.conv3.weight, layer3.4.bn3.weight, layer3.4.bn3.bias, layer3.4.bn3.running_mean, layer3.4.bn3.running_var, layer3.5.conv1.weight, layer3.5.bn1.weight, layer3.5.bn1.bias, layer3.5.bn1.running_mean, layer3.5.bn1.running_var, layer3.5.conv2.weight, layer3.5.bn2.weight, layer3.5.bn2.bias, layer3.5.bn2.running_mean, layer3.5.bn2.running_var, layer3.5.conv3.weight, layer3.5.bn3.weight, layer3.5.bn3.bias, layer3.5.bn3.running_mean, layer3.5.bn3.running_var, layer4.0.conv1.weight, layer4.0.bn1.weight, layer4.0.bn1.bias, layer4.0.bn1.running_mean, layer4.0.bn1.running_var, layer4.0.conv2.weight, layer4.0.bn2.weight, layer4.0.bn2.bias, layer4.0.bn2.running_mean, layer4.0.bn2.running_var, layer4.0.conv3.weight, layer4.0.bn3.weight, layer4.0.bn3.bias, layer4.0.bn3.running_mean, layer4.0.bn3.running_var, layer4.0.downsample.0.weight, layer4.0.downsample.1.weight, layer4.0.downsample.1.bias, layer4.0.downsample.1.running_mean, layer4.0.downsample.1.running_var, layer4.1.conv1.weight, layer4.1.bn1.weight, layer4.1.bn1.bias, layer4.1.bn1.running_mean, layer4.1.bn1.running_var, layer4.1.conv2.weight, layer4.1.bn2.weight, layer4.1.bn2.bias, layer4.1.bn2.running_mean, layer4.1.bn2.running_var, layer4.1.conv3.weight, layer4.1.bn3.weight, layer4.1.bn3.bias, layer4.1.bn3.running_mean, layer4.1.bn3.running_var, layer4.2.conv1.weight, layer4.2.bn1.weight, layer4.2.bn1.bias, layer4.2.bn1.running_mean, layer4.2.bn1.running_var, layer4.2.conv2.weight, layer4.2.bn2.weight, layer4.2.bn2.bias, layer4.2.bn2.running_mean, layer4.2.bn2.running_var, layer4.2.conv3.weight, layer4.2.bn3.weight, layer4.2.bn3.bias, layer4.2.bn3.running_mean, layer4.2.bn3.running_var

2021-07-21 07:08:31,023 - mmdet - INFO - Start running, host: root@efe7fbebbac3, work_dir: /home/zq/work/SOLO/work_dirs/solov2_release_r50_fpn_8gpu_3x_weight
2021-07-21 07:08:31,023 - mmdet - INFO - workflow: [('train', 1)], max: 36 epochs
loading annotations into memory...
Done (t=0.02s)
creating index...
index created!
{'type': 'CocoDataset', 'ann_file': 'data/annotation/merge/merge_train_coco.json', 'img_prefix': 'data/road/train/', 'pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'LoadAnnotations', 'with_bbox': True, 'with_mask': True}, {'type': 'Resize', 'img_scale': [(1333, 800), (1333, 768), (1333, 736), (1333, 704), (1333, 672), (1333, 640)], 'multiscale_mode': 'value', 'keep_ratio': True}, {'type': 'RandomFlip', 'flip_ratio': 0.5}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'DefaultFormatBundle'}, {'type': 'Collect', 'keys': ['img', 'gt_bboxes', 'gt_labels', 'gt_masks']}]}
/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:2494: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
Traceback (most recent call last):
  File "tools/train.py", line 133, in <module>
    main()
  File "tools/train.py", line 129, in main
    timestamp=timestamp)
  File "/home/zq/work/SOLO/mmdet/apis/train.py", line 111, in train_detector
    timestamp=timestamp)
  File "/home/zq/work/SOLO/mmdet/apis/train.py", line 297, in _non_dist_train
    runner.run(data_loaders, cfg.workflow, cfg.total_epochs)
  File "/opt/conda/lib/python3.6/site-packages/mmcv/runner/runner.py", line 364, in run
    epoch_runner(data_loaders[i], **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/mmcv/runner/runner.py", line 268, in train
    self.model, data_batch, train_mode=True, **kwargs)
  File "/home/zq/work/SOLO/mmdet/apis/train.py", line 78, in batch_processor
    losses = model(**data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py", line 150, in forward
    return self.module(*inputs[0], **kwargs[0])
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/zq/work/SOLO/mmdet/core/fp16/decorators.py", line 49, in new_func
    return old_func(*args, **kwargs)
  File "/home/zq/work/SOLO/mmdet/models/detectors/base.py", line 142, in forward
    return self.forward_train(img, img_meta, **kwargs)
  File "/home/zq/work/SOLO/mmdet/models/detectors/single_stage_ins.py", line 73, in forward_train
    start_level:self.mask_feat_head.end_level + 1])
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/zq/work/SOLO/mmdet/models/mask_heads/mask_feat_head.py", line 116, in forward
    feature_add_all_level += self.convs_all_levels[i](input_p)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 92, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/upsampling.py", line 131, in forward
    return F.interpolate(input, self.size, self.scale_factor, self.mode, self.align_corners)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 2518, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, _output_size(2), align_corners)
RuntimeError: CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 10.75 GiB total capacity; 3.64 GiB already allocated; 17.50 MiB free; 94.20 MiB cached)
2021-07-21 07:08:38,811 - mmdet - INFO - Epoch [4][300/673]	lr: 0.01000, eta: 1:46:28, time: 0.311, data_time: 0.013, memory: 4415, loss_ins: 0.4698, loss_cate: 0.3671, loss: 0.8369
2021-07-21 07:08:53,626 - mmdet - INFO - Epoch [4][350/673]	lr: 0.01000, eta: 1:46:16, time: 0.296, data_time: 0.014, memory: 4415, loss_ins: 0.4926, loss_cate: 0.3831, loss: 0.8758
2021-07-21 07:09:09,021 - mmdet - INFO - Epoch [4][400/673]	lr: 0.01000, eta: 1:46:09, time: 0.308, data_time: 0.014, memory: 4415, loss_ins: 0.7227, loss_cate: 0.3426, loss: 1.0652
2021-07-21 07:09:24,219 - mmdet - INFO - Epoch [4][450/673]	lr: 0.01000, eta: 1:45:59, time: 0.304, data_time: 0.014, memory: 4415, loss_ins: 0.6338, loss_cate: 0.3836, loss: 1.0173
2021-07-21 07:09:39,354 - mmdet - INFO - Epoch [4][500/673]	lr: 0.01000, eta: 1:45:49, time: 0.303, data_time: 0.014, memory: 4415, loss_ins: 0.5713, loss_cate: 0.3552, loss: 0.9264
2021-07-21 07:09:54,300 - mmdet - INFO - Epoch [4][550/673]	lr: 0.01000, eta: 1:45:37, time: 0.299, data_time: 0.014, memory: 4415, loss_ins: 0.6658, loss_cate: 0.3825, loss: 1.0483
2021-07-21 07:10:09,320 - mmdet - INFO - Epoch [4][600/673]	lr: 0.01000, eta: 1:45:26, time: 0.300, data_time: 0.014, memory: 4415, loss_ins: 0.5229, loss_cate: 0.3424, loss: 0.8653
2021-07-21 07:10:22,718 - mmdet - INFO - Distributed training: False
2021-07-21 07:10:22,718 - mmdet - INFO - MMDetection Version: 1.0.0+c7b294a
2021-07-21 07:10:22,718 - mmdet - INFO - Config:
# model settings
model = dict(
    type='SOLOv2',
    pretrained='torchvision://resnet50',
    backbone=dict(
        type='ResNet',
        depth=50,
        num_stages=4,
        out_indices=(0, 1, 2, 3),  # C2, C3, C4, C5
        frozen_stages=1,
        style='pytorch'),
    neck=dict(
        type='FPN',
        in_channels=[256, 512, 1024, 2048],
        out_channels=256,
        start_level=0,
        num_outs=5),
    bbox_head=dict(
        type='SOLOv2Head',
        num_classes=2,
        in_channels=256,
        stacked_convs=4,
        seg_feat_channels=512,
        strides=[8, 8, 16, 32, 32],
        scale_ranges=((1, 96), (48, 192), (96, 384), (192, 768), (384, 2048)),
        # scale_ranges=((1, 376), (188, 752), (752, 1400)),
        sigma=0.2,
        num_grids=[40, 36, 24, 16, 12],
        ins_out_channels=256,
        loss_ins=dict(
            type='DiceLoss',
            use_sigmoid=True,
            # loss_weight=3.0),
            loss_weight=10.0),
        loss_cate=dict(
            type='FocalLoss',
            use_sigmoid=True,
            gamma=2.0,
            alpha=0.25,
            loss_weight=1.0)),
    mask_feat_head=dict(
        type='MaskFeatHead',
        in_channels=256,
        out_channels=128,
        start_level=0,
        end_level=3,
        num_classes=256,
        norm_cfg=dict(type='GN', num_groups=32, requires_grad=True)),
)
# training and testing settings
train_cfg = dict()
test_cfg = dict(
    nms_pre=500,
    score_thr=0.1,
    mask_thr=0.5,
    update_thr=0.05,
    kernel='gaussian',  # gaussian/linear
    sigma=2.0,
    max_per_img=100)
# dataset settings
dataset_type = 'CocoDataset'
data_root = 'data/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),
    dict(type='Resize',
         img_scale=[(1333, 800), (1333, 768), (1333, 736),
                    (1333, 704), (1333, 672), (1333, 640)],
         multiscale_mode='value',
         keep_ratio=True),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(type='Normalize', **img_norm_cfg),
    dict(type='Pad', size_divisor=32),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks']),
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(1333, 800),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(type='Normalize', **img_norm_cfg),
            dict(type='Pad', size_divisor=32),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img']),
        ])
]
data = dict(
    imgs_per_gpu=2,
    workers_per_gpu=2,
    train=dict(
        type=dataset_type,
        ann_file=data_root + 'annotation/merge/merge_train_coco.json',
        img_prefix=data_root + 'road/train/',
        pipeline=train_pipeline),
    val=dict(
        type=dataset_type,
        ann_file=data_root + 'annotation/merge/merge_val_coco.json',
        img_prefix=data_root + 'road/val/',
        pipeline=test_pipeline),
    test=dict(
        type=dataset_type,
        ann_file=data_root + 'annotation/merge/merge_val_coco.json',
        img_prefix=data_root + 'road/val/',
        pipeline=test_pipeline))
# optimizer
optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0001)
optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))
# learning policy
lr_config = dict(
    policy='step',
    warmup='linear',
    warmup_iters=500,
    warmup_ratio=0.01,
    step=[27, 33])
checkpoint_config = dict(interval=1)
# yapf:disable
log_config = dict(
    interval=50,
    hooks=[
        dict(type='TextLoggerHook'),
        # dict(type='TensorboardLoggerHook')
    ])
# yapf:enable
# runtime settings
total_epochs = 36
device_ids = range(8)
dist_params = dict(backend='nccl')
log_level = 'INFO'
# work_dir = './work_dirs/solov2_release_r50_fpn_8gpu_3x'
# work_dir = './work_dirs/solov2_release_r50_fpn_8gpu_3x_scale'
work_dir = './work_dirs/solov2_release_r50_fpn_8gpu_3x_weight'
load_from = None
resume_from = None
workflow = [('train', 1)]
# workflow = [('train', 1), ('val', 1)]

2021-07-21 07:10:23,103 - mmdet - INFO - load model from: torchvision://resnet50
2021-07-21 07:10:24,256 - mmdet - INFO - Epoch [4][650/673]	lr: 0.01000, eta: 1:45:14, time: 0.299, data_time: 0.013, memory: 4415, loss_ins: 0.4702, loss_cate: 0.3409, loss: 0.8111
2021-07-21 07:10:26,377 - mmdet - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: backbone.conv1.weight, backbone.bn1.weight, backbone.bn1.bias, backbone.bn1.running_mean, backbone.bn1.running_var, backbone.bn1.num_batches_tracked, backbone.layer1.0.conv1.weight, backbone.layer1.0.bn1.weight, backbone.layer1.0.bn1.bias, backbone.layer1.0.bn1.running_mean, backbone.layer1.0.bn1.running_var, backbone.layer1.0.bn1.num_batches_tracked, backbone.layer1.0.conv2.weight, backbone.layer1.0.bn2.weight, backbone.layer1.0.bn2.bias, backbone.layer1.0.bn2.running_mean, backbone.layer1.0.bn2.running_var, backbone.layer1.0.bn2.num_batches_tracked, backbone.layer1.0.conv3.weight, backbone.layer1.0.bn3.weight, backbone.layer1.0.bn3.bias, backbone.layer1.0.bn3.running_mean, backbone.layer1.0.bn3.running_var, backbone.layer1.0.bn3.num_batches_tracked, backbone.layer1.0.downsample.0.weight, backbone.layer1.0.downsample.1.weight, backbone.layer1.0.downsample.1.bias, backbone.layer1.0.downsample.1.running_mean, backbone.layer1.0.downsample.1.running_var, backbone.layer1.0.downsample.1.num_batches_tracked, backbone.layer1.1.conv1.weight, backbone.layer1.1.bn1.weight, backbone.layer1.1.bn1.bias, backbone.layer1.1.bn1.running_mean, backbone.layer1.1.bn1.running_var, backbone.layer1.1.bn1.num_batches_tracked, backbone.layer1.1.conv2.weight, backbone.layer1.1.bn2.weight, backbone.layer1.1.bn2.bias, backbone.layer1.1.bn2.running_mean, backbone.layer1.1.bn2.running_var, backbone.layer1.1.bn2.num_batches_tracked, backbone.layer1.1.conv3.weight, backbone.layer1.1.bn3.weight, backbone.layer1.1.bn3.bias, backbone.layer1.1.bn3.running_mean, backbone.layer1.1.bn3.running_var, backbone.layer1.1.bn3.num_batches_tracked, backbone.layer1.2.conv1.weight, backbone.layer1.2.bn1.weight, backbone.layer1.2.bn1.bias, backbone.layer1.2.bn1.running_mean, backbone.layer1.2.bn1.running_var, backbone.layer1.2.bn1.num_batches_tracked, backbone.layer1.2.conv2.weight, backbone.layer1.2.bn2.weight, backbone.layer1.2.bn2.bias, backbone.layer1.2.bn2.running_mean, backbone.layer1.2.bn2.running_var, backbone.layer1.2.bn2.num_batches_tracked, backbone.layer1.2.conv3.weight, backbone.layer1.2.bn3.weight, backbone.layer1.2.bn3.bias, backbone.layer1.2.bn3.running_mean, backbone.layer1.2.bn3.running_var, backbone.layer1.2.bn3.num_batches_tracked, backbone.layer2.0.conv1.weight, backbone.layer2.0.bn1.weight, backbone.layer2.0.bn1.bias, backbone.layer2.0.bn1.running_mean, backbone.layer2.0.bn1.running_var, backbone.layer2.0.bn1.num_batches_tracked, backbone.layer2.0.conv2.weight, backbone.layer2.0.bn2.weight, backbone.layer2.0.bn2.bias, backbone.layer2.0.bn2.running_mean, backbone.layer2.0.bn2.running_var, backbone.layer2.0.bn2.num_batches_tracked, backbone.layer2.0.conv3.weight, backbone.layer2.0.bn3.weight, backbone.layer2.0.bn3.bias, backbone.layer2.0.bn3.running_mean, backbone.layer2.0.bn3.running_var, backbone.layer2.0.bn3.num_batches_tracked, backbone.layer2.0.downsample.0.weight, backbone.layer2.0.downsample.1.weight, backbone.layer2.0.downsample.1.bias, backbone.layer2.0.downsample.1.running_mean, backbone.layer2.0.downsample.1.running_var, backbone.layer2.0.downsample.1.num_batches_tracked, backbone.layer2.1.conv1.weight, backbone.layer2.1.bn1.weight, backbone.layer2.1.bn1.bias, backbone.layer2.1.bn1.running_mean, backbone.layer2.1.bn1.running_var, backbone.layer2.1.bn1.num_batches_tracked, backbone.layer2.1.conv2.weight, backbone.layer2.1.bn2.weight, backbone.layer2.1.bn2.bias, backbone.layer2.1.bn2.running_mean, backbone.layer2.1.bn2.running_var, backbone.layer2.1.bn2.num_batches_tracked, backbone.layer2.1.conv3.weight, backbone.layer2.1.bn3.weight, backbone.layer2.1.bn3.bias, backbone.layer2.1.bn3.running_mean, backbone.layer2.1.bn3.running_var, backbone.layer2.1.bn3.num_batches_tracked, backbone.layer2.2.conv1.weight, backbone.layer2.2.bn1.weight, backbone.layer2.2.bn1.bias, backbone.layer2.2.bn1.running_mean, backbone.layer2.2.bn1.running_var, backbone.layer2.2.bn1.num_batches_tracked, backbone.layer2.2.conv2.weight, backbone.layer2.2.bn2.weight, backbone.layer2.2.bn2.bias, backbone.layer2.2.bn2.running_mean, backbone.layer2.2.bn2.running_var, backbone.layer2.2.bn2.num_batches_tracked, backbone.layer2.2.conv3.weight, backbone.layer2.2.bn3.weight, backbone.layer2.2.bn3.bias, backbone.layer2.2.bn3.running_mean, backbone.layer2.2.bn3.running_var, backbone.layer2.2.bn3.num_batches_tracked, backbone.layer2.3.conv1.weight, backbone.layer2.3.bn1.weight, backbone.layer2.3.bn1.bias, backbone.layer2.3.bn1.running_mean, backbone.layer2.3.bn1.running_var, backbone.layer2.3.bn1.num_batches_tracked, backbone.layer2.3.conv2.weight, backbone.layer2.3.bn2.weight, backbone.layer2.3.bn2.bias, backbone.layer2.3.bn2.running_mean, backbone.layer2.3.bn2.running_var, backbone.layer2.3.bn2.num_batches_tracked, backbone.layer2.3.conv3.weight, backbone.layer2.3.bn3.weight, backbone.layer2.3.bn3.bias, backbone.layer2.3.bn3.running_mean, backbone.layer2.3.bn3.running_var, backbone.layer2.3.bn3.num_batches_tracked, backbone.layer3.0.conv1.weight, backbone.layer3.0.bn1.weight, backbone.layer3.0.bn1.bias, backbone.layer3.0.bn1.running_mean, backbone.layer3.0.bn1.running_var, backbone.layer3.0.bn1.num_batches_tracked, backbone.layer3.0.conv2.weight, backbone.layer3.0.bn2.weight, backbone.layer3.0.bn2.bias, backbone.layer3.0.bn2.running_mean, backbone.layer3.0.bn2.running_var, backbone.layer3.0.bn2.num_batches_tracked, backbone.layer3.0.conv3.weight, backbone.layer3.0.bn3.weight, backbone.layer3.0.bn3.bias, backbone.layer3.0.bn3.running_mean, backbone.layer3.0.bn3.running_var, backbone.layer3.0.bn3.num_batches_tracked, backbone.layer3.0.downsample.0.weight, backbone.layer3.0.downsample.1.weight, backbone.layer3.0.downsample.1.bias, backbone.layer3.0.downsample.1.running_mean, backbone.layer3.0.downsample.1.running_var, backbone.layer3.0.downsample.1.num_batches_tracked, backbone.layer3.1.conv1.weight, backbone.layer3.1.bn1.weight, backbone.layer3.1.bn1.bias, backbone.layer3.1.bn1.running_mean, backbone.layer3.1.bn1.running_var, backbone.layer3.1.bn1.num_batches_tracked, backbone.layer3.1.conv2.weight, backbone.layer3.1.bn2.weight, backbone.layer3.1.bn2.bias, backbone.layer3.1.bn2.running_mean, backbone.layer3.1.bn2.running_var, backbone.layer3.1.bn2.num_batches_tracked, backbone.layer3.1.conv3.weight, backbone.layer3.1.bn3.weight, backbone.layer3.1.bn3.bias, backbone.layer3.1.bn3.running_mean, backbone.layer3.1.bn3.running_var, backbone.layer3.1.bn3.num_batches_tracked, backbone.layer3.2.conv1.weight, backbone.layer3.2.bn1.weight, backbone.layer3.2.bn1.bias, backbone.layer3.2.bn1.running_mean, backbone.layer3.2.bn1.running_var, backbone.layer3.2.bn1.num_batches_tracked, backbone.layer3.2.conv2.weight, backbone.layer3.2.bn2.weight, backbone.layer3.2.bn2.bias, backbone.layer3.2.bn2.running_mean, backbone.layer3.2.bn2.running_var, backbone.layer3.2.bn2.num_batches_tracked, backbone.layer3.2.conv3.weight, backbone.layer3.2.bn3.weight, backbone.layer3.2.bn3.bias, backbone.layer3.2.bn3.running_mean, backbone.layer3.2.bn3.running_var, backbone.layer3.2.bn3.num_batches_tracked, backbone.layer3.3.conv1.weight, backbone.layer3.3.bn1.weight, backbone.layer3.3.bn1.bias, backbone.layer3.3.bn1.running_mean, backbone.layer3.3.bn1.running_var, backbone.layer3.3.bn1.num_batches_tracked, backbone.layer3.3.conv2.weight, backbone.layer3.3.bn2.weight, backbone.layer3.3.bn2.bias, backbone.layer3.3.bn2.running_mean, backbone.layer3.3.bn2.running_var, backbone.layer3.3.bn2.num_batches_tracked, backbone.layer3.3.conv3.weight, backbone.layer3.3.bn3.weight, backbone.layer3.3.bn3.bias, backbone.layer3.3.bn3.running_mean, backbone.layer3.3.bn3.running_var, backbone.layer3.3.bn3.num_batches_tracked, backbone.layer3.4.conv1.weight, backbone.layer3.4.bn1.weight, backbone.layer3.4.bn1.bias, backbone.layer3.4.bn1.running_mean, backbone.layer3.4.bn1.running_var, backbone.layer3.4.bn1.num_batches_tracked, backbone.layer3.4.conv2.weight, backbone.layer3.4.bn2.weight, backbone.layer3.4.bn2.bias, backbone.layer3.4.bn2.running_mean, backbone.layer3.4.bn2.running_var, backbone.layer3.4.bn2.num_batches_tracked, backbone.layer3.4.conv3.weight, backbone.layer3.4.bn3.weight, backbone.layer3.4.bn3.bias, backbone.layer3.4.bn3.running_mean, backbone.layer3.4.bn3.running_var, backbone.layer3.4.bn3.num_batches_tracked, backbone.layer3.5.conv1.weight, backbone.layer3.5.bn1.weight, backbone.layer3.5.bn1.bias, backbone.layer3.5.bn1.running_mean, backbone.layer3.5.bn1.running_var, backbone.layer3.5.bn1.num_batches_tracked, backbone.layer3.5.conv2.weight, backbone.layer3.5.bn2.weight, backbone.layer3.5.bn2.bias, backbone.layer3.5.bn2.running_mean, backbone.layer3.5.bn2.running_var, backbone.layer3.5.bn2.num_batches_tracked, backbone.layer3.5.conv3.weight, backbone.layer3.5.bn3.weight, backbone.layer3.5.bn3.bias, backbone.layer3.5.bn3.running_mean, backbone.layer3.5.bn3.running_var, backbone.layer3.5.bn3.num_batches_tracked, backbone.layer4.0.conv1.weight, backbone.layer4.0.bn1.weight, backbone.layer4.0.bn1.bias, backbone.layer4.0.bn1.running_mean, backbone.layer4.0.bn1.running_var, backbone.layer4.0.bn1.num_batches_tracked, backbone.layer4.0.conv2.weight, backbone.layer4.0.bn2.weight, backbone.layer4.0.bn2.bias, backbone.layer4.0.bn2.running_mean, backbone.layer4.0.bn2.running_var, backbone.layer4.0.bn2.num_batches_tracked, backbone.layer4.0.conv3.weight, backbone.layer4.0.bn3.weight, backbone.layer4.0.bn3.bias, backbone.layer4.0.bn3.running_mean, backbone.layer4.0.bn3.running_var, backbone.layer4.0.bn3.num_batches_tracked, backbone.layer4.0.downsample.0.weight, backbone.layer4.0.downsample.1.weight, backbone.layer4.0.downsample.1.bias, backbone.layer4.0.downsample.1.running_mean, backbone.layer4.0.downsample.1.running_var, backbone.layer4.0.downsample.1.num_batches_tracked, backbone.layer4.1.conv1.weight, backbone.layer4.1.bn1.weight, backbone.layer4.1.bn1.bias, backbone.layer4.1.bn1.running_mean, backbone.layer4.1.bn1.running_var, backbone.layer4.1.bn1.num_batches_tracked, backbone.layer4.1.conv2.weight, backbone.layer4.1.bn2.weight, backbone.layer4.1.bn2.bias, backbone.layer4.1.bn2.running_mean, backbone.layer4.1.bn2.running_var, backbone.layer4.1.bn2.num_batches_tracked, backbone.layer4.1.conv3.weight, backbone.layer4.1.bn3.weight, backbone.layer4.1.bn3.bias, backbone.layer4.1.bn3.running_mean, backbone.layer4.1.bn3.running_var, backbone.layer4.1.bn3.num_batches_tracked, backbone.layer4.2.conv1.weight, backbone.layer4.2.bn1.weight, backbone.layer4.2.bn1.bias, backbone.layer4.2.bn1.running_mean, backbone.layer4.2.bn1.running_var, backbone.layer4.2.bn1.num_batches_tracked, backbone.layer4.2.conv2.weight, backbone.layer4.2.bn2.weight, backbone.layer4.2.bn2.bias, backbone.layer4.2.bn2.running_mean, backbone.layer4.2.bn2.running_var, backbone.layer4.2.bn2.num_batches_tracked, backbone.layer4.2.conv3.weight, backbone.layer4.2.bn3.weight, backbone.layer4.2.bn3.bias, backbone.layer4.2.bn3.running_mean, backbone.layer4.2.bn3.running_var, backbone.layer4.2.bn3.num_batches_tracked, neck.lateral_convs.0.conv.weight, neck.lateral_convs.0.conv.bias, neck.lateral_convs.1.conv.weight, neck.lateral_convs.1.conv.bias, neck.lateral_convs.2.conv.weight, neck.lateral_convs.2.conv.bias, neck.lateral_convs.3.conv.weight, neck.lateral_convs.3.conv.bias, neck.fpn_convs.0.conv.weight, neck.fpn_convs.0.conv.bias, neck.fpn_convs.1.conv.weight, neck.fpn_convs.1.conv.bias, neck.fpn_convs.2.conv.weight, neck.fpn_convs.2.conv.bias, neck.fpn_convs.3.conv.weight, neck.fpn_convs.3.conv.bias, mask_feat_head.convs_all_levels.0.conv0.conv.weight, mask_feat_head.convs_all_levels.0.conv0.gn.weight, mask_feat_head.convs_all_levels.0.conv0.gn.bias, mask_feat_head.convs_all_levels.1.conv0.conv.weight, mask_feat_head.convs_all_levels.1.conv0.gn.weight, mask_feat_head.convs_all_levels.1.conv0.gn.bias, mask_feat_head.convs_all_levels.2.conv0.conv.weight, mask_feat_head.convs_all_levels.2.conv0.gn.weight, mask_feat_head.convs_all_levels.2.conv0.gn.bias, mask_feat_head.convs_all_levels.2.conv1.conv.weight, mask_feat_head.convs_all_levels.2.conv1.gn.weight, mask_feat_head.convs_all_levels.2.conv1.gn.bias, mask_feat_head.convs_all_levels.3.conv0.conv.weight, mask_feat_head.convs_all_levels.3.conv0.gn.weight, mask_feat_head.convs_all_levels.3.conv0.gn.bias, mask_feat_head.convs_all_levels.3.conv1.conv.weight, mask_feat_head.convs_all_levels.3.conv1.gn.weight, mask_feat_head.convs_all_levels.3.conv1.gn.bias, mask_feat_head.convs_all_levels.3.conv2.conv.weight, mask_feat_head.convs_all_levels.3.conv2.gn.weight, mask_feat_head.convs_all_levels.3.conv2.gn.bias, mask_feat_head.conv_pred.0.conv.weight, mask_feat_head.conv_pred.0.gn.weight, mask_feat_head.conv_pred.0.gn.bias, bbox_head.cate_convs.0.conv.weight, bbox_head.cate_convs.0.gn.weight, bbox_head.cate_convs.0.gn.bias, bbox_head.cate_convs.1.conv.weight, bbox_head.cate_convs.1.gn.weight, bbox_head.cate_convs.1.gn.bias, bbox_head.cate_convs.2.conv.weight, bbox_head.cate_convs.2.gn.weight, bbox_head.cate_convs.2.gn.bias, bbox_head.cate_convs.3.conv.weight, bbox_head.cate_convs.3.gn.weight, bbox_head.cate_convs.3.gn.bias, bbox_head.kernel_convs.0.conv.weight, bbox_head.kernel_convs.0.gn.weight, bbox_head.kernel_convs.0.gn.bias, bbox_head.kernel_convs.1.conv.weight, bbox_head.kernel_convs.1.gn.weight, bbox_head.kernel_convs.1.gn.bias, bbox_head.kernel_convs.2.conv.weight, bbox_head.kernel_convs.2.gn.weight, bbox_head.kernel_convs.2.gn.bias, bbox_head.kernel_convs.3.conv.weight, bbox_head.kernel_convs.3.gn.weight, bbox_head.kernel_convs.3.gn.bias, bbox_head.solo_cate.weight, bbox_head.solo_cate.bias, bbox_head.solo_kernel.weight, bbox_head.solo_kernel.bias

missing keys in source state_dict: conv1.weight, bn1.weight, bn1.bias, bn1.running_mean, bn1.running_var, layer1.0.conv1.weight, layer1.0.bn1.weight, layer1.0.bn1.bias, layer1.0.bn1.running_mean, layer1.0.bn1.running_var, layer1.0.conv2.weight, layer1.0.bn2.weight, layer1.0.bn2.bias, layer1.0.bn2.running_mean, layer1.0.bn2.running_var, layer1.0.conv3.weight, layer1.0.bn3.weight, layer1.0.bn3.bias, layer1.0.bn3.running_mean, layer1.0.bn3.running_var, layer1.0.downsample.0.weight, layer1.0.downsample.1.weight, layer1.0.downsample.1.bias, layer1.0.downsample.1.running_mean, layer1.0.downsample.1.running_var, layer1.1.conv1.weight, layer1.1.bn1.weight, layer1.1.bn1.bias, layer1.1.bn1.running_mean, layer1.1.bn1.running_var, layer1.1.conv2.weight, layer1.1.bn2.weight, layer1.1.bn2.bias, layer1.1.bn2.running_mean, layer1.1.bn2.running_var, layer1.1.conv3.weight, layer1.1.bn3.weight, layer1.1.bn3.bias, layer1.1.bn3.running_mean, layer1.1.bn3.running_var, layer1.2.conv1.weight, layer1.2.bn1.weight, layer1.2.bn1.bias, layer1.2.bn1.running_mean, layer1.2.bn1.running_var, layer1.2.conv2.weight, layer1.2.bn2.weight, layer1.2.bn2.bias, layer1.2.bn2.running_mean, layer1.2.bn2.running_var, layer1.2.conv3.weight, layer1.2.bn3.weight, layer1.2.bn3.bias, layer1.2.bn3.running_mean, layer1.2.bn3.running_var, layer2.0.conv1.weight, layer2.0.bn1.weight, layer2.0.bn1.bias, layer2.0.bn1.running_mean, layer2.0.bn1.running_var, layer2.0.conv2.weight, layer2.0.bn2.weight, layer2.0.bn2.bias, layer2.0.bn2.running_mean, layer2.0.bn2.running_var, layer2.0.conv3.weight, layer2.0.bn3.weight, layer2.0.bn3.bias, layer2.0.bn3.running_mean, layer2.0.bn3.running_var, layer2.0.downsample.0.weight, layer2.0.downsample.1.weight, layer2.0.downsample.1.bias, layer2.0.downsample.1.running_mean, layer2.0.downsample.1.running_var, layer2.1.conv1.weight, layer2.1.bn1.weight, layer2.1.bn1.bias, layer2.1.bn1.running_mean, layer2.1.bn1.running_var, layer2.1.conv2.weight, layer2.1.bn2.weight, layer2.1.bn2.bias, layer2.1.bn2.running_mean, layer2.1.bn2.running_var, layer2.1.conv3.weight, layer2.1.bn3.weight, layer2.1.bn3.bias, layer2.1.bn3.running_mean, layer2.1.bn3.running_var, layer2.2.conv1.weight, layer2.2.bn1.weight, layer2.2.bn1.bias, layer2.2.bn1.running_mean, layer2.2.bn1.running_var, layer2.2.conv2.weight, layer2.2.bn2.weight, layer2.2.bn2.bias, layer2.2.bn2.running_mean, layer2.2.bn2.running_var, layer2.2.conv3.weight, layer2.2.bn3.weight, layer2.2.bn3.bias, layer2.2.bn3.running_mean, layer2.2.bn3.running_var, layer2.3.conv1.weight, layer2.3.bn1.weight, layer2.3.bn1.bias, layer2.3.bn1.running_mean, layer2.3.bn1.running_var, layer2.3.conv2.weight, layer2.3.bn2.weight, layer2.3.bn2.bias, layer2.3.bn2.running_mean, layer2.3.bn2.running_var, layer2.3.conv3.weight, layer2.3.bn3.weight, layer2.3.bn3.bias, layer2.3.bn3.running_mean, layer2.3.bn3.running_var, layer3.0.conv1.weight, layer3.0.bn1.weight, layer3.0.bn1.bias, layer3.0.bn1.running_mean, layer3.0.bn1.running_var, layer3.0.conv2.weight, layer3.0.bn2.weight, layer3.0.bn2.bias, layer3.0.bn2.running_mean, layer3.0.bn2.running_var, layer3.0.conv3.weight, layer3.0.bn3.weight, layer3.0.bn3.bias, layer3.0.bn3.running_mean, layer3.0.bn3.running_var, layer3.0.downsample.0.weight, layer3.0.downsample.1.weight, layer3.0.downsample.1.bias, layer3.0.downsample.1.running_mean, layer3.0.downsample.1.running_var, layer3.1.conv1.weight, layer3.1.bn1.weight, layer3.1.bn1.bias, layer3.1.bn1.running_mean, layer3.1.bn1.running_var, layer3.1.conv2.weight, layer3.1.bn2.weight, layer3.1.bn2.bias, layer3.1.bn2.running_mean, layer3.1.bn2.running_var, layer3.1.conv3.weight, layer3.1.bn3.weight, layer3.1.bn3.bias, layer3.1.bn3.running_mean, layer3.1.bn3.running_var, layer3.2.conv1.weight, layer3.2.bn1.weight, layer3.2.bn1.bias, layer3.2.bn1.running_mean, layer3.2.bn1.running_var, layer3.2.conv2.weight, layer3.2.bn2.weight, layer3.2.bn2.bias, layer3.2.bn2.running_mean, layer3.2.bn2.running_var, layer3.2.conv3.weight, layer3.2.bn3.weight, layer3.2.bn3.bias, layer3.2.bn3.running_mean, layer3.2.bn3.running_var, layer3.3.conv1.weight, layer3.3.bn1.weight, layer3.3.bn1.bias, layer3.3.bn1.running_mean, layer3.3.bn1.running_var, layer3.3.conv2.weight, layer3.3.bn2.weight, layer3.3.bn2.bias, layer3.3.bn2.running_mean, layer3.3.bn2.running_var, layer3.3.conv3.weight, layer3.3.bn3.weight, layer3.3.bn3.bias, layer3.3.bn3.running_mean, layer3.3.bn3.running_var, layer3.4.conv1.weight, layer3.4.bn1.weight, layer3.4.bn1.bias, layer3.4.bn1.running_mean, layer3.4.bn1.running_var, layer3.4.conv2.weight, layer3.4.bn2.weight, layer3.4.bn2.bias, layer3.4.bn2.running_mean, layer3.4.bn2.running_var, layer3.4.conv3.weight, layer3.4.bn3.weight, layer3.4.bn3.bias, layer3.4.bn3.running_mean, layer3.4.bn3.running_var, layer3.5.conv1.weight, layer3.5.bn1.weight, layer3.5.bn1.bias, layer3.5.bn1.running_mean, layer3.5.bn1.running_var, layer3.5.conv2.weight, layer3.5.bn2.weight, layer3.5.bn2.bias, layer3.5.bn2.running_mean, layer3.5.bn2.running_var, layer3.5.conv3.weight, layer3.5.bn3.weight, layer3.5.bn3.bias, layer3.5.bn3.running_mean, layer3.5.bn3.running_var, layer4.0.conv1.weight, layer4.0.bn1.weight, layer4.0.bn1.bias, layer4.0.bn1.running_mean, layer4.0.bn1.running_var, layer4.0.conv2.weight, layer4.0.bn2.weight, layer4.0.bn2.bias, layer4.0.bn2.running_mean, layer4.0.bn2.running_var, layer4.0.conv3.weight, layer4.0.bn3.weight, layer4.0.bn3.bias, layer4.0.bn3.running_mean, layer4.0.bn3.running_var, layer4.0.downsample.0.weight, layer4.0.downsample.1.weight, layer4.0.downsample.1.bias, layer4.0.downsample.1.running_mean, layer4.0.downsample.1.running_var, layer4.1.conv1.weight, layer4.1.bn1.weight, layer4.1.bn1.bias, layer4.1.bn1.running_mean, layer4.1.bn1.running_var, layer4.1.conv2.weight, layer4.1.bn2.weight, layer4.1.bn2.bias, layer4.1.bn2.running_mean, layer4.1.bn2.running_var, layer4.1.conv3.weight, layer4.1.bn3.weight, layer4.1.bn3.bias, layer4.1.bn3.running_mean, layer4.1.bn3.running_var, layer4.2.conv1.weight, layer4.2.bn1.weight, layer4.2.bn1.bias, layer4.2.bn1.running_mean, layer4.2.bn1.running_var, layer4.2.conv2.weight, layer4.2.bn2.weight, layer4.2.bn2.bias, layer4.2.bn2.running_mean, layer4.2.bn2.running_var, layer4.2.conv3.weight, layer4.2.bn3.weight, layer4.2.bn3.bias, layer4.2.bn3.running_mean, layer4.2.bn3.running_var

2021-07-21 07:10:26,873 - mmdet - INFO - Start running, host: root@efe7fbebbac3, work_dir: /home/zq/work/SOLO/work_dirs/solov2_release_r50_fpn_8gpu_3x_weight
2021-07-21 07:10:26,873 - mmdet - INFO - workflow: [('train', 1)], max: 36 epochs
loading annotations into memory...
Done (t=0.02s)
creating index...
index created!
{'type': 'CocoDataset', 'ann_file': 'data/annotation/merge/merge_train_coco.json', 'img_prefix': 'data/road/train/', 'pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'LoadAnnotations', 'with_bbox': True, 'with_mask': True}, {'type': 'Resize', 'img_scale': [(1333, 800), (1333, 768), (1333, 736), (1333, 704), (1333, 672), (1333, 640)], 'multiscale_mode': 'value', 'keep_ratio': True}, {'type': 'RandomFlip', 'flip_ratio': 0.5}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'DefaultFormatBundle'}, {'type': 'Collect', 'keys': ['img', 'gt_bboxes', 'gt_labels', 'gt_masks']}]}
/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:2494: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
Traceback (most recent call last):
  File "tools/train.py", line 133, in <module>
    main()
  File "tools/train.py", line 129, in main
    timestamp=timestamp)
  File "/home/zq/work/SOLO/mmdet/apis/train.py", line 111, in train_detector
    timestamp=timestamp)
  File "/home/zq/work/SOLO/mmdet/apis/train.py", line 297, in _non_dist_train
    runner.run(data_loaders, cfg.workflow, cfg.total_epochs)
  File "/opt/conda/lib/python3.6/site-packages/mmcv/runner/runner.py", line 364, in run
    epoch_runner(data_loaders[i], **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/mmcv/runner/runner.py", line 275, in train
    self.call_hook('after_train_iter')
  File "/opt/conda/lib/python3.6/site-packages/mmcv/runner/runner.py", line 231, in call_hook
    getattr(hook, fn_name)(self)
  File "/opt/conda/lib/python3.6/site-packages/mmcv/runner/hooks/optimizer.py", line 18, in after_train_iter
    runner.outputs['loss'].backward()
  File "/opt/conda/lib/python3.6/site-packages/torch/tensor.py", line 150, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/opt/conda/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 110.00 MiB (GPU 0; 10.75 GiB total capacity; 3.51 GiB already allocated; 31.94 MiB free; 217.61 MiB cached)
2021-07-21 07:10:47,576 - mmdet - INFO - Epoch [5][50/673]	lr: 0.01000, eta: 1:44:04, time: 0.304, data_time: 0.018, memory: 4415, loss_ins: 0.4480, loss_cate: 0.3559, loss: 0.8039
2021-07-21 07:11:02,672 - mmdet - INFO - Epoch [5][100/673]	lr: 0.01000, eta: 1:43:54, time: 0.302, data_time: 0.014, memory: 4415, loss_ins: 0.5739, loss_cate: 0.3449, loss: 0.9188
2021-07-21 07:11:18,023 - mmdet - INFO - Epoch [5][150/673]	lr: 0.01000, eta: 1:43:45, time: 0.307, data_time: 0.014, memory: 4415, loss_ins: 0.5509, loss_cate: 0.3507, loss: 0.9016
2021-07-21 07:11:33,329 - mmdet - INFO - Epoch [5][200/673]	lr: 0.01000, eta: 1:43:36, time: 0.306, data_time: 0.013, memory: 4415, loss_ins: 0.4504, loss_cate: 0.3570, loss: 0.8074
2021-07-21 07:11:47,994 - mmdet - INFO - Epoch [5][250/673]	lr: 0.01000, eta: 1:43:22, time: 0.293, data_time: 0.012, memory: 4415, loss_ins: 0.3787, loss_cate: 0.3184, loss: 0.6971
2021-07-21 07:12:03,176 - mmdet - INFO - Epoch [5][300/673]	lr: 0.01000, eta: 1:43:12, time: 0.304, data_time: 0.012, memory: 4415, loss_ins: 0.6772, loss_cate: 0.3474, loss: 1.0246
2021-07-21 07:12:18,594 - mmdet - INFO - Epoch [5][350/673]	lr: 0.01000, eta: 1:43:03, time: 0.308, data_time: 0.013, memory: 4415, loss_ins: 0.7200, loss_cate: 0.3418, loss: 1.0618
2021-07-21 07:12:33,335 - mmdet - INFO - Epoch [5][400/673]	lr: 0.01000, eta: 1:42:50, time: 0.295, data_time: 0.013, memory: 4415, loss_ins: 0.5620, loss_cate: 0.3685, loss: 0.9305
2021-07-21 07:12:47,713 - mmdet - INFO - Epoch [5][450/673]	lr: 0.01000, eta: 1:42:34, time: 0.288, data_time: 0.011, memory: 4415, loss_ins: 0.5426, loss_cate: 0.3659, loss: 0.9085
2021-07-21 07:13:02,504 - mmdet - INFO - Epoch [5][500/673]	lr: 0.01000, eta: 1:42:20, time: 0.296, data_time: 0.012, memory: 4415, loss_ins: 0.4819, loss_cate: 0.3638, loss: 0.8457
2021-07-21 07:13:17,307 - mmdet - INFO - Epoch [5][550/673]	lr: 0.01000, eta: 1:42:07, time: 0.296, data_time: 0.013, memory: 4415, loss_ins: 0.6146, loss_cate: 0.3932, loss: 1.0079
2021-07-21 07:13:32,205 - mmdet - INFO - Epoch [5][600/673]	lr: 0.01000, eta: 1:41:54, time: 0.298, data_time: 0.013, memory: 4415, loss_ins: 0.5419, loss_cate: 0.3852, loss: 0.9272
2021-07-21 07:13:47,086 - mmdet - INFO - Epoch [5][650/673]	lr: 0.01000, eta: 1:41:42, time: 0.298, data_time: 0.011, memory: 4415, loss_ins: 0.6899, loss_cate: 0.3854, loss: 1.0753
2021-07-21 07:14:09,581 - mmdet - INFO - Epoch [6][50/673]	lr: 0.01000, eta: 1:40:44, time: 0.307, data_time: 0.019, memory: 4415, loss_ins: 0.5201, loss_cate: 0.3358, loss: 0.8559
2021-07-21 07:14:24,864 - mmdet - INFO - Epoch [6][100/673]	lr: 0.01000, eta: 1:40:34, time: 0.306, data_time: 0.016, memory: 4415, loss_ins: 0.5195, loss_cate: 0.3685, loss: 0.8880
2021-07-21 07:14:39,930 - mmdet - INFO - Epoch [6][150/673]	lr: 0.01000, eta: 1:40:23, time: 0.301, data_time: 0.016, memory: 4415, loss_ins: 0.5771, loss_cate: 0.3775, loss: 0.9546
2021-07-21 07:14:55,426 - mmdet - INFO - Epoch [6][200/673]	lr: 0.01000, eta: 1:40:14, time: 0.310, data_time: 0.016, memory: 4415, loss_ins: 0.6158, loss_cate: 0.3663, loss: 0.9821
2021-07-21 07:15:10,725 - mmdet - INFO - Epoch [6][250/673]	lr: 0.01000, eta: 1:40:03, time: 0.306, data_time: 0.015, memory: 4415, loss_ins: 0.3788, loss_cate: 0.3555, loss: 0.7343
2021-07-21 07:15:26,198 - mmdet - INFO - Epoch [6][300/673]	lr: 0.01000, eta: 1:39:54, time: 0.309, data_time: 0.015, memory: 4415, loss_ins: 0.7084, loss_cate: 0.5249, loss: 1.2334
2021-07-21 07:15:41,520 - mmdet - INFO - Epoch [6][350/673]	lr: 0.01000, eta: 1:39:43, time: 0.306, data_time: 0.015, memory: 4415, loss_ins: 0.5930, loss_cate: 0.4469, loss: 1.0399
2021-07-21 07:15:56,714 - mmdet - INFO - Epoch [6][400/673]	lr: 0.01000, eta: 1:39:32, time: 0.304, data_time: 0.014, memory: 4415, loss_ins: 0.5770, loss_cate: 0.3929, loss: 0.9699
2021-07-21 07:16:11,899 - mmdet - INFO - Epoch [6][450/673]	lr: 0.01000, eta: 1:39:21, time: 0.304, data_time: 0.014, memory: 4415, loss_ins: 0.5503, loss_cate: 0.3564, loss: 0.9067
2021-07-21 07:16:27,491 - mmdet - INFO - Epoch [6][500/673]	lr: 0.01000, eta: 1:39:11, time: 0.312, data_time: 0.015, memory: 4415, loss_ins: 0.6297, loss_cate: 0.3322, loss: 0.9619
2021-07-21 07:16:42,764 - mmdet - INFO - Epoch [6][550/673]	lr: 0.01000, eta: 1:39:00, time: 0.305, data_time: 0.016, memory: 4415, loss_ins: 0.4760, loss_cate: 0.3372, loss: 0.8131
2021-07-21 07:16:58,233 - mmdet - INFO - Epoch [6][600/673]	lr: 0.01000, eta: 1:38:50, time: 0.309, data_time: 0.014, memory: 4415, loss_ins: 0.5636, loss_cate: 0.3299, loss: 0.8935
2021-07-21 07:17:13,378 - mmdet - INFO - Epoch [6][650/673]	lr: 0.01000, eta: 1:38:38, time: 0.303, data_time: 0.014, memory: 4415, loss_ins: 0.5483, loss_cate: 0.3334, loss: 0.8816
2021-07-21 07:17:36,092 - mmdet - INFO - Epoch [7][50/673]	lr: 0.01000, eta: 1:37:46, time: 0.306, data_time: 0.020, memory: 4415, loss_ins: 0.4041, loss_cate: 0.3354, loss: 0.7395
2021-07-21 07:17:51,488 - mmdet - INFO - Epoch [7][100/673]	lr: 0.01000, eta: 1:37:36, time: 0.308, data_time: 0.015, memory: 4415, loss_ins: 0.6039, loss_cate: 0.3363, loss: 0.9402
2021-07-21 07:18:06,927 - mmdet - INFO - Epoch [7][150/673]	lr: 0.01000, eta: 1:37:25, time: 0.309, data_time: 0.014, memory: 4415, loss_ins: 0.4837, loss_cate: 0.3269, loss: 0.8106
2021-07-21 07:18:21,809 - mmdet - INFO - Epoch [7][200/673]	lr: 0.01000, eta: 1:37:12, time: 0.298, data_time: 0.014, memory: 4415, loss_ins: 0.4443, loss_cate: 0.3305, loss: 0.7749
2021-07-21 07:18:37,030 - mmdet - INFO - Epoch [7][250/673]	lr: 0.01000, eta: 1:37:01, time: 0.304, data_time: 0.014, memory: 4415, loss_ins: 0.5697, loss_cate: 0.3320, loss: 0.9017
2021-07-21 07:18:52,052 - mmdet - INFO - Epoch [7][300/673]	lr: 0.01000, eta: 1:36:48, time: 0.300, data_time: 0.014, memory: 4415, loss_ins: 0.5239, loss_cate: 0.3139, loss: 0.8378
2021-07-21 07:19:07,346 - mmdet - INFO - Epoch [7][350/673]	lr: 0.01000, eta: 1:36:36, time: 0.306, data_time: 0.014, memory: 4415, loss_ins: 0.5720, loss_cate: 0.3455, loss: 0.9175
2021-07-21 07:19:22,902 - mmdet - INFO - Epoch [7][400/673]	lr: 0.01000, eta: 1:36:26, time: 0.311, data_time: 0.015, memory: 4415, loss_ins: 0.4959, loss_cate: 0.3100, loss: 0.8059
2021-07-21 07:19:38,214 - mmdet - INFO - Epoch [7][450/673]	lr: 0.01000, eta: 1:36:14, time: 0.306, data_time: 0.015, memory: 4415, loss_ins: 0.6457, loss_cate: 0.3201, loss: 0.9658
2021-07-21 07:19:53,165 - mmdet - INFO - Epoch [7][500/673]	lr: 0.01000, eta: 1:36:01, time: 0.299, data_time: 0.015, memory: 4415, loss_ins: 0.6581, loss_cate: 0.3889, loss: 1.0471
2021-07-21 07:20:08,326 - mmdet - INFO - Epoch [7][550/673]	lr: 0.01000, eta: 1:35:49, time: 0.303, data_time: 0.015, memory: 4415, loss_ins: 0.5828, loss_cate: 0.3647, loss: 0.9475
2021-07-21 07:20:23,367 - mmdet - INFO - Epoch [7][600/673]	lr: 0.01000, eta: 1:35:36, time: 0.301, data_time: 0.014, memory: 4415, loss_ins: 0.5044, loss_cate: 0.3477, loss: 0.8521
2021-07-21 07:20:38,366 - mmdet - INFO - Epoch [7][650/673]	lr: 0.01000, eta: 1:35:23, time: 0.300, data_time: 0.014, memory: 4415, loss_ins: 0.5584, loss_cate: 0.3243, loss: 0.8827
2021-07-21 07:21:00,837 - mmdet - INFO - Epoch [8][50/673]	lr: 0.01000, eta: 1:34:36, time: 0.304, data_time: 0.019, memory: 4415, loss_ins: 0.4923, loss_cate: 0.3103, loss: 0.8026
2021-07-21 07:21:16,195 - mmdet - INFO - Epoch [8][100/673]	lr: 0.01000, eta: 1:34:25, time: 0.307, data_time: 0.015, memory: 4415, loss_ins: 0.6028, loss_cate: 0.3375, loss: 0.9403
2021-07-21 07:21:30,988 - mmdet - INFO - Epoch [8][150/673]	lr: 0.01000, eta: 1:34:11, time: 0.296, data_time: 0.014, memory: 4415, loss_ins: 0.4412, loss_cate: 0.3636, loss: 0.8048
2021-07-21 07:21:45,852 - mmdet - INFO - Epoch [8][200/673]	lr: 0.01000, eta: 1:33:57, time: 0.297, data_time: 0.015, memory: 4415, loss_ins: 0.5247, loss_cate: 0.3623, loss: 0.8870
2021-07-21 07:22:00,980 - mmdet - INFO - Epoch [8][250/673]	lr: 0.01000, eta: 1:33:45, time: 0.303, data_time: 0.013, memory: 4415, loss_ins: 0.4066, loss_cate: 0.3439, loss: 0.7505
2021-07-21 07:22:15,985 - mmdet - INFO - Epoch [8][300/673]	lr: 0.01000, eta: 1:33:32, time: 0.300, data_time: 0.014, memory: 4415, loss_ins: 0.4747, loss_cate: 0.3273, loss: 0.8020
2021-07-21 07:22:30,929 - mmdet - INFO - Epoch [8][350/673]	lr: 0.01000, eta: 1:33:18, time: 0.299, data_time: 0.014, memory: 4416, loss_ins: 0.5951, loss_cate: 0.3409, loss: 0.9360
2021-07-21 07:22:45,819 - mmdet - INFO - Epoch [8][400/673]	lr: 0.01000, eta: 1:33:05, time: 0.298, data_time: 0.014, memory: 4416, loss_ins: 0.4902, loss_cate: 0.3428, loss: 0.8330
2021-07-21 07:23:00,992 - mmdet - INFO - Epoch [8][450/673]	lr: 0.01000, eta: 1:32:52, time: 0.303, data_time: 0.014, memory: 4416, loss_ins: 0.3521, loss_cate: 0.3308, loss: 0.6829
2021-07-21 07:23:15,816 - mmdet - INFO - Epoch [8][500/673]	lr: 0.01000, eta: 1:32:39, time: 0.296, data_time: 0.013, memory: 4416, loss_ins: 0.4978, loss_cate: 0.4206, loss: 0.9183
2021-07-21 07:23:30,838 - mmdet - INFO - Epoch [8][550/673]	lr: 0.01000, eta: 1:32:25, time: 0.300, data_time: 0.014, memory: 4416, loss_ins: 0.4085, loss_cate: 0.3786, loss: 0.7870
2021-07-21 07:23:46,155 - mmdet - INFO - Epoch [8][600/673]	lr: 0.01000, eta: 1:32:13, time: 0.306, data_time: 0.014, memory: 4416, loss_ins: 0.6294, loss_cate: 0.3843, loss: 1.0138
2021-07-21 07:24:01,643 - mmdet - INFO - Epoch [8][650/673]	lr: 0.01000, eta: 1:32:02, time: 0.310, data_time: 0.016, memory: 4416, loss_ins: 0.5408, loss_cate: 0.3732, loss: 0.9140
2021-07-21 07:24:24,403 - mmdet - INFO - Epoch [9][50/673]	lr: 0.01000, eta: 1:31:19, time: 0.306, data_time: 0.019, memory: 4416, loss_ins: 0.4900, loss_cate: 0.3639, loss: 0.8539
2021-07-21 07:24:39,678 - mmdet - INFO - Epoch [9][100/673]	lr: 0.01000, eta: 1:31:07, time: 0.305, data_time: 0.016, memory: 4416, loss_ins: 0.5016, loss_cate: 0.3756, loss: 0.8772
2021-07-21 07:24:54,950 - mmdet - INFO - Epoch [9][150/673]	lr: 0.01000, eta: 1:30:55, time: 0.305, data_time: 0.016, memory: 4416, loss_ins: 0.5267, loss_cate: 0.3972, loss: 0.9239
2021-07-21 07:25:09,750 - mmdet - INFO - Epoch [9][200/673]	lr: 0.01000, eta: 1:30:41, time: 0.296, data_time: 0.015, memory: 4416, loss_ins: 0.5263, loss_cate: 0.3563, loss: 0.8826
2021-07-21 07:25:25,047 - mmdet - INFO - Epoch [9][250/673]	lr: 0.01000, eta: 1:30:29, time: 0.306, data_time: 0.016, memory: 4416, loss_ins: 0.6736, loss_cate: 0.3408, loss: 1.0144
2021-07-21 07:25:40,219 - mmdet - INFO - Epoch [9][300/673]	lr: 0.01000, eta: 1:30:16, time: 0.303, data_time: 0.015, memory: 4416, loss_ins: 0.4994, loss_cate: 0.3524, loss: 0.8519
2021-07-21 07:25:55,090 - mmdet - INFO - Epoch [9][350/673]	lr: 0.01000, eta: 1:30:02, time: 0.297, data_time: 0.014, memory: 4416, loss_ins: 0.6176, loss_cate: 0.4205, loss: 1.0381
2021-07-21 07:26:09,772 - mmdet - INFO - Epoch [9][400/673]	lr: 0.01000, eta: 1:29:48, time: 0.294, data_time: 0.014, memory: 4416, loss_ins: 0.5160, loss_cate: 0.4319, loss: 0.9479
2021-07-21 07:26:24,902 - mmdet - INFO - Epoch [9][450/673]	lr: 0.01000, eta: 1:29:35, time: 0.303, data_time: 0.015, memory: 4416, loss_ins: 0.5361, loss_cate: 0.3909, loss: 0.9270
2021-07-21 07:26:40,214 - mmdet - INFO - Epoch [9][500/673]	lr: 0.01000, eta: 1:29:22, time: 0.306, data_time: 0.015, memory: 4416, loss_ins: 0.5066, loss_cate: 0.3669, loss: 0.8735
2021-07-21 07:26:55,298 - mmdet - INFO - Epoch [9][550/673]	lr: 0.01000, eta: 1:29:09, time: 0.302, data_time: 0.014, memory: 4416, loss_ins: 0.5069, loss_cate: 0.3544, loss: 0.8613
2021-07-21 07:27:10,646 - mmdet - INFO - Epoch [9][600/673]	lr: 0.01000, eta: 1:28:57, time: 0.307, data_time: 0.015, memory: 4416, loss_ins: 0.5915, loss_cate: 0.3311, loss: 0.9225
2021-07-21 07:27:25,879 - mmdet - INFO - Epoch [9][650/673]	lr: 0.01000, eta: 1:28:44, time: 0.305, data_time: 0.015, memory: 4416, loss_ins: 0.5530, loss_cate: 0.3337, loss: 0.8866
2021-07-21 07:27:48,855 - mmdet - INFO - Epoch [10][50/673]	lr: 0.01000, eta: 1:28:05, time: 0.312, data_time: 0.019, memory: 4416, loss_ins: 0.5241, loss_cate: 0.3226, loss: 0.8467
2021-07-21 07:28:04,090 - mmdet - INFO - Epoch [10][100/673]	lr: 0.01000, eta: 1:27:53, time: 0.305, data_time: 0.015, memory: 4416, loss_ins: 0.4841, loss_cate: 0.3481, loss: 0.8322
2021-07-21 07:28:19,373 - mmdet - INFO - Epoch [10][150/673]	lr: 0.01000, eta: 1:27:40, time: 0.306, data_time: 0.015, memory: 4416, loss_ins: 0.4817, loss_cate: 0.3164, loss: 0.7981
2021-07-21 07:28:34,434 - mmdet - INFO - Epoch [10][200/673]	lr: 0.01000, eta: 1:27:27, time: 0.301, data_time: 0.014, memory: 4416, loss_ins: 0.4782, loss_cate: 0.3431, loss: 0.8213
2021-07-21 07:28:49,596 - mmdet - INFO - Epoch [10][250/673]	lr: 0.01000, eta: 1:27:14, time: 0.303, data_time: 0.013, memory: 4416, loss_ins: 0.5073, loss_cate: 0.3245, loss: 0.8318
2021-07-21 07:29:04,725 - mmdet - INFO - Epoch [10][300/673]	lr: 0.01000, eta: 1:27:01, time: 0.303, data_time: 0.014, memory: 4416, loss_ins: 0.4378, loss_cate: 0.3235, loss: 0.7613
2021-07-21 07:29:19,691 - mmdet - INFO - Epoch [10][350/673]	lr: 0.01000, eta: 1:26:47, time: 0.299, data_time: 0.014, memory: 4416, loss_ins: 0.3301, loss_cate: 0.3405, loss: 0.6706
2021-07-21 07:29:34,596 - mmdet - INFO - Epoch [10][400/673]	lr: 0.01000, eta: 1:26:33, time: 0.298, data_time: 0.014, memory: 4416, loss_ins: 0.4196, loss_cate: 0.3408, loss: 0.7605
2021-07-21 07:29:50,106 - mmdet - INFO - Epoch [10][450/673]	lr: 0.01000, eta: 1:26:21, time: 0.310, data_time: 0.014, memory: 4416, loss_ins: 0.5207, loss_cate: 0.3404, loss: 0.8611
2021-07-21 07:30:05,551 - mmdet - INFO - Epoch [10][500/673]	lr: 0.01000, eta: 1:26:09, time: 0.309, data_time: 0.013, memory: 4416, loss_ins: 0.3699, loss_cate: 0.3278, loss: 0.6977
2021-07-21 07:30:20,643 - mmdet - INFO - Epoch [10][550/673]	lr: 0.01000, eta: 1:25:55, time: 0.302, data_time: 0.014, memory: 4416, loss_ins: 0.4376, loss_cate: 0.3108, loss: 0.7485
2021-07-21 07:30:35,953 - mmdet - INFO - Epoch [10][600/673]	lr: 0.01000, eta: 1:25:43, time: 0.306, data_time: 0.015, memory: 4416, loss_ins: 0.4613, loss_cate: 0.3328, loss: 0.7941
2021-07-21 07:30:50,819 - mmdet - INFO - Epoch [10][650/673]	lr: 0.01000, eta: 1:25:29, time: 0.297, data_time: 0.014, memory: 4416, loss_ins: 0.3417, loss_cate: 0.3230, loss: 0.6648
2021-07-21 07:31:13,303 - mmdet - INFO - Epoch [11][50/673]	lr: 0.01000, eta: 1:24:51, time: 0.300, data_time: 0.018, memory: 4416, loss_ins: 0.4297, loss_cate: 0.3143, loss: 0.7440
2021-07-21 07:31:28,248 - mmdet - INFO - Epoch [11][100/673]	lr: 0.01000, eta: 1:24:37, time: 0.299, data_time: 0.014, memory: 4416, loss_ins: 0.4744, loss_cate: 0.3265, loss: 0.8009
2021-07-21 07:31:43,190 - mmdet - INFO - Epoch [11][150/673]	lr: 0.01000, eta: 1:24:23, time: 0.299, data_time: 0.014, memory: 4416, loss_ins: 0.3489, loss_cate: 0.3401, loss: 0.6890
2021-07-21 07:31:58,269 - mmdet - INFO - Epoch [11][200/673]	lr: 0.01000, eta: 1:24:10, time: 0.302, data_time: 0.014, memory: 4416, loss_ins: 0.4271, loss_cate: 0.3688, loss: 0.7959
2021-07-21 07:32:13,420 - mmdet - INFO - Epoch [11][250/673]	lr: 0.01000, eta: 1:23:57, time: 0.303, data_time: 0.014, memory: 4416, loss_ins: 0.4868, loss_cate: 0.3687, loss: 0.8555
2021-07-21 07:32:28,921 - mmdet - INFO - Epoch [11][300/673]	lr: 0.01000, eta: 1:23:44, time: 0.310, data_time: 0.014, memory: 4416, loss_ins: 0.5990, loss_cate: 0.3599, loss: 0.9588
2021-07-21 07:32:44,157 - mmdet - INFO - Epoch [11][350/673]	lr: 0.01000, eta: 1:23:31, time: 0.305, data_time: 0.014, memory: 4416, loss_ins: 0.3906, loss_cate: 0.3323, loss: 0.7229
2021-07-21 07:32:59,039 - mmdet - INFO - Epoch [11][400/673]	lr: 0.01000, eta: 1:23:17, time: 0.298, data_time: 0.013, memory: 4416, loss_ins: 0.5275, loss_cate: 0.3445, loss: 0.8720
2021-07-21 07:33:14,011 - mmdet - INFO - Epoch [11][450/673]	lr: 0.01000, eta: 1:23:04, time: 0.299, data_time: 0.013, memory: 4416, loss_ins: 0.3228, loss_cate: 0.3082, loss: 0.6310
2021-07-21 07:33:29,102 - mmdet - INFO - Epoch [11][500/673]	lr: 0.01000, eta: 1:22:50, time: 0.302, data_time: 0.014, memory: 4416, loss_ins: 0.2903, loss_cate: 0.2996, loss: 0.5899
2021-07-21 07:33:44,247 - mmdet - INFO - Epoch [11][550/673]	lr: 0.01000, eta: 1:22:37, time: 0.303, data_time: 0.014, memory: 4416, loss_ins: 0.4558, loss_cate: 0.3295, loss: 0.7853
2021-07-21 07:33:59,380 - mmdet - INFO - Epoch [11][600/673]	lr: 0.01000, eta: 1:22:23, time: 0.303, data_time: 0.014, memory: 4416, loss_ins: 0.3439, loss_cate: 0.3301, loss: 0.6739
2021-07-21 07:34:14,381 - mmdet - INFO - Epoch [11][650/673]	lr: 0.01000, eta: 1:22:09, time: 0.300, data_time: 0.014, memory: 4416, loss_ins: 0.3890, loss_cate: 0.3279, loss: 0.7170
2021-07-21 07:34:37,271 - mmdet - INFO - Epoch [12][50/673]	lr: 0.01000, eta: 1:21:35, time: 0.307, data_time: 0.018, memory: 4416, loss_ins: 0.3834, loss_cate: 0.3370, loss: 0.7204
2021-07-21 07:34:52,172 - mmdet - INFO - Epoch [12][100/673]	lr: 0.01000, eta: 1:21:21, time: 0.298, data_time: 0.013, memory: 4416, loss_ins: 0.3364, loss_cate: 0.3350, loss: 0.6713
2021-07-21 07:35:07,252 - mmdet - INFO - Epoch [12][150/673]	lr: 0.01000, eta: 1:21:07, time: 0.302, data_time: 0.014, memory: 4416, loss_ins: 0.4109, loss_cate: 0.3409, loss: 0.7518
2021-07-21 07:35:22,503 - mmdet - INFO - Epoch [12][200/673]	lr: 0.01000, eta: 1:20:54, time: 0.305, data_time: 0.014, memory: 4416, loss_ins: 0.3611, loss_cate: 0.3273, loss: 0.6884
2021-07-21 07:35:37,475 - mmdet - INFO - Epoch [12][250/673]	lr: 0.01000, eta: 1:20:40, time: 0.299, data_time: 0.013, memory: 4416, loss_ins: 0.3624, loss_cate: 0.3155, loss: 0.6779
2021-07-21 07:35:52,780 - mmdet - INFO - Epoch [12][300/673]	lr: 0.01000, eta: 1:20:27, time: 0.306, data_time: 0.014, memory: 4416, loss_ins: 0.3567, loss_cate: 0.3084, loss: 0.6651
2021-07-21 07:36:07,915 - mmdet - INFO - Epoch [12][350/673]	lr: 0.01000, eta: 1:20:14, time: 0.303, data_time: 0.013, memory: 4416, loss_ins: 0.2882, loss_cate: 0.3165, loss: 0.6047
2021-07-21 07:36:23,292 - mmdet - INFO - Epoch [12][400/673]	lr: 0.01000, eta: 1:20:01, time: 0.308, data_time: 0.014, memory: 4416, loss_ins: 0.3162, loss_cate: 0.2977, loss: 0.6139
2021-07-21 07:36:38,527 - mmdet - INFO - Epoch [12][450/673]	lr: 0.01000, eta: 1:19:47, time: 0.305, data_time: 0.014, memory: 4416, loss_ins: 0.3226, loss_cate: 0.2820, loss: 0.6045
2021-07-21 07:36:53,931 - mmdet - INFO - Epoch [12][500/673]	lr: 0.01000, eta: 1:19:34, time: 0.308, data_time: 0.014, memory: 4416, loss_ins: 0.3441, loss_cate: 0.2893, loss: 0.6333
2021-07-21 07:37:09,299 - mmdet - INFO - Epoch [12][550/673]	lr: 0.01000, eta: 1:19:21, time: 0.307, data_time: 0.014, memory: 4416, loss_ins: 0.3401, loss_cate: 0.2924, loss: 0.6325
2021-07-21 07:37:24,344 - mmdet - INFO - Epoch [12][600/673]	lr: 0.01000, eta: 1:19:07, time: 0.301, data_time: 0.013, memory: 4416, loss_ins: 0.3751, loss_cate: 0.3117, loss: 0.6868
2021-07-21 07:37:39,117 - mmdet - INFO - Epoch [12][650/673]	lr: 0.01000, eta: 1:18:53, time: 0.295, data_time: 0.013, memory: 4416, loss_ins: 0.2776, loss_cate: 0.3037, loss: 0.5813
2021-07-21 07:38:01,898 - mmdet - INFO - Epoch [13][50/673]	lr: 0.01000, eta: 1:18:20, time: 0.305, data_time: 0.018, memory: 4416, loss_ins: 0.2541, loss_cate: 0.3199, loss: 0.5741
2021-07-21 07:38:17,281 - mmdet - INFO - Epoch [13][100/673]	lr: 0.01000, eta: 1:18:07, time: 0.308, data_time: 0.014, memory: 4416, loss_ins: 0.3063, loss_cate: 0.2891, loss: 0.5954
2021-07-21 07:38:32,626 - mmdet - INFO - Epoch [13][150/673]	lr: 0.01000, eta: 1:17:53, time: 0.307, data_time: 0.013, memory: 4416, loss_ins: 0.3246, loss_cate: 0.2908, loss: 0.6154
2021-07-21 07:38:47,717 - mmdet - INFO - Epoch [13][200/673]	lr: 0.01000, eta: 1:17:40, time: 0.302, data_time: 0.013, memory: 4416, loss_ins: 0.3428, loss_cate: 0.3016, loss: 0.6443
2021-07-21 07:39:02,636 - mmdet - INFO - Epoch [13][250/673]	lr: 0.01000, eta: 1:17:26, time: 0.298, data_time: 0.013, memory: 4416, loss_ins: 0.3066, loss_cate: 0.2791, loss: 0.5857
2021-07-21 07:39:17,746 - mmdet - INFO - Epoch [13][300/673]	lr: 0.01000, eta: 1:17:12, time: 0.302, data_time: 0.013, memory: 4416, loss_ins: 0.3249, loss_cate: 0.3065, loss: 0.6314
2021-07-21 07:39:33,082 - mmdet - INFO - Epoch [13][350/673]	lr: 0.01000, eta: 1:16:59, time: 0.307, data_time: 0.014, memory: 4416, loss_ins: 0.3473, loss_cate: 0.2984, loss: 0.6457
2021-07-21 07:39:48,059 - mmdet - INFO - Epoch [13][400/673]	lr: 0.01000, eta: 1:16:45, time: 0.300, data_time: 0.013, memory: 4416, loss_ins: 0.3541, loss_cate: 0.3192, loss: 0.6733
2021-07-21 07:40:03,240 - mmdet - INFO - Epoch [13][450/673]	lr: 0.01000, eta: 1:16:31, time: 0.304, data_time: 0.014, memory: 4416, loss_ins: 0.3315, loss_cate: 0.2884, loss: 0.6199
2021-07-21 07:40:18,224 - mmdet - INFO - Epoch [13][500/673]	lr: 0.01000, eta: 1:16:17, time: 0.300, data_time: 0.013, memory: 4416, loss_ins: 0.3184, loss_cate: 0.3235, loss: 0.6418
2021-07-21 07:40:33,507 - mmdet - INFO - Epoch [13][550/673]	lr: 0.01000, eta: 1:16:04, time: 0.306, data_time: 0.012, memory: 4416, loss_ins: 0.2407, loss_cate: 0.2955, loss: 0.5362
2021-07-21 07:40:48,821 - mmdet - INFO - Epoch [13][600/673]	lr: 0.01000, eta: 1:15:50, time: 0.306, data_time: 0.013, memory: 4416, loss_ins: 0.2262, loss_cate: 0.3068, loss: 0.5329
2021-07-21 07:41:04,448 - mmdet - INFO - Epoch [13][650/673]	lr: 0.01000, eta: 1:15:38, time: 0.313, data_time: 0.013, memory: 4416, loss_ins: 0.3118, loss_cate: 0.2963, loss: 0.6081
2021-07-21 07:41:27,172 - mmdet - INFO - Epoch [14][50/673]	lr: 0.01000, eta: 1:15:05, time: 0.304, data_time: 0.018, memory: 4416, loss_ins: 0.2872, loss_cate: 0.2900, loss: 0.5772
2021-07-21 07:41:42,679 - mmdet - INFO - Epoch [14][100/673]	lr: 0.01000, eta: 1:14:52, time: 0.310, data_time: 0.015, memory: 4416, loss_ins: 0.3753, loss_cate: 0.2937, loss: 0.6690
2021-07-21 07:41:58,065 - mmdet - INFO - Epoch [14][150/673]	lr: 0.01000, eta: 1:14:39, time: 0.308, data_time: 0.015, memory: 4416, loss_ins: 0.2850, loss_cate: 0.3046, loss: 0.5896
2021-07-21 07:42:13,370 - mmdet - INFO - Epoch [14][200/673]	lr: 0.01000, eta: 1:14:26, time: 0.306, data_time: 0.015, memory: 4416, loss_ins: 0.3204, loss_cate: 0.2839, loss: 0.6043
2021-07-21 07:42:28,418 - mmdet - INFO - Epoch [14][250/673]	lr: 0.01000, eta: 1:14:12, time: 0.301, data_time: 0.014, memory: 4416, loss_ins: 0.2763, loss_cate: 0.3027, loss: 0.5790
2021-07-21 07:42:43,615 - mmdet - INFO - Epoch [14][300/673]	lr: 0.01000, eta: 1:13:58, time: 0.304, data_time: 0.015, memory: 4416, loss_ins: 0.2833, loss_cate: 0.2853, loss: 0.5686
2021-07-21 07:42:58,598 - mmdet - INFO - Epoch [14][350/673]	lr: 0.01000, eta: 1:13:44, time: 0.300, data_time: 0.013, memory: 4416, loss_ins: 0.2636, loss_cate: 0.2851, loss: 0.5487
2021-07-21 07:43:13,465 - mmdet - INFO - Epoch [14][400/673]	lr: 0.01000, eta: 1:13:30, time: 0.297, data_time: 0.013, memory: 4416, loss_ins: 0.3407, loss_cate: 0.3144, loss: 0.6551
2021-07-21 07:43:28,579 - mmdet - INFO - Epoch [14][450/673]	lr: 0.01000, eta: 1:13:16, time: 0.302, data_time: 0.014, memory: 4416, loss_ins: 0.2519, loss_cate: 0.2732, loss: 0.5251
2021-07-21 07:43:43,905 - mmdet - INFO - Epoch [14][500/673]	lr: 0.01000, eta: 1:13:03, time: 0.307, data_time: 0.014, memory: 4416, loss_ins: 0.2964, loss_cate: 0.2785, loss: 0.5749
2021-07-21 07:43:59,158 - mmdet - INFO - Epoch [14][550/673]	lr: 0.01000, eta: 1:12:49, time: 0.305, data_time: 0.014, memory: 4416, loss_ins: 0.2655, loss_cate: 0.2698, loss: 0.5352
2021-07-21 07:44:14,316 - mmdet - INFO - Epoch [14][600/673]	lr: 0.01000, eta: 1:12:35, time: 0.303, data_time: 0.014, memory: 4416, loss_ins: 0.2614, loss_cate: 0.2777, loss: 0.5390
2021-07-21 07:44:29,615 - mmdet - INFO - Epoch [14][650/673]	lr: 0.01000, eta: 1:12:22, time: 0.306, data_time: 0.014, memory: 4416, loss_ins: 0.2593, loss_cate: 0.2822, loss: 0.5415
2021-07-21 07:44:52,692 - mmdet - INFO - Epoch [15][50/673]	lr: 0.01000, eta: 1:11:51, time: 0.313, data_time: 0.018, memory: 4416, loss_ins: 0.2738, loss_cate: 0.2688, loss: 0.5426
2021-07-21 07:45:07,771 - mmdet - INFO - Epoch [15][100/673]	lr: 0.01000, eta: 1:11:37, time: 0.302, data_time: 0.014, memory: 4416, loss_ins: 0.2599, loss_cate: 0.2947, loss: 0.5547
2021-07-21 07:45:23,025 - mmdet - INFO - Epoch [15][150/673]	lr: 0.01000, eta: 1:11:24, time: 0.305, data_time: 0.014, memory: 4416, loss_ins: 0.2687, loss_cate: 0.2803, loss: 0.5490
2021-07-21 07:45:38,383 - mmdet - INFO - Epoch [15][200/673]	lr: 0.01000, eta: 1:11:10, time: 0.307, data_time: 0.014, memory: 4416, loss_ins: 0.2879, loss_cate: 0.2733, loss: 0.5612
2021-07-21 07:45:53,761 - mmdet - INFO - Epoch [15][250/673]	lr: 0.01000, eta: 1:10:57, time: 0.308, data_time: 0.013, memory: 4416, loss_ins: 0.3094, loss_cate: 0.2827, loss: 0.5921
2021-07-21 07:46:08,790 - mmdet - INFO - Epoch [15][300/673]	lr: 0.01000, eta: 1:10:43, time: 0.301, data_time: 0.013, memory: 4416, loss_ins: 0.2489, loss_cate: 0.2755, loss: 0.5244
2021-07-21 07:46:24,143 - mmdet - INFO - Epoch [15][350/673]	lr: 0.01000, eta: 1:10:29, time: 0.307, data_time: 0.013, memory: 4416, loss_ins: 0.3056, loss_cate: 0.3009, loss: 0.6065
2021-07-21 07:46:38,973 - mmdet - INFO - Epoch [15][400/673]	lr: 0.01000, eta: 1:10:15, time: 0.297, data_time: 0.012, memory: 4416, loss_ins: 0.2452, loss_cate: 0.2868, loss: 0.5320
2021-07-21 07:46:53,822 - mmdet - INFO - Epoch [15][450/673]	lr: 0.01000, eta: 1:10:01, time: 0.297, data_time: 0.012, memory: 4416, loss_ins: 0.2574, loss_cate: 0.3027, loss: 0.5602
2021-07-21 07:47:08,911 - mmdet - INFO - Epoch [15][500/673]	lr: 0.01000, eta: 1:09:47, time: 0.302, data_time: 0.013, memory: 4416, loss_ins: 0.2786, loss_cate: 0.2677, loss: 0.5463
2021-07-21 07:47:24,097 - mmdet - INFO - Epoch [15][550/673]	lr: 0.01000, eta: 1:09:33, time: 0.304, data_time: 0.013, memory: 4416, loss_ins: 0.2734, loss_cate: 0.2743, loss: 0.5477
2021-07-21 07:47:39,079 - mmdet - INFO - Epoch [15][600/673]	lr: 0.01000, eta: 1:09:19, time: 0.300, data_time: 0.013, memory: 4416, loss_ins: 0.2411, loss_cate: 0.2827, loss: 0.5238
2021-07-21 07:47:54,226 - mmdet - INFO - Epoch [15][650/673]	lr: 0.01000, eta: 1:09:05, time: 0.303, data_time: 0.013, memory: 4416, loss_ins: 0.2528, loss_cate: 0.2793, loss: 0.5321
2021-07-21 07:48:16,535 - mmdet - INFO - Epoch [16][50/673]	lr: 0.01000, eta: 1:08:35, time: 0.302, data_time: 0.018, memory: 4416, loss_ins: 0.2051, loss_cate: 0.2860, loss: 0.4911
2021-07-21 07:48:31,879 - mmdet - INFO - Epoch [16][100/673]	lr: 0.01000, eta: 1:08:21, time: 0.307, data_time: 0.014, memory: 4416, loss_ins: 0.2456, loss_cate: 0.2732, loss: 0.5188
2021-07-21 07:48:46,971 - mmdet - INFO - Epoch [16][150/673]	lr: 0.01000, eta: 1:08:07, time: 0.302, data_time: 0.013, memory: 4416, loss_ins: 0.2622, loss_cate: 0.2797, loss: 0.5419
2021-07-21 07:49:02,044 - mmdet - INFO - Epoch [16][200/673]	lr: 0.01000, eta: 1:07:53, time: 0.301, data_time: 0.014, memory: 4416, loss_ins: 0.2378, loss_cate: 0.2828, loss: 0.5206
2021-07-21 07:49:17,350 - mmdet - INFO - Epoch [16][250/673]	lr: 0.01000, eta: 1:07:39, time: 0.306, data_time: 0.014, memory: 4416, loss_ins: 0.2922, loss_cate: 0.2764, loss: 0.5686
2021-07-21 07:49:32,566 - mmdet - INFO - Epoch [16][300/673]	lr: 0.01000, eta: 1:07:26, time: 0.304, data_time: 0.013, memory: 4416, loss_ins: 0.3003, loss_cate: 0.2896, loss: 0.5899
2021-07-21 07:49:47,633 - mmdet - INFO - Epoch [16][350/673]	lr: 0.01000, eta: 1:07:11, time: 0.301, data_time: 0.013, memory: 4416, loss_ins: 0.2327, loss_cate: 0.2925, loss: 0.5252
2021-07-21 07:50:02,822 - mmdet - INFO - Epoch [16][400/673]	lr: 0.01000, eta: 1:06:58, time: 0.304, data_time: 0.014, memory: 4416, loss_ins: 0.2657, loss_cate: 0.2768, loss: 0.5425
2021-07-21 07:50:18,019 - mmdet - INFO - Epoch [16][450/673]	lr: 0.01000, eta: 1:06:44, time: 0.304, data_time: 0.014, memory: 4416, loss_ins: 0.2357, loss_cate: 0.2800, loss: 0.5157
2021-07-21 07:50:33,153 - mmdet - INFO - Epoch [16][500/673]	lr: 0.01000, eta: 1:06:30, time: 0.303, data_time: 0.014, memory: 4416, loss_ins: 0.2575, loss_cate: 0.2972, loss: 0.5546
2021-07-21 07:50:48,481 - mmdet - INFO - Epoch [16][550/673]	lr: 0.01000, eta: 1:06:16, time: 0.307, data_time: 0.014, memory: 4416, loss_ins: 0.2774, loss_cate: 0.3437, loss: 0.6211
2021-07-21 07:51:03,916 - mmdet - INFO - Epoch [16][600/673]	lr: 0.01000, eta: 1:06:02, time: 0.309, data_time: 0.014, memory: 4416, loss_ins: 0.2621, loss_cate: 0.2655, loss: 0.5276
2021-07-21 07:51:18,635 - mmdet - INFO - Epoch [16][650/673]	lr: 0.01000, eta: 1:05:48, time: 0.294, data_time: 0.012, memory: 4416, loss_ins: 0.2230, loss_cate: 0.2892, loss: 0.5122
2021-07-21 07:51:41,196 - mmdet - INFO - Epoch [17][50/673]	lr: 0.01000, eta: 1:05:19, time: 0.308, data_time: 0.019, memory: 4416, loss_ins: 0.2134, loss_cate: 0.2559, loss: 0.4693
2021-07-21 07:51:56,645 - mmdet - INFO - Epoch [17][100/673]	lr: 0.01000, eta: 1:05:05, time: 0.309, data_time: 0.014, memory: 4416, loss_ins: 0.2632, loss_cate: 0.2704, loss: 0.5335
2021-07-21 07:52:11,790 - mmdet - INFO - Epoch [17][150/673]	lr: 0.01000, eta: 1:04:51, time: 0.303, data_time: 0.014, memory: 4416, loss_ins: 0.2395, loss_cate: 0.2746, loss: 0.5141
2021-07-21 07:52:26,745 - mmdet - INFO - Epoch [17][200/673]	lr: 0.01000, eta: 1:04:37, time: 0.299, data_time: 0.013, memory: 4416, loss_ins: 0.2365, loss_cate: 0.2555, loss: 0.4920
2021-07-21 07:52:41,876 - mmdet - INFO - Epoch [17][250/673]	lr: 0.01000, eta: 1:04:23, time: 0.303, data_time: 0.013, memory: 4416, loss_ins: 0.2350, loss_cate: 0.2650, loss: 0.5000
2021-07-21 07:52:56,847 - mmdet - INFO - Epoch [17][300/673]	lr: 0.01000, eta: 1:04:09, time: 0.299, data_time: 0.013, memory: 4416, loss_ins: 0.2263, loss_cate: 0.2987, loss: 0.5251
2021-07-21 07:53:11,915 - mmdet - INFO - Epoch [17][350/673]	lr: 0.01000, eta: 1:03:55, time: 0.301, data_time: 0.013, memory: 4416, loss_ins: 0.2183, loss_cate: 0.2585, loss: 0.4768
2021-07-21 07:53:26,632 - mmdet - INFO - Epoch [17][400/673]	lr: 0.01000, eta: 1:03:40, time: 0.294, data_time: 0.013, memory: 4416, loss_ins: 0.2374, loss_cate: 0.2588, loss: 0.4962
2021-07-21 07:53:41,747 - mmdet - INFO - Epoch [17][450/673]	lr: 0.01000, eta: 1:03:26, time: 0.302, data_time: 0.013, memory: 4416, loss_ins: 0.2689, loss_cate: 0.2735, loss: 0.5424
2021-07-21 07:53:56,964 - mmdet - INFO - Epoch [17][500/673]	lr: 0.01000, eta: 1:03:12, time: 0.304, data_time: 0.013, memory: 4416, loss_ins: 0.2519, loss_cate: 0.3054, loss: 0.5573
2021-07-21 07:54:12,495 - mmdet - INFO - Epoch [17][550/673]	lr: 0.01000, eta: 1:02:59, time: 0.311, data_time: 0.014, memory: 4416, loss_ins: 0.2990, loss_cate: 0.3270, loss: 0.6261
2021-07-21 07:54:27,854 - mmdet - INFO - Epoch [17][600/673]	lr: 0.01000, eta: 1:02:45, time: 0.307, data_time: 0.013, memory: 4416, loss_ins: 0.2226, loss_cate: 0.2618, loss: 0.4844
2021-07-21 07:54:43,236 - mmdet - INFO - Epoch [17][650/673]	lr: 0.01000, eta: 1:02:31, time: 0.308, data_time: 0.013, memory: 4416, loss_ins: 0.2676, loss_cate: 0.2782, loss: 0.5458
2021-07-21 07:55:06,032 - mmdet - INFO - Epoch [18][50/673]	lr: 0.01000, eta: 1:02:03, time: 0.308, data_time: 0.018, memory: 4416, loss_ins: 0.2445, loss_cate: 0.2764, loss: 0.5209
2021-07-21 07:55:21,200 - mmdet - INFO - Epoch [18][100/673]	lr: 0.01000, eta: 1:01:49, time: 0.303, data_time: 0.014, memory: 4416, loss_ins: 0.2437, loss_cate: 0.2583, loss: 0.5020
2021-07-21 07:55:36,211 - mmdet - INFO - Epoch [18][150/673]	lr: 0.01000, eta: 1:01:35, time: 0.300, data_time: 0.013, memory: 4416, loss_ins: 0.1988, loss_cate: 0.2803, loss: 0.4791
2021-07-21 07:55:51,290 - mmdet - INFO - Epoch [18][200/673]	lr: 0.01000, eta: 1:01:21, time: 0.302, data_time: 0.013, memory: 4416, loss_ins: 0.2350, loss_cate: 0.2330, loss: 0.4681
2021-07-21 07:56:06,392 - mmdet - INFO - Epoch [18][250/673]	lr: 0.01000, eta: 1:01:07, time: 0.302, data_time: 0.013, memory: 4416, loss_ins: 0.2293, loss_cate: 0.2620, loss: 0.4913
2021-07-21 07:56:21,145 - mmdet - INFO - Epoch [18][300/673]	lr: 0.01000, eta: 1:00:52, time: 0.295, data_time: 0.012, memory: 4416, loss_ins: 0.2066, loss_cate: 0.2540, loss: 0.4606
2021-07-21 07:56:35,983 - mmdet - INFO - Epoch [18][350/673]	lr: 0.01000, eta: 1:00:38, time: 0.297, data_time: 0.013, memory: 4416, loss_ins: 0.2256, loss_cate: 0.2783, loss: 0.5039
2021-07-21 07:56:51,190 - mmdet - INFO - Epoch [18][400/673]	lr: 0.01000, eta: 1:00:24, time: 0.304, data_time: 0.014, memory: 4416, loss_ins: 0.2410, loss_cate: 0.2757, loss: 0.5167
2021-07-21 07:57:06,269 - mmdet - INFO - Epoch [18][450/673]	lr: 0.01000, eta: 1:00:10, time: 0.302, data_time: 0.013, memory: 4416, loss_ins: 0.2409, loss_cate: 0.2678, loss: 0.5088
2021-07-21 07:57:21,273 - mmdet - INFO - Epoch [18][500/673]	lr: 0.01000, eta: 0:59:55, time: 0.300, data_time: 0.013, memory: 4416, loss_ins: 0.1943, loss_cate: 0.2534, loss: 0.4477
2021-07-21 07:57:35,959 - mmdet - INFO - Epoch [18][550/673]	lr: 0.01000, eta: 0:59:41, time: 0.294, data_time: 0.013, memory: 4416, loss_ins: 0.1982, loss_cate: 0.2629, loss: 0.4611
2021-07-21 07:57:51,060 - mmdet - INFO - Epoch [18][600/673]	lr: 0.01000, eta: 0:59:27, time: 0.302, data_time: 0.014, memory: 4416, loss_ins: 0.2254, loss_cate: 0.2649, loss: 0.4903
2021-07-21 07:58:06,360 - mmdet - INFO - Epoch [18][650/673]	lr: 0.01000, eta: 0:59:13, time: 0.306, data_time: 0.014, memory: 4416, loss_ins: 0.3104, loss_cate: 0.2699, loss: 0.5803
2021-07-21 07:58:28,912 - mmdet - INFO - Epoch [19][50/673]	lr: 0.01000, eta: 0:58:45, time: 0.303, data_time: 0.019, memory: 4416, loss_ins: 0.2100, loss_cate: 0.2434, loss: 0.4534
2021-07-21 07:58:43,784 - mmdet - INFO - Epoch [19][100/673]	lr: 0.01000, eta: 0:58:31, time: 0.297, data_time: 0.013, memory: 4416, loss_ins: 0.2137, loss_cate: 0.2550, loss: 0.4687
2021-07-21 07:58:58,574 - mmdet - INFO - Epoch [19][150/673]	lr: 0.01000, eta: 0:58:16, time: 0.296, data_time: 0.013, memory: 4416, loss_ins: 0.2301, loss_cate: 0.2955, loss: 0.5256
2021-07-21 07:59:13,299 - mmdet - INFO - Epoch [19][200/673]	lr: 0.01000, eta: 0:58:02, time: 0.295, data_time: 0.013, memory: 4416, loss_ins: 0.2142, loss_cate: 0.2482, loss: 0.4624
2021-07-21 07:59:28,147 - mmdet - INFO - Epoch [19][250/673]	lr: 0.01000, eta: 0:57:47, time: 0.297, data_time: 0.014, memory: 4416, loss_ins: 0.2243, loss_cate: 0.2537, loss: 0.4781
2021-07-21 07:59:43,287 - mmdet - INFO - Epoch [19][300/673]	lr: 0.01000, eta: 0:57:33, time: 0.303, data_time: 0.015, memory: 4416, loss_ins: 0.2249, loss_cate: 0.2339, loss: 0.4588
2021-07-21 07:59:58,444 - mmdet - INFO - Epoch [19][350/673]	lr: 0.01000, eta: 0:57:19, time: 0.303, data_time: 0.014, memory: 4416, loss_ins: 0.2280, loss_cate: 0.2520, loss: 0.4800
2021-07-21 08:00:13,606 - mmdet - INFO - Epoch [19][400/673]	lr: 0.01000, eta: 0:57:05, time: 0.303, data_time: 0.014, memory: 4416, loss_ins: 0.2602, loss_cate: 0.2945, loss: 0.5547
2021-07-21 08:00:28,161 - mmdet - INFO - Epoch [19][450/673]	lr: 0.01000, eta: 0:56:50, time: 0.291, data_time: 0.013, memory: 4416, loss_ins: 0.2225, loss_cate: 0.2704, loss: 0.4929
2021-07-21 08:00:43,181 - mmdet - INFO - Epoch [19][500/673]	lr: 0.01000, eta: 0:56:36, time: 0.300, data_time: 0.014, memory: 4416, loss_ins: 0.2435, loss_cate: 0.2701, loss: 0.5136
2021-07-21 08:00:58,351 - mmdet - INFO - Epoch [19][550/673]	lr: 0.01000, eta: 0:56:22, time: 0.303, data_time: 0.014, memory: 4416, loss_ins: 0.2540, loss_cate: 0.2511, loss: 0.5051
2021-07-21 08:01:13,108 - mmdet - INFO - Epoch [19][600/673]	lr: 0.01000, eta: 0:56:08, time: 0.295, data_time: 0.013, memory: 4416, loss_ins: 0.2067, loss_cate: 0.2566, loss: 0.4633
2021-07-21 08:01:28,051 - mmdet - INFO - Epoch [19][650/673]	lr: 0.01000, eta: 0:55:53, time: 0.299, data_time: 0.013, memory: 4416, loss_ins: 0.1907, loss_cate: 0.2694, loss: 0.4601
2021-07-21 08:01:50,839 - mmdet - INFO - Epoch [20][50/673]	lr: 0.01000, eta: 0:55:27, time: 0.309, data_time: 0.020, memory: 4416, loss_ins: 0.2235, loss_cate: 0.2393, loss: 0.4628
2021-07-21 08:02:05,842 - mmdet - INFO - Epoch [20][100/673]	lr: 0.01000, eta: 0:55:12, time: 0.300, data_time: 0.015, memory: 4416, loss_ins: 0.2129, loss_cate: 0.2656, loss: 0.4785
2021-07-21 08:02:21,154 - mmdet - INFO - Epoch [20][150/673]	lr: 0.01000, eta: 0:54:58, time: 0.306, data_time: 0.015, memory: 4416, loss_ins: 0.2212, loss_cate: 0.2720, loss: 0.4932
2021-07-21 08:02:36,154 - mmdet - INFO - Epoch [20][200/673]	lr: 0.01000, eta: 0:54:44, time: 0.300, data_time: 0.014, memory: 4416, loss_ins: 0.2004, loss_cate: 0.2491, loss: 0.4495
2021-07-21 08:02:51,111 - mmdet - INFO - Epoch [20][250/673]	lr: 0.01000, eta: 0:54:30, time: 0.299, data_time: 0.014, memory: 4416, loss_ins: 0.1958, loss_cate: 0.2620, loss: 0.4578
2021-07-21 08:03:06,150 - mmdet - INFO - Epoch [20][300/673]	lr: 0.01000, eta: 0:54:16, time: 0.301, data_time: 0.014, memory: 4416, loss_ins: 0.2336, loss_cate: 0.2520, loss: 0.4856
2021-07-21 08:03:21,179 - mmdet - INFO - Epoch [20][350/673]	lr: 0.01000, eta: 0:54:01, time: 0.301, data_time: 0.014, memory: 4416, loss_ins: 0.1784, loss_cate: 0.2412, loss: 0.4196
2021-07-21 08:03:36,351 - mmdet - INFO - Epoch [20][400/673]	lr: 0.01000, eta: 0:53:47, time: 0.303, data_time: 0.014, memory: 4416, loss_ins: 0.2413, loss_cate: 0.2493, loss: 0.4905
2021-07-21 08:03:51,513 - mmdet - INFO - Epoch [20][450/673]	lr: 0.01000, eta: 0:53:33, time: 0.303, data_time: 0.014, memory: 4416, loss_ins: 0.2457, loss_cate: 0.2513, loss: 0.4970
2021-07-21 08:04:06,540 - mmdet - INFO - Epoch [20][500/673]	lr: 0.01000, eta: 0:53:19, time: 0.301, data_time: 0.014, memory: 4416, loss_ins: 0.2763, loss_cate: 0.2761, loss: 0.5524
2021-07-21 08:04:21,585 - mmdet - INFO - Epoch [20][550/673]	lr: 0.01000, eta: 0:53:04, time: 0.301, data_time: 0.014, memory: 4416, loss_ins: 0.2236, loss_cate: 0.2651, loss: 0.4887
2021-07-21 08:04:36,482 - mmdet - INFO - Epoch [20][600/673]	lr: 0.01000, eta: 0:52:50, time: 0.298, data_time: 0.014, memory: 4416, loss_ins: 0.2135, loss_cate: 0.2541, loss: 0.4676
2021-07-21 08:04:51,782 - mmdet - INFO - Epoch [20][650/673]	lr: 0.01000, eta: 0:52:36, time: 0.306, data_time: 0.014, memory: 4416, loss_ins: 0.1979, loss_cate: 0.2493, loss: 0.4472
2021-07-21 08:05:14,274 - mmdet - INFO - Epoch [21][50/673]	lr: 0.01000, eta: 0:52:10, time: 0.302, data_time: 0.018, memory: 4416, loss_ins: 0.2049, loss_cate: 0.2580, loss: 0.4629
2021-07-21 08:05:29,446 - mmdet - INFO - Epoch [21][100/673]	lr: 0.01000, eta: 0:51:55, time: 0.303, data_time: 0.013, memory: 4416, loss_ins: 0.2270, loss_cate: 0.2699, loss: 0.4969
2021-07-21 08:05:44,372 - mmdet - INFO - Epoch [21][150/673]	lr: 0.01000, eta: 0:51:41, time: 0.299, data_time: 0.014, memory: 4416, loss_ins: 0.2211, loss_cate: 0.2515, loss: 0.4726
2021-07-21 08:05:59,069 - mmdet - INFO - Epoch [21][200/673]	lr: 0.01000, eta: 0:51:27, time: 0.294, data_time: 0.011, memory: 4416, loss_ins: 0.1803, loss_cate: 0.2451, loss: 0.4254
2021-07-21 08:06:14,095 - mmdet - INFO - Epoch [21][250/673]	lr: 0.01000, eta: 0:51:12, time: 0.301, data_time: 0.014, memory: 4416, loss_ins: 0.2274, loss_cate: 0.2575, loss: 0.4849
2021-07-21 08:06:29,174 - mmdet - INFO - Epoch [21][300/673]	lr: 0.01000, eta: 0:50:58, time: 0.302, data_time: 0.014, memory: 4416, loss_ins: 0.1807, loss_cate: 0.2479, loss: 0.4286
2021-07-21 08:06:44,233 - mmdet - INFO - Epoch [21][350/673]	lr: 0.01000, eta: 0:50:44, time: 0.301, data_time: 0.014, memory: 4416, loss_ins: 0.2459, loss_cate: 0.2567, loss: 0.5027
2021-07-21 08:06:59,089 - mmdet - INFO - Epoch [21][400/673]	lr: 0.01000, eta: 0:50:29, time: 0.297, data_time: 0.012, memory: 4416, loss_ins: 0.2149, loss_cate: 0.2679, loss: 0.4828
2021-07-21 08:07:14,175 - mmdet - INFO - Epoch [21][450/673]	lr: 0.01000, eta: 0:50:15, time: 0.302, data_time: 0.014, memory: 4416, loss_ins: 0.2207, loss_cate: 0.2719, loss: 0.4926
2021-07-21 08:07:29,063 - mmdet - INFO - Epoch [21][500/673]	lr: 0.01000, eta: 0:50:01, time: 0.298, data_time: 0.013, memory: 4416, loss_ins: 0.2422, loss_cate: 0.2769, loss: 0.5191
2021-07-21 08:07:43,862 - mmdet - INFO - Epoch [21][550/673]	lr: 0.01000, eta: 0:49:46, time: 0.296, data_time: 0.013, memory: 4416, loss_ins: 0.1874, loss_cate: 0.2564, loss: 0.4437
2021-07-21 08:07:58,808 - mmdet - INFO - Epoch [21][600/673]	lr: 0.01000, eta: 0:49:32, time: 0.299, data_time: 0.013, memory: 4416, loss_ins: 0.2189, loss_cate: 0.2486, loss: 0.4675
2021-07-21 08:08:13,846 - mmdet - INFO - Epoch [21][650/673]	lr: 0.01000, eta: 0:49:17, time: 0.301, data_time: 0.013, memory: 4416, loss_ins: 0.2276, loss_cate: 0.2622, loss: 0.4899
2021-07-21 08:08:36,322 - mmdet - INFO - Epoch [22][50/673]	lr: 0.01000, eta: 0:48:52, time: 0.307, data_time: 0.019, memory: 4416, loss_ins: 0.2003, loss_cate: 0.2619, loss: 0.4622
2021-07-21 08:08:51,582 - mmdet - INFO - Epoch [22][100/673]	lr: 0.01000, eta: 0:48:38, time: 0.305, data_time: 0.015, memory: 4416, loss_ins: 0.1928, loss_cate: 0.2356, loss: 0.4284
2021-07-21 08:09:06,786 - mmdet - INFO - Epoch [22][150/673]	lr: 0.01000, eta: 0:48:24, time: 0.304, data_time: 0.014, memory: 4416, loss_ins: 0.2107, loss_cate: 0.2570, loss: 0.4677
2021-07-21 08:09:21,809 - mmdet - INFO - Epoch [22][200/673]	lr: 0.01000, eta: 0:48:09, time: 0.300, data_time: 0.014, memory: 4416, loss_ins: 0.1873, loss_cate: 0.2566, loss: 0.4439
2021-07-21 08:09:36,937 - mmdet - INFO - Epoch [22][250/673]	lr: 0.01000, eta: 0:47:55, time: 0.303, data_time: 0.014, memory: 4416, loss_ins: 0.1893, loss_cate: 0.2288, loss: 0.4182
2021-07-21 08:09:52,453 - mmdet - INFO - Epoch [22][300/673]	lr: 0.01000, eta: 0:47:41, time: 0.310, data_time: 0.015, memory: 4416, loss_ins: 0.2411, loss_cate: 0.2434, loss: 0.4845
2021-07-21 08:10:07,667 - mmdet - INFO - Epoch [22][350/673]	lr: 0.01000, eta: 0:47:27, time: 0.304, data_time: 0.015, memory: 4416, loss_ins: 0.2374, loss_cate: 0.2540, loss: 0.4914
2021-07-21 08:10:23,025 - mmdet - INFO - Epoch [22][400/673]	lr: 0.01000, eta: 0:47:13, time: 0.307, data_time: 0.015, memory: 4416, loss_ins: 0.2085, loss_cate: 0.2364, loss: 0.4449
2021-07-21 08:10:38,080 - mmdet - INFO - Epoch [22][450/673]	lr: 0.01000, eta: 0:46:58, time: 0.301, data_time: 0.014, memory: 4416, loss_ins: 0.2083, loss_cate: 0.2429, loss: 0.4512
2021-07-21 08:10:53,406 - mmdet - INFO - Epoch [22][500/673]	lr: 0.01000, eta: 0:46:44, time: 0.307, data_time: 0.015, memory: 4416, loss_ins: 0.2183, loss_cate: 0.2465, loss: 0.4647
2021-07-21 08:11:08,438 - mmdet - INFO - Epoch [22][550/673]	lr: 0.01000, eta: 0:46:30, time: 0.301, data_time: 0.014, memory: 4416, loss_ins: 0.2159, loss_cate: 0.2481, loss: 0.4640
2021-07-21 08:11:23,509 - mmdet - INFO - Epoch [22][600/673]	lr: 0.01000, eta: 0:46:16, time: 0.301, data_time: 0.014, memory: 4416, loss_ins: 0.1598, loss_cate: 0.2286, loss: 0.3884
2021-07-21 08:11:38,700 - mmdet - INFO - Epoch [22][650/673]	lr: 0.01000, eta: 0:46:01, time: 0.304, data_time: 0.014, memory: 4416, loss_ins: 0.2046, loss_cate: 0.2494, loss: 0.4540
2021-07-21 08:12:01,529 - mmdet - INFO - Epoch [23][50/673]	lr: 0.01000, eta: 0:45:36, time: 0.307, data_time: 0.020, memory: 4416, loss_ins: 0.2242, loss_cate: 0.2407, loss: 0.4649
2021-07-21 08:12:16,820 - mmdet - INFO - Epoch [23][100/673]	lr: 0.01000, eta: 0:45:22, time: 0.306, data_time: 0.015, memory: 4416, loss_ins: 0.2108, loss_cate: 0.2423, loss: 0.4531
2021-07-21 08:12:32,047 - mmdet - INFO - Epoch [23][150/673]	lr: 0.01000, eta: 0:45:08, time: 0.305, data_time: 0.014, memory: 4416, loss_ins: 0.1941, loss_cate: 0.2390, loss: 0.4330
2021-07-21 08:12:47,019 - mmdet - INFO - Epoch [23][200/673]	lr: 0.01000, eta: 0:44:53, time: 0.299, data_time: 0.014, memory: 4416, loss_ins: 0.1812, loss_cate: 0.2539, loss: 0.4351
2021-07-21 08:13:02,054 - mmdet - INFO - Epoch [23][250/673]	lr: 0.01000, eta: 0:44:39, time: 0.301, data_time: 0.014, memory: 4416, loss_ins: 0.1755, loss_cate: 0.2332, loss: 0.4087
2021-07-21 08:13:17,270 - mmdet - INFO - Epoch [23][300/673]	lr: 0.01000, eta: 0:44:25, time: 0.304, data_time: 0.014, memory: 4416, loss_ins: 0.2288, loss_cate: 0.2548, loss: 0.4836
2021-07-21 08:13:32,328 - mmdet - INFO - Epoch [23][350/673]	lr: 0.01000, eta: 0:44:11, time: 0.301, data_time: 0.014, memory: 4416, loss_ins: 0.2071, loss_cate: 0.2413, loss: 0.4483
2021-07-21 08:13:47,216 - mmdet - INFO - Epoch [23][400/673]	lr: 0.01000, eta: 0:43:56, time: 0.298, data_time: 0.014, memory: 4416, loss_ins: 0.1725, loss_cate: 0.2283, loss: 0.4007
2021-07-21 08:14:02,153 - mmdet - INFO - Epoch [23][450/673]	lr: 0.01000, eta: 0:43:42, time: 0.299, data_time: 0.014, memory: 4416, loss_ins: 0.1638, loss_cate: 0.2429, loss: 0.4067
2021-07-21 08:14:17,065 - mmdet - INFO - Epoch [23][500/673]	lr: 0.01000, eta: 0:43:27, time: 0.298, data_time: 0.014, memory: 4416, loss_ins: 0.1817, loss_cate: 0.2527, loss: 0.4344
2021-07-21 08:14:32,107 - mmdet - INFO - Epoch [23][550/673]	lr: 0.01000, eta: 0:43:13, time: 0.301, data_time: 0.014, memory: 4416, loss_ins: 0.1790, loss_cate: 0.2226, loss: 0.4016
2021-07-21 08:14:47,204 - mmdet - INFO - Epoch [23][600/673]	lr: 0.01000, eta: 0:42:59, time: 0.302, data_time: 0.014, memory: 4416, loss_ins: 0.2132, loss_cate: 0.2535, loss: 0.4666
2021-07-21 08:15:02,255 - mmdet - INFO - Epoch [23][650/673]	lr: 0.01000, eta: 0:42:44, time: 0.301, data_time: 0.014, memory: 4416, loss_ins: 0.1844, loss_cate: 0.2552, loss: 0.4396
2021-07-21 08:15:25,029 - mmdet - INFO - Epoch [24][50/673]	lr: 0.01000, eta: 0:42:19, time: 0.306, data_time: 0.019, memory: 4416, loss_ins: 0.1570, loss_cate: 0.2376, loss: 0.3946
2021-07-21 08:15:40,206 - mmdet - INFO - Epoch [24][100/673]	lr: 0.01000, eta: 0:42:05, time: 0.304, data_time: 0.016, memory: 4416, loss_ins: 0.1713, loss_cate: 0.2425, loss: 0.4139
2021-07-21 08:15:55,409 - mmdet - INFO - Epoch [24][150/673]	lr: 0.01000, eta: 0:41:51, time: 0.304, data_time: 0.014, memory: 4416, loss_ins: 0.2080, loss_cate: 0.2411, loss: 0.4491
2021-07-21 08:16:10,412 - mmdet - INFO - Epoch [24][200/673]	lr: 0.01000, eta: 0:41:36, time: 0.300, data_time: 0.014, memory: 4416, loss_ins: 0.1625, loss_cate: 0.2310, loss: 0.3935
2021-07-21 08:16:25,285 - mmdet - INFO - Epoch [24][250/673]	lr: 0.01000, eta: 0:41:22, time: 0.297, data_time: 0.014, memory: 4416, loss_ins: 0.2149, loss_cate: 0.2354, loss: 0.4503
2021-07-21 08:16:40,392 - mmdet - INFO - Epoch [24][300/673]	lr: 0.01000, eta: 0:41:08, time: 0.302, data_time: 0.014, memory: 4416, loss_ins: 0.1916, loss_cate: 0.2450, loss: 0.4366
2021-07-21 08:16:55,458 - mmdet - INFO - Epoch [24][350/673]	lr: 0.01000, eta: 0:40:53, time: 0.301, data_time: 0.014, memory: 4416, loss_ins: 0.2219, loss_cate: 0.2576, loss: 0.4795
2021-07-21 08:17:10,651 - mmdet - INFO - Epoch [24][400/673]	lr: 0.01000, eta: 0:40:39, time: 0.304, data_time: 0.014, memory: 4416, loss_ins: 0.2127, loss_cate: 0.2386, loss: 0.4513
2021-07-21 08:17:25,722 - mmdet - INFO - Epoch [24][450/673]	lr: 0.01000, eta: 0:40:25, time: 0.301, data_time: 0.014, memory: 4416, loss_ins: 0.1584, loss_cate: 0.2368, loss: 0.3952
2021-07-21 08:17:40,776 - mmdet - INFO - Epoch [24][500/673]	lr: 0.01000, eta: 0:40:10, time: 0.301, data_time: 0.014, memory: 4416, loss_ins: 0.2030, loss_cate: 0.2530, loss: 0.4560
2021-07-21 08:17:56,068 - mmdet - INFO - Epoch [24][550/673]	lr: 0.01000, eta: 0:39:56, time: 0.306, data_time: 0.014, memory: 4416, loss_ins: 0.2065, loss_cate: 0.2359, loss: 0.4423
2021-07-21 08:18:11,254 - mmdet - INFO - Epoch [24][600/673]	lr: 0.01000, eta: 0:39:42, time: 0.304, data_time: 0.014, memory: 4416, loss_ins: 0.1900, loss_cate: 0.2417, loss: 0.4317
2021-07-21 08:18:26,170 - mmdet - INFO - Epoch [24][650/673]	lr: 0.01000, eta: 0:39:27, time: 0.298, data_time: 0.013, memory: 4416, loss_ins: 0.1962, loss_cate: 0.2545, loss: 0.4507
2021-07-21 08:18:48,699 - mmdet - INFO - Epoch [25][50/673]	lr: 0.01000, eta: 0:39:03, time: 0.310, data_time: 0.019, memory: 4416, loss_ins: 0.1550, loss_cate: 0.2239, loss: 0.3789
2021-07-21 08:19:03,923 - mmdet - INFO - Epoch [25][100/673]	lr: 0.01000, eta: 0:38:49, time: 0.304, data_time: 0.014, memory: 4416, loss_ins: 0.2100, loss_cate: 0.2336, loss: 0.4436
2021-07-21 08:19:18,596 - mmdet - INFO - Epoch [25][150/673]	lr: 0.01000, eta: 0:38:34, time: 0.293, data_time: 0.014, memory: 4416, loss_ins: 0.1538, loss_cate: 0.2157, loss: 0.3694
2021-07-21 08:19:33,434 - mmdet - INFO - Epoch [25][200/673]	lr: 0.01000, eta: 0:38:20, time: 0.297, data_time: 0.014, memory: 4416, loss_ins: 0.1870, loss_cate: 0.2416, loss: 0.4286
2021-07-21 08:19:48,337 - mmdet - INFO - Epoch [25][250/673]	lr: 0.01000, eta: 0:38:05, time: 0.298, data_time: 0.014, memory: 4416, loss_ins: 0.1743, loss_cate: 0.2445, loss: 0.4189
2021-07-21 08:20:03,383 - mmdet - INFO - Epoch [25][300/673]	lr: 0.01000, eta: 0:37:51, time: 0.301, data_time: 0.014, memory: 4416, loss_ins: 0.1912, loss_cate: 0.2297, loss: 0.4210
2021-07-21 08:20:18,724 - mmdet - INFO - Epoch [25][350/673]	lr: 0.01000, eta: 0:37:37, time: 0.307, data_time: 0.015, memory: 4416, loss_ins: 0.2049, loss_cate: 0.2362, loss: 0.4411
2021-07-21 08:20:33,562 - mmdet - INFO - Epoch [25][400/673]	lr: 0.01000, eta: 0:37:22, time: 0.297, data_time: 0.014, memory: 4416, loss_ins: 0.2131, loss_cate: 0.2285, loss: 0.4417
2021-07-21 08:20:48,730 - mmdet - INFO - Epoch [25][450/673]	lr: 0.01000, eta: 0:37:08, time: 0.303, data_time: 0.014, memory: 4416, loss_ins: 0.2150, loss_cate: 0.2510, loss: 0.4660
2021-07-21 08:21:03,845 - mmdet - INFO - Epoch [25][500/673]	lr: 0.01000, eta: 0:36:53, time: 0.302, data_time: 0.014, memory: 4416, loss_ins: 0.1652, loss_cate: 0.2344, loss: 0.3996
2021-07-21 08:21:18,865 - mmdet - INFO - Epoch [25][550/673]	lr: 0.01000, eta: 0:36:39, time: 0.300, data_time: 0.013, memory: 4416, loss_ins: 0.1930, loss_cate: 0.2646, loss: 0.4576
2021-07-21 08:21:33,775 - mmdet - INFO - Epoch [25][600/673]	lr: 0.01000, eta: 0:36:24, time: 0.298, data_time: 0.013, memory: 4416, loss_ins: 0.1839, loss_cate: 0.2443, loss: 0.4282
2021-07-21 08:21:48,682 - mmdet - INFO - Epoch [25][650/673]	lr: 0.01000, eta: 0:36:10, time: 0.298, data_time: 0.013, memory: 4416, loss_ins: 0.2056, loss_cate: 0.2428, loss: 0.4485
2021-07-21 08:22:10,996 - mmdet - INFO - Epoch [26][50/673]	lr: 0.01000, eta: 0:35:46, time: 0.301, data_time: 0.018, memory: 4416, loss_ins: 0.1656, loss_cate: 0.2416, loss: 0.4072
2021-07-21 08:22:25,981 - mmdet - INFO - Epoch [26][100/673]	lr: 0.01000, eta: 0:35:31, time: 0.300, data_time: 0.014, memory: 4416, loss_ins: 0.1724, loss_cate: 0.2380, loss: 0.4104
2021-07-21 08:22:41,025 - mmdet - INFO - Epoch [26][150/673]	lr: 0.01000, eta: 0:35:17, time: 0.301, data_time: 0.014, memory: 4416, loss_ins: 0.1932, loss_cate: 0.2263, loss: 0.4195
2021-07-21 08:22:56,113 - mmdet - INFO - Epoch [26][200/673]	lr: 0.01000, eta: 0:35:03, time: 0.302, data_time: 0.014, memory: 4416, loss_ins: 0.1826, loss_cate: 0.2729, loss: 0.4555
2021-07-21 08:23:11,043 - mmdet - INFO - Epoch [26][250/673]	lr: 0.01000, eta: 0:34:48, time: 0.299, data_time: 0.013, memory: 4416, loss_ins: 0.1770, loss_cate: 0.2423, loss: 0.4192
2021-07-21 08:23:25,966 - mmdet - INFO - Epoch [26][300/673]	lr: 0.01000, eta: 0:34:34, time: 0.298, data_time: 0.013, memory: 4416, loss_ins: 0.1940, loss_cate: 0.2364, loss: 0.4304
2021-07-21 08:23:40,986 - mmdet - INFO - Epoch [26][350/673]	lr: 0.01000, eta: 0:34:19, time: 0.300, data_time: 0.014, memory: 4416, loss_ins: 0.1909, loss_cate: 0.2263, loss: 0.4173
2021-07-21 08:23:56,165 - mmdet - INFO - Epoch [26][400/673]	lr: 0.01000, eta: 0:34:05, time: 0.304, data_time: 0.014, memory: 4416, loss_ins: 0.1820, loss_cate: 0.2201, loss: 0.4020
2021-07-21 08:24:10,951 - mmdet - INFO - Epoch [26][450/673]	lr: 0.01000, eta: 0:33:50, time: 0.296, data_time: 0.012, memory: 4416, loss_ins: 0.1908, loss_cate: 0.2360, loss: 0.4268
2021-07-21 08:24:25,757 - mmdet - INFO - Epoch [26][500/673]	lr: 0.01000, eta: 0:33:36, time: 0.296, data_time: 0.012, memory: 4416, loss_ins: 0.1593, loss_cate: 0.2223, loss: 0.3817
2021-07-21 08:24:40,490 - mmdet - INFO - Epoch [26][550/673]	lr: 0.01000, eta: 0:33:21, time: 0.295, data_time: 0.013, memory: 4416, loss_ins: 0.1757, loss_cate: 0.2370, loss: 0.4127
2021-07-21 08:24:55,581 - mmdet - INFO - Epoch [26][600/673]	lr: 0.01000, eta: 0:33:07, time: 0.302, data_time: 0.013, memory: 4416, loss_ins: 0.1725, loss_cate: 0.2312, loss: 0.4037
2021-07-21 08:25:10,683 - mmdet - INFO - Epoch [26][650/673]	lr: 0.01000, eta: 0:32:52, time: 0.302, data_time: 0.014, memory: 4416, loss_ins: 0.2089, loss_cate: 0.2479, loss: 0.4568
2021-07-21 08:25:33,419 - mmdet - INFO - Epoch [27][50/673]	lr: 0.01000, eta: 0:32:29, time: 0.306, data_time: 0.018, memory: 4416, loss_ins: 0.1592, loss_cate: 0.2126, loss: 0.3717
2021-07-21 08:25:48,505 - mmdet - INFO - Epoch [27][100/673]	lr: 0.01000, eta: 0:32:14, time: 0.302, data_time: 0.015, memory: 4416, loss_ins: 0.1588, loss_cate: 0.2277, loss: 0.3864
2021-07-21 08:26:03,547 - mmdet - INFO - Epoch [27][150/673]	lr: 0.01000, eta: 0:32:00, time: 0.301, data_time: 0.014, memory: 4416, loss_ins: 0.1580, loss_cate: 0.2207, loss: 0.3787
2021-07-21 08:26:18,464 - mmdet - INFO - Epoch [27][200/673]	lr: 0.01000, eta: 0:31:46, time: 0.298, data_time: 0.014, memory: 4416, loss_ins: 0.1895, loss_cate: 0.2442, loss: 0.4337
2021-07-21 08:26:33,549 - mmdet - INFO - Epoch [27][250/673]	lr: 0.01000, eta: 0:31:31, time: 0.302, data_time: 0.014, memory: 4416, loss_ins: 0.2170, loss_cate: 0.2536, loss: 0.4706
2021-07-21 08:26:48,578 - mmdet - INFO - Epoch [27][300/673]	lr: 0.01000, eta: 0:31:17, time: 0.301, data_time: 0.013, memory: 4416, loss_ins: 0.1699, loss_cate: 0.2381, loss: 0.4081
2021-07-21 08:27:03,718 - mmdet - INFO - Epoch [27][350/673]	lr: 0.01000, eta: 0:31:02, time: 0.303, data_time: 0.013, memory: 4416, loss_ins: 0.1749, loss_cate: 0.2216, loss: 0.3965
2021-07-21 08:27:18,480 - mmdet - INFO - Epoch [27][400/673]	lr: 0.01000, eta: 0:30:48, time: 0.295, data_time: 0.013, memory: 4416, loss_ins: 0.1542, loss_cate: 0.2378, loss: 0.3920
2021-07-21 08:27:33,501 - mmdet - INFO - Epoch [27][450/673]	lr: 0.01000, eta: 0:30:33, time: 0.300, data_time: 0.014, memory: 4416, loss_ins: 0.1353, loss_cate: 0.2300, loss: 0.3653
2021-07-21 08:27:48,538 - mmdet - INFO - Epoch [27][500/673]	lr: 0.01000, eta: 0:30:19, time: 0.301, data_time: 0.013, memory: 4416, loss_ins: 0.1724, loss_cate: 0.2249, loss: 0.3972
2021-07-21 08:28:03,592 - mmdet - INFO - Epoch [27][550/673]	lr: 0.01000, eta: 0:30:04, time: 0.301, data_time: 0.014, memory: 4416, loss_ins: 0.1976, loss_cate: 0.2166, loss: 0.4141
2021-07-21 08:28:18,916 - mmdet - INFO - Epoch [27][600/673]	lr: 0.01000, eta: 0:29:50, time: 0.306, data_time: 0.014, memory: 4416, loss_ins: 0.1985, loss_cate: 0.2522, loss: 0.4507
2021-07-21 08:28:33,991 - mmdet - INFO - Epoch [27][650/673]	lr: 0.01000, eta: 0:29:36, time: 0.301, data_time: 0.014, memory: 4416, loss_ins: 0.1754, loss_cate: 0.2471, loss: 0.4225
2021-07-21 08:29:03,368 - mmdet - INFO - Epoch [28][50/673]	lr: 0.00100, eta: 0:29:14, time: 0.437, data_time: 0.018, memory: 4416, loss_ins: 0.1622, loss_cate: 0.2204, loss: 0.3826
2021-07-21 08:29:19,687 - mmdet - INFO - Epoch [28][100/673]	lr: 0.00100, eta: 0:29:00, time: 0.326, data_time: 0.015, memory: 4416, loss_ins: 0.1773, loss_cate: 0.2189, loss: 0.3962
2021-07-21 08:29:34,507 - mmdet - INFO - Epoch [28][150/673]	lr: 0.00100, eta: 0:28:46, time: 0.296, data_time: 0.014, memory: 4416, loss_ins: 0.1521, loss_cate: 0.1943, loss: 0.3464
2021-07-21 08:29:49,627 - mmdet - INFO - Epoch [28][200/673]	lr: 0.00100, eta: 0:28:31, time: 0.302, data_time: 0.015, memory: 4416, loss_ins: 0.1453, loss_cate: 0.2027, loss: 0.3480
2021-07-21 08:30:04,442 - mmdet - INFO - Epoch [28][250/673]	lr: 0.00100, eta: 0:28:17, time: 0.296, data_time: 0.013, memory: 4416, loss_ins: 0.1516, loss_cate: 0.2356, loss: 0.3873
2021-07-21 08:30:19,624 - mmdet - INFO - Epoch [28][300/673]	lr: 0.00100, eta: 0:28:02, time: 0.304, data_time: 0.014, memory: 4416, loss_ins: 0.1393, loss_cate: 0.2057, loss: 0.3451
2021-07-21 08:30:34,863 - mmdet - INFO - Epoch [28][350/673]	lr: 0.00100, eta: 0:27:48, time: 0.305, data_time: 0.013, memory: 4416, loss_ins: 0.1503, loss_cate: 0.2111, loss: 0.3614
2021-07-21 08:30:56,015 - mmdet - INFO - Epoch [28][400/673]	lr: 0.00100, eta: 0:27:35, time: 0.423, data_time: 0.013, memory: 4416, loss_ins: 0.1427, loss_cate: 0.2099, loss: 0.3526
2021-07-21 08:31:12,359 - mmdet - INFO - Epoch [28][450/673]	lr: 0.00100, eta: 0:27:21, time: 0.327, data_time: 0.014, memory: 4416, loss_ins: 0.1482, loss_cate: 0.2066, loss: 0.3549
2021-07-21 08:31:27,523 - mmdet - INFO - Epoch [28][500/673]	lr: 0.00100, eta: 0:27:07, time: 0.303, data_time: 0.013, memory: 4416, loss_ins: 0.1729, loss_cate: 0.2043, loss: 0.3771
2021-07-21 08:31:42,672 - mmdet - INFO - Epoch [28][550/673]	lr: 0.00100, eta: 0:26:52, time: 0.303, data_time: 0.014, memory: 4416, loss_ins: 0.1483, loss_cate: 0.2207, loss: 0.3691
2021-07-21 08:31:57,806 - mmdet - INFO - Epoch [28][600/673]	lr: 0.00100, eta: 0:26:38, time: 0.303, data_time: 0.014, memory: 4416, loss_ins: 0.1189, loss_cate: 0.2091, loss: 0.3279
2021-07-21 08:32:13,035 - mmdet - INFO - Epoch [28][650/673]	lr: 0.00100, eta: 0:26:23, time: 0.305, data_time: 0.014, memory: 4416, loss_ins: 0.1501, loss_cate: 0.2022, loss: 0.3523
2021-07-21 08:32:35,983 - mmdet - INFO - Epoch [29][50/673]	lr: 0.00100, eta: 0:26:00, time: 0.314, data_time: 0.021, memory: 4416, loss_ins: 0.1330, loss_cate: 0.1880, loss: 0.3209
2021-07-21 08:32:51,446 - mmdet - INFO - Epoch [29][100/673]	lr: 0.00100, eta: 0:25:46, time: 0.309, data_time: 0.017, memory: 4416, loss_ins: 0.1344, loss_cate: 0.1976, loss: 0.3320
2021-07-21 08:33:06,592 - mmdet - INFO - Epoch [29][150/673]	lr: 0.00100, eta: 0:25:31, time: 0.303, data_time: 0.015, memory: 4416, loss_ins: 0.1438, loss_cate: 0.2111, loss: 0.3548
2021-07-21 08:33:22,034 - mmdet - INFO - Epoch [29][200/673]	lr: 0.00100, eta: 0:25:17, time: 0.309, data_time: 0.014, memory: 4416, loss_ins: 0.1480, loss_cate: 0.2103, loss: 0.3583
2021-07-21 08:33:37,642 - mmdet - INFO - Epoch [29][250/673]	lr: 0.00100, eta: 0:25:03, time: 0.312, data_time: 0.016, memory: 4416, loss_ins: 0.1704, loss_cate: 0.1996, loss: 0.3700
2021-07-21 08:33:52,672 - mmdet - INFO - Epoch [29][300/673]	lr: 0.00100, eta: 0:24:48, time: 0.301, data_time: 0.014, memory: 4416, loss_ins: 0.1252, loss_cate: 0.2025, loss: 0.3277
2021-07-21 08:34:08,056 - mmdet - INFO - Epoch [29][350/673]	lr: 0.00100, eta: 0:24:34, time: 0.308, data_time: 0.015, memory: 4416, loss_ins: 0.1440, loss_cate: 0.1970, loss: 0.3410
2021-07-21 08:34:23,135 - mmdet - INFO - Epoch [29][400/673]	lr: 0.00100, eta: 0:24:19, time: 0.302, data_time: 0.014, memory: 4416, loss_ins: 0.1469, loss_cate: 0.2064, loss: 0.3533
2021-07-21 08:34:38,414 - mmdet - INFO - Epoch [29][450/673]	lr: 0.00100, eta: 0:24:05, time: 0.306, data_time: 0.014, memory: 4416, loss_ins: 0.1355, loss_cate: 0.1959, loss: 0.3315
2021-07-21 08:34:53,537 - mmdet - INFO - Epoch [29][500/673]	lr: 0.00100, eta: 0:23:50, time: 0.302, data_time: 0.014, memory: 4416, loss_ins: 0.1549, loss_cate: 0.1796, loss: 0.3345
2021-07-21 08:35:08,835 - mmdet - INFO - Epoch [29][550/673]	lr: 0.00100, eta: 0:23:36, time: 0.306, data_time: 0.014, memory: 4416, loss_ins: 0.1538, loss_cate: 0.1941, loss: 0.3479
2021-07-21 08:35:23,833 - mmdet - INFO - Epoch [29][600/673]	lr: 0.00100, eta: 0:23:21, time: 0.300, data_time: 0.014, memory: 4416, loss_ins: 0.1471, loss_cate: 0.1870, loss: 0.3341
2021-07-21 08:35:38,836 - mmdet - INFO - Epoch [29][650/673]	lr: 0.00100, eta: 0:23:06, time: 0.300, data_time: 0.014, memory: 4416, loss_ins: 0.1242, loss_cate: 0.2018, loss: 0.3260
2021-07-21 08:36:01,857 - mmdet - INFO - Epoch [30][50/673]	lr: 0.00100, eta: 0:22:44, time: 0.307, data_time: 0.019, memory: 4416, loss_ins: 0.1347, loss_cate: 0.2057, loss: 0.3404
2021-07-21 08:36:17,075 - mmdet - INFO - Epoch [30][100/673]	lr: 0.00100, eta: 0:22:29, time: 0.304, data_time: 0.012, memory: 4416, loss_ins: 0.1306, loss_cate: 0.2022, loss: 0.3328
2021-07-21 08:36:32,293 - mmdet - INFO - Epoch [30][150/673]	lr: 0.00100, eta: 0:22:15, time: 0.304, data_time: 0.013, memory: 4416, loss_ins: 0.1447, loss_cate: 0.2002, loss: 0.3449
2021-07-21 08:36:47,513 - mmdet - INFO - Epoch [30][200/673]	lr: 0.00100, eta: 0:22:00, time: 0.304, data_time: 0.015, memory: 4416, loss_ins: 0.1485, loss_cate: 0.2000, loss: 0.3485
2021-07-21 08:37:02,767 - mmdet - INFO - Epoch [30][250/673]	lr: 0.00100, eta: 0:21:46, time: 0.305, data_time: 0.014, memory: 4416, loss_ins: 0.1334, loss_cate: 0.1894, loss: 0.3229
2021-07-21 08:37:22,450 - mmdet - INFO - Epoch [30][300/673]	lr: 0.00100, eta: 0:21:32, time: 0.394, data_time: 0.014, memory: 4416, loss_ins: 0.1351, loss_cate: 0.1971, loss: 0.3322
2021-07-21 08:37:41,232 - mmdet - INFO - Epoch [30][350/673]	lr: 0.00100, eta: 0:21:18, time: 0.376, data_time: 0.015, memory: 4416, loss_ins: 0.1456, loss_cate: 0.1982, loss: 0.3439
2021-07-21 08:38:02,892 - mmdet - INFO - Epoch [30][400/673]	lr: 0.00100, eta: 0:21:05, time: 0.433, data_time: 0.015, memory: 4416, loss_ins: 0.1467, loss_cate: 0.2095, loss: 0.3562
2021-07-21 08:38:19,305 - mmdet - INFO - Epoch [30][450/673]	lr: 0.00100, eta: 0:20:51, time: 0.328, data_time: 0.014, memory: 4416, loss_ins: 0.1437, loss_cate: 0.2063, loss: 0.3500
2021-07-21 08:38:34,852 - mmdet - INFO - Epoch [30][500/673]	lr: 0.00100, eta: 0:20:36, time: 0.311, data_time: 0.015, memory: 4416, loss_ins: 0.1718, loss_cate: 0.2003, loss: 0.3721
2021-07-21 08:38:50,258 - mmdet - INFO - Epoch [30][550/673]	lr: 0.00100, eta: 0:20:22, time: 0.308, data_time: 0.015, memory: 4416, loss_ins: 0.1379, loss_cate: 0.1877, loss: 0.3257
2021-07-21 08:39:05,194 - mmdet - INFO - Epoch [30][600/673]	lr: 0.00100, eta: 0:20:07, time: 0.299, data_time: 0.014, memory: 4416, loss_ins: 0.1329, loss_cate: 0.2558, loss: 0.3888
2021-07-21 08:39:20,140 - mmdet - INFO - Epoch [30][650/673]	lr: 0.00100, eta: 0:19:53, time: 0.299, data_time: 0.013, memory: 4416, loss_ins: 0.1329, loss_cate: 0.1859, loss: 0.3188
2021-07-21 08:39:43,213 - mmdet - INFO - Epoch [31][50/673]	lr: 0.00100, eta: 0:19:30, time: 0.309, data_time: 0.018, memory: 4416, loss_ins: 0.1452, loss_cate: 0.1978, loss: 0.3430
2021-07-21 08:39:58,514 - mmdet - INFO - Epoch [31][100/673]	lr: 0.00100, eta: 0:19:15, time: 0.306, data_time: 0.013, memory: 4416, loss_ins: 0.1302, loss_cate: 0.1998, loss: 0.3300
2021-07-21 08:40:13,522 - mmdet - INFO - Epoch [31][150/673]	lr: 0.00100, eta: 0:19:01, time: 0.300, data_time: 0.013, memory: 4416, loss_ins: 0.1206, loss_cate: 0.2186, loss: 0.3392
2021-07-21 08:40:28,657 - mmdet - INFO - Epoch [31][200/673]	lr: 0.00100, eta: 0:18:46, time: 0.303, data_time: 0.013, memory: 4416, loss_ins: 0.1487, loss_cate: 0.2127, loss: 0.3614
2021-07-21 08:40:43,856 - mmdet - INFO - Epoch [31][250/673]	lr: 0.00100, eta: 0:18:32, time: 0.304, data_time: 0.013, memory: 4416, loss_ins: 0.1391, loss_cate: 0.1971, loss: 0.3362
2021-07-21 08:40:58,982 - mmdet - INFO - Epoch [31][300/673]	lr: 0.00100, eta: 0:18:17, time: 0.303, data_time: 0.014, memory: 4416, loss_ins: 0.1580, loss_cate: 0.1985, loss: 0.3565
2021-07-21 08:41:13,934 - mmdet - INFO - Epoch [31][350/673]	lr: 0.00100, eta: 0:18:02, time: 0.299, data_time: 0.013, memory: 4416, loss_ins: 0.1168, loss_cate: 0.2019, loss: 0.3187
2021-07-21 08:41:29,387 - mmdet - INFO - Epoch [31][400/673]	lr: 0.00100, eta: 0:17:48, time: 0.309, data_time: 0.014, memory: 4416, loss_ins: 0.1308, loss_cate: 0.1826, loss: 0.3134
2021-07-21 08:41:45,156 - mmdet - INFO - Epoch [31][450/673]	lr: 0.00100, eta: 0:17:33, time: 0.315, data_time: 0.014, memory: 4416, loss_ins: 0.1440, loss_cate: 0.1949, loss: 0.3390
2021-07-21 08:42:00,158 - mmdet - INFO - Epoch [31][500/673]	lr: 0.00100, eta: 0:17:19, time: 0.300, data_time: 0.013, memory: 4416, loss_ins: 0.1321, loss_cate: 0.1875, loss: 0.3196
2021-07-21 08:42:15,333 - mmdet - INFO - Epoch [31][550/673]	lr: 0.00100, eta: 0:17:04, time: 0.303, data_time: 0.014, memory: 4416, loss_ins: 0.1327, loss_cate: 0.1896, loss: 0.3223
2021-07-21 08:42:30,388 - mmdet - INFO - Epoch [31][600/673]	lr: 0.00100, eta: 0:16:50, time: 0.301, data_time: 0.013, memory: 4416, loss_ins: 0.1387, loss_cate: 0.2001, loss: 0.3388
2021-07-21 08:42:45,814 - mmdet - INFO - Epoch [31][650/673]	lr: 0.00100, eta: 0:16:35, time: 0.309, data_time: 0.014, memory: 4416, loss_ins: 0.1391, loss_cate: 0.1964, loss: 0.3355
2021-07-21 08:43:08,352 - mmdet - INFO - Epoch [32][50/673]	lr: 0.00100, eta: 0:16:12, time: 0.300, data_time: 0.018, memory: 4416, loss_ins: 0.1317, loss_cate: 0.1887, loss: 0.3204
2021-07-21 08:43:23,218 - mmdet - INFO - Epoch [32][100/673]	lr: 0.00100, eta: 0:15:58, time: 0.297, data_time: 0.014, memory: 4416, loss_ins: 0.1475, loss_cate: 0.1967, loss: 0.3442
2021-07-21 08:43:38,501 - mmdet - INFO - Epoch [32][150/673]	lr: 0.00100, eta: 0:15:43, time: 0.306, data_time: 0.014, memory: 4416, loss_ins: 0.1477, loss_cate: 0.1858, loss: 0.3336
2021-07-21 08:43:53,641 - mmdet - INFO - Epoch [32][200/673]	lr: 0.00100, eta: 0:15:29, time: 0.303, data_time: 0.014, memory: 4416, loss_ins: 0.1423, loss_cate: 0.1931, loss: 0.3355
2021-07-21 08:44:08,817 - mmdet - INFO - Epoch [32][250/673]	lr: 0.00100, eta: 0:15:14, time: 0.304, data_time: 0.014, memory: 4416, loss_ins: 0.1431, loss_cate: 0.1943, loss: 0.3374
2021-07-21 08:44:23,327 - mmdet - INFO - Epoch [32][300/673]	lr: 0.00100, eta: 0:14:59, time: 0.290, data_time: 0.012, memory: 4416, loss_ins: 0.1302, loss_cate: 0.1995, loss: 0.3297
2021-07-21 08:44:38,477 - mmdet - INFO - Epoch [32][350/673]	lr: 0.00100, eta: 0:14:45, time: 0.303, data_time: 0.014, memory: 4416, loss_ins: 0.1162, loss_cate: 0.1985, loss: 0.3146
2021-07-21 08:44:53,671 - mmdet - INFO - Epoch [32][400/673]	lr: 0.00100, eta: 0:14:30, time: 0.304, data_time: 0.014, memory: 4416, loss_ins: 0.1408, loss_cate: 0.1859, loss: 0.3267
2021-07-21 08:45:08,799 - mmdet - INFO - Epoch [32][450/673]	lr: 0.00100, eta: 0:14:15, time: 0.303, data_time: 0.013, memory: 4416, loss_ins: 0.1192, loss_cate: 0.1841, loss: 0.3033
2021-07-21 08:45:23,640 - mmdet - INFO - Epoch [32][500/673]	lr: 0.00100, eta: 0:14:01, time: 0.297, data_time: 0.013, memory: 4416, loss_ins: 0.1447, loss_cate: 0.1955, loss: 0.3402
2021-07-21 08:45:38,602 - mmdet - INFO - Epoch [32][550/673]	lr: 0.00100, eta: 0:13:46, time: 0.299, data_time: 0.013, memory: 4416, loss_ins: 0.1464, loss_cate: 0.1926, loss: 0.3390
2021-07-21 08:45:53,628 - mmdet - INFO - Epoch [32][600/673]	lr: 0.00100, eta: 0:13:32, time: 0.301, data_time: 0.013, memory: 4416, loss_ins: 0.1281, loss_cate: 0.1981, loss: 0.3262
2021-07-21 08:46:08,658 - mmdet - INFO - Epoch [32][650/673]	lr: 0.00100, eta: 0:13:17, time: 0.301, data_time: 0.013, memory: 4416, loss_ins: 0.1232, loss_cate: 0.1920, loss: 0.3151
2021-07-21 08:46:31,511 - mmdet - INFO - Epoch [33][50/673]	lr: 0.00100, eta: 0:12:55, time: 0.311, data_time: 0.021, memory: 4416, loss_ins: 0.1543, loss_cate: 0.1814, loss: 0.3358
2021-07-21 08:46:46,550 - mmdet - INFO - Epoch [33][100/673]	lr: 0.00100, eta: 0:12:40, time: 0.301, data_time: 0.016, memory: 4416, loss_ins: 0.1282, loss_cate: 0.2075, loss: 0.3357
2021-07-21 08:47:01,549 - mmdet - INFO - Epoch [33][150/673]	lr: 0.00100, eta: 0:12:25, time: 0.300, data_time: 0.015, memory: 4416, loss_ins: 0.1307, loss_cate: 0.1957, loss: 0.3264
2021-07-21 08:47:16,790 - mmdet - INFO - Epoch [33][200/673]	lr: 0.00100, eta: 0:12:11, time: 0.305, data_time: 0.016, memory: 4416, loss_ins: 0.1285, loss_cate: 0.1962, loss: 0.3248
2021-07-21 08:47:32,296 - mmdet - INFO - Epoch [33][250/673]	lr: 0.00100, eta: 0:11:56, time: 0.310, data_time: 0.015, memory: 4416, loss_ins: 0.1529, loss_cate: 0.1746, loss: 0.3276
2021-07-21 08:47:47,558 - mmdet - INFO - Epoch [33][300/673]	lr: 0.00100, eta: 0:11:42, time: 0.305, data_time: 0.015, memory: 4416, loss_ins: 0.1283, loss_cate: 0.1824, loss: 0.3107
2021-07-21 08:48:02,311 - mmdet - INFO - Epoch [33][350/673]	lr: 0.00100, eta: 0:11:27, time: 0.295, data_time: 0.014, memory: 4416, loss_ins: 0.1220, loss_cate: 0.1842, loss: 0.3062
2021-07-21 08:48:17,440 - mmdet - INFO - Epoch [33][400/673]	lr: 0.00100, eta: 0:11:12, time: 0.303, data_time: 0.016, memory: 4416, loss_ins: 0.1498, loss_cate: 0.2017, loss: 0.3514
2021-07-21 08:48:32,904 - mmdet - INFO - Epoch [33][450/673]	lr: 0.00100, eta: 0:10:58, time: 0.309, data_time: 0.016, memory: 4416, loss_ins: 0.1316, loss_cate: 0.1998, loss: 0.3314
Traceback (most recent call last):
  File "tools/train.py", line 133, in <module>
    main()
  File "tools/train.py", line 129, in main
    timestamp=timestamp)
  File "/home/zq/work/SOLO/mmdet/apis/train.py", line 111, in train_detector
    timestamp=timestamp)
  File "/home/zq/work/SOLO/mmdet/apis/train.py", line 297, in _non_dist_train
    runner.run(data_loaders, cfg.workflow, cfg.total_epochs)
  File "/opt/conda/lib/python3.6/site-packages/mmcv/runner/runner.py", line 364, in run
    epoch_runner(data_loaders[i], **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/mmcv/runner/runner.py", line 268, in train
    self.model, data_batch, train_mode=True, **kwargs)
  File "/home/zq/work/SOLO/mmdet/apis/train.py", line 78, in batch_processor
    losses = model(**data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py", line 150, in forward
    return self.module(*inputs[0], **kwargs[0])
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/zq/work/SOLO/mmdet/core/fp16/decorators.py", line 49, in new_func
    return old_func(*args, **kwargs)
  File "/home/zq/work/SOLO/mmdet/models/detectors/base.py", line 142, in forward
    return self.forward_train(img, img_meta, **kwargs)
  File "/home/zq/work/SOLO/mmdet/models/detectors/single_stage_ins.py", line 78, in forward_train
    *loss_inputs, gt_bboxes_ignore=gt_bboxes_ignore)
  File "/home/zq/work/SOLO/mmdet/models/anchor_heads/solov2_head.py", line 200, in loss
    mask_feat_size=mask_feat_size)
  File "/home/zq/work/SOLO/mmdet/core/utils/misc.py", line 24, in multi_apply
    return tuple(map(list, zip(*map_results)))
  File "/home/zq/work/SOLO/mmdet/models/anchor_heads/solov2_head.py", line 271, in solov2_target_single
    def solov2_target_single(self,
KeyboardInterrupt
2021-07-21 08:49:25,934 - mmdet - INFO - Distributed training: False
2021-07-21 08:49:25,934 - mmdet - INFO - MMDetection Version: 1.0.0+c7b294a
2021-07-21 08:49:25,934 - mmdet - INFO - Config:
# model settings
model = dict(
    type='SOLOv2',
    pretrained='torchvision://resnet50',
    backbone=dict(
        type='ResNet',
        depth=50,
        num_stages=4,
        out_indices=(0, 1, 2, 3),  # C2, C3, C4, C5
        frozen_stages=1,
        style='pytorch'),
    neck=dict(
        type='FPN',
        in_channels=[256, 512, 1024, 2048],
        out_channels=256,
        start_level=0,
        num_outs=5),
    bbox_head=dict(
        type='SOLOv2Head',
        num_classes=2,
        in_channels=256,
        stacked_convs=4,
        seg_feat_channels=512,
        strides=[8, 8, 16, 32, 32],
        scale_ranges=((1, 96), (48, 192), (96, 384), (192, 768), (384, 2048)),
        # scale_ranges=((1, 376), (188, 752), (752, 1400)),
        sigma=0.2,
        num_grids=[40, 36, 24, 16, 12],
        ins_out_channels=256,
        loss_ins=dict(
            type='DiceLoss',
            use_sigmoid=True,
            # loss_weight=3.0),
            loss_weight=10.0),
        loss_cate=dict(
            type='FocalLoss',
            use_sigmoid=True,
            gamma=2.0,
            alpha=0.25,
            loss_weight=1.0)),
    mask_feat_head=dict(
        type='MaskFeatHead',
        in_channels=256,
        out_channels=128,
        start_level=0,
        end_level=3,
        num_classes=256,
        norm_cfg=dict(type='GN', num_groups=32, requires_grad=True)),
)
# training and testing settings
train_cfg = dict()
test_cfg = dict(
    nms_pre=500,
    score_thr=0.1,
    mask_thr=0.5,
    update_thr=0.05,
    kernel='gaussian',  # gaussian/linear
    sigma=2.0,
    max_per_img=100)
# dataset settings
dataset_type = 'CocoDataset'
data_root = 'data/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),
    dict(type='Resize',
         img_scale=[(1333, 800), (1333, 768), (1333, 736),
                    (1333, 704), (1333, 672), (1333, 640)],
         multiscale_mode='value',
         keep_ratio=True),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(type='Normalize', **img_norm_cfg),
    dict(type='Pad', size_divisor=32),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks']),
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(1333, 800),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(type='Normalize', **img_norm_cfg),
            dict(type='Pad', size_divisor=32),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img']),
        ])
]
data = dict(
    imgs_per_gpu=2,
    workers_per_gpu=2,
    train=dict(
        type=dataset_type,
        ann_file=data_root + 'annotation/merge/merge_train_coco.json',
        img_prefix=data_root + 'road/train/',
        pipeline=train_pipeline),
    val=dict(
        type=dataset_type,
        ann_file=data_root + 'annotation/merge/merge_val_coco.json',
        img_prefix=data_root + 'road/val/',
        pipeline=test_pipeline),
    test=dict(
        type=dataset_type,
        ann_file=data_root + 'annotation/merge/merge_val_coco.json',
        img_prefix=data_root + 'road/val/',
        pipeline=test_pipeline))
# optimizer
optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0001)
optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))
# learning policy
lr_config = dict(
    policy='step',
    warmup='linear',
    warmup_iters=500,
    warmup_ratio=0.01,
    step=[27, 33])
checkpoint_config = dict(interval=1)
# yapf:disable
log_config = dict(
    interval=50,
    hooks=[
        dict(type='TextLoggerHook'),
        # dict(type='TensorboardLoggerHook')
    ])
# yapf:enable
# runtime settings
total_epochs = 36
device_ids = range(8)
dist_params = dict(backend='nccl')
log_level = 'INFO'
# work_dir = './work_dirs/solov2_release_r50_fpn_8gpu_3x'
# work_dir = './work_dirs/solov2_release_r50_fpn_8gpu_3x_scale'
work_dir = './work_dirs/solov2_release_r50_fpn_8gpu_3x_weight'
load_from = None
resume_from = None
workflow = [('train', 1)]
# workflow = [('train', 1), ('val', 1)]

2021-07-21 08:49:26,339 - mmdet - INFO - load model from: torchvision://resnet50
2021-07-21 08:49:28,689 - mmdet - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: backbone.conv1.weight, backbone.bn1.weight, backbone.bn1.bias, backbone.bn1.running_mean, backbone.bn1.running_var, backbone.bn1.num_batches_tracked, backbone.layer1.0.conv1.weight, backbone.layer1.0.bn1.weight, backbone.layer1.0.bn1.bias, backbone.layer1.0.bn1.running_mean, backbone.layer1.0.bn1.running_var, backbone.layer1.0.bn1.num_batches_tracked, backbone.layer1.0.conv2.weight, backbone.layer1.0.bn2.weight, backbone.layer1.0.bn2.bias, backbone.layer1.0.bn2.running_mean, backbone.layer1.0.bn2.running_var, backbone.layer1.0.bn2.num_batches_tracked, backbone.layer1.0.conv3.weight, backbone.layer1.0.bn3.weight, backbone.layer1.0.bn3.bias, backbone.layer1.0.bn3.running_mean, backbone.layer1.0.bn3.running_var, backbone.layer1.0.bn3.num_batches_tracked, backbone.layer1.0.downsample.0.weight, backbone.layer1.0.downsample.1.weight, backbone.layer1.0.downsample.1.bias, backbone.layer1.0.downsample.1.running_mean, backbone.layer1.0.downsample.1.running_var, backbone.layer1.0.downsample.1.num_batches_tracked, backbone.layer1.1.conv1.weight, backbone.layer1.1.bn1.weight, backbone.layer1.1.bn1.bias, backbone.layer1.1.bn1.running_mean, backbone.layer1.1.bn1.running_var, backbone.layer1.1.bn1.num_batches_tracked, backbone.layer1.1.conv2.weight, backbone.layer1.1.bn2.weight, backbone.layer1.1.bn2.bias, backbone.layer1.1.bn2.running_mean, backbone.layer1.1.bn2.running_var, backbone.layer1.1.bn2.num_batches_tracked, backbone.layer1.1.conv3.weight, backbone.layer1.1.bn3.weight, backbone.layer1.1.bn3.bias, backbone.layer1.1.bn3.running_mean, backbone.layer1.1.bn3.running_var, backbone.layer1.1.bn3.num_batches_tracked, backbone.layer1.2.conv1.weight, backbone.layer1.2.bn1.weight, backbone.layer1.2.bn1.bias, backbone.layer1.2.bn1.running_mean, backbone.layer1.2.bn1.running_var, backbone.layer1.2.bn1.num_batches_tracked, backbone.layer1.2.conv2.weight, backbone.layer1.2.bn2.weight, backbone.layer1.2.bn2.bias, backbone.layer1.2.bn2.running_mean, backbone.layer1.2.bn2.running_var, backbone.layer1.2.bn2.num_batches_tracked, backbone.layer1.2.conv3.weight, backbone.layer1.2.bn3.weight, backbone.layer1.2.bn3.bias, backbone.layer1.2.bn3.running_mean, backbone.layer1.2.bn3.running_var, backbone.layer1.2.bn3.num_batches_tracked, backbone.layer2.0.conv1.weight, backbone.layer2.0.bn1.weight, backbone.layer2.0.bn1.bias, backbone.layer2.0.bn1.running_mean, backbone.layer2.0.bn1.running_var, backbone.layer2.0.bn1.num_batches_tracked, backbone.layer2.0.conv2.weight, backbone.layer2.0.bn2.weight, backbone.layer2.0.bn2.bias, backbone.layer2.0.bn2.running_mean, backbone.layer2.0.bn2.running_var, backbone.layer2.0.bn2.num_batches_tracked, backbone.layer2.0.conv3.weight, backbone.layer2.0.bn3.weight, backbone.layer2.0.bn3.bias, backbone.layer2.0.bn3.running_mean, backbone.layer2.0.bn3.running_var, backbone.layer2.0.bn3.num_batches_tracked, backbone.layer2.0.downsample.0.weight, backbone.layer2.0.downsample.1.weight, backbone.layer2.0.downsample.1.bias, backbone.layer2.0.downsample.1.running_mean, backbone.layer2.0.downsample.1.running_var, backbone.layer2.0.downsample.1.num_batches_tracked, backbone.layer2.1.conv1.weight, backbone.layer2.1.bn1.weight, backbone.layer2.1.bn1.bias, backbone.layer2.1.bn1.running_mean, backbone.layer2.1.bn1.running_var, backbone.layer2.1.bn1.num_batches_tracked, backbone.layer2.1.conv2.weight, backbone.layer2.1.bn2.weight, backbone.layer2.1.bn2.bias, backbone.layer2.1.bn2.running_mean, backbone.layer2.1.bn2.running_var, backbone.layer2.1.bn2.num_batches_tracked, backbone.layer2.1.conv3.weight, backbone.layer2.1.bn3.weight, backbone.layer2.1.bn3.bias, backbone.layer2.1.bn3.running_mean, backbone.layer2.1.bn3.running_var, backbone.layer2.1.bn3.num_batches_tracked, backbone.layer2.2.conv1.weight, backbone.layer2.2.bn1.weight, backbone.layer2.2.bn1.bias, backbone.layer2.2.bn1.running_mean, backbone.layer2.2.bn1.running_var, backbone.layer2.2.bn1.num_batches_tracked, backbone.layer2.2.conv2.weight, backbone.layer2.2.bn2.weight, backbone.layer2.2.bn2.bias, backbone.layer2.2.bn2.running_mean, backbone.layer2.2.bn2.running_var, backbone.layer2.2.bn2.num_batches_tracked, backbone.layer2.2.conv3.weight, backbone.layer2.2.bn3.weight, backbone.layer2.2.bn3.bias, backbone.layer2.2.bn3.running_mean, backbone.layer2.2.bn3.running_var, backbone.layer2.2.bn3.num_batches_tracked, backbone.layer2.3.conv1.weight, backbone.layer2.3.bn1.weight, backbone.layer2.3.bn1.bias, backbone.layer2.3.bn1.running_mean, backbone.layer2.3.bn1.running_var, backbone.layer2.3.bn1.num_batches_tracked, backbone.layer2.3.conv2.weight, backbone.layer2.3.bn2.weight, backbone.layer2.3.bn2.bias, backbone.layer2.3.bn2.running_mean, backbone.layer2.3.bn2.running_var, backbone.layer2.3.bn2.num_batches_tracked, backbone.layer2.3.conv3.weight, backbone.layer2.3.bn3.weight, backbone.layer2.3.bn3.bias, backbone.layer2.3.bn3.running_mean, backbone.layer2.3.bn3.running_var, backbone.layer2.3.bn3.num_batches_tracked, backbone.layer3.0.conv1.weight, backbone.layer3.0.bn1.weight, backbone.layer3.0.bn1.bias, backbone.layer3.0.bn1.running_mean, backbone.layer3.0.bn1.running_var, backbone.layer3.0.bn1.num_batches_tracked, backbone.layer3.0.conv2.weight, backbone.layer3.0.bn2.weight, backbone.layer3.0.bn2.bias, backbone.layer3.0.bn2.running_mean, backbone.layer3.0.bn2.running_var, backbone.layer3.0.bn2.num_batches_tracked, backbone.layer3.0.conv3.weight, backbone.layer3.0.bn3.weight, backbone.layer3.0.bn3.bias, backbone.layer3.0.bn3.running_mean, backbone.layer3.0.bn3.running_var, backbone.layer3.0.bn3.num_batches_tracked, backbone.layer3.0.downsample.0.weight, backbone.layer3.0.downsample.1.weight, backbone.layer3.0.downsample.1.bias, backbone.layer3.0.downsample.1.running_mean, backbone.layer3.0.downsample.1.running_var, backbone.layer3.0.downsample.1.num_batches_tracked, backbone.layer3.1.conv1.weight, backbone.layer3.1.bn1.weight, backbone.layer3.1.bn1.bias, backbone.layer3.1.bn1.running_mean, backbone.layer3.1.bn1.running_var, backbone.layer3.1.bn1.num_batches_tracked, backbone.layer3.1.conv2.weight, backbone.layer3.1.bn2.weight, backbone.layer3.1.bn2.bias, backbone.layer3.1.bn2.running_mean, backbone.layer3.1.bn2.running_var, backbone.layer3.1.bn2.num_batches_tracked, backbone.layer3.1.conv3.weight, backbone.layer3.1.bn3.weight, backbone.layer3.1.bn3.bias, backbone.layer3.1.bn3.running_mean, backbone.layer3.1.bn3.running_var, backbone.layer3.1.bn3.num_batches_tracked, backbone.layer3.2.conv1.weight, backbone.layer3.2.bn1.weight, backbone.layer3.2.bn1.bias, backbone.layer3.2.bn1.running_mean, backbone.layer3.2.bn1.running_var, backbone.layer3.2.bn1.num_batches_tracked, backbone.layer3.2.conv2.weight, backbone.layer3.2.bn2.weight, backbone.layer3.2.bn2.bias, backbone.layer3.2.bn2.running_mean, backbone.layer3.2.bn2.running_var, backbone.layer3.2.bn2.num_batches_tracked, backbone.layer3.2.conv3.weight, backbone.layer3.2.bn3.weight, backbone.layer3.2.bn3.bias, backbone.layer3.2.bn3.running_mean, backbone.layer3.2.bn3.running_var, backbone.layer3.2.bn3.num_batches_tracked, backbone.layer3.3.conv1.weight, backbone.layer3.3.bn1.weight, backbone.layer3.3.bn1.bias, backbone.layer3.3.bn1.running_mean, backbone.layer3.3.bn1.running_var, backbone.layer3.3.bn1.num_batches_tracked, backbone.layer3.3.conv2.weight, backbone.layer3.3.bn2.weight, backbone.layer3.3.bn2.bias, backbone.layer3.3.bn2.running_mean, backbone.layer3.3.bn2.running_var, backbone.layer3.3.bn2.num_batches_tracked, backbone.layer3.3.conv3.weight, backbone.layer3.3.bn3.weight, backbone.layer3.3.bn3.bias, backbone.layer3.3.bn3.running_mean, backbone.layer3.3.bn3.running_var, backbone.layer3.3.bn3.num_batches_tracked, backbone.layer3.4.conv1.weight, backbone.layer3.4.bn1.weight, backbone.layer3.4.bn1.bias, backbone.layer3.4.bn1.running_mean, backbone.layer3.4.bn1.running_var, backbone.layer3.4.bn1.num_batches_tracked, backbone.layer3.4.conv2.weight, backbone.layer3.4.bn2.weight, backbone.layer3.4.bn2.bias, backbone.layer3.4.bn2.running_mean, backbone.layer3.4.bn2.running_var, backbone.layer3.4.bn2.num_batches_tracked, backbone.layer3.4.conv3.weight, backbone.layer3.4.bn3.weight, backbone.layer3.4.bn3.bias, backbone.layer3.4.bn3.running_mean, backbone.layer3.4.bn3.running_var, backbone.layer3.4.bn3.num_batches_tracked, backbone.layer3.5.conv1.weight, backbone.layer3.5.bn1.weight, backbone.layer3.5.bn1.bias, backbone.layer3.5.bn1.running_mean, backbone.layer3.5.bn1.running_var, backbone.layer3.5.bn1.num_batches_tracked, backbone.layer3.5.conv2.weight, backbone.layer3.5.bn2.weight, backbone.layer3.5.bn2.bias, backbone.layer3.5.bn2.running_mean, backbone.layer3.5.bn2.running_var, backbone.layer3.5.bn2.num_batches_tracked, backbone.layer3.5.conv3.weight, backbone.layer3.5.bn3.weight, backbone.layer3.5.bn3.bias, backbone.layer3.5.bn3.running_mean, backbone.layer3.5.bn3.running_var, backbone.layer3.5.bn3.num_batches_tracked, backbone.layer4.0.conv1.weight, backbone.layer4.0.bn1.weight, backbone.layer4.0.bn1.bias, backbone.layer4.0.bn1.running_mean, backbone.layer4.0.bn1.running_var, backbone.layer4.0.bn1.num_batches_tracked, backbone.layer4.0.conv2.weight, backbone.layer4.0.bn2.weight, backbone.layer4.0.bn2.bias, backbone.layer4.0.bn2.running_mean, backbone.layer4.0.bn2.running_var, backbone.layer4.0.bn2.num_batches_tracked, backbone.layer4.0.conv3.weight, backbone.layer4.0.bn3.weight, backbone.layer4.0.bn3.bias, backbone.layer4.0.bn3.running_mean, backbone.layer4.0.bn3.running_var, backbone.layer4.0.bn3.num_batches_tracked, backbone.layer4.0.downsample.0.weight, backbone.layer4.0.downsample.1.weight, backbone.layer4.0.downsample.1.bias, backbone.layer4.0.downsample.1.running_mean, backbone.layer4.0.downsample.1.running_var, backbone.layer4.0.downsample.1.num_batches_tracked, backbone.layer4.1.conv1.weight, backbone.layer4.1.bn1.weight, backbone.layer4.1.bn1.bias, backbone.layer4.1.bn1.running_mean, backbone.layer4.1.bn1.running_var, backbone.layer4.1.bn1.num_batches_tracked, backbone.layer4.1.conv2.weight, backbone.layer4.1.bn2.weight, backbone.layer4.1.bn2.bias, backbone.layer4.1.bn2.running_mean, backbone.layer4.1.bn2.running_var, backbone.layer4.1.bn2.num_batches_tracked, backbone.layer4.1.conv3.weight, backbone.layer4.1.bn3.weight, backbone.layer4.1.bn3.bias, backbone.layer4.1.bn3.running_mean, backbone.layer4.1.bn3.running_var, backbone.layer4.1.bn3.num_batches_tracked, backbone.layer4.2.conv1.weight, backbone.layer4.2.bn1.weight, backbone.layer4.2.bn1.bias, backbone.layer4.2.bn1.running_mean, backbone.layer4.2.bn1.running_var, backbone.layer4.2.bn1.num_batches_tracked, backbone.layer4.2.conv2.weight, backbone.layer4.2.bn2.weight, backbone.layer4.2.bn2.bias, backbone.layer4.2.bn2.running_mean, backbone.layer4.2.bn2.running_var, backbone.layer4.2.bn2.num_batches_tracked, backbone.layer4.2.conv3.weight, backbone.layer4.2.bn3.weight, backbone.layer4.2.bn3.bias, backbone.layer4.2.bn3.running_mean, backbone.layer4.2.bn3.running_var, backbone.layer4.2.bn3.num_batches_tracked, neck.lateral_convs.0.conv.weight, neck.lateral_convs.0.conv.bias, neck.lateral_convs.1.conv.weight, neck.lateral_convs.1.conv.bias, neck.lateral_convs.2.conv.weight, neck.lateral_convs.2.conv.bias, neck.lateral_convs.3.conv.weight, neck.lateral_convs.3.conv.bias, neck.fpn_convs.0.conv.weight, neck.fpn_convs.0.conv.bias, neck.fpn_convs.1.conv.weight, neck.fpn_convs.1.conv.bias, neck.fpn_convs.2.conv.weight, neck.fpn_convs.2.conv.bias, neck.fpn_convs.3.conv.weight, neck.fpn_convs.3.conv.bias, mask_feat_head.convs_all_levels.0.conv0.conv.weight, mask_feat_head.convs_all_levels.0.conv0.gn.weight, mask_feat_head.convs_all_levels.0.conv0.gn.bias, mask_feat_head.convs_all_levels.1.conv0.conv.weight, mask_feat_head.convs_all_levels.1.conv0.gn.weight, mask_feat_head.convs_all_levels.1.conv0.gn.bias, mask_feat_head.convs_all_levels.2.conv0.conv.weight, mask_feat_head.convs_all_levels.2.conv0.gn.weight, mask_feat_head.convs_all_levels.2.conv0.gn.bias, mask_feat_head.convs_all_levels.2.conv1.conv.weight, mask_feat_head.convs_all_levels.2.conv1.gn.weight, mask_feat_head.convs_all_levels.2.conv1.gn.bias, mask_feat_head.convs_all_levels.3.conv0.conv.weight, mask_feat_head.convs_all_levels.3.conv0.gn.weight, mask_feat_head.convs_all_levels.3.conv0.gn.bias, mask_feat_head.convs_all_levels.3.conv1.conv.weight, mask_feat_head.convs_all_levels.3.conv1.gn.weight, mask_feat_head.convs_all_levels.3.conv1.gn.bias, mask_feat_head.convs_all_levels.3.conv2.conv.weight, mask_feat_head.convs_all_levels.3.conv2.gn.weight, mask_feat_head.convs_all_levels.3.conv2.gn.bias, mask_feat_head.conv_pred.0.conv.weight, mask_feat_head.conv_pred.0.gn.weight, mask_feat_head.conv_pred.0.gn.bias, bbox_head.cate_convs.0.conv.weight, bbox_head.cate_convs.0.gn.weight, bbox_head.cate_convs.0.gn.bias, bbox_head.cate_convs.1.conv.weight, bbox_head.cate_convs.1.gn.weight, bbox_head.cate_convs.1.gn.bias, bbox_head.cate_convs.2.conv.weight, bbox_head.cate_convs.2.gn.weight, bbox_head.cate_convs.2.gn.bias, bbox_head.cate_convs.3.conv.weight, bbox_head.cate_convs.3.gn.weight, bbox_head.cate_convs.3.gn.bias, bbox_head.kernel_convs.0.conv.weight, bbox_head.kernel_convs.0.gn.weight, bbox_head.kernel_convs.0.gn.bias, bbox_head.kernel_convs.1.conv.weight, bbox_head.kernel_convs.1.gn.weight, bbox_head.kernel_convs.1.gn.bias, bbox_head.kernel_convs.2.conv.weight, bbox_head.kernel_convs.2.gn.weight, bbox_head.kernel_convs.2.gn.bias, bbox_head.kernel_convs.3.conv.weight, bbox_head.kernel_convs.3.gn.weight, bbox_head.kernel_convs.3.gn.bias, bbox_head.solo_cate.weight, bbox_head.solo_cate.bias, bbox_head.solo_kernel.weight, bbox_head.solo_kernel.bias

missing keys in source state_dict: conv1.weight, bn1.weight, bn1.bias, bn1.running_mean, bn1.running_var, layer1.0.conv1.weight, layer1.0.bn1.weight, layer1.0.bn1.bias, layer1.0.bn1.running_mean, layer1.0.bn1.running_var, layer1.0.conv2.weight, layer1.0.bn2.weight, layer1.0.bn2.bias, layer1.0.bn2.running_mean, layer1.0.bn2.running_var, layer1.0.conv3.weight, layer1.0.bn3.weight, layer1.0.bn3.bias, layer1.0.bn3.running_mean, layer1.0.bn3.running_var, layer1.0.downsample.0.weight, layer1.0.downsample.1.weight, layer1.0.downsample.1.bias, layer1.0.downsample.1.running_mean, layer1.0.downsample.1.running_var, layer1.1.conv1.weight, layer1.1.bn1.weight, layer1.1.bn1.bias, layer1.1.bn1.running_mean, layer1.1.bn1.running_var, layer1.1.conv2.weight, layer1.1.bn2.weight, layer1.1.bn2.bias, layer1.1.bn2.running_mean, layer1.1.bn2.running_var, layer1.1.conv3.weight, layer1.1.bn3.weight, layer1.1.bn3.bias, layer1.1.bn3.running_mean, layer1.1.bn3.running_var, layer1.2.conv1.weight, layer1.2.bn1.weight, layer1.2.bn1.bias, layer1.2.bn1.running_mean, layer1.2.bn1.running_var, layer1.2.conv2.weight, layer1.2.bn2.weight, layer1.2.bn2.bias, layer1.2.bn2.running_mean, layer1.2.bn2.running_var, layer1.2.conv3.weight, layer1.2.bn3.weight, layer1.2.bn3.bias, layer1.2.bn3.running_mean, layer1.2.bn3.running_var, layer2.0.conv1.weight, layer2.0.bn1.weight, layer2.0.bn1.bias, layer2.0.bn1.running_mean, layer2.0.bn1.running_var, layer2.0.conv2.weight, layer2.0.bn2.weight, layer2.0.bn2.bias, layer2.0.bn2.running_mean, layer2.0.bn2.running_var, layer2.0.conv3.weight, layer2.0.bn3.weight, layer2.0.bn3.bias, layer2.0.bn3.running_mean, layer2.0.bn3.running_var, layer2.0.downsample.0.weight, layer2.0.downsample.1.weight, layer2.0.downsample.1.bias, layer2.0.downsample.1.running_mean, layer2.0.downsample.1.running_var, layer2.1.conv1.weight, layer2.1.bn1.weight, layer2.1.bn1.bias, layer2.1.bn1.running_mean, layer2.1.bn1.running_var, layer2.1.conv2.weight, layer2.1.bn2.weight, layer2.1.bn2.bias, layer2.1.bn2.running_mean, layer2.1.bn2.running_var, layer2.1.conv3.weight, layer2.1.bn3.weight, layer2.1.bn3.bias, layer2.1.bn3.running_mean, layer2.1.bn3.running_var, layer2.2.conv1.weight, layer2.2.bn1.weight, layer2.2.bn1.bias, layer2.2.bn1.running_mean, layer2.2.bn1.running_var, layer2.2.conv2.weight, layer2.2.bn2.weight, layer2.2.bn2.bias, layer2.2.bn2.running_mean, layer2.2.bn2.running_var, layer2.2.conv3.weight, layer2.2.bn3.weight, layer2.2.bn3.bias, layer2.2.bn3.running_mean, layer2.2.bn3.running_var, layer2.3.conv1.weight, layer2.3.bn1.weight, layer2.3.bn1.bias, layer2.3.bn1.running_mean, layer2.3.bn1.running_var, layer2.3.conv2.weight, layer2.3.bn2.weight, layer2.3.bn2.bias, layer2.3.bn2.running_mean, layer2.3.bn2.running_var, layer2.3.conv3.weight, layer2.3.bn3.weight, layer2.3.bn3.bias, layer2.3.bn3.running_mean, layer2.3.bn3.running_var, layer3.0.conv1.weight, layer3.0.bn1.weight, layer3.0.bn1.bias, layer3.0.bn1.running_mean, layer3.0.bn1.running_var, layer3.0.conv2.weight, layer3.0.bn2.weight, layer3.0.bn2.bias, layer3.0.bn2.running_mean, layer3.0.bn2.running_var, layer3.0.conv3.weight, layer3.0.bn3.weight, layer3.0.bn3.bias, layer3.0.bn3.running_mean, layer3.0.bn3.running_var, layer3.0.downsample.0.weight, layer3.0.downsample.1.weight, layer3.0.downsample.1.bias, layer3.0.downsample.1.running_mean, layer3.0.downsample.1.running_var, layer3.1.conv1.weight, layer3.1.bn1.weight, layer3.1.bn1.bias, layer3.1.bn1.running_mean, layer3.1.bn1.running_var, layer3.1.conv2.weight, layer3.1.bn2.weight, layer3.1.bn2.bias, layer3.1.bn2.running_mean, layer3.1.bn2.running_var, layer3.1.conv3.weight, layer3.1.bn3.weight, layer3.1.bn3.bias, layer3.1.bn3.running_mean, layer3.1.bn3.running_var, layer3.2.conv1.weight, layer3.2.bn1.weight, layer3.2.bn1.bias, layer3.2.bn1.running_mean, layer3.2.bn1.running_var, layer3.2.conv2.weight, layer3.2.bn2.weight, layer3.2.bn2.bias, layer3.2.bn2.running_mean, layer3.2.bn2.running_var, layer3.2.conv3.weight, layer3.2.bn3.weight, layer3.2.bn3.bias, layer3.2.bn3.running_mean, layer3.2.bn3.running_var, layer3.3.conv1.weight, layer3.3.bn1.weight, layer3.3.bn1.bias, layer3.3.bn1.running_mean, layer3.3.bn1.running_var, layer3.3.conv2.weight, layer3.3.bn2.weight, layer3.3.bn2.bias, layer3.3.bn2.running_mean, layer3.3.bn2.running_var, layer3.3.conv3.weight, layer3.3.bn3.weight, layer3.3.bn3.bias, layer3.3.bn3.running_mean, layer3.3.bn3.running_var, layer3.4.conv1.weight, layer3.4.bn1.weight, layer3.4.bn1.bias, layer3.4.bn1.running_mean, layer3.4.bn1.running_var, layer3.4.conv2.weight, layer3.4.bn2.weight, layer3.4.bn2.bias, layer3.4.bn2.running_mean, layer3.4.bn2.running_var, layer3.4.conv3.weight, layer3.4.bn3.weight, layer3.4.bn3.bias, layer3.4.bn3.running_mean, layer3.4.bn3.running_var, layer3.5.conv1.weight, layer3.5.bn1.weight, layer3.5.bn1.bias, layer3.5.bn1.running_mean, layer3.5.bn1.running_var, layer3.5.conv2.weight, layer3.5.bn2.weight, layer3.5.bn2.bias, layer3.5.bn2.running_mean, layer3.5.bn2.running_var, layer3.5.conv3.weight, layer3.5.bn3.weight, layer3.5.bn3.bias, layer3.5.bn3.running_mean, layer3.5.bn3.running_var, layer4.0.conv1.weight, layer4.0.bn1.weight, layer4.0.bn1.bias, layer4.0.bn1.running_mean, layer4.0.bn1.running_var, layer4.0.conv2.weight, layer4.0.bn2.weight, layer4.0.bn2.bias, layer4.0.bn2.running_mean, layer4.0.bn2.running_var, layer4.0.conv3.weight, layer4.0.bn3.weight, layer4.0.bn3.bias, layer4.0.bn3.running_mean, layer4.0.bn3.running_var, layer4.0.downsample.0.weight, layer4.0.downsample.1.weight, layer4.0.downsample.1.bias, layer4.0.downsample.1.running_mean, layer4.0.downsample.1.running_var, layer4.1.conv1.weight, layer4.1.bn1.weight, layer4.1.bn1.bias, layer4.1.bn1.running_mean, layer4.1.bn1.running_var, layer4.1.conv2.weight, layer4.1.bn2.weight, layer4.1.bn2.bias, layer4.1.bn2.running_mean, layer4.1.bn2.running_var, layer4.1.conv3.weight, layer4.1.bn3.weight, layer4.1.bn3.bias, layer4.1.bn3.running_mean, layer4.1.bn3.running_var, layer4.2.conv1.weight, layer4.2.bn1.weight, layer4.2.bn1.bias, layer4.2.bn1.running_mean, layer4.2.bn1.running_var, layer4.2.conv2.weight, layer4.2.bn2.weight, layer4.2.bn2.bias, layer4.2.bn2.running_mean, layer4.2.bn2.running_var, layer4.2.conv3.weight, layer4.2.bn3.weight, layer4.2.bn3.bias, layer4.2.bn3.running_mean, layer4.2.bn3.running_var

2021-07-21 08:49:28,998 - mmdet - INFO - Start running, host: root@efe7fbebbac3, work_dir: /home/zq/work/SOLO/work_dirs/solov2_release_r50_fpn_8gpu_3x_weight
2021-07-21 08:49:28,999 - mmdet - INFO - workflow: [('train', 1)], max: 36 epochs
loading annotations into memory...
Done (t=0.02s)
creating index...
index created!
{'type': 'CocoDataset', 'ann_file': 'data/annotation/merge/merge_train_coco.json', 'img_prefix': 'data/road/train/', 'pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'LoadAnnotations', 'with_bbox': True, 'with_mask': True}, {'type': 'Resize', 'img_scale': [(1333, 800), (1333, 768), (1333, 736), (1333, 704), (1333, 672), (1333, 640)], 'multiscale_mode': 'value', 'keep_ratio': True}, {'type': 'RandomFlip', 'flip_ratio': 0.5}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'DefaultFormatBundle'}, {'type': 'Collect', 'keys': ['img', 'gt_bboxes', 'gt_labels', 'gt_masks']}]}
/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:2494: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
2021-07-21 08:49:44,245 - mmdet - INFO - Epoch [1][50/673]	lr: 0.00107, eta: 2:02:51, time: 0.305, data_time: 0.018, memory: 4440, loss_ins: 4.5884, loss_cate: 0.5155, loss: 5.1039
2021-07-21 08:49:58,931 - mmdet - INFO - Epoch [1][100/673]	lr: 0.00206, eta: 2:00:21, time: 0.294, data_time: 0.011, memory: 4440, loss_ins: 4.4343, loss_cate: 0.4817, loss: 4.9161
2021-07-21 08:50:13,699 - mmdet - INFO - Epoch [1][150/673]	lr: 0.00305, eta: 1:59:34, time: 0.295, data_time: 0.012, memory: 4440, loss_ins: 4.3427, loss_cate: 0.4392, loss: 4.7819
2021-07-21 08:50:28,722 - mmdet - INFO - Epoch [1][200/673]	lr: 0.00404, eta: 1:59:34, time: 0.300, data_time: 0.012, memory: 4440, loss_ins: 4.4909, loss_cate: 0.5266, loss: 5.0175
2021-07-21 08:50:43,695 - mmdet - INFO - Epoch [1][250/673]	lr: 0.00503, eta: 1:59:23, time: 0.299, data_time: 0.011, memory: 4440, loss_ins: 4.6411, loss_cate: 0.3366, loss: 4.9778
2021-07-21 08:50:58,550 - mmdet - INFO - Epoch [1][300/673]	lr: 0.00602, eta: 1:59:02, time: 0.297, data_time: 0.013, memory: 4440, loss_ins: 4.2719, loss_cate: 0.4183, loss: 4.6902
2021-07-21 08:51:13,190 - mmdet - INFO - Epoch [1][350/673]	lr: 0.00701, eta: 1:58:27, time: 0.293, data_time: 0.011, memory: 4440, loss_ins: 4.3412, loss_cate: 0.6312, loss: 4.9724
2021-07-21 08:51:27,960 - mmdet - INFO - Epoch [1][400/673]	lr: 0.00800, eta: 1:58:06, time: 0.295, data_time: 0.012, memory: 4440, loss_ins: 4.5997, loss_cate: 0.3691, loss: 4.9688
2021-07-21 08:51:42,701 - mmdet - INFO - Epoch [1][450/673]	lr: 0.00899, eta: 1:57:44, time: 0.295, data_time: 0.012, memory: 4440, loss_ins: 4.6406, loss_cate: 0.2920, loss: 4.9327
2021-07-21 08:51:57,310 - mmdet - INFO - Epoch [1][500/673]	lr: 0.00998, eta: 1:57:18, time: 0.292, data_time: 0.012, memory: 4440, loss_ins: 4.3801, loss_cate: 0.2949, loss: 4.6751
2021-07-21 08:52:12,126 - mmdet - INFO - Epoch [1][550/673]	lr: 0.01000, eta: 1:57:02, time: 0.296, data_time: 0.012, memory: 4440, loss_ins: 4.5575, loss_cate: 0.2930, loss: 4.8505
2021-07-21 08:52:27,049 - mmdet - INFO - Epoch [1][600/673]	lr: 0.01000, eta: 1:56:51, time: 0.298, data_time: 0.013, memory: 4440, loss_ins: 4.4643, loss_cate: 0.2616, loss: 4.7259
2021-07-21 08:52:41,961 - mmdet - INFO - Epoch [1][650/673]	lr: 0.01000, eta: 1:56:39, time: 0.298, data_time: 0.012, memory: 4440, loss_ins: 4.6260, loss_cate: 0.2748, loss: 4.9007
2021-07-21 08:53:04,784 - mmdet - INFO - Epoch [2][50/673]	lr: 0.01000, eta: 1:53:00, time: 0.312, data_time: 0.020, memory: 4440, loss_ins: 4.6721, loss_cate: 0.2789, loss: 4.9510
2021-07-21 08:53:20,187 - mmdet - INFO - Epoch [2][100/673]	lr: 0.01000, eta: 1:53:15, time: 0.308, data_time: 0.015, memory: 4440, loss_ins: 4.5013, loss_cate: 0.2551, loss: 4.7565
2021-07-21 08:53:35,294 - mmdet - INFO - Epoch [2][150/673]	lr: 0.01000, eta: 1:53:19, time: 0.302, data_time: 0.013, memory: 4440, loss_ins: 4.4676, loss_cate: 0.2762, loss: 4.7438
2021-07-21 08:53:50,800 - mmdet - INFO - Epoch [2][200/673]	lr: 0.01000, eta: 1:53:30, time: 0.310, data_time: 0.015, memory: 4440, loss_ins: 4.7761, loss_cate: 0.2479, loss: 5.0240
2021-07-21 08:54:05,904 - mmdet - INFO - Epoch [2][250/673]	lr: 0.01000, eta: 1:53:29, time: 0.302, data_time: 0.014, memory: 4440, loss_ins: 4.3740, loss_cate: 0.2156, loss: 4.5896
2021-07-21 08:54:20,773 - mmdet - INFO - Epoch [2][300/673]	lr: 0.01000, eta: 1:53:20, time: 0.297, data_time: 0.013, memory: 4440, loss_ins: 4.3490, loss_cate: 0.2179, loss: 4.5670
2021-07-21 08:54:35,792 - mmdet - INFO - Epoch [2][350/673]	lr: 0.01000, eta: 1:53:15, time: 0.300, data_time: 0.014, memory: 4440, loss_ins: 4.5728, loss_cate: 0.2633, loss: 4.8361
2021-07-21 08:54:50,842 - mmdet - INFO - Epoch [2][400/673]	lr: 0.01000, eta: 1:53:09, time: 0.301, data_time: 0.012, memory: 4440, loss_ins: 4.4799, loss_cate: 0.2322, loss: 4.7121
2021-07-21 08:55:05,719 - mmdet - INFO - Epoch [2][450/673]	lr: 0.01000, eta: 1:52:59, time: 0.298, data_time: 0.013, memory: 4440, loss_ins: 4.6467, loss_cate: 0.2697, loss: 4.9164
2021-07-21 08:55:20,484 - mmdet - INFO - Epoch [2][500/673]	lr: 0.01000, eta: 1:52:46, time: 0.295, data_time: 0.013, memory: 4440, loss_ins: 4.3807, loss_cate: 0.2183, loss: 4.5990
2021-07-21 08:55:35,301 - mmdet - INFO - Epoch [2][550/673]	lr: 0.01000, eta: 1:52:34, time: 0.296, data_time: 0.012, memory: 4440, loss_ins: 4.5023, loss_cate: 0.2269, loss: 4.7293
2021-07-21 08:55:50,762 - mmdet - INFO - Epoch [2][600/673]	lr: 0.01000, eta: 1:52:33, time: 0.309, data_time: 0.015, memory: 4440, loss_ins: 4.5548, loss_cate: 0.2278, loss: 4.7826
2021-07-21 08:56:05,754 - mmdet - INFO - Epoch [2][650/673]	lr: 0.01000, eta: 1:52:23, time: 0.300, data_time: 0.014, memory: 4440, loss_ins: 4.5444, loss_cate: 0.2450, loss: 4.7894
2021-07-21 08:56:28,322 - mmdet - INFO - Epoch [3][50/673]	lr: 0.01000, eta: 1:50:22, time: 0.307, data_time: 0.018, memory: 4440, loss_ins: 4.5540, loss_cate: 0.2565, loss: 4.8104
2021-07-21 08:56:43,220 - mmdet - INFO - Epoch [3][100/673]	lr: 0.01000, eta: 1:50:13, time: 0.298, data_time: 0.014, memory: 4440, loss_ins: 4.6488, loss_cate: 0.2475, loss: 4.8964
2021-07-21 08:56:58,008 - mmdet - INFO - Epoch [3][150/673]	lr: 0.01000, eta: 1:50:03, time: 0.296, data_time: 0.012, memory: 4440, loss_ins: 4.3866, loss_cate: 0.2018, loss: 4.5883
2021-07-21 08:57:12,994 - mmdet - INFO - Epoch [3][200/673]	lr: 0.01000, eta: 1:49:55, time: 0.300, data_time: 0.012, memory: 4440, loss_ins: 4.5029, loss_cate: 0.2187, loss: 4.7215
2021-07-21 08:57:27,901 - mmdet - INFO - Epoch [3][250/673]	lr: 0.01000, eta: 1:49:46, time: 0.298, data_time: 0.013, memory: 4440, loss_ins: 4.1076, loss_cate: 0.1912, loss: 4.2988
2021-07-21 08:57:42,764 - mmdet - INFO - Epoch [3][300/673]	lr: 0.01000, eta: 1:49:36, time: 0.297, data_time: 0.013, memory: 4440, loss_ins: 4.5172, loss_cate: 0.2174, loss: 4.7346
2021-07-21 08:57:57,513 - mmdet - INFO - Epoch [3][350/673]	lr: 0.01000, eta: 1:49:23, time: 0.295, data_time: 0.013, memory: 4440, loss_ins: 4.6061, loss_cate: 0.2000, loss: 4.8061
2021-07-21 08:58:12,525 - mmdet - INFO - Epoch [3][400/673]	lr: 0.01000, eta: 1:49:15, time: 0.300, data_time: 0.013, memory: 4440, loss_ins: 4.3934, loss_cate: 0.1946, loss: 4.5880
2021-07-21 08:58:27,374 - mmdet - INFO - Epoch [3][450/673]	lr: 0.01000, eta: 1:49:03, time: 0.297, data_time: 0.012, memory: 4440, loss_ins: 4.5243, loss_cate: 0.2291, loss: 4.7534
2021-07-21 08:58:42,108 - mmdet - INFO - Epoch [3][500/673]	lr: 0.01000, eta: 1:48:51, time: 0.295, data_time: 0.013, memory: 4440, loss_ins: 4.5581, loss_cate: 0.2085, loss: 4.7666
2021-07-21 08:58:57,123 - mmdet - INFO - Epoch [3][550/673]	lr: 0.01000, eta: 1:48:41, time: 0.300, data_time: 0.013, memory: 4440, loss_ins: 4.4884, loss_cate: 0.1928, loss: 4.6811
2021-07-21 08:59:12,210 - mmdet - INFO - Epoch [3][600/673]	lr: 0.01000, eta: 1:48:32, time: 0.302, data_time: 0.013, memory: 4440, loss_ins: 4.4877, loss_cate: 0.2011, loss: 4.6888
2021-07-21 08:59:26,862 - mmdet - INFO - Epoch [3][650/673]	lr: 0.01000, eta: 1:48:18, time: 0.293, data_time: 0.012, memory: 4440, loss_ins: 4.5323, loss_cate: 0.1960, loss: 4.7282
2021-07-21 08:59:49,305 - mmdet - INFO - Epoch [4][50/673]	lr: 0.01000, eta: 1:46:51, time: 0.305, data_time: 0.019, memory: 4440, loss_ins: 4.5960, loss_cate: 0.2010, loss: 4.7970
2021-07-21 09:00:03,796 - mmdet - INFO - Epoch [4][100/673]	lr: 0.01000, eta: 1:46:37, time: 0.290, data_time: 0.012, memory: 4440, loss_ins: 4.4425, loss_cate: 0.2257, loss: 4.6682
2021-07-21 09:00:18,438 - mmdet - INFO - Epoch [4][150/673]	lr: 0.01000, eta: 1:46:24, time: 0.293, data_time: 0.013, memory: 4440, loss_ins: 4.3989, loss_cate: 0.2060, loss: 4.6049
2021-07-21 09:00:33,420 - mmdet - INFO - Epoch [4][200/673]	lr: 0.01000, eta: 1:46:15, time: 0.300, data_time: 0.012, memory: 4440, loss_ins: 4.5276, loss_cate: 0.1845, loss: 4.7121
2021-07-21 09:00:48,339 - mmdet - INFO - Epoch [4][250/673]	lr: 0.01000, eta: 1:46:04, time: 0.298, data_time: 0.013, memory: 4440, loss_ins: 4.4816, loss_cate: 0.2123, loss: 4.6939
2021-07-21 09:01:03,284 - mmdet - INFO - Epoch [4][300/673]	lr: 0.01000, eta: 1:45:54, time: 0.299, data_time: 0.013, memory: 4440, loss_ins: 4.5923, loss_cate: 0.2134, loss: 4.8056
2021-07-21 09:01:18,195 - mmdet - INFO - Epoch [4][350/673]	lr: 0.01000, eta: 1:45:44, time: 0.298, data_time: 0.014, memory: 4440, loss_ins: 4.2152, loss_cate: 0.1755, loss: 4.3907
2021-07-21 09:01:33,120 - mmdet - INFO - Epoch [4][400/673]	lr: 0.01000, eta: 1:45:33, time: 0.298, data_time: 0.012, memory: 4440, loss_ins: 4.4449, loss_cate: 0.1811, loss: 4.6260
2021-07-21 09:01:47,801 - mmdet - INFO - Epoch [4][450/673]	lr: 0.01000, eta: 1:45:20, time: 0.294, data_time: 0.012, memory: 4440, loss_ins: 4.4151, loss_cate: 0.1774, loss: 4.5926
2021-07-21 09:02:02,987 - mmdet - INFO - Epoch [4][500/673]	lr: 0.01000, eta: 1:45:11, time: 0.304, data_time: 0.013, memory: 4440, loss_ins: 4.5970, loss_cate: 0.1846, loss: 4.7817
2021-07-21 09:02:17,664 - mmdet - INFO - Epoch [4][550/673]	lr: 0.01000, eta: 1:44:57, time: 0.294, data_time: 0.013, memory: 4440, loss_ins: 4.3345, loss_cate: 0.1954, loss: 4.5299
2021-07-21 09:02:32,445 - mmdet - INFO - Epoch [4][600/673]	lr: 0.01000, eta: 1:44:45, time: 0.296, data_time: 0.013, memory: 4440, loss_ins: 4.6516, loss_cate: 0.2072, loss: 4.8588
2021-07-21 09:02:47,114 - mmdet - INFO - Epoch [4][650/673]	lr: 0.01000, eta: 1:44:31, time: 0.293, data_time: 0.013, memory: 4440, loss_ins: 4.5190, loss_cate: 0.1767, loss: 4.6957
2021-07-21 09:03:09,396 - mmdet - INFO - Epoch [5][50/673]	lr: 0.01000, eta: 1:43:21, time: 0.300, data_time: 0.018, memory: 4440, loss_ins: 4.5551, loss_cate: 0.1823, loss: 4.7374
2021-07-21 09:03:24,332 - mmdet - INFO - Epoch [5][100/673]	lr: 0.01000, eta: 1:43:11, time: 0.299, data_time: 0.012, memory: 4440, loss_ins: 4.4383, loss_cate: 0.1767, loss: 4.6150
2021-07-21 09:03:39,313 - mmdet - INFO - Epoch [5][150/673]	lr: 0.01000, eta: 1:43:00, time: 0.300, data_time: 0.013, memory: 4440, loss_ins: 4.5239, loss_cate: 0.1871, loss: 4.7111
2021-07-21 09:03:54,103 - mmdet - INFO - Epoch [5][200/673]	lr: 0.01000, eta: 1:42:49, time: 0.296, data_time: 0.011, memory: 4440, loss_ins: 4.2924, loss_cate: 0.1981, loss: 4.4905
2021-07-21 09:04:08,718 - mmdet - INFO - Epoch [5][250/673]	lr: 0.01000, eta: 1:42:35, time: 0.292, data_time: 0.012, memory: 4440, loss_ins: 4.3482, loss_cate: 0.1904, loss: 4.5386
2021-07-21 09:04:24,093 - mmdet - INFO - Epoch [5][300/673]	lr: 0.01000, eta: 1:42:27, time: 0.307, data_time: 0.013, memory: 4440, loss_ins: 4.5707, loss_cate: 0.1946, loss: 4.7652
2021-07-21 09:04:39,104 - mmdet - INFO - Epoch [5][350/673]	lr: 0.01000, eta: 1:42:17, time: 0.300, data_time: 0.012, memory: 4440, loss_ins: 4.4460, loss_cate: 0.1846, loss: 4.6306
2021-07-21 09:04:54,117 - mmdet - INFO - Epoch [5][400/673]	lr: 0.01000, eta: 1:42:06, time: 0.300, data_time: 0.013, memory: 4440, loss_ins: 4.8156, loss_cate: 0.1941, loss: 5.0097
2021-07-21 09:05:08,977 - mmdet - INFO - Epoch [5][450/673]	lr: 0.01000, eta: 1:41:54, time: 0.297, data_time: 0.012, memory: 4440, loss_ins: 4.4200, loss_cate: 0.1783, loss: 4.5983
2021-07-21 09:05:23,889 - mmdet - INFO - Epoch [5][500/673]	lr: 0.01000, eta: 1:41:42, time: 0.298, data_time: 0.012, memory: 4440, loss_ins: 4.5705, loss_cate: 0.1914, loss: 4.7620
2021-07-21 09:05:38,742 - mmdet - INFO - Epoch [5][550/673]	lr: 0.01000, eta: 1:41:30, time: 0.297, data_time: 0.012, memory: 4440, loss_ins: 4.2572, loss_cate: 0.1674, loss: 4.4246
2021-07-21 09:05:53,661 - mmdet - INFO - Epoch [5][600/673]	lr: 0.01000, eta: 1:41:18, time: 0.298, data_time: 0.012, memory: 4440, loss_ins: 4.4761, loss_cate: 0.1626, loss: 4.6387
2021-07-21 09:06:08,552 - mmdet - INFO - Epoch [5][650/673]	lr: 0.01000, eta: 1:41:06, time: 0.298, data_time: 0.012, memory: 4440, loss_ins: 4.3792, loss_cate: 0.1831, loss: 4.5623
2021-07-21 09:06:30,797 - mmdet - INFO - Epoch [6][50/673]	lr: 0.01000, eta: 1:40:06, time: 0.299, data_time: 0.018, memory: 4440, loss_ins: 4.4970, loss_cate: 0.1871, loss: 4.6842
2021-07-21 09:06:45,479 - mmdet - INFO - Epoch [6][100/673]	lr: 0.01000, eta: 1:39:53, time: 0.294, data_time: 0.013, memory: 4440, loss_ins: 4.3219, loss_cate: 0.1758, loss: 4.4977
2021-07-21 09:07:00,182 - mmdet - INFO - Epoch [6][150/673]	lr: 0.01000, eta: 1:39:40, time: 0.294, data_time: 0.012, memory: 4440, loss_ins: 4.5448, loss_cate: 0.1655, loss: 4.7104
2021-07-21 09:07:15,117 - mmdet - INFO - Epoch [6][200/673]	lr: 0.01000, eta: 1:39:29, time: 0.299, data_time: 0.013, memory: 4440, loss_ins: 4.8762, loss_cate: 0.1757, loss: 5.0518
2021-07-21 09:07:30,034 - mmdet - INFO - Epoch [6][250/673]	lr: 0.01000, eta: 1:39:17, time: 0.298, data_time: 0.012, memory: 4440, loss_ins: 4.6725, loss_cate: 0.2025, loss: 4.8750
2021-07-21 09:07:44,828 - mmdet - INFO - Epoch [6][300/673]	lr: 0.01000, eta: 1:39:05, time: 0.296, data_time: 0.013, memory: 4440, loss_ins: 4.5002, loss_cate: 0.1656, loss: 4.6658
2021-07-21 09:07:59,680 - mmdet - INFO - Epoch [6][350/673]	lr: 0.01000, eta: 1:38:52, time: 0.297, data_time: 0.013, memory: 4440, loss_ins: 4.3008, loss_cate: 0.1667, loss: 4.4674
2021-07-21 09:08:14,675 - mmdet - INFO - Epoch [6][400/673]	lr: 0.01000, eta: 1:38:41, time: 0.300, data_time: 0.012, memory: 4440, loss_ins: 4.3797, loss_cate: 0.1729, loss: 4.5526
2021-07-21 09:08:29,414 - mmdet - INFO - Epoch [6][450/673]	lr: 0.01000, eta: 1:38:28, time: 0.295, data_time: 0.013, memory: 4440, loss_ins: 4.4541, loss_cate: 0.1768, loss: 4.6310
2021-07-21 09:08:44,167 - mmdet - INFO - Epoch [6][500/673]	lr: 0.01000, eta: 1:38:15, time: 0.295, data_time: 0.012, memory: 4440, loss_ins: 4.5739, loss_cate: 0.1775, loss: 4.7513
2021-07-21 09:08:58,996 - mmdet - INFO - Epoch [6][550/673]	lr: 0.01000, eta: 1:38:02, time: 0.297, data_time: 0.013, memory: 4440, loss_ins: 4.4427, loss_cate: 0.1655, loss: 4.6082
2021-07-21 09:09:13,795 - mmdet - INFO - Epoch [6][600/673]	lr: 0.01000, eta: 1:37:49, time: 0.296, data_time: 0.012, memory: 4440, loss_ins: 4.5618, loss_cate: 0.1583, loss: 4.7201
2021-07-21 09:09:28,868 - mmdet - INFO - Epoch [6][650/673]	lr: 0.01000, eta: 1:37:38, time: 0.301, data_time: 0.012, memory: 4440, loss_ins: 4.5509, loss_cate: 0.1753, loss: 4.7263
2021-07-21 09:09:51,559 - mmdet - INFO - Epoch [7][50/673]	lr: 0.01000, eta: 1:36:49, time: 0.312, data_time: 0.020, memory: 4440, loss_ins: 4.5129, loss_cate: 0.1632, loss: 4.6761
2021-07-21 09:10:06,786 - mmdet - INFO - Epoch [7][100/673]	lr: 0.01000, eta: 1:36:39, time: 0.305, data_time: 0.014, memory: 4440, loss_ins: 4.6363, loss_cate: 0.1616, loss: 4.7979
2021-07-21 09:10:21,842 - mmdet - INFO - Epoch [7][150/673]	lr: 0.01000, eta: 1:36:27, time: 0.301, data_time: 0.015, memory: 4440, loss_ins: 4.3528, loss_cate: 0.1705, loss: 4.5233
2021-07-21 09:10:36,778 - mmdet - INFO - Epoch [7][200/673]	lr: 0.01000, eta: 1:36:15, time: 0.299, data_time: 0.014, memory: 4440, loss_ins: 4.4546, loss_cate: 0.1655, loss: 4.6200
2021-07-21 09:10:51,410 - mmdet - INFO - Epoch [7][250/673]	lr: 0.01000, eta: 1:36:01, time: 0.293, data_time: 0.013, memory: 4440, loss_ins: 4.2894, loss_cate: 0.1628, loss: 4.4522
2021-07-21 09:11:06,682 - mmdet - INFO - Epoch [7][300/673]	lr: 0.01000, eta: 1:35:51, time: 0.305, data_time: 0.014, memory: 4440, loss_ins: 4.3370, loss_cate: 0.1656, loss: 4.5026
2021-07-21 09:11:21,709 - mmdet - INFO - Epoch [7][350/673]	lr: 0.01000, eta: 1:35:39, time: 0.301, data_time: 0.013, memory: 4440, loss_ins: 4.7021, loss_cate: 0.1747, loss: 4.8768
2021-07-21 09:11:36,681 - mmdet - INFO - Epoch [7][400/673]	lr: 0.01000, eta: 1:35:27, time: 0.299, data_time: 0.013, memory: 4440, loss_ins: 4.4680, loss_cate: 0.1544, loss: 4.6224
2021-07-21 09:11:51,899 - mmdet - INFO - Epoch [7][450/673]	lr: 0.01000, eta: 1:35:16, time: 0.304, data_time: 0.014, memory: 4440, loss_ins: 4.3765, loss_cate: 0.1740, loss: 4.5505
2021-07-21 09:12:07,070 - mmdet - INFO - Epoch [7][500/673]	lr: 0.01000, eta: 1:35:04, time: 0.303, data_time: 0.014, memory: 4440, loss_ins: 4.5028, loss_cate: 0.1828, loss: 4.6856
2021-07-21 09:12:22,443 - mmdet - INFO - Epoch [7][550/673]	lr: 0.01000, eta: 1:34:53, time: 0.307, data_time: 0.014, memory: 4440, loss_ins: 4.5887, loss_cate: 0.1660, loss: 4.7547
2021-07-21 09:12:37,681 - mmdet - INFO - Epoch [7][600/673]	lr: 0.01000, eta: 1:34:42, time: 0.305, data_time: 0.014, memory: 4440, loss_ins: 4.6075, loss_cate: 0.1618, loss: 4.7693
2021-07-21 09:12:52,841 - mmdet - INFO - Epoch [7][650/673]	lr: 0.01000, eta: 1:34:30, time: 0.303, data_time: 0.013, memory: 4440, loss_ins: 4.6600, loss_cate: 0.1679, loss: 4.8278
2021-07-21 09:13:15,529 - mmdet - INFO - Epoch [8][50/673]	lr: 0.01000, eta: 1:33:46, time: 0.310, data_time: 0.019, memory: 4440, loss_ins: 4.7013, loss_cate: 0.1772, loss: 4.8785
2021-07-21 09:13:30,427 - mmdet - INFO - Epoch [8][100/673]	lr: 0.01000, eta: 1:33:33, time: 0.298, data_time: 0.014, memory: 4440, loss_ins: 4.5902, loss_cate: 0.1504, loss: 4.7406
2021-07-21 09:13:45,405 - mmdet - INFO - Epoch [8][150/673]	lr: 0.01000, eta: 1:33:21, time: 0.300, data_time: 0.013, memory: 4440, loss_ins: 4.6789, loss_cate: 0.1726, loss: 4.8515
2021-07-21 09:14:00,303 - mmdet - INFO - Epoch [8][200/673]	lr: 0.01000, eta: 1:33:08, time: 0.298, data_time: 0.013, memory: 4440, loss_ins: 4.5226, loss_cate: 0.1637, loss: 4.6863
2021-07-21 09:14:15,563 - mmdet - INFO - Epoch [8][250/673]	lr: 0.01000, eta: 1:32:57, time: 0.305, data_time: 0.013, memory: 4440, loss_ins: 4.6917, loss_cate: 0.1677, loss: 4.8594
2021-07-21 09:14:29,940 - mmdet - INFO - Epoch [8][300/673]	lr: 0.01000, eta: 1:32:42, time: 0.288, data_time: 0.012, memory: 4440, loss_ins: 4.3175, loss_cate: 0.1623, loss: 4.4798
2021-07-21 09:14:44,721 - mmdet - INFO - Epoch [8][350/673]	lr: 0.01000, eta: 1:32:29, time: 0.296, data_time: 0.013, memory: 4440, loss_ins: 4.2367, loss_cate: 0.1596, loss: 4.3963
2021-07-21 09:14:59,728 - mmdet - INFO - Epoch [8][400/673]	lr: 0.01000, eta: 1:32:16, time: 0.300, data_time: 0.013, memory: 4440, loss_ins: 4.3730, loss_cate: 0.1699, loss: 4.5429
2021-07-21 09:15:14,553 - mmdet - INFO - Epoch [8][450/673]	lr: 0.01000, eta: 1:32:03, time: 0.297, data_time: 0.013, memory: 4440, loss_ins: 4.0845, loss_cate: 0.1541, loss: 4.2386
2021-07-21 09:15:29,478 - mmdet - INFO - Epoch [8][500/673]	lr: 0.01000, eta: 1:31:50, time: 0.298, data_time: 0.013, memory: 4440, loss_ins: 4.4167, loss_cate: 0.1506, loss: 4.5673
2021-07-21 09:15:44,339 - mmdet - INFO - Epoch [8][550/673]	lr: 0.01000, eta: 1:31:37, time: 0.297, data_time: 0.013, memory: 4440, loss_ins: 4.4555, loss_cate: 0.1470, loss: 4.6026
2021-07-21 09:15:59,017 - mmdet - INFO - Epoch [8][600/673]	lr: 0.01000, eta: 1:31:23, time: 0.294, data_time: 0.011, memory: 4440, loss_ins: 4.2072, loss_cate: 0.1383, loss: 4.3455
2021-07-21 09:16:14,083 - mmdet - INFO - Epoch [8][650/673]	lr: 0.01000, eta: 1:31:11, time: 0.301, data_time: 0.012, memory: 4440, loss_ins: 4.6597, loss_cate: 0.1775, loss: 4.8373
2021-07-21 09:16:36,567 - mmdet - INFO - Epoch [9][50/673]	lr: 0.01000, eta: 1:30:28, time: 0.300, data_time: 0.017, memory: 4440, loss_ins: 4.4429, loss_cate: 0.1693, loss: 4.6123
2021-07-21 09:16:51,237 - mmdet - INFO - Epoch [9][100/673]	lr: 0.01000, eta: 1:30:14, time: 0.293, data_time: 0.010, memory: 4440, loss_ins: 4.6392, loss_cate: 0.1496, loss: 4.7887
2021-07-21 09:17:06,190 - mmdet - INFO - Epoch [9][150/673]	lr: 0.01000, eta: 1:30:02, time: 0.299, data_time: 0.012, memory: 4440, loss_ins: 4.5662, loss_cate: 0.1493, loss: 4.7156
2021-07-21 09:17:21,059 - mmdet - INFO - Epoch [9][200/673]	lr: 0.01000, eta: 1:29:49, time: 0.297, data_time: 0.012, memory: 4440, loss_ins: 4.4770, loss_cate: 0.1546, loss: 4.6316
2021-07-21 09:17:38,497 - mmdet - INFO - Epoch [9][250/673]	lr: 0.01000, eta: 1:29:44, time: 0.349, data_time: 0.014, memory: 4440, loss_ins: 4.4600, loss_cate: 0.1638, loss: 4.6237
2021-07-21 09:17:58,819 - mmdet - INFO - Epoch [9][300/673]	lr: 0.01000, eta: 1:29:49, time: 0.406, data_time: 0.013, memory: 4440, loss_ins: 4.4921, loss_cate: 0.1413, loss: 4.6334
2021-07-21 09:18:13,749 - mmdet - INFO - Epoch [9][350/673]	lr: 0.01000, eta: 1:29:35, time: 0.299, data_time: 0.013, memory: 4440, loss_ins: 4.7190, loss_cate: 0.1657, loss: 4.8847
2021-07-21 09:18:28,838 - mmdet - INFO - Epoch [9][400/673]	lr: 0.01000, eta: 1:29:23, time: 0.302, data_time: 0.014, memory: 4440, loss_ins: 4.2622, loss_cate: 0.1371, loss: 4.3993
2021-07-21 09:18:43,435 - mmdet - INFO - Epoch [9][450/673]	lr: 0.01000, eta: 1:29:08, time: 0.292, data_time: 0.013, memory: 4440, loss_ins: 4.3627, loss_cate: 0.1539, loss: 4.5165
2021-07-21 09:18:58,094 - mmdet - INFO - Epoch [9][500/673]	lr: 0.01000, eta: 1:28:54, time: 0.293, data_time: 0.013, memory: 4440, loss_ins: 4.1592, loss_cate: 0.1440, loss: 4.3032
2021-07-21 09:19:12,979 - mmdet - INFO - Epoch [9][550/673]	lr: 0.01000, eta: 1:28:41, time: 0.298, data_time: 0.013, memory: 4440, loss_ins: 4.3004, loss_cate: 0.1620, loss: 4.4624
2021-07-21 09:19:27,895 - mmdet - INFO - Epoch [9][600/673]	lr: 0.01000, eta: 1:28:27, time: 0.298, data_time: 0.014, memory: 4440, loss_ins: 4.3222, loss_cate: 0.1535, loss: 4.4757
2021-07-21 09:19:42,900 - mmdet - INFO - Epoch [9][650/673]	lr: 0.01000, eta: 1:28:14, time: 0.300, data_time: 0.014, memory: 4440, loss_ins: 4.7945, loss_cate: 0.1519, loss: 4.9464
2021-07-21 09:20:05,323 - mmdet - INFO - Epoch [10][50/673]	lr: 0.01000, eta: 1:27:35, time: 0.306, data_time: 0.017, memory: 4440, loss_ins: 4.2856, loss_cate: 0.1454, loss: 4.4310
2021-07-21 09:20:20,214 - mmdet - INFO - Epoch [10][100/673]	lr: 0.01000, eta: 1:27:22, time: 0.298, data_time: 0.013, memory: 4440, loss_ins: 4.4241, loss_cate: 0.1405, loss: 4.5646
2021-07-21 09:20:35,234 - mmdet - INFO - Epoch [10][150/673]	lr: 0.01000, eta: 1:27:09, time: 0.300, data_time: 0.012, memory: 4440, loss_ins: 4.6858, loss_cate: 0.1649, loss: 4.8507
2021-07-21 09:20:50,272 - mmdet - INFO - Epoch [10][200/673]	lr: 0.01000, eta: 1:26:56, time: 0.301, data_time: 0.013, memory: 4440, loss_ins: 4.2342, loss_cate: 0.1381, loss: 4.3723
2021-07-21 09:21:05,202 - mmdet - INFO - Epoch [10][250/673]	lr: 0.01000, eta: 1:26:42, time: 0.299, data_time: 0.013, memory: 4440, loss_ins: 4.2841, loss_cate: 0.1466, loss: 4.4308
2021-07-21 09:21:19,890 - mmdet - INFO - Epoch [10][300/673]	lr: 0.01000, eta: 1:26:28, time: 0.294, data_time: 0.013, memory: 4440, loss_ins: 4.3779, loss_cate: 0.1418, loss: 4.5198
2021-07-21 09:21:34,683 - mmdet - INFO - Epoch [10][350/673]	lr: 0.01000, eta: 1:26:15, time: 0.296, data_time: 0.013, memory: 4440, loss_ins: 4.3511, loss_cate: 0.1359, loss: 4.4869
2021-07-21 09:21:49,796 - mmdet - INFO - Epoch [10][400/673]	lr: 0.01000, eta: 1:26:02, time: 0.302, data_time: 0.012, memory: 4440, loss_ins: 4.7732, loss_cate: 0.1650, loss: 4.9381
2021-07-21 09:22:04,537 - mmdet - INFO - Epoch [10][450/673]	lr: 0.01000, eta: 1:25:48, time: 0.295, data_time: 0.012, memory: 4440, loss_ins: 4.5650, loss_cate: 0.1559, loss: 4.7209
2021-07-21 09:22:19,271 - mmdet - INFO - Epoch [10][500/673]	lr: 0.01000, eta: 1:25:34, time: 0.295, data_time: 0.012, memory: 4440, loss_ins: 4.3348, loss_cate: 0.1554, loss: 4.4903
2021-07-21 09:22:34,301 - mmdet - INFO - Epoch [10][550/673]	lr: 0.01000, eta: 1:25:21, time: 0.301, data_time: 0.013, memory: 4440, loss_ins: 4.7227, loss_cate: 0.1472, loss: 4.8699
2021-07-21 09:22:49,101 - mmdet - INFO - Epoch [10][600/673]	lr: 0.01000, eta: 1:25:07, time: 0.296, data_time: 0.013, memory: 4440, loss_ins: 4.5353, loss_cate: 0.1648, loss: 4.7001
2021-07-21 09:23:03,908 - mmdet - INFO - Epoch [10][650/673]	lr: 0.01000, eta: 1:24:53, time: 0.296, data_time: 0.012, memory: 4440, loss_ins: 4.4358, loss_cate: 0.1543, loss: 4.5900
2021-07-21 09:23:26,389 - mmdet - INFO - Epoch [11][50/673]	lr: 0.01000, eta: 1:24:16, time: 0.304, data_time: 0.018, memory: 4440, loss_ins: 4.3206, loss_cate: 0.1324, loss: 4.4530
2021-07-21 09:23:41,315 - mmdet - INFO - Epoch [11][100/673]	lr: 0.01000, eta: 1:24:03, time: 0.299, data_time: 0.014, memory: 4440, loss_ins: 4.6613, loss_cate: 0.1628, loss: 4.8242
2021-07-21 09:23:56,058 - mmdet - INFO - Epoch [11][150/673]	lr: 0.01000, eta: 1:23:49, time: 0.295, data_time: 0.013, memory: 4440, loss_ins: 4.5138, loss_cate: 0.1335, loss: 4.6473
2021-07-21 09:24:10,841 - mmdet - INFO - Epoch [11][200/673]	lr: 0.01000, eta: 1:23:35, time: 0.296, data_time: 0.012, memory: 4440, loss_ins: 4.4076, loss_cate: 0.1374, loss: 4.5449
2021-07-21 09:24:25,775 - mmdet - INFO - Epoch [11][250/673]	lr: 0.01000, eta: 1:23:22, time: 0.299, data_time: 0.013, memory: 4440, loss_ins: 4.6199, loss_cate: 0.1458, loss: 4.7657
2021-07-21 09:24:40,715 - mmdet - INFO - Epoch [11][300/673]	lr: 0.01000, eta: 1:23:08, time: 0.299, data_time: 0.013, memory: 4440, loss_ins: 4.3292, loss_cate: 0.1471, loss: 4.4764
2021-07-21 09:24:55,203 - mmdet - INFO - Epoch [11][350/673]	lr: 0.01000, eta: 1:22:54, time: 0.290, data_time: 0.012, memory: 4440, loss_ins: 4.2318, loss_cate: 0.1428, loss: 4.3746
2021-07-21 09:25:10,062 - mmdet - INFO - Epoch [11][400/673]	lr: 0.01000, eta: 1:22:40, time: 0.297, data_time: 0.013, memory: 4440, loss_ins: 4.3739, loss_cate: 0.1340, loss: 4.5080
2021-07-21 09:25:24,978 - mmdet - INFO - Epoch [11][450/673]	lr: 0.01000, eta: 1:22:27, time: 0.298, data_time: 0.013, memory: 4440, loss_ins: 4.3081, loss_cate: 0.1357, loss: 4.4438
2021-07-21 09:25:39,969 - mmdet - INFO - Epoch [11][500/673]	lr: 0.01000, eta: 1:22:13, time: 0.300, data_time: 0.013, memory: 4440, loss_ins: 4.4437, loss_cate: 0.1366, loss: 4.5803
2021-07-21 09:25:54,942 - mmdet - INFO - Epoch [11][550/673]	lr: 0.01000, eta: 1:22:00, time: 0.299, data_time: 0.013, memory: 4440, loss_ins: 4.4794, loss_cate: 0.1537, loss: 4.6331
2021-07-21 09:26:09,823 - mmdet - INFO - Epoch [11][600/673]	lr: 0.01000, eta: 1:21:46, time: 0.298, data_time: 0.013, memory: 4440, loss_ins: 4.7786, loss_cate: 0.1569, loss: 4.9355
2021-07-21 09:26:24,921 - mmdet - INFO - Epoch [11][650/673]	lr: 0.01000, eta: 1:21:33, time: 0.302, data_time: 0.013, memory: 4440, loss_ins: 4.7219, loss_cate: 0.1434, loss: 4.8652
2021-07-21 09:26:47,333 - mmdet - INFO - Epoch [12][50/673]	lr: 0.01000, eta: 1:20:58, time: 0.303, data_time: 0.018, memory: 4440, loss_ins: 4.3053, loss_cate: 0.1501, loss: 4.4554
2021-07-21 09:27:02,148 - mmdet - INFO - Epoch [12][100/673]	lr: 0.01000, eta: 1:20:44, time: 0.296, data_time: 0.012, memory: 4440, loss_ins: 4.5447, loss_cate: 0.1412, loss: 4.6859
2021-07-21 09:27:17,046 - mmdet - INFO - Epoch [12][150/673]	lr: 0.01000, eta: 1:20:31, time: 0.298, data_time: 0.012, memory: 4440, loss_ins: 4.6130, loss_cate: 0.1516, loss: 4.7645
2021-07-21 09:27:31,979 - mmdet - INFO - Epoch [12][200/673]	lr: 0.01000, eta: 1:20:17, time: 0.299, data_time: 0.013, memory: 4440, loss_ins: 4.5109, loss_cate: 0.1643, loss: 4.6752
2021-07-21 09:27:47,072 - mmdet - INFO - Epoch [12][250/673]	lr: 0.01000, eta: 1:20:04, time: 0.302, data_time: 0.013, memory: 4440, loss_ins: 4.2866, loss_cate: 0.1387, loss: 4.4253
2021-07-21 09:28:03,612 - mmdet - INFO - Epoch [12][300/673]	lr: 0.01000, eta: 1:19:54, time: 0.331, data_time: 0.013, memory: 4440, loss_ins: 4.6405, loss_cate: 0.1380, loss: 4.7785
2021-07-21 09:28:25,025 - mmdet - INFO - Epoch [12][350/673]	lr: 0.01000, eta: 1:19:54, time: 0.428, data_time: 0.013, memory: 4440, loss_ins: 4.5484, loss_cate: 0.1409, loss: 4.6893
2021-07-21 09:28:39,935 - mmdet - INFO - Epoch [12][400/673]	lr: 0.01000, eta: 1:19:40, time: 0.298, data_time: 0.013, memory: 4440, loss_ins: 4.5537, loss_cate: 0.1412, loss: 4.6950
2021-07-21 09:28:54,577 - mmdet - INFO - Epoch [12][450/673]	lr: 0.01000, eta: 1:19:26, time: 0.293, data_time: 0.013, memory: 4440, loss_ins: 4.3735, loss_cate: 0.1337, loss: 4.5071
2021-07-21 09:29:09,423 - mmdet - INFO - Epoch [12][500/673]	lr: 0.01000, eta: 1:19:12, time: 0.297, data_time: 0.013, memory: 4440, loss_ins: 4.3168, loss_cate: 0.1454, loss: 4.4621
2021-07-21 09:29:24,337 - mmdet - INFO - Epoch [12][550/673]	lr: 0.01000, eta: 1:18:58, time: 0.298, data_time: 0.012, memory: 4440, loss_ins: 4.3953, loss_cate: 0.1527, loss: 4.5480
2021-07-21 09:29:38,893 - mmdet - INFO - Epoch [12][600/673]	lr: 0.01000, eta: 1:18:44, time: 0.291, data_time: 0.011, memory: 4440, loss_ins: 4.2159, loss_cate: 0.1334, loss: 4.3492
2021-07-21 09:29:53,782 - mmdet - INFO - Epoch [12][650/673]	lr: 0.01000, eta: 1:18:30, time: 0.298, data_time: 0.012, memory: 4440, loss_ins: 4.7330, loss_cate: 0.1736, loss: 4.9066
2021-07-21 09:30:16,172 - mmdet - INFO - Epoch [13][50/673]	lr: 0.01000, eta: 1:17:56, time: 0.303, data_time: 0.018, memory: 4440, loss_ins: 4.5293, loss_cate: 0.1410, loss: 4.6704
2021-07-21 09:30:31,083 - mmdet - INFO - Epoch [13][100/673]	lr: 0.01000, eta: 1:17:43, time: 0.298, data_time: 0.012, memory: 4440, loss_ins: 4.5804, loss_cate: 0.1466, loss: 4.7271
2021-07-21 09:30:45,900 - mmdet - INFO - Epoch [13][150/673]	lr: 0.01000, eta: 1:17:29, time: 0.296, data_time: 0.011, memory: 4440, loss_ins: 4.3102, loss_cate: 0.1305, loss: 4.4406
2021-07-21 09:31:00,888 - mmdet - INFO - Epoch [13][200/673]	lr: 0.01000, eta: 1:17:15, time: 0.300, data_time: 0.011, memory: 4440, loss_ins: 4.4485, loss_cate: 0.1489, loss: 4.5974
2021-07-21 09:31:15,732 - mmdet - INFO - Epoch [13][250/673]	lr: 0.01000, eta: 1:17:01, time: 0.297, data_time: 0.012, memory: 4440, loss_ins: 4.5365, loss_cate: 0.1378, loss: 4.6743
2021-07-21 09:31:30,506 - mmdet - INFO - Epoch [13][300/673]	lr: 0.01000, eta: 1:16:47, time: 0.295, data_time: 0.013, memory: 4440, loss_ins: 4.4582, loss_cate: 0.1341, loss: 4.5923
2021-07-21 09:31:45,654 - mmdet - INFO - Epoch [13][350/673]	lr: 0.01000, eta: 1:16:34, time: 0.303, data_time: 0.014, memory: 4440, loss_ins: 4.3793, loss_cate: 0.1520, loss: 4.5313
2021-07-21 09:32:00,497 - mmdet - INFO - Epoch [13][400/673]	lr: 0.01000, eta: 1:16:20, time: 0.297, data_time: 0.012, memory: 4440, loss_ins: 4.4224, loss_cate: 0.1341, loss: 4.5565
2021-07-21 09:32:15,507 - mmdet - INFO - Epoch [13][450/673]	lr: 0.01000, eta: 1:16:06, time: 0.300, data_time: 0.012, memory: 4440, loss_ins: 4.4551, loss_cate: 0.1303, loss: 4.5854
2021-07-21 09:32:30,381 - mmdet - INFO - Epoch [13][500/673]	lr: 0.01000, eta: 1:15:52, time: 0.297, data_time: 0.013, memory: 4440, loss_ins: 4.7780, loss_cate: 0.1551, loss: 4.9330
2021-07-21 09:32:45,118 - mmdet - INFO - Epoch [13][550/673]	lr: 0.01000, eta: 1:15:38, time: 0.295, data_time: 0.011, memory: 4440, loss_ins: 4.5622, loss_cate: 0.1385, loss: 4.7007
2021-07-21 09:32:59,811 - mmdet - INFO - Epoch [13][600/673]	lr: 0.01000, eta: 1:15:24, time: 0.294, data_time: 0.012, memory: 4440, loss_ins: 4.4466, loss_cate: 0.1361, loss: 4.5828
2021-07-21 09:33:14,565 - mmdet - INFO - Epoch [13][650/673]	lr: 0.01000, eta: 1:15:09, time: 0.295, data_time: 0.013, memory: 4440, loss_ins: 4.4550, loss_cate: 0.1373, loss: 4.5923
2021-07-21 09:33:37,098 - mmdet - INFO - Epoch [14][50/673]	lr: 0.01000, eta: 1:14:38, time: 0.306, data_time: 0.018, memory: 4440, loss_ins: 4.7057, loss_cate: 0.1325, loss: 4.8382
2021-07-21 09:33:52,189 - mmdet - INFO - Epoch [14][100/673]	lr: 0.01000, eta: 1:14:24, time: 0.302, data_time: 0.013, memory: 4440, loss_ins: 4.5284, loss_cate: 0.1372, loss: 4.6656
2021-07-21 09:34:06,957 - mmdet - INFO - Epoch [14][150/673]	lr: 0.01000, eta: 1:14:10, time: 0.295, data_time: 0.013, memory: 4440, loss_ins: 4.5375, loss_cate: 0.1378, loss: 4.6754
2021-07-21 09:34:21,952 - mmdet - INFO - Epoch [14][200/673]	lr: 0.01000, eta: 1:13:56, time: 0.300, data_time: 0.013, memory: 4440, loss_ins: 4.3988, loss_cate: 0.1359, loss: 4.5346
2021-07-21 09:34:37,122 - mmdet - INFO - Epoch [14][250/673]	lr: 0.01000, eta: 1:13:43, time: 0.303, data_time: 0.013, memory: 4440, loss_ins: 4.5444, loss_cate: 0.1251, loss: 4.6695
2021-07-21 09:34:51,858 - mmdet - INFO - Epoch [14][300/673]	lr: 0.01000, eta: 1:13:29, time: 0.295, data_time: 0.013, memory: 4440, loss_ins: 4.2815, loss_cate: 0.1288, loss: 4.4103
2021-07-21 09:35:06,914 - mmdet - INFO - Epoch [14][350/673]	lr: 0.01000, eta: 1:13:15, time: 0.301, data_time: 0.013, memory: 4440, loss_ins: 4.4007, loss_cate: 0.1449, loss: 4.5456
2021-07-21 09:35:21,911 - mmdet - INFO - Epoch [14][400/673]	lr: 0.01000, eta: 1:13:01, time: 0.300, data_time: 0.012, memory: 4440, loss_ins: 4.4478, loss_cate: 0.1641, loss: 4.6118
2021-07-21 09:35:36,934 - mmdet - INFO - Epoch [14][450/673]	lr: 0.01000, eta: 1:12:48, time: 0.300, data_time: 0.012, memory: 4440, loss_ins: 4.4510, loss_cate: 0.1314, loss: 4.5824
2021-07-21 09:35:51,961 - mmdet - INFO - Epoch [14][500/673]	lr: 0.01000, eta: 1:12:34, time: 0.301, data_time: 0.012, memory: 4440, loss_ins: 4.6024, loss_cate: 0.1354, loss: 4.7379
2021-07-21 09:36:06,905 - mmdet - INFO - Epoch [14][550/673]	lr: 0.01000, eta: 1:12:20, time: 0.299, data_time: 0.012, memory: 4440, loss_ins: 4.5054, loss_cate: 0.1554, loss: 4.6607
2021-07-21 09:36:22,093 - mmdet - INFO - Epoch [14][600/673]	lr: 0.01000, eta: 1:12:07, time: 0.304, data_time: 0.013, memory: 4440, loss_ins: 4.6377, loss_cate: 0.1346, loss: 4.7722
2021-07-21 09:36:37,072 - mmdet - INFO - Epoch [14][650/673]	lr: 0.01000, eta: 1:11:53, time: 0.300, data_time: 0.013, memory: 4440, loss_ins: 4.6054, loss_cate: 0.1250, loss: 4.7304
2021-07-21 09:36:59,698 - mmdet - INFO - Epoch [15][50/673]	lr: 0.01000, eta: 1:11:22, time: 0.303, data_time: 0.019, memory: 4440, loss_ins: 4.5611, loss_cate: 0.1293, loss: 4.6904
2021-07-21 09:37:14,607 - mmdet - INFO - Epoch [15][100/673]	lr: 0.01000, eta: 1:11:08, time: 0.298, data_time: 0.013, memory: 4440, loss_ins: 4.5697, loss_cate: 0.1474, loss: 4.7171
2021-07-21 09:37:29,369 - mmdet - INFO - Epoch [15][150/673]	lr: 0.01000, eta: 1:10:54, time: 0.295, data_time: 0.013, memory: 4440, loss_ins: 4.3235, loss_cate: 0.1206, loss: 4.4441
2021-07-21 09:37:44,218 - mmdet - INFO - Epoch [15][200/673]	lr: 0.01000, eta: 1:10:40, time: 0.297, data_time: 0.012, memory: 4440, loss_ins: 4.5514, loss_cate: 0.1271, loss: 4.6785
2021-07-21 09:37:58,951 - mmdet - INFO - Epoch [15][250/673]	lr: 0.01000, eta: 1:10:26, time: 0.295, data_time: 0.012, memory: 4440, loss_ins: 4.5421, loss_cate: 0.1272, loss: 4.6693
2021-07-21 09:38:14,006 - mmdet - INFO - Epoch [15][300/673]	lr: 0.01000, eta: 1:10:12, time: 0.301, data_time: 0.012, memory: 4440, loss_ins: 4.4033, loss_cate: 0.1290, loss: 4.5324
2021-07-21 09:38:29,017 - mmdet - INFO - Epoch [15][350/673]	lr: 0.01000, eta: 1:09:58, time: 0.300, data_time: 0.011, memory: 4440, loss_ins: 4.3310, loss_cate: 0.1235, loss: 4.4546
2021-07-21 09:38:43,914 - mmdet - INFO - Epoch [15][400/673]	lr: 0.01000, eta: 1:09:44, time: 0.298, data_time: 0.012, memory: 4440, loss_ins: 4.6154, loss_cate: 0.1275, loss: 4.7428
2021-07-21 09:38:58,550 - mmdet - INFO - Epoch [15][450/673]	lr: 0.01000, eta: 1:09:30, time: 0.293, data_time: 0.012, memory: 4440, loss_ins: 4.3183, loss_cate: 0.1333, loss: 4.4516
2021-07-21 09:39:13,355 - mmdet - INFO - Epoch [15][500/673]	lr: 0.01000, eta: 1:09:16, time: 0.296, data_time: 0.013, memory: 4440, loss_ins: 4.2709, loss_cate: 0.1379, loss: 4.4088
2021-07-21 09:39:28,364 - mmdet - INFO - Epoch [15][550/673]	lr: 0.01000, eta: 1:09:02, time: 0.300, data_time: 0.012, memory: 4440, loss_ins: 4.6124, loss_cate: 0.1471, loss: 4.7595
2021-07-21 09:39:43,159 - mmdet - INFO - Epoch [15][600/673]	lr: 0.01000, eta: 1:08:48, time: 0.296, data_time: 0.012, memory: 4440, loss_ins: 4.4538, loss_cate: 0.1385, loss: 4.5923
2021-07-21 09:39:58,261 - mmdet - INFO - Epoch [15][650/673]	lr: 0.01000, eta: 1:08:34, time: 0.302, data_time: 0.013, memory: 4440, loss_ins: 4.6885, loss_cate: 0.1460, loss: 4.8345
2021-07-21 09:40:20,669 - mmdet - INFO - Epoch [16][50/673]	lr: 0.01000, eta: 1:08:05, time: 0.303, data_time: 0.017, memory: 4440, loss_ins: 4.4285, loss_cate: 0.1321, loss: 4.5606
2021-07-21 09:40:35,383 - mmdet - INFO - Epoch [16][100/673]	lr: 0.01000, eta: 1:07:50, time: 0.294, data_time: 0.012, memory: 4440, loss_ins: 4.4683, loss_cate: 0.1412, loss: 4.6095
2021-07-21 09:40:50,183 - mmdet - INFO - Epoch [16][150/673]	lr: 0.01000, eta: 1:07:36, time: 0.296, data_time: 0.012, memory: 4440, loss_ins: 4.6265, loss_cate: 0.1394, loss: 4.7659
2021-07-21 09:41:05,092 - mmdet - INFO - Epoch [16][200/673]	lr: 0.01000, eta: 1:07:22, time: 0.298, data_time: 0.012, memory: 4440, loss_ins: 4.4964, loss_cate: 0.1319, loss: 4.6283
2021-07-21 09:41:19,888 - mmdet - INFO - Epoch [16][250/673]	lr: 0.01000, eta: 1:07:08, time: 0.296, data_time: 0.013, memory: 4440, loss_ins: 4.4335, loss_cate: 0.1345, loss: 4.5680
2021-07-21 09:41:34,797 - mmdet - INFO - Epoch [16][300/673]	lr: 0.01000, eta: 1:06:54, time: 0.298, data_time: 0.013, memory: 4440, loss_ins: 4.2973, loss_cate: 0.1246, loss: 4.4219
2021-07-21 09:41:49,559 - mmdet - INFO - Epoch [16][350/673]	lr: 0.01000, eta: 1:06:40, time: 0.295, data_time: 0.013, memory: 4440, loss_ins: 4.4821, loss_cate: 0.1363, loss: 4.6184
2021-07-21 09:42:04,793 - mmdet - INFO - Epoch [16][400/673]	lr: 0.01000, eta: 1:06:26, time: 0.305, data_time: 0.014, memory: 4440, loss_ins: 4.3600, loss_cate: 0.1256, loss: 4.4856
2021-07-21 09:42:19,749 - mmdet - INFO - Epoch [16][450/673]	lr: 0.01000, eta: 1:06:12, time: 0.299, data_time: 0.012, memory: 4440, loss_ins: 4.5666, loss_cate: 0.1355, loss: 4.7021
2021-07-21 09:42:34,598 - mmdet - INFO - Epoch [16][500/673]	lr: 0.01000, eta: 1:05:58, time: 0.297, data_time: 0.012, memory: 4440, loss_ins: 4.4041, loss_cate: 0.1233, loss: 4.5274
2021-07-21 09:42:49,749 - mmdet - INFO - Epoch [16][550/673]	lr: 0.01000, eta: 1:05:45, time: 0.303, data_time: 0.013, memory: 4440, loss_ins: 4.6536, loss_cate: 0.1197, loss: 4.7733
2021-07-21 09:43:04,700 - mmdet - INFO - Epoch [16][600/673]	lr: 0.01000, eta: 1:05:31, time: 0.299, data_time: 0.013, memory: 4440, loss_ins: 4.5949, loss_cate: 0.1367, loss: 4.7317
2021-07-21 09:43:19,767 - mmdet - INFO - Epoch [16][650/673]	lr: 0.01000, eta: 1:05:17, time: 0.301, data_time: 0.012, memory: 4440, loss_ins: 4.5488, loss_cate: 0.1160, loss: 4.6648
2021-07-21 09:43:42,542 - mmdet - INFO - Epoch [17][50/673]	lr: 0.01000, eta: 1:04:49, time: 0.309, data_time: 0.019, memory: 4440, loss_ins: 4.7027, loss_cate: 0.1220, loss: 4.8247
2021-07-21 09:43:57,647 - mmdet - INFO - Epoch [17][100/673]	lr: 0.01000, eta: 1:04:35, time: 0.302, data_time: 0.014, memory: 4440, loss_ins: 4.5425, loss_cate: 0.1240, loss: 4.6665
2021-07-21 09:44:12,480 - mmdet - INFO - Epoch [17][150/673]	lr: 0.01000, eta: 1:04:21, time: 0.297, data_time: 0.013, memory: 4440, loss_ins: 4.6508, loss_cate: 0.1503, loss: 4.8011
2021-07-21 09:44:27,344 - mmdet - INFO - Epoch [17][200/673]	lr: 0.01000, eta: 1:04:07, time: 0.297, data_time: 0.013, memory: 4440, loss_ins: 4.1046, loss_cate: 0.1155, loss: 4.2200
2021-07-21 09:44:42,139 - mmdet - INFO - Epoch [17][250/673]	lr: 0.01000, eta: 1:03:52, time: 0.296, data_time: 0.013, memory: 4440, loss_ins: 4.3905, loss_cate: 0.1365, loss: 4.5269
2021-07-21 09:44:57,070 - mmdet - INFO - Epoch [17][300/673]	lr: 0.01000, eta: 1:03:38, time: 0.299, data_time: 0.013, memory: 4440, loss_ins: 4.4493, loss_cate: 0.1196, loss: 4.5689
2021-07-21 09:45:11,982 - mmdet - INFO - Epoch [17][350/673]	lr: 0.01000, eta: 1:03:24, time: 0.298, data_time: 0.013, memory: 4440, loss_ins: 4.2830, loss_cate: 0.1238, loss: 4.4068
2021-07-21 09:45:27,081 - mmdet - INFO - Epoch [17][400/673]	lr: 0.01000, eta: 1:03:11, time: 0.302, data_time: 0.014, memory: 4440, loss_ins: 4.5440, loss_cate: 0.1387, loss: 4.6827
2021-07-21 09:45:42,298 - mmdet - INFO - Epoch [17][450/673]	lr: 0.01000, eta: 1:02:57, time: 0.304, data_time: 0.014, memory: 4440, loss_ins: 4.5261, loss_cate: 0.1214, loss: 4.6475
2021-07-21 09:45:57,185 - mmdet - INFO - Epoch [17][500/673]	lr: 0.01000, eta: 1:02:43, time: 0.298, data_time: 0.013, memory: 4440, loss_ins: 4.5904, loss_cate: 0.1310, loss: 4.7214
2021-07-21 09:46:11,935 - mmdet - INFO - Epoch [17][550/673]	lr: 0.01000, eta: 1:02:29, time: 0.295, data_time: 0.013, memory: 4440, loss_ins: 4.4530, loss_cate: 0.1284, loss: 4.5814
2021-07-21 09:46:26,945 - mmdet - INFO - Epoch [17][600/673]	lr: 0.01000, eta: 1:02:15, time: 0.300, data_time: 0.013, memory: 4440, loss_ins: 4.4886, loss_cate: 0.1329, loss: 4.6215
2021-07-21 09:46:42,095 - mmdet - INFO - Epoch [17][650/673]	lr: 0.01000, eta: 1:02:01, time: 0.303, data_time: 0.014, memory: 4440, loss_ins: 4.5083, loss_cate: 0.1268, loss: 4.6351
2021-07-21 09:47:04,501 - mmdet - INFO - Epoch [18][50/673]	lr: 0.01000, eta: 1:01:33, time: 0.301, data_time: 0.018, memory: 4440, loss_ins: 4.2739, loss_cate: 0.1172, loss: 4.3911
2021-07-21 09:47:19,791 - mmdet - INFO - Epoch [18][100/673]	lr: 0.01000, eta: 1:01:19, time: 0.306, data_time: 0.014, memory: 4440, loss_ins: 4.4522, loss_cate: 0.1212, loss: 4.5734
2021-07-21 09:47:34,812 - mmdet - INFO - Epoch [18][150/673]	lr: 0.01000, eta: 1:01:05, time: 0.300, data_time: 0.013, memory: 4440, loss_ins: 4.6218, loss_cate: 0.1348, loss: 4.7566
2021-07-21 09:47:50,057 - mmdet - INFO - Epoch [18][200/673]	lr: 0.01000, eta: 1:00:51, time: 0.305, data_time: 0.014, memory: 4440, loss_ins: 4.3831, loss_cate: 0.1458, loss: 4.5289
2021-07-21 09:48:05,258 - mmdet - INFO - Epoch [18][250/673]	lr: 0.01000, eta: 1:00:38, time: 0.304, data_time: 0.014, memory: 4440, loss_ins: 4.5213, loss_cate: 0.1303, loss: 4.6516
2021-07-21 09:48:20,435 - mmdet - INFO - Epoch [18][300/673]	lr: 0.01000, eta: 1:00:24, time: 0.304, data_time: 0.014, memory: 4440, loss_ins: 4.3687, loss_cate: 0.1198, loss: 4.4885
2021-07-21 09:48:35,667 - mmdet - INFO - Epoch [18][350/673]	lr: 0.01000, eta: 1:00:10, time: 0.305, data_time: 0.014, memory: 4440, loss_ins: 4.6434, loss_cate: 0.1257, loss: 4.7691
2021-07-21 09:48:50,730 - mmdet - INFO - Epoch [18][400/673]	lr: 0.01000, eta: 0:59:56, time: 0.301, data_time: 0.014, memory: 4440, loss_ins: 4.4146, loss_cate: 0.1166, loss: 4.5312
2021-07-21 09:49:05,559 - mmdet - INFO - Epoch [18][450/673]	lr: 0.01000, eta: 0:59:42, time: 0.297, data_time: 0.013, memory: 4440, loss_ins: 4.3143, loss_cate: 0.1181, loss: 4.4324
2021-07-21 09:49:20,789 - mmdet - INFO - Epoch [18][500/673]	lr: 0.01000, eta: 0:59:28, time: 0.305, data_time: 0.013, memory: 4440, loss_ins: 4.4540, loss_cate: 0.1284, loss: 4.5824
2021-07-21 09:49:36,023 - mmdet - INFO - Epoch [18][550/673]	lr: 0.01000, eta: 0:59:14, time: 0.305, data_time: 0.014, memory: 4440, loss_ins: 4.7304, loss_cate: 0.1381, loss: 4.8685
2021-07-21 09:49:51,117 - mmdet - INFO - Epoch [18][600/673]	lr: 0.01000, eta: 0:59:00, time: 0.302, data_time: 0.014, memory: 4440, loss_ins: 4.4945, loss_cate: 0.1249, loss: 4.6194
2021-07-21 09:50:06,248 - mmdet - INFO - Epoch [18][650/673]	lr: 0.01000, eta: 0:58:47, time: 0.303, data_time: 0.014, memory: 4440, loss_ins: 4.5493, loss_cate: 0.1333, loss: 4.6826
2021-07-21 09:50:28,879 - mmdet - INFO - Epoch [19][50/673]	lr: 0.01000, eta: 0:58:20, time: 0.309, data_time: 0.018, memory: 4440, loss_ins: 4.6307, loss_cate: 0.1242, loss: 4.7549
2021-07-21 09:50:43,758 - mmdet - INFO - Epoch [19][100/673]	lr: 0.01000, eta: 0:58:05, time: 0.298, data_time: 0.013, memory: 4440, loss_ins: 4.6092, loss_cate: 0.1232, loss: 4.7324
2021-07-21 09:50:58,666 - mmdet - INFO - Epoch [19][150/673]	lr: 0.01000, eta: 0:57:51, time: 0.298, data_time: 0.012, memory: 4440, loss_ins: 4.3443, loss_cate: 0.1142, loss: 4.4586
2021-07-21 09:51:13,686 - mmdet - INFO - Epoch [19][200/673]	lr: 0.01000, eta: 0:57:37, time: 0.300, data_time: 0.013, memory: 4440, loss_ins: 4.5599, loss_cate: 0.1269, loss: 4.6868
2021-07-21 09:51:28,747 - mmdet - INFO - Epoch [19][250/673]	lr: 0.01000, eta: 0:57:23, time: 0.301, data_time: 0.013, memory: 4440, loss_ins: 4.5335, loss_cate: 0.1260, loss: 4.6595
2021-07-21 09:51:43,682 - mmdet - INFO - Epoch [19][300/673]	lr: 0.01000, eta: 0:57:09, time: 0.299, data_time: 0.013, memory: 4440, loss_ins: 4.5598, loss_cate: 0.1305, loss: 4.6903
2021-07-21 09:51:58,504 - mmdet - INFO - Epoch [19][350/673]	lr: 0.01000, eta: 0:56:55, time: 0.296, data_time: 0.013, memory: 4440, loss_ins: 4.3127, loss_cate: 0.1167, loss: 4.4294
2021-07-21 09:52:13,771 - mmdet - INFO - Epoch [19][400/673]	lr: 0.01000, eta: 0:56:41, time: 0.305, data_time: 0.013, memory: 4440, loss_ins: 4.4378, loss_cate: 0.1198, loss: 4.5575
2021-07-21 09:52:28,473 - mmdet - INFO - Epoch [19][450/673]	lr: 0.01000, eta: 0:56:27, time: 0.294, data_time: 0.012, memory: 4440, loss_ins: 4.4164, loss_cate: 0.1239, loss: 4.5403
2021-07-21 09:52:43,420 - mmdet - INFO - Epoch [19][500/673]	lr: 0.01000, eta: 0:56:13, time: 0.299, data_time: 0.013, memory: 4440, loss_ins: 4.5839, loss_cate: 0.1297, loss: 4.7136
2021-07-21 09:52:58,415 - mmdet - INFO - Epoch [19][550/673]	lr: 0.01000, eta: 0:55:59, time: 0.300, data_time: 0.013, memory: 4440, loss_ins: 4.3111, loss_cate: 0.1253, loss: 4.4364
2021-07-21 09:53:13,392 - mmdet - INFO - Epoch [19][600/673]	lr: 0.01000, eta: 0:55:44, time: 0.300, data_time: 0.013, memory: 4440, loss_ins: 4.5357, loss_cate: 0.1464, loss: 4.6821
2021-07-21 09:53:28,522 - mmdet - INFO - Epoch [19][650/673]	lr: 0.01000, eta: 0:55:31, time: 0.303, data_time: 0.013, memory: 4440, loss_ins: 4.6566, loss_cate: 0.1316, loss: 4.7882
2021-07-21 09:53:50,934 - mmdet - INFO - Epoch [20][50/673]	lr: 0.01000, eta: 0:55:04, time: 0.301, data_time: 0.017, memory: 4440, loss_ins: 4.5601, loss_cate: 0.1214, loss: 4.6815
2021-07-21 09:54:06,127 - mmdet - INFO - Epoch [20][100/673]	lr: 0.01000, eta: 0:54:50, time: 0.304, data_time: 0.013, memory: 4440, loss_ins: 4.4708, loss_cate: 0.1237, loss: 4.5944
2021-07-21 09:54:20,718 - mmdet - INFO - Epoch [20][150/673]	lr: 0.01000, eta: 0:54:35, time: 0.292, data_time: 0.013, memory: 4440, loss_ins: 4.6479, loss_cate: 0.1152, loss: 4.7630
2021-07-21 09:54:35,791 - mmdet - INFO - Epoch [20][200/673]	lr: 0.01000, eta: 0:54:21, time: 0.301, data_time: 0.012, memory: 4440, loss_ins: 4.6249, loss_cate: 0.1172, loss: 4.7421
2021-07-21 09:54:50,413 - mmdet - INFO - Epoch [20][250/673]	lr: 0.01000, eta: 0:54:07, time: 0.292, data_time: 0.011, memory: 4440, loss_ins: 4.3023, loss_cate: 0.1064, loss: 4.4087
2021-07-21 09:55:05,331 - mmdet - INFO - Epoch [20][300/673]	lr: 0.01000, eta: 0:53:53, time: 0.298, data_time: 0.013, memory: 4440, loss_ins: 4.4184, loss_cate: 0.1273, loss: 4.5457
2021-07-21 09:55:20,098 - mmdet - INFO - Epoch [20][350/673]	lr: 0.01000, eta: 0:53:39, time: 0.295, data_time: 0.013, memory: 4440, loss_ins: 4.5067, loss_cate: 0.1079, loss: 4.6146
2021-07-21 09:55:35,061 - mmdet - INFO - Epoch [20][400/673]	lr: 0.01000, eta: 0:53:24, time: 0.299, data_time: 0.013, memory: 4440, loss_ins: 4.5141, loss_cate: 0.1180, loss: 4.6322
2021-07-21 09:55:50,095 - mmdet - INFO - Epoch [20][450/673]	lr: 0.01000, eta: 0:53:10, time: 0.301, data_time: 0.013, memory: 4440, loss_ins: 4.4120, loss_cate: 0.1288, loss: 4.5407
2021-07-21 09:56:05,003 - mmdet - INFO - Epoch [20][500/673]	lr: 0.01000, eta: 0:52:56, time: 0.298, data_time: 0.013, memory: 4440, loss_ins: 4.7096, loss_cate: 0.1213, loss: 4.8309
2021-07-21 09:56:19,605 - mmdet - INFO - Epoch [20][550/673]	lr: 0.01000, eta: 0:52:42, time: 0.292, data_time: 0.012, memory: 4440, loss_ins: 4.4052, loss_cate: 0.1228, loss: 4.5280
2021-07-21 09:56:34,429 - mmdet - INFO - Epoch [20][600/673]	lr: 0.01000, eta: 0:52:27, time: 0.296, data_time: 0.013, memory: 4440, loss_ins: 4.2176, loss_cate: 0.0964, loss: 4.3140
2021-07-21 09:56:49,518 - mmdet - INFO - Epoch [20][650/673]	lr: 0.01000, eta: 0:52:13, time: 0.302, data_time: 0.013, memory: 4440, loss_ins: 4.4395, loss_cate: 0.1275, loss: 4.5670
2021-07-21 09:57:11,812 - mmdet - INFO - Epoch [21][50/673]	lr: 0.01000, eta: 0:51:47, time: 0.299, data_time: 0.017, memory: 4440, loss_ins: 4.1951, loss_cate: 0.1163, loss: 4.3114
2021-07-21 09:57:26,685 - mmdet - INFO - Epoch [21][100/673]	lr: 0.01000, eta: 0:51:33, time: 0.297, data_time: 0.013, memory: 4440, loss_ins: 4.2249, loss_cate: 0.1169, loss: 4.3418
2021-07-21 09:57:41,878 - mmdet - INFO - Epoch [21][150/673]	lr: 0.01000, eta: 0:51:19, time: 0.304, data_time: 0.013, memory: 4440, loss_ins: 4.5276, loss_cate: 0.1131, loss: 4.6408
2021-07-21 09:57:56,774 - mmdet - INFO - Epoch [21][200/673]	lr: 0.01000, eta: 0:51:05, time: 0.298, data_time: 0.013, memory: 4440, loss_ins: 4.3127, loss_cate: 0.1222, loss: 4.4349
2021-07-21 09:58:11,968 - mmdet - INFO - Epoch [21][250/673]	lr: 0.01000, eta: 0:50:51, time: 0.304, data_time: 0.013, memory: 4440, loss_ins: 4.5687, loss_cate: 0.1241, loss: 4.6929
2021-07-21 09:58:26,979 - mmdet - INFO - Epoch [21][300/673]	lr: 0.01000, eta: 0:50:37, time: 0.300, data_time: 0.011, memory: 4440, loss_ins: 4.6612, loss_cate: 0.1094, loss: 4.7705
2021-07-21 09:58:41,928 - mmdet - INFO - Epoch [21][350/673]	lr: 0.01000, eta: 0:50:23, time: 0.299, data_time: 0.011, memory: 4440, loss_ins: 4.4783, loss_cate: 0.1113, loss: 4.5896
2021-07-21 09:58:57,105 - mmdet - INFO - Epoch [21][400/673]	lr: 0.01000, eta: 0:50:09, time: 0.304, data_time: 0.013, memory: 4440, loss_ins: 4.5716, loss_cate: 0.1196, loss: 4.6912
2021-07-21 09:59:11,813 - mmdet - INFO - Epoch [21][450/673]	lr: 0.01000, eta: 0:49:54, time: 0.294, data_time: 0.013, memory: 4440, loss_ins: 4.3275, loss_cate: 0.1173, loss: 4.4447
2021-07-21 09:59:27,089 - mmdet - INFO - Epoch [21][500/673]	lr: 0.01000, eta: 0:49:40, time: 0.306, data_time: 0.014, memory: 4440, loss_ins: 4.9609, loss_cate: 0.1291, loss: 5.0900
2021-07-21 09:59:42,301 - mmdet - INFO - Epoch [21][550/673]	lr: 0.01000, eta: 0:49:26, time: 0.304, data_time: 0.013, memory: 4440, loss_ins: 4.4959, loss_cate: 0.1245, loss: 4.6204
2021-07-21 09:59:57,270 - mmdet - INFO - Epoch [21][600/673]	lr: 0.01000, eta: 0:49:12, time: 0.299, data_time: 0.013, memory: 4440, loss_ins: 4.4604, loss_cate: 0.1203, loss: 4.5807
2021-07-21 10:00:12,201 - mmdet - INFO - Epoch [21][650/673]	lr: 0.01000, eta: 0:48:58, time: 0.299, data_time: 0.013, memory: 4440, loss_ins: 4.4054, loss_cate: 0.1285, loss: 4.5339
2021-07-21 10:00:35,163 - mmdet - INFO - Epoch [22][50/673]	lr: 0.01000, eta: 0:48:33, time: 0.310, data_time: 0.019, memory: 4440, loss_ins: 4.2826, loss_cate: 0.1160, loss: 4.3986
2021-07-21 10:00:49,960 - mmdet - INFO - Epoch [22][100/673]	lr: 0.01000, eta: 0:48:18, time: 0.296, data_time: 0.012, memory: 4440, loss_ins: 4.3224, loss_cate: 0.1121, loss: 4.4345
2021-07-21 10:01:04,820 - mmdet - INFO - Epoch [22][150/673]	lr: 0.01000, eta: 0:48:04, time: 0.297, data_time: 0.013, memory: 4440, loss_ins: 4.6041, loss_cate: 0.1208, loss: 4.7249
2021-07-21 10:01:19,754 - mmdet - INFO - Epoch [22][200/673]	lr: 0.01000, eta: 0:47:50, time: 0.299, data_time: 0.013, memory: 4440, loss_ins: 4.5195, loss_cate: 0.1198, loss: 4.6394
2021-07-21 10:01:34,400 - mmdet - INFO - Epoch [22][250/673]	lr: 0.01000, eta: 0:47:36, time: 0.293, data_time: 0.012, memory: 4440, loss_ins: 4.1481, loss_cate: 0.1164, loss: 4.2645
2021-07-21 10:01:49,515 - mmdet - INFO - Epoch [22][300/673]	lr: 0.01000, eta: 0:47:21, time: 0.302, data_time: 0.013, memory: 4440, loss_ins: 4.5246, loss_cate: 0.1199, loss: 4.6445
2021-07-21 10:02:04,523 - mmdet - INFO - Epoch [22][350/673]	lr: 0.01000, eta: 0:47:07, time: 0.300, data_time: 0.013, memory: 4440, loss_ins: 4.6338, loss_cate: 0.1182, loss: 4.7520
2021-07-21 10:02:19,519 - mmdet - INFO - Epoch [22][400/673]	lr: 0.01000, eta: 0:46:53, time: 0.300, data_time: 0.013, memory: 4440, loss_ins: 4.5975, loss_cate: 0.1162, loss: 4.7137
2021-07-21 10:02:34,484 - mmdet - INFO - Epoch [22][450/673]	lr: 0.01000, eta: 0:46:39, time: 0.299, data_time: 0.013, memory: 4440, loss_ins: 4.3987, loss_cate: 0.1200, loss: 4.5187
2021-07-21 10:02:49,740 - mmdet - INFO - Epoch [22][500/673]	lr: 0.01000, eta: 0:46:25, time: 0.305, data_time: 0.014, memory: 4440, loss_ins: 4.6721, loss_cate: 0.1253, loss: 4.7974
2021-07-21 10:03:04,886 - mmdet - INFO - Epoch [22][550/673]	lr: 0.01000, eta: 0:46:11, time: 0.303, data_time: 0.013, memory: 4440, loss_ins: 4.4242, loss_cate: 0.1234, loss: 4.5475
2021-07-21 10:03:20,107 - mmdet - INFO - Epoch [22][600/673]	lr: 0.01000, eta: 0:45:57, time: 0.304, data_time: 0.013, memory: 4440, loss_ins: 4.6664, loss_cate: 0.1133, loss: 4.7797
2021-07-21 10:03:35,405 - mmdet - INFO - Epoch [22][650/673]	lr: 0.01000, eta: 0:45:43, time: 0.306, data_time: 0.014, memory: 4440, loss_ins: 4.6893, loss_cate: 0.1137, loss: 4.8030
2021-07-21 10:03:57,845 - mmdet - INFO - Epoch [23][50/673]	lr: 0.01000, eta: 0:45:18, time: 0.301, data_time: 0.017, memory: 4440, loss_ins: 4.6382, loss_cate: 0.1204, loss: 4.7586
2021-07-21 10:04:12,864 - mmdet - INFO - Epoch [23][100/673]	lr: 0.01000, eta: 0:45:03, time: 0.300, data_time: 0.013, memory: 4440, loss_ins: 4.2986, loss_cate: 0.1223, loss: 4.4209
2021-07-21 10:04:27,707 - mmdet - INFO - Epoch [23][150/673]	lr: 0.01000, eta: 0:44:49, time: 0.297, data_time: 0.013, memory: 4440, loss_ins: 4.3386, loss_cate: 0.1093, loss: 4.4478
2021-07-21 10:04:42,727 - mmdet - INFO - Epoch [23][200/673]	lr: 0.01000, eta: 0:44:35, time: 0.300, data_time: 0.013, memory: 4440, loss_ins: 4.6468, loss_cate: 0.1232, loss: 4.7700
2021-07-21 10:04:57,732 - mmdet - INFO - Epoch [23][250/673]	lr: 0.01000, eta: 0:44:21, time: 0.300, data_time: 0.013, memory: 4440, loss_ins: 4.6311, loss_cate: 0.1260, loss: 4.7571
2021-07-21 10:05:12,762 - mmdet - INFO - Epoch [23][300/673]	lr: 0.01000, eta: 0:44:07, time: 0.301, data_time: 0.013, memory: 4440, loss_ins: 4.4526, loss_cate: 0.1083, loss: 4.5609
2021-07-21 10:05:27,892 - mmdet - INFO - Epoch [23][350/673]	lr: 0.01000, eta: 0:43:52, time: 0.303, data_time: 0.014, memory: 4440, loss_ins: 4.5472, loss_cate: 0.1223, loss: 4.6695
2021-07-21 10:05:42,883 - mmdet - INFO - Epoch [23][400/673]	lr: 0.01000, eta: 0:43:38, time: 0.300, data_time: 0.013, memory: 4440, loss_ins: 4.3859, loss_cate: 0.1134, loss: 4.4993
2021-07-21 10:05:57,851 - mmdet - INFO - Epoch [23][450/673]	lr: 0.01000, eta: 0:43:24, time: 0.299, data_time: 0.013, memory: 4440, loss_ins: 4.4815, loss_cate: 0.1079, loss: 4.5895
2021-07-21 10:06:12,543 - mmdet - INFO - Epoch [23][500/673]	lr: 0.01000, eta: 0:43:09, time: 0.294, data_time: 0.012, memory: 4440, loss_ins: 4.4006, loss_cate: 0.1128, loss: 4.5134
2021-07-21 10:06:27,446 - mmdet - INFO - Epoch [23][550/673]	lr: 0.01000, eta: 0:42:55, time: 0.298, data_time: 0.013, memory: 4440, loss_ins: 4.4222, loss_cate: 0.1136, loss: 4.5358
2021-07-21 10:06:42,444 - mmdet - INFO - Epoch [23][600/673]	lr: 0.01000, eta: 0:42:41, time: 0.300, data_time: 0.013, memory: 4440, loss_ins: 4.3801, loss_cate: 0.1090, loss: 4.4891
2021-07-21 10:06:57,798 - mmdet - INFO - Epoch [23][650/673]	lr: 0.01000, eta: 0:42:27, time: 0.307, data_time: 0.013, memory: 4440, loss_ins: 4.5078, loss_cate: 0.1042, loss: 4.6120
2021-07-21 10:07:20,695 - mmdet - INFO - Epoch [24][50/673]	lr: 0.01000, eta: 0:42:03, time: 0.309, data_time: 0.019, memory: 4440, loss_ins: 4.5909, loss_cate: 0.1172, loss: 4.7081
2021-07-21 10:07:35,518 - mmdet - INFO - Epoch [24][100/673]	lr: 0.01000, eta: 0:41:48, time: 0.296, data_time: 0.012, memory: 4440, loss_ins: 4.2946, loss_cate: 0.1138, loss: 4.4084
2021-07-21 10:07:50,714 - mmdet - INFO - Epoch [24][150/673]	lr: 0.01000, eta: 0:41:34, time: 0.304, data_time: 0.014, memory: 4440, loss_ins: 4.5727, loss_cate: 0.1149, loss: 4.6876
2021-07-21 10:08:05,630 - mmdet - INFO - Epoch [24][200/673]	lr: 0.01000, eta: 0:41:20, time: 0.298, data_time: 0.013, memory: 4440, loss_ins: 4.4600, loss_cate: 0.1172, loss: 4.5771
2021-07-21 10:08:20,735 - mmdet - INFO - Epoch [24][250/673]	lr: 0.01000, eta: 0:41:06, time: 0.302, data_time: 0.013, memory: 4440, loss_ins: 4.4751, loss_cate: 0.0999, loss: 4.5750
2021-07-21 10:08:35,791 - mmdet - INFO - Epoch [24][300/673]	lr: 0.01000, eta: 0:40:51, time: 0.301, data_time: 0.013, memory: 4440, loss_ins: 4.0906, loss_cate: 0.1037, loss: 4.1943
2021-07-21 10:08:50,695 - mmdet - INFO - Epoch [24][350/673]	lr: 0.01000, eta: 0:40:37, time: 0.298, data_time: 0.013, memory: 4440, loss_ins: 4.3272, loss_cate: 0.1165, loss: 4.4436
2021-07-21 10:09:05,577 - mmdet - INFO - Epoch [24][400/673]	lr: 0.01000, eta: 0:40:23, time: 0.298, data_time: 0.012, memory: 4440, loss_ins: 4.4716, loss_cate: 0.1017, loss: 4.5732
2021-07-21 10:09:20,726 - mmdet - INFO - Epoch [24][450/673]	lr: 0.01000, eta: 0:40:09, time: 0.303, data_time: 0.013, memory: 4440, loss_ins: 4.3137, loss_cate: 0.0982, loss: 4.4120
2021-07-21 10:09:35,918 - mmdet - INFO - Epoch [24][500/673]	lr: 0.01000, eta: 0:39:54, time: 0.304, data_time: 0.013, memory: 4440, loss_ins: 4.8379, loss_cate: 0.1126, loss: 4.9504
2021-07-21 10:09:50,832 - mmdet - INFO - Epoch [24][550/673]	lr: 0.01000, eta: 0:39:40, time: 0.298, data_time: 0.013, memory: 4440, loss_ins: 4.5980, loss_cate: 0.1258, loss: 4.7239
2021-07-21 10:10:05,872 - mmdet - INFO - Epoch [24][600/673]	lr: 0.01000, eta: 0:39:26, time: 0.301, data_time: 0.012, memory: 4440, loss_ins: 4.5112, loss_cate: 0.1106, loss: 4.6218
2021-07-21 10:10:20,805 - mmdet - INFO - Epoch [24][650/673]	lr: 0.01000, eta: 0:39:12, time: 0.299, data_time: 0.012, memory: 4440, loss_ins: 4.6608, loss_cate: 0.1312, loss: 4.7921
2021-07-21 10:10:43,528 - mmdet - INFO - Epoch [25][50/673]	lr: 0.01000, eta: 0:38:47, time: 0.308, data_time: 0.019, memory: 4440, loss_ins: 4.4443, loss_cate: 0.1121, loss: 4.5564
2021-07-21 10:10:58,768 - mmdet - INFO - Epoch [25][100/673]	lr: 0.01000, eta: 0:38:33, time: 0.305, data_time: 0.014, memory: 4440, loss_ins: 4.6214, loss_cate: 0.1173, loss: 4.7387
2021-07-21 10:11:13,982 - mmdet - INFO - Epoch [25][150/673]	lr: 0.01000, eta: 0:38:19, time: 0.304, data_time: 0.014, memory: 4440, loss_ins: 4.6042, loss_cate: 0.1123, loss: 4.7164
2021-07-21 10:11:28,916 - mmdet - INFO - Epoch [25][200/673]	lr: 0.01000, eta: 0:38:05, time: 0.299, data_time: 0.013, memory: 4440, loss_ins: 4.4299, loss_cate: 0.0955, loss: 4.5254
2021-07-21 10:11:43,902 - mmdet - INFO - Epoch [25][250/673]	lr: 0.01000, eta: 0:37:51, time: 0.300, data_time: 0.014, memory: 4440, loss_ins: 4.2671, loss_cate: 0.1105, loss: 4.3777
2021-07-21 10:11:58,845 - mmdet - INFO - Epoch [25][300/673]	lr: 0.01000, eta: 0:37:36, time: 0.299, data_time: 0.014, memory: 4440, loss_ins: 4.3603, loss_cate: 0.1248, loss: 4.4852
2021-07-21 10:12:14,014 - mmdet - INFO - Epoch [25][350/673]	lr: 0.01000, eta: 0:37:22, time: 0.303, data_time: 0.014, memory: 4440, loss_ins: 4.2936, loss_cate: 0.1016, loss: 4.3952
2021-07-21 10:12:29,298 - mmdet - INFO - Epoch [25][400/673]	lr: 0.01000, eta: 0:37:08, time: 0.306, data_time: 0.014, memory: 4440, loss_ins: 4.4206, loss_cate: 0.1192, loss: 4.5398
2021-07-21 10:12:44,253 - mmdet - INFO - Epoch [25][450/673]	lr: 0.01000, eta: 0:36:54, time: 0.299, data_time: 0.014, memory: 4440, loss_ins: 4.6570, loss_cate: 0.1087, loss: 4.7657
2021-07-21 10:12:59,510 - mmdet - INFO - Epoch [25][500/673]	lr: 0.01000, eta: 0:36:39, time: 0.305, data_time: 0.014, memory: 4440, loss_ins: 4.6600, loss_cate: 0.1205, loss: 4.7805
2021-07-21 10:13:14,587 - mmdet - INFO - Epoch [25][550/673]	lr: 0.01000, eta: 0:36:25, time: 0.302, data_time: 0.013, memory: 4440, loss_ins: 4.6158, loss_cate: 0.1134, loss: 4.7292
2021-07-21 10:13:29,616 - mmdet - INFO - Epoch [25][600/673]	lr: 0.01000, eta: 0:36:11, time: 0.301, data_time: 0.014, memory: 4440, loss_ins: 4.3831, loss_cate: 0.1175, loss: 4.5006
2021-07-21 10:13:44,242 - mmdet - INFO - Epoch [25][650/673]	lr: 0.01000, eta: 0:35:56, time: 0.293, data_time: 0.013, memory: 4440, loss_ins: 4.2044, loss_cate: 0.1079, loss: 4.3123
2021-07-21 10:14:06,849 - mmdet - INFO - Epoch [26][50/673]	lr: 0.01000, eta: 0:35:33, time: 0.306, data_time: 0.019, memory: 4440, loss_ins: 4.4416, loss_cate: 0.1108, loss: 4.5524
2021-07-21 10:14:21,826 - mmdet - INFO - Epoch [26][100/673]	lr: 0.01000, eta: 0:35:18, time: 0.300, data_time: 0.013, memory: 4440, loss_ins: 4.3866, loss_cate: 0.1079, loss: 4.4945
2021-07-21 10:14:36,597 - mmdet - INFO - Epoch [26][150/673]	lr: 0.01000, eta: 0:35:04, time: 0.295, data_time: 0.013, memory: 4440, loss_ins: 4.3514, loss_cate: 0.1202, loss: 4.4716
2021-07-21 10:14:51,385 - mmdet - INFO - Epoch [26][200/673]	lr: 0.01000, eta: 0:34:50, time: 0.296, data_time: 0.012, memory: 4440, loss_ins: 4.4531, loss_cate: 0.1061, loss: 4.5592
2021-07-21 10:15:06,444 - mmdet - INFO - Epoch [26][250/673]	lr: 0.01000, eta: 0:34:35, time: 0.301, data_time: 0.013, memory: 4440, loss_ins: 4.6808, loss_cate: 0.1187, loss: 4.7995
2021-07-21 10:15:21,709 - mmdet - INFO - Epoch [26][300/673]	lr: 0.01000, eta: 0:34:21, time: 0.305, data_time: 0.013, memory: 4440, loss_ins: 4.6192, loss_cate: 0.1235, loss: 4.7427
2021-07-21 10:15:36,616 - mmdet - INFO - Epoch [26][350/673]	lr: 0.01000, eta: 0:34:07, time: 0.298, data_time: 0.013, memory: 4440, loss_ins: 4.3130, loss_cate: 0.1159, loss: 4.4289
2021-07-21 10:15:51,667 - mmdet - INFO - Epoch [26][400/673]	lr: 0.01000, eta: 0:33:52, time: 0.301, data_time: 0.013, memory: 4440, loss_ins: 4.4658, loss_cate: 0.1183, loss: 4.5841
2021-07-21 10:16:06,846 - mmdet - INFO - Epoch [26][450/673]	lr: 0.01000, eta: 0:33:38, time: 0.304, data_time: 0.013, memory: 4440, loss_ins: 4.3613, loss_cate: 0.1009, loss: 4.4622
2021-07-21 10:16:21,888 - mmdet - INFO - Epoch [26][500/673]	lr: 0.01000, eta: 0:33:24, time: 0.301, data_time: 0.013, memory: 4440, loss_ins: 4.3604, loss_cate: 0.1110, loss: 4.4714
2021-07-21 10:16:36,961 - mmdet - INFO - Epoch [26][550/673]	lr: 0.01000, eta: 0:33:10, time: 0.301, data_time: 0.013, memory: 4440, loss_ins: 4.6615, loss_cate: 0.0974, loss: 4.7589
2021-07-21 10:16:52,180 - mmdet - INFO - Epoch [26][600/673]	lr: 0.01000, eta: 0:32:55, time: 0.304, data_time: 0.015, memory: 4440, loss_ins: 4.5861, loss_cate: 0.1070, loss: 4.6931
2021-07-21 10:17:07,591 - mmdet - INFO - Epoch [26][650/673]	lr: 0.01000, eta: 0:32:41, time: 0.308, data_time: 0.014, memory: 4440, loss_ins: 4.7447, loss_cate: 0.1117, loss: 4.8565
2021-07-21 10:17:29,846 - mmdet - INFO - Epoch [27][50/673]	lr: 0.01000, eta: 0:32:18, time: 0.301, data_time: 0.016, memory: 4440, loss_ins: 4.4486, loss_cate: 0.1066, loss: 4.5552
2021-07-21 10:17:44,422 - mmdet - INFO - Epoch [27][100/673]	lr: 0.01000, eta: 0:32:03, time: 0.292, data_time: 0.013, memory: 4440, loss_ins: 4.3371, loss_cate: 0.1053, loss: 4.4424
2021-07-21 10:17:59,081 - mmdet - INFO - Epoch [27][150/673]	lr: 0.01000, eta: 0:31:49, time: 0.293, data_time: 0.014, memory: 4440, loss_ins: 4.3667, loss_cate: 0.1093, loss: 4.4760
2021-07-21 10:18:14,092 - mmdet - INFO - Epoch [27][200/673]	lr: 0.01000, eta: 0:31:34, time: 0.300, data_time: 0.014, memory: 4440, loss_ins: 4.7874, loss_cate: 0.1151, loss: 4.9025
2021-07-21 10:18:28,796 - mmdet - INFO - Epoch [27][250/673]	lr: 0.01000, eta: 0:31:20, time: 0.294, data_time: 0.013, memory: 4440, loss_ins: 4.3469, loss_cate: 0.1027, loss: 4.4497
2021-07-21 10:18:43,864 - mmdet - INFO - Epoch [27][300/673]	lr: 0.01000, eta: 0:31:06, time: 0.301, data_time: 0.013, memory: 4440, loss_ins: 4.4998, loss_cate: 0.1033, loss: 4.6031
2021-07-21 10:18:58,632 - mmdet - INFO - Epoch [27][350/673]	lr: 0.01000, eta: 0:30:51, time: 0.295, data_time: 0.012, memory: 4440, loss_ins: 4.3534, loss_cate: 0.1119, loss: 4.4653
2021-07-21 10:19:13,589 - mmdet - INFO - Epoch [27][400/673]	lr: 0.01000, eta: 0:30:37, time: 0.299, data_time: 0.013, memory: 4440, loss_ins: 4.4826, loss_cate: 0.1195, loss: 4.6021
2021-07-21 10:19:28,922 - mmdet - INFO - Epoch [27][450/673]	lr: 0.01000, eta: 0:30:23, time: 0.307, data_time: 0.012, memory: 4440, loss_ins: 4.7606, loss_cate: 0.1179, loss: 4.8784
2021-07-21 10:19:43,876 - mmdet - INFO - Epoch [27][500/673]	lr: 0.01000, eta: 0:30:08, time: 0.299, data_time: 0.012, memory: 4440, loss_ins: 4.5033, loss_cate: 0.1093, loss: 4.6126
2021-07-21 10:19:58,583 - mmdet - INFO - Epoch [27][550/673]	lr: 0.01000, eta: 0:29:54, time: 0.294, data_time: 0.011, memory: 4440, loss_ins: 4.3488, loss_cate: 0.0980, loss: 4.4468
2021-07-21 10:20:13,732 - mmdet - INFO - Epoch [27][600/673]	lr: 0.01000, eta: 0:29:39, time: 0.303, data_time: 0.013, memory: 4440, loss_ins: 4.4548, loss_cate: 0.1186, loss: 4.5734
2021-07-21 10:20:28,456 - mmdet - INFO - Epoch [27][650/673]	lr: 0.01000, eta: 0:29:25, time: 0.294, data_time: 0.011, memory: 4440, loss_ins: 4.7502, loss_cate: 0.1052, loss: 4.8554
2021-07-21 10:20:50,776 - mmdet - INFO - Epoch [28][50/673]	lr: 0.00100, eta: 0:29:02, time: 0.299, data_time: 0.017, memory: 4440, loss_ins: 4.3471, loss_cate: 0.1076, loss: 4.4547
2021-07-21 10:21:05,571 - mmdet - INFO - Epoch [28][100/673]	lr: 0.00100, eta: 0:28:47, time: 0.296, data_time: 0.012, memory: 4440, loss_ins: 4.5435, loss_cate: 0.0982, loss: 4.6416
2021-07-21 10:21:20,747 - mmdet - INFO - Epoch [28][150/673]	lr: 0.00100, eta: 0:28:33, time: 0.304, data_time: 0.014, memory: 4440, loss_ins: 4.5749, loss_cate: 0.1113, loss: 4.6862
2021-07-21 10:21:35,568 - mmdet - INFO - Epoch [28][200/673]	lr: 0.00100, eta: 0:28:19, time: 0.296, data_time: 0.012, memory: 4440, loss_ins: 4.4866, loss_cate: 0.1070, loss: 4.5936
2021-07-21 10:21:50,392 - mmdet - INFO - Epoch [28][250/673]	lr: 0.00100, eta: 0:28:04, time: 0.296, data_time: 0.013, memory: 4440, loss_ins: 4.5143, loss_cate: 0.0964, loss: 4.6107
2021-07-21 10:22:05,525 - mmdet - INFO - Epoch [28][300/673]	lr: 0.00100, eta: 0:27:50, time: 0.303, data_time: 0.013, memory: 4440, loss_ins: 4.5183, loss_cate: 0.0832, loss: 4.6016
2021-07-21 10:22:20,550 - mmdet - INFO - Epoch [28][350/673]	lr: 0.00100, eta: 0:27:36, time: 0.300, data_time: 0.013, memory: 4440, loss_ins: 4.3775, loss_cate: 0.0903, loss: 4.4678
2021-07-21 10:22:35,542 - mmdet - INFO - Epoch [28][400/673]	lr: 0.00100, eta: 0:27:21, time: 0.300, data_time: 0.012, memory: 4440, loss_ins: 4.6245, loss_cate: 0.0925, loss: 4.7170
2021-07-21 10:22:50,304 - mmdet - INFO - Epoch [28][450/673]	lr: 0.00100, eta: 0:27:07, time: 0.295, data_time: 0.012, memory: 4440, loss_ins: 4.6251, loss_cate: 0.0876, loss: 4.7127
2021-07-21 10:23:05,076 - mmdet - INFO - Epoch [28][500/673]	lr: 0.00100, eta: 0:26:52, time: 0.295, data_time: 0.012, memory: 4440, loss_ins: 4.3486, loss_cate: 0.0779, loss: 4.4265
2021-07-21 10:23:20,173 - mmdet - INFO - Epoch [28][550/673]	lr: 0.00100, eta: 0:26:38, time: 0.302, data_time: 0.013, memory: 4440, loss_ins: 4.3690, loss_cate: 0.0872, loss: 4.4562
2021-07-21 10:23:35,235 - mmdet - INFO - Epoch [28][600/673]	lr: 0.00100, eta: 0:26:24, time: 0.301, data_time: 0.013, memory: 4440, loss_ins: 4.7465, loss_cate: 0.1016, loss: 4.8481
2021-07-21 10:23:50,073 - mmdet - INFO - Epoch [28][650/673]	lr: 0.00100, eta: 0:26:09, time: 0.297, data_time: 0.012, memory: 4440, loss_ins: 4.3817, loss_cate: 0.0866, loss: 4.4683
2021-07-21 10:24:12,529 - mmdet - INFO - Epoch [29][50/673]	lr: 0.00100, eta: 0:25:46, time: 0.308, data_time: 0.017, memory: 4440, loss_ins: 4.4531, loss_cate: 0.0834, loss: 4.5365
2021-07-21 10:24:27,693 - mmdet - INFO - Epoch [29][100/673]	lr: 0.00100, eta: 0:25:32, time: 0.303, data_time: 0.014, memory: 4440, loss_ins: 4.6443, loss_cate: 0.0946, loss: 4.7389
2021-07-21 10:24:42,822 - mmdet - INFO - Epoch [29][150/673]	lr: 0.00100, eta: 0:25:18, time: 0.303, data_time: 0.014, memory: 4440, loss_ins: 4.5892, loss_cate: 0.0899, loss: 4.6791
2021-07-21 10:24:57,826 - mmdet - INFO - Epoch [29][200/673]	lr: 0.00100, eta: 0:25:03, time: 0.300, data_time: 0.013, memory: 4440, loss_ins: 4.6461, loss_cate: 0.0926, loss: 4.7388
2021-07-21 10:25:12,850 - mmdet - INFO - Epoch [29][250/673]	lr: 0.00100, eta: 0:24:49, time: 0.300, data_time: 0.013, memory: 4440, loss_ins: 4.5284, loss_cate: 0.0777, loss: 4.6061
2021-07-21 10:25:27,857 - mmdet - INFO - Epoch [29][300/673]	lr: 0.00100, eta: 0:24:35, time: 0.300, data_time: 0.013, memory: 4440, loss_ins: 4.3670, loss_cate: 0.0842, loss: 4.4512
2021-07-21 10:25:42,909 - mmdet - INFO - Epoch [29][350/673]	lr: 0.00100, eta: 0:24:20, time: 0.301, data_time: 0.012, memory: 4440, loss_ins: 4.5326, loss_cate: 0.0987, loss: 4.6313
2021-07-21 10:25:58,008 - mmdet - INFO - Epoch [29][400/673]	lr: 0.00100, eta: 0:24:06, time: 0.302, data_time: 0.013, memory: 4440, loss_ins: 4.4897, loss_cate: 0.0859, loss: 4.5756
2021-07-21 10:26:13,044 - mmdet - INFO - Epoch [29][450/673]	lr: 0.00100, eta: 0:23:52, time: 0.301, data_time: 0.012, memory: 4440, loss_ins: 4.4463, loss_cate: 0.0810, loss: 4.5273
2021-07-21 10:26:28,203 - mmdet - INFO - Epoch [29][500/673]	lr: 0.00100, eta: 0:23:37, time: 0.303, data_time: 0.013, memory: 4440, loss_ins: 4.7392, loss_cate: 0.0944, loss: 4.8336
2021-07-21 10:26:43,058 - mmdet - INFO - Epoch [29][550/673]	lr: 0.00100, eta: 0:23:23, time: 0.297, data_time: 0.013, memory: 4440, loss_ins: 4.3263, loss_cate: 0.0828, loss: 4.4090
2021-07-21 10:26:58,330 - mmdet - INFO - Epoch [29][600/673]	lr: 0.00100, eta: 0:23:08, time: 0.305, data_time: 0.013, memory: 4440, loss_ins: 4.3135, loss_cate: 0.0778, loss: 4.3912
2021-07-21 10:27:13,240 - mmdet - INFO - Epoch [29][650/673]	lr: 0.00100, eta: 0:22:54, time: 0.298, data_time: 0.013, memory: 4440, loss_ins: 4.4021, loss_cate: 0.0922, loss: 4.4943
2021-07-21 10:27:35,744 - mmdet - INFO - Epoch [30][50/673]	lr: 0.00100, eta: 0:22:31, time: 0.303, data_time: 0.019, memory: 4440, loss_ins: 4.7511, loss_cate: 0.0867, loss: 4.8378
2021-07-21 10:27:50,919 - mmdet - INFO - Epoch [30][100/673]	lr: 0.00100, eta: 0:22:17, time: 0.303, data_time: 0.014, memory: 4440, loss_ins: 4.6880, loss_cate: 0.0888, loss: 4.7768
2021-07-21 10:28:05,896 - mmdet - INFO - Epoch [30][150/673]	lr: 0.00100, eta: 0:22:03, time: 0.300, data_time: 0.013, memory: 4440, loss_ins: 4.0751, loss_cate: 0.0818, loss: 4.1569
2021-07-21 10:28:20,636 - mmdet - INFO - Epoch [30][200/673]	lr: 0.00100, eta: 0:21:48, time: 0.295, data_time: 0.013, memory: 4440, loss_ins: 4.2047, loss_cate: 0.0832, loss: 4.2879
2021-07-21 10:28:35,970 - mmdet - INFO - Epoch [30][250/673]	lr: 0.00100, eta: 0:21:34, time: 0.307, data_time: 0.014, memory: 4440, loss_ins: 4.6763, loss_cate: 0.0848, loss: 4.7611
2021-07-21 10:28:51,157 - mmdet - INFO - Epoch [30][300/673]	lr: 0.00100, eta: 0:21:20, time: 0.304, data_time: 0.014, memory: 4440, loss_ins: 4.5706, loss_cate: 0.0887, loss: 4.6593
2021-07-21 10:29:06,164 - mmdet - INFO - Epoch [30][350/673]	lr: 0.00100, eta: 0:21:05, time: 0.300, data_time: 0.013, memory: 4440, loss_ins: 4.3684, loss_cate: 0.0933, loss: 4.4617
2021-07-21 10:29:20,853 - mmdet - INFO - Epoch [30][400/673]	lr: 0.00100, eta: 0:20:51, time: 0.294, data_time: 0.013, memory: 4440, loss_ins: 4.3265, loss_cate: 0.0884, loss: 4.4148
2021-07-21 10:29:35,995 - mmdet - INFO - Epoch [30][450/673]	lr: 0.00100, eta: 0:20:36, time: 0.303, data_time: 0.014, memory: 4440, loss_ins: 4.6054, loss_cate: 0.0846, loss: 4.6901
2021-07-21 10:29:51,217 - mmdet - INFO - Epoch [30][500/673]	lr: 0.00100, eta: 0:20:22, time: 0.304, data_time: 0.014, memory: 4440, loss_ins: 4.4137, loss_cate: 0.0881, loss: 4.5018
2021-07-21 10:30:06,289 - mmdet - INFO - Epoch [30][550/673]	lr: 0.00100, eta: 0:20:08, time: 0.301, data_time: 0.012, memory: 4440, loss_ins: 4.6365, loss_cate: 0.0889, loss: 4.7254
2021-07-21 10:30:21,302 - mmdet - INFO - Epoch [30][600/673]	lr: 0.00100, eta: 0:19:53, time: 0.300, data_time: 0.010, memory: 4440, loss_ins: 4.2638, loss_cate: 0.0845, loss: 4.3483
2021-07-21 10:30:36,208 - mmdet - INFO - Epoch [30][650/673]	lr: 0.00100, eta: 0:19:39, time: 0.298, data_time: 0.012, memory: 4440, loss_ins: 4.5654, loss_cate: 0.0892, loss: 4.6546
2021-07-21 10:30:58,886 - mmdet - INFO - Epoch [31][50/673]	lr: 0.00100, eta: 0:19:16, time: 0.307, data_time: 0.019, memory: 4440, loss_ins: 4.4664, loss_cate: 0.0838, loss: 4.5502
2021-07-21 10:31:13,998 - mmdet - INFO - Epoch [31][100/673]	lr: 0.00100, eta: 0:19:02, time: 0.302, data_time: 0.014, memory: 4440, loss_ins: 4.4395, loss_cate: 0.0756, loss: 4.5150
2021-07-21 10:31:28,985 - mmdet - INFO - Epoch [31][150/673]	lr: 0.00100, eta: 0:18:48, time: 0.300, data_time: 0.013, memory: 4440, loss_ins: 4.4016, loss_cate: 0.0766, loss: 4.4783
2021-07-21 10:31:43,943 - mmdet - INFO - Epoch [31][200/673]	lr: 0.00100, eta: 0:18:33, time: 0.299, data_time: 0.013, memory: 4440, loss_ins: 4.5528, loss_cate: 0.0835, loss: 4.6363
2021-07-21 10:31:58,744 - mmdet - INFO - Epoch [31][250/673]	lr: 0.00100, eta: 0:18:19, time: 0.296, data_time: 0.012, memory: 4440, loss_ins: 4.5166, loss_cate: 0.0933, loss: 4.6098
2021-07-21 10:32:13,901 - mmdet - INFO - Epoch [31][300/673]	lr: 0.00100, eta: 0:18:04, time: 0.303, data_time: 0.013, memory: 4440, loss_ins: 4.7115, loss_cate: 0.0900, loss: 4.8015
2021-07-21 10:32:29,089 - mmdet - INFO - Epoch [31][350/673]	lr: 0.00100, eta: 0:17:50, time: 0.304, data_time: 0.013, memory: 4440, loss_ins: 4.6840, loss_cate: 0.0885, loss: 4.7725
2021-07-21 10:32:44,168 - mmdet - INFO - Epoch [31][400/673]	lr: 0.00100, eta: 0:17:35, time: 0.302, data_time: 0.013, memory: 4440, loss_ins: 4.4842, loss_cate: 0.0951, loss: 4.5793
2021-07-21 10:32:59,046 - mmdet - INFO - Epoch [31][450/673]	lr: 0.00100, eta: 0:17:21, time: 0.298, data_time: 0.012, memory: 4440, loss_ins: 4.6405, loss_cate: 0.0881, loss: 4.7286
2021-07-21 10:33:14,175 - mmdet - INFO - Epoch [31][500/673]	lr: 0.00100, eta: 0:17:07, time: 0.303, data_time: 0.013, memory: 4440, loss_ins: 4.6075, loss_cate: 0.0924, loss: 4.6998
2021-07-21 10:33:29,274 - mmdet - INFO - Epoch [31][550/673]	lr: 0.00100, eta: 0:16:52, time: 0.302, data_time: 0.013, memory: 4440, loss_ins: 4.3487, loss_cate: 0.0709, loss: 4.4196
2021-07-21 10:33:44,207 - mmdet - INFO - Epoch [31][600/673]	lr: 0.00100, eta: 0:16:38, time: 0.299, data_time: 0.013, memory: 4440, loss_ins: 4.5618, loss_cate: 0.0879, loss: 4.6497
2021-07-21 10:33:59,267 - mmdet - INFO - Epoch [31][650/673]	lr: 0.00100, eta: 0:16:23, time: 0.301, data_time: 0.013, memory: 4440, loss_ins: 4.4363, loss_cate: 0.0831, loss: 4.5194
2021-07-21 10:34:21,937 - mmdet - INFO - Epoch [32][50/673]	lr: 0.00100, eta: 0:16:01, time: 0.308, data_time: 0.019, memory: 4440, loss_ins: 4.4118, loss_cate: 0.0831, loss: 4.4949
2021-07-21 10:34:36,527 - mmdet - INFO - Epoch [32][100/673]	lr: 0.00100, eta: 0:15:47, time: 0.292, data_time: 0.013, memory: 4440, loss_ins: 4.6122, loss_cate: 0.0894, loss: 4.7016
2021-07-21 10:34:51,594 - mmdet - INFO - Epoch [32][150/673]	lr: 0.00100, eta: 0:15:32, time: 0.301, data_time: 0.013, memory: 4440, loss_ins: 4.4440, loss_cate: 0.0895, loss: 4.5335
2021-07-21 10:35:06,802 - mmdet - INFO - Epoch [32][200/673]	lr: 0.00100, eta: 0:15:18, time: 0.304, data_time: 0.013, memory: 4440, loss_ins: 4.4695, loss_cate: 0.0836, loss: 4.5531
2021-07-21 10:35:21,963 - mmdet - INFO - Epoch [32][250/673]	lr: 0.00100, eta: 0:15:03, time: 0.303, data_time: 0.012, memory: 4440, loss_ins: 4.6667, loss_cate: 0.0984, loss: 4.7651
2021-07-21 10:35:36,784 - mmdet - INFO - Epoch [32][300/673]	lr: 0.00100, eta: 0:14:49, time: 0.296, data_time: 0.013, memory: 4440, loss_ins: 4.3590, loss_cate: 0.0876, loss: 4.4466
2021-07-21 10:35:51,817 - mmdet - INFO - Epoch [32][350/673]	lr: 0.00100, eta: 0:14:35, time: 0.301, data_time: 0.012, memory: 4440, loss_ins: 4.5624, loss_cate: 0.0868, loss: 4.6492
2021-07-21 10:36:06,873 - mmdet - INFO - Epoch [32][400/673]	lr: 0.00100, eta: 0:14:20, time: 0.301, data_time: 0.013, memory: 4440, loss_ins: 4.6992, loss_cate: 0.0806, loss: 4.7798
2021-07-21 10:36:21,636 - mmdet - INFO - Epoch [32][450/673]	lr: 0.00100, eta: 0:14:06, time: 0.295, data_time: 0.013, memory: 4440, loss_ins: 4.3728, loss_cate: 0.0864, loss: 4.4592
2021-07-21 10:36:36,463 - mmdet - INFO - Epoch [32][500/673]	lr: 0.00100, eta: 0:13:51, time: 0.297, data_time: 0.012, memory: 4440, loss_ins: 4.4585, loss_cate: 0.0799, loss: 4.5384
2021-07-21 10:36:51,412 - mmdet - INFO - Epoch [32][550/673]	lr: 0.00100, eta: 0:13:37, time: 0.299, data_time: 0.012, memory: 4440, loss_ins: 4.4578, loss_cate: 0.0848, loss: 4.5426
2021-07-21 10:37:06,194 - mmdet - INFO - Epoch [32][600/673]	lr: 0.00100, eta: 0:13:22, time: 0.296, data_time: 0.012, memory: 4440, loss_ins: 4.4908, loss_cate: 0.0884, loss: 4.5792
2021-07-21 10:37:21,227 - mmdet - INFO - Epoch [32][650/673]	lr: 0.00100, eta: 0:13:08, time: 0.301, data_time: 0.012, memory: 4440, loss_ins: 4.4161, loss_cate: 0.0756, loss: 4.4917
2021-07-21 10:37:43,553 - mmdet - INFO - Epoch [33][50/673]	lr: 0.00100, eta: 0:12:46, time: 0.304, data_time: 0.018, memory: 4440, loss_ins: 4.3138, loss_cate: 0.0737, loss: 4.3875
2021-07-21 10:37:58,438 - mmdet - INFO - Epoch [33][100/673]	lr: 0.00100, eta: 0:12:31, time: 0.298, data_time: 0.013, memory: 4440, loss_ins: 4.4617, loss_cate: 0.0841, loss: 4.5458
2021-07-21 10:38:13,576 - mmdet - INFO - Epoch [33][150/673]	lr: 0.00100, eta: 0:12:17, time: 0.303, data_time: 0.013, memory: 4440, loss_ins: 4.8766, loss_cate: 0.0779, loss: 4.9544
2021-07-21 10:38:28,488 - mmdet - INFO - Epoch [33][200/673]	lr: 0.00100, eta: 0:12:03, time: 0.298, data_time: 0.013, memory: 4440, loss_ins: 4.5792, loss_cate: 0.0878, loss: 4.6670
2021-07-21 10:38:43,310 - mmdet - INFO - Epoch [33][250/673]	lr: 0.00100, eta: 0:11:48, time: 0.296, data_time: 0.012, memory: 4440, loss_ins: 4.4569, loss_cate: 0.0948, loss: 4.5516
2021-07-21 10:38:58,661 - mmdet - INFO - Epoch [33][300/673]	lr: 0.00100, eta: 0:11:34, time: 0.307, data_time: 0.013, memory: 4440, loss_ins: 4.6247, loss_cate: 0.0806, loss: 4.7053
2021-07-21 10:39:13,634 - mmdet - INFO - Epoch [33][350/673]	lr: 0.00100, eta: 0:11:19, time: 0.299, data_time: 0.012, memory: 4440, loss_ins: 4.5027, loss_cate: 0.0709, loss: 4.5737
2021-07-21 10:39:28,717 - mmdet - INFO - Epoch [33][400/673]	lr: 0.00100, eta: 0:11:05, time: 0.302, data_time: 0.013, memory: 4440, loss_ins: 4.5886, loss_cate: 0.0829, loss: 4.6715
2021-07-21 10:39:43,620 - mmdet - INFO - Epoch [33][450/673]	lr: 0.00100, eta: 0:10:50, time: 0.298, data_time: 0.012, memory: 4440, loss_ins: 4.3953, loss_cate: 0.0774, loss: 4.4727
2021-07-21 10:39:58,573 - mmdet - INFO - Epoch [33][500/673]	lr: 0.00100, eta: 0:10:36, time: 0.299, data_time: 0.012, memory: 4440, loss_ins: 4.6165, loss_cate: 0.0850, loss: 4.7015
2021-07-21 10:40:13,562 - mmdet - INFO - Epoch [33][550/673]	lr: 0.00100, eta: 0:10:21, time: 0.300, data_time: 0.013, memory: 4440, loss_ins: 4.4882, loss_cate: 0.0858, loss: 4.5740
2021-07-21 10:40:28,521 - mmdet - INFO - Epoch [33][600/673]	lr: 0.00100, eta: 0:10:07, time: 0.299, data_time: 0.012, memory: 4440, loss_ins: 4.3103, loss_cate: 0.0795, loss: 4.3898
2021-07-21 10:40:43,657 - mmdet - INFO - Epoch [33][650/673]	lr: 0.00100, eta: 0:09:52, time: 0.303, data_time: 0.013, memory: 4440, loss_ins: 4.5159, loss_cate: 0.0841, loss: 4.6000
2021-07-21 10:41:05,774 - mmdet - INFO - Epoch [34][50/673]	lr: 0.00010, eta: 0:09:31, time: 0.296, data_time: 0.017, memory: 4440, loss_ins: 4.4992, loss_cate: 0.0833, loss: 4.5825
2021-07-21 10:41:20,975 - mmdet - INFO - Epoch [34][100/673]	lr: 0.00010, eta: 0:09:16, time: 0.304, data_time: 0.013, memory: 4440, loss_ins: 4.3561, loss_cate: 0.0780, loss: 4.4341
2021-07-21 10:41:36,126 - mmdet - INFO - Epoch [34][150/673]	lr: 0.00010, eta: 0:09:02, time: 0.303, data_time: 0.013, memory: 4440, loss_ins: 4.5979, loss_cate: 0.0992, loss: 4.6971
2021-07-21 10:41:51,026 - mmdet - INFO - Epoch [34][200/673]	lr: 0.00010, eta: 0:08:47, time: 0.298, data_time: 0.012, memory: 4440, loss_ins: 4.4902, loss_cate: 0.0819, loss: 4.5721
2021-07-21 10:42:05,795 - mmdet - INFO - Epoch [34][250/673]	lr: 0.00010, eta: 0:08:33, time: 0.295, data_time: 0.011, memory: 4440, loss_ins: 4.4361, loss_cate: 0.0800, loss: 4.5160
2021-07-21 10:42:20,943 - mmdet - INFO - Epoch [34][300/673]	lr: 0.00010, eta: 0:08:18, time: 0.303, data_time: 0.012, memory: 4440, loss_ins: 4.4087, loss_cate: 0.0803, loss: 4.4890
2021-07-21 10:42:36,019 - mmdet - INFO - Epoch [34][350/673]	lr: 0.00010, eta: 0:08:04, time: 0.302, data_time: 0.013, memory: 4440, loss_ins: 4.4530, loss_cate: 0.0793, loss: 4.5323
2021-07-21 10:42:50,851 - mmdet - INFO - Epoch [34][400/673]	lr: 0.00010, eta: 0:07:49, time: 0.297, data_time: 0.012, memory: 4440, loss_ins: 4.4314, loss_cate: 0.0829, loss: 4.5143
2021-07-21 10:43:06,010 - mmdet - INFO - Epoch [34][450/673]	lr: 0.00010, eta: 0:07:35, time: 0.303, data_time: 0.012, memory: 4440, loss_ins: 4.4202, loss_cate: 0.0726, loss: 4.4928
2021-07-21 10:43:21,012 - mmdet - INFO - Epoch [34][500/673]	lr: 0.00010, eta: 0:07:20, time: 0.300, data_time: 0.013, memory: 4440, loss_ins: 4.4493, loss_cate: 0.0793, loss: 4.5287
2021-07-21 10:43:36,001 - mmdet - INFO - Epoch [34][550/673]	lr: 0.00010, eta: 0:07:06, time: 0.300, data_time: 0.013, memory: 4440, loss_ins: 4.7149, loss_cate: 0.0830, loss: 4.7980
2021-07-21 10:43:50,885 - mmdet - INFO - Epoch [34][600/673]	lr: 0.00010, eta: 0:06:51, time: 0.298, data_time: 0.012, memory: 4440, loss_ins: 4.5481, loss_cate: 0.0832, loss: 4.6313
2021-07-21 10:44:05,926 - mmdet - INFO - Epoch [34][650/673]	lr: 0.00010, eta: 0:06:37, time: 0.301, data_time: 0.013, memory: 4440, loss_ins: 4.4608, loss_cate: 0.0906, loss: 4.5513
2021-07-21 10:44:28,424 - mmdet - INFO - Epoch [35][50/673]	lr: 0.00010, eta: 0:06:15, time: 0.306, data_time: 0.018, memory: 4440, loss_ins: 4.6645, loss_cate: 0.0760, loss: 4.7405
2021-07-21 10:44:43,481 - mmdet - INFO - Epoch [35][100/673]	lr: 0.00010, eta: 0:06:01, time: 0.301, data_time: 0.013, memory: 4440, loss_ins: 4.3466, loss_cate: 0.0708, loss: 4.4174
2021-07-21 10:44:58,605 - mmdet - INFO - Epoch [35][150/673]	lr: 0.00010, eta: 0:05:46, time: 0.302, data_time: 0.013, memory: 4440, loss_ins: 4.6605, loss_cate: 0.0791, loss: 4.7396
2021-07-21 10:45:13,475 - mmdet - INFO - Epoch [35][200/673]	lr: 0.00010, eta: 0:05:32, time: 0.297, data_time: 0.013, memory: 4440, loss_ins: 4.6480, loss_cate: 0.0782, loss: 4.7262
2021-07-21 10:45:28,393 - mmdet - INFO - Epoch [35][250/673]	lr: 0.00010, eta: 0:05:18, time: 0.298, data_time: 0.013, memory: 4440, loss_ins: 4.3542, loss_cate: 0.0746, loss: 4.4288
2021-07-21 10:45:43,492 - mmdet - INFO - Epoch [35][300/673]	lr: 0.00010, eta: 0:05:03, time: 0.302, data_time: 0.013, memory: 4440, loss_ins: 4.2288, loss_cate: 0.0790, loss: 4.3078
2021-07-21 10:45:58,627 - mmdet - INFO - Epoch [35][350/673]	lr: 0.00010, eta: 0:04:49, time: 0.303, data_time: 0.013, memory: 4440, loss_ins: 4.5003, loss_cate: 0.0772, loss: 4.5775
2021-07-21 10:46:13,766 - mmdet - INFO - Epoch [35][400/673]	lr: 0.00010, eta: 0:04:34, time: 0.303, data_time: 0.013, memory: 4440, loss_ins: 4.6062, loss_cate: 0.0888, loss: 4.6950
2021-07-21 10:46:28,819 - mmdet - INFO - Epoch [35][450/673]	lr: 0.00010, eta: 0:04:20, time: 0.301, data_time: 0.013, memory: 4440, loss_ins: 4.3421, loss_cate: 0.0764, loss: 4.4185
2021-07-21 10:46:43,831 - mmdet - INFO - Epoch [35][500/673]	lr: 0.00010, eta: 0:04:05, time: 0.300, data_time: 0.013, memory: 4440, loss_ins: 4.5398, loss_cate: 0.0886, loss: 4.6284
2021-07-21 10:46:58,951 - mmdet - INFO - Epoch [35][550/673]	lr: 0.00010, eta: 0:03:51, time: 0.302, data_time: 0.013, memory: 4440, loss_ins: 4.5758, loss_cate: 0.0872, loss: 4.6630
2021-07-21 10:47:13,661 - mmdet - INFO - Epoch [35][600/673]	lr: 0.00010, eta: 0:03:36, time: 0.294, data_time: 0.012, memory: 4440, loss_ins: 4.3546, loss_cate: 0.0789, loss: 4.4335
2021-07-21 10:47:28,640 - mmdet - INFO - Epoch [35][650/673]	lr: 0.00010, eta: 0:03:22, time: 0.300, data_time: 0.012, memory: 4440, loss_ins: 4.1602, loss_cate: 0.0786, loss: 4.2388
2021-07-21 10:47:50,962 - mmdet - INFO - Epoch [36][50/673]	lr: 0.00010, eta: 0:03:00, time: 0.302, data_time: 0.018, memory: 4440, loss_ins: 4.7661, loss_cate: 0.0850, loss: 4.8510
2021-07-21 10:48:05,988 - mmdet - INFO - Epoch [36][100/673]	lr: 0.00010, eta: 0:02:46, time: 0.301, data_time: 0.014, memory: 4440, loss_ins: 4.7482, loss_cate: 0.0903, loss: 4.8385
2021-07-21 10:48:21,174 - mmdet - INFO - Epoch [36][150/673]	lr: 0.00010, eta: 0:02:31, time: 0.304, data_time: 0.014, memory: 4440, loss_ins: 4.3369, loss_cate: 0.0741, loss: 4.4110
2021-07-21 10:48:36,246 - mmdet - INFO - Epoch [36][200/673]	lr: 0.00010, eta: 0:02:17, time: 0.301, data_time: 0.014, memory: 4440, loss_ins: 4.3479, loss_cate: 0.0766, loss: 4.4245
2021-07-21 10:48:51,318 - mmdet - INFO - Epoch [36][250/673]	lr: 0.00010, eta: 0:02:02, time: 0.301, data_time: 0.013, memory: 4440, loss_ins: 4.4533, loss_cate: 0.0752, loss: 4.5285
2021-07-21 10:49:06,366 - mmdet - INFO - Epoch [36][300/673]	lr: 0.00010, eta: 0:01:48, time: 0.301, data_time: 0.012, memory: 4440, loss_ins: 4.5570, loss_cate: 0.0748, loss: 4.6318
2021-07-21 10:49:21,435 - mmdet - INFO - Epoch [36][350/673]	lr: 0.00010, eta: 0:01:33, time: 0.301, data_time: 0.013, memory: 4440, loss_ins: 4.2759, loss_cate: 0.0714, loss: 4.3473
2021-07-21 10:49:36,515 - mmdet - INFO - Epoch [36][400/673]	lr: 0.00010, eta: 0:01:19, time: 0.302, data_time: 0.013, memory: 4440, loss_ins: 4.5542, loss_cate: 0.0897, loss: 4.6439
2021-07-21 10:49:51,594 - mmdet - INFO - Epoch [36][450/673]	lr: 0.00010, eta: 0:01:04, time: 0.302, data_time: 0.013, memory: 4440, loss_ins: 4.5005, loss_cate: 0.0701, loss: 4.5706
2021-07-21 10:50:06,467 - mmdet - INFO - Epoch [36][500/673]	lr: 0.00010, eta: 0:00:50, time: 0.297, data_time: 0.013, memory: 4440, loss_ins: 4.4270, loss_cate: 0.0792, loss: 4.5063
2021-07-21 10:50:21,614 - mmdet - INFO - Epoch [36][550/673]	lr: 0.00010, eta: 0:00:35, time: 0.303, data_time: 0.013, memory: 4440, loss_ins: 4.6223, loss_cate: 0.0871, loss: 4.7094
2021-07-21 10:50:36,547 - mmdet - INFO - Epoch [36][600/673]	lr: 0.00010, eta: 0:00:21, time: 0.299, data_time: 0.013, memory: 4440, loss_ins: 4.3854, loss_cate: 0.0783, loss: 4.4636
2021-07-21 10:50:51,449 - mmdet - INFO - Epoch [36][650/673]	lr: 0.00010, eta: 0:00:06, time: 0.298, data_time: 0.012, memory: 4440, loss_ins: 4.4411, loss_cate: 0.0862, loss: 4.5273
2021-07-22 03:21:28,706 - mmdet - INFO - Distributed training: False
2021-07-22 03:21:28,706 - mmdet - INFO - MMDetection Version: 1.0.0+c7b294a
2021-07-22 03:21:28,706 - mmdet - INFO - Config:
# model settings
model = dict(
    type='SOLOv2',
    pretrained='torchvision://resnet50',
    backbone=dict(
        type='ResNet',
        depth=50,
        num_stages=4,
        out_indices=(0, 1, 2, 3),  # C2, C3, C4, C5
        frozen_stages=1,
        style='pytorch'),
    neck=dict(
        type='FPN',
        in_channels=[256, 512, 1024, 2048],
        out_channels=256,
        start_level=0,
        num_outs=5),
    bbox_head=dict(
        type='SOLOv2Head',
        num_classes=2,
        in_channels=256,
        stacked_convs=4,
        seg_feat_channels=512,
        strides=[8, 8, 16, 32, 32],
        scale_ranges=((1, 96), (48, 192), (96, 384), (192, 768), (384, 2048)),
        # scale_ranges=((1, 376), (188, 752), (752, 1400)),
        sigma=0.2,
        num_grids=[40, 36, 24, 16, 12],
        ins_out_channels=256,
        loss_ins=dict(
            type='DiceLoss',
            use_sigmoid=True,
            loss_weight=3.0),
            # loss_weight=10.0),
        loss_cate=dict(
            type='FocalLoss',
            use_sigmoid=True,
            gamma=2.0,
            alpha=0.25,
            loss_weight=1.0)),
    mask_feat_head=dict(
        type='MaskFeatHead',
        in_channels=256,
        out_channels=128,
        start_level=0,
        end_level=3,
        num_classes=256,
        norm_cfg=dict(type='GN', num_groups=32, requires_grad=True)),
)
# training and testing settings
train_cfg = dict()
test_cfg = dict(
    nms_pre=500,
    score_thr=0.1,
    mask_thr=0.5,
    update_thr=0.05,
    kernel='gaussian',  # gaussian/linear
    sigma=2.0,
    max_per_img=100)
# dataset settings
dataset_type = 'CocoDataset'
data_root = 'data/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),
    dict(type='Resize',
         img_scale=[(1333, 800), (1333, 768), (1333, 736),
                    (1333, 704), (1333, 672), (1333, 640)],
         multiscale_mode='value',
         keep_ratio=True),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(type='Normalize', **img_norm_cfg),
    dict(type='Pad', size_divisor=32),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks']),
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(1333, 800),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(type='Normalize', **img_norm_cfg),
            dict(type='Pad', size_divisor=32),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img']),
        ])
]
data = dict(
    imgs_per_gpu=2,
    workers_per_gpu=2,
    train=dict(
        type=dataset_type,
        ann_file=data_root + 'annotation/merge/merge_train_coco.json',
        img_prefix=data_root + 'road/train/',
        pipeline=train_pipeline),
    val=dict(
        type=dataset_type,
        ann_file=data_root + 'annotation/merge/merge_val_coco.json',
        img_prefix=data_root + 'road/val/',
        pipeline=test_pipeline),
    test=dict(
        type=dataset_type,
        ann_file=data_root + 'annotation/merge/merge_val_coco.json',
        img_prefix=data_root + 'road/val/',
        pipeline=test_pipeline))
# optimizer
optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0001)
optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))
# learning policy
lr_config = dict(
    policy='step',
    warmup='linear',
    warmup_iters=500,
    warmup_ratio=0.01,
    step=[27, 33])
checkpoint_config = dict(interval=1)
# yapf:disable
log_config = dict(
    interval=50,
    hooks=[
        dict(type='TextLoggerHook'),
        # dict(type='TensorboardLoggerHook')
    ])
# yapf:enable
# runtime settings
total_epochs = 36
device_ids = range(8)
dist_params = dict(backend='nccl')
log_level = 'INFO'
# work_dir = './work_dirs/solov2_release_r50_fpn_8gpu_3x'
# work_dir = './work_dirs/solov2_release_r50_fpn_8gpu_3x_scale'
# work_dir = './work_dirs/solov2_release_r50_fpn_8gpu_3x_weight'
work_dir = './work_dirs/solov2_release_r50_fpn_8gpu_3x_workflow'

load_from = None
resume_from = None
# workflow = [('train', 1)]
workflow = [('train', 1), ('val', 1)]

2021-07-22 03:21:29,109 - mmdet - INFO - load model from: torchvision://resnet50
2021-07-22 03:21:31,456 - mmdet - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: backbone.conv1.weight, backbone.bn1.weight, backbone.bn1.bias, backbone.bn1.running_mean, backbone.bn1.running_var, backbone.bn1.num_batches_tracked, backbone.layer1.0.conv1.weight, backbone.layer1.0.bn1.weight, backbone.layer1.0.bn1.bias, backbone.layer1.0.bn1.running_mean, backbone.layer1.0.bn1.running_var, backbone.layer1.0.bn1.num_batches_tracked, backbone.layer1.0.conv2.weight, backbone.layer1.0.bn2.weight, backbone.layer1.0.bn2.bias, backbone.layer1.0.bn2.running_mean, backbone.layer1.0.bn2.running_var, backbone.layer1.0.bn2.num_batches_tracked, backbone.layer1.0.conv3.weight, backbone.layer1.0.bn3.weight, backbone.layer1.0.bn3.bias, backbone.layer1.0.bn3.running_mean, backbone.layer1.0.bn3.running_var, backbone.layer1.0.bn3.num_batches_tracked, backbone.layer1.0.downsample.0.weight, backbone.layer1.0.downsample.1.weight, backbone.layer1.0.downsample.1.bias, backbone.layer1.0.downsample.1.running_mean, backbone.layer1.0.downsample.1.running_var, backbone.layer1.0.downsample.1.num_batches_tracked, backbone.layer1.1.conv1.weight, backbone.layer1.1.bn1.weight, backbone.layer1.1.bn1.bias, backbone.layer1.1.bn1.running_mean, backbone.layer1.1.bn1.running_var, backbone.layer1.1.bn1.num_batches_tracked, backbone.layer1.1.conv2.weight, backbone.layer1.1.bn2.weight, backbone.layer1.1.bn2.bias, backbone.layer1.1.bn2.running_mean, backbone.layer1.1.bn2.running_var, backbone.layer1.1.bn2.num_batches_tracked, backbone.layer1.1.conv3.weight, backbone.layer1.1.bn3.weight, backbone.layer1.1.bn3.bias, backbone.layer1.1.bn3.running_mean, backbone.layer1.1.bn3.running_var, backbone.layer1.1.bn3.num_batches_tracked, backbone.layer1.2.conv1.weight, backbone.layer1.2.bn1.weight, backbone.layer1.2.bn1.bias, backbone.layer1.2.bn1.running_mean, backbone.layer1.2.bn1.running_var, backbone.layer1.2.bn1.num_batches_tracked, backbone.layer1.2.conv2.weight, backbone.layer1.2.bn2.weight, backbone.layer1.2.bn2.bias, backbone.layer1.2.bn2.running_mean, backbone.layer1.2.bn2.running_var, backbone.layer1.2.bn2.num_batches_tracked, backbone.layer1.2.conv3.weight, backbone.layer1.2.bn3.weight, backbone.layer1.2.bn3.bias, backbone.layer1.2.bn3.running_mean, backbone.layer1.2.bn3.running_var, backbone.layer1.2.bn3.num_batches_tracked, backbone.layer2.0.conv1.weight, backbone.layer2.0.bn1.weight, backbone.layer2.0.bn1.bias, backbone.layer2.0.bn1.running_mean, backbone.layer2.0.bn1.running_var, backbone.layer2.0.bn1.num_batches_tracked, backbone.layer2.0.conv2.weight, backbone.layer2.0.bn2.weight, backbone.layer2.0.bn2.bias, backbone.layer2.0.bn2.running_mean, backbone.layer2.0.bn2.running_var, backbone.layer2.0.bn2.num_batches_tracked, backbone.layer2.0.conv3.weight, backbone.layer2.0.bn3.weight, backbone.layer2.0.bn3.bias, backbone.layer2.0.bn3.running_mean, backbone.layer2.0.bn3.running_var, backbone.layer2.0.bn3.num_batches_tracked, backbone.layer2.0.downsample.0.weight, backbone.layer2.0.downsample.1.weight, backbone.layer2.0.downsample.1.bias, backbone.layer2.0.downsample.1.running_mean, backbone.layer2.0.downsample.1.running_var, backbone.layer2.0.downsample.1.num_batches_tracked, backbone.layer2.1.conv1.weight, backbone.layer2.1.bn1.weight, backbone.layer2.1.bn1.bias, backbone.layer2.1.bn1.running_mean, backbone.layer2.1.bn1.running_var, backbone.layer2.1.bn1.num_batches_tracked, backbone.layer2.1.conv2.weight, backbone.layer2.1.bn2.weight, backbone.layer2.1.bn2.bias, backbone.layer2.1.bn2.running_mean, backbone.layer2.1.bn2.running_var, backbone.layer2.1.bn2.num_batches_tracked, backbone.layer2.1.conv3.weight, backbone.layer2.1.bn3.weight, backbone.layer2.1.bn3.bias, backbone.layer2.1.bn3.running_mean, backbone.layer2.1.bn3.running_var, backbone.layer2.1.bn3.num_batches_tracked, backbone.layer2.2.conv1.weight, backbone.layer2.2.bn1.weight, backbone.layer2.2.bn1.bias, backbone.layer2.2.bn1.running_mean, backbone.layer2.2.bn1.running_var, backbone.layer2.2.bn1.num_batches_tracked, backbone.layer2.2.conv2.weight, backbone.layer2.2.bn2.weight, backbone.layer2.2.bn2.bias, backbone.layer2.2.bn2.running_mean, backbone.layer2.2.bn2.running_var, backbone.layer2.2.bn2.num_batches_tracked, backbone.layer2.2.conv3.weight, backbone.layer2.2.bn3.weight, backbone.layer2.2.bn3.bias, backbone.layer2.2.bn3.running_mean, backbone.layer2.2.bn3.running_var, backbone.layer2.2.bn3.num_batches_tracked, backbone.layer2.3.conv1.weight, backbone.layer2.3.bn1.weight, backbone.layer2.3.bn1.bias, backbone.layer2.3.bn1.running_mean, backbone.layer2.3.bn1.running_var, backbone.layer2.3.bn1.num_batches_tracked, backbone.layer2.3.conv2.weight, backbone.layer2.3.bn2.weight, backbone.layer2.3.bn2.bias, backbone.layer2.3.bn2.running_mean, backbone.layer2.3.bn2.running_var, backbone.layer2.3.bn2.num_batches_tracked, backbone.layer2.3.conv3.weight, backbone.layer2.3.bn3.weight, backbone.layer2.3.bn3.bias, backbone.layer2.3.bn3.running_mean, backbone.layer2.3.bn3.running_var, backbone.layer2.3.bn3.num_batches_tracked, backbone.layer3.0.conv1.weight, backbone.layer3.0.bn1.weight, backbone.layer3.0.bn1.bias, backbone.layer3.0.bn1.running_mean, backbone.layer3.0.bn1.running_var, backbone.layer3.0.bn1.num_batches_tracked, backbone.layer3.0.conv2.weight, backbone.layer3.0.bn2.weight, backbone.layer3.0.bn2.bias, backbone.layer3.0.bn2.running_mean, backbone.layer3.0.bn2.running_var, backbone.layer3.0.bn2.num_batches_tracked, backbone.layer3.0.conv3.weight, backbone.layer3.0.bn3.weight, backbone.layer3.0.bn3.bias, backbone.layer3.0.bn3.running_mean, backbone.layer3.0.bn3.running_var, backbone.layer3.0.bn3.num_batches_tracked, backbone.layer3.0.downsample.0.weight, backbone.layer3.0.downsample.1.weight, backbone.layer3.0.downsample.1.bias, backbone.layer3.0.downsample.1.running_mean, backbone.layer3.0.downsample.1.running_var, backbone.layer3.0.downsample.1.num_batches_tracked, backbone.layer3.1.conv1.weight, backbone.layer3.1.bn1.weight, backbone.layer3.1.bn1.bias, backbone.layer3.1.bn1.running_mean, backbone.layer3.1.bn1.running_var, backbone.layer3.1.bn1.num_batches_tracked, backbone.layer3.1.conv2.weight, backbone.layer3.1.bn2.weight, backbone.layer3.1.bn2.bias, backbone.layer3.1.bn2.running_mean, backbone.layer3.1.bn2.running_var, backbone.layer3.1.bn2.num_batches_tracked, backbone.layer3.1.conv3.weight, backbone.layer3.1.bn3.weight, backbone.layer3.1.bn3.bias, backbone.layer3.1.bn3.running_mean, backbone.layer3.1.bn3.running_var, backbone.layer3.1.bn3.num_batches_tracked, backbone.layer3.2.conv1.weight, backbone.layer3.2.bn1.weight, backbone.layer3.2.bn1.bias, backbone.layer3.2.bn1.running_mean, backbone.layer3.2.bn1.running_var, backbone.layer3.2.bn1.num_batches_tracked, backbone.layer3.2.conv2.weight, backbone.layer3.2.bn2.weight, backbone.layer3.2.bn2.bias, backbone.layer3.2.bn2.running_mean, backbone.layer3.2.bn2.running_var, backbone.layer3.2.bn2.num_batches_tracked, backbone.layer3.2.conv3.weight, backbone.layer3.2.bn3.weight, backbone.layer3.2.bn3.bias, backbone.layer3.2.bn3.running_mean, backbone.layer3.2.bn3.running_var, backbone.layer3.2.bn3.num_batches_tracked, backbone.layer3.3.conv1.weight, backbone.layer3.3.bn1.weight, backbone.layer3.3.bn1.bias, backbone.layer3.3.bn1.running_mean, backbone.layer3.3.bn1.running_var, backbone.layer3.3.bn1.num_batches_tracked, backbone.layer3.3.conv2.weight, backbone.layer3.3.bn2.weight, backbone.layer3.3.bn2.bias, backbone.layer3.3.bn2.running_mean, backbone.layer3.3.bn2.running_var, backbone.layer3.3.bn2.num_batches_tracked, backbone.layer3.3.conv3.weight, backbone.layer3.3.bn3.weight, backbone.layer3.3.bn3.bias, backbone.layer3.3.bn3.running_mean, backbone.layer3.3.bn3.running_var, backbone.layer3.3.bn3.num_batches_tracked, backbone.layer3.4.conv1.weight, backbone.layer3.4.bn1.weight, backbone.layer3.4.bn1.bias, backbone.layer3.4.bn1.running_mean, backbone.layer3.4.bn1.running_var, backbone.layer3.4.bn1.num_batches_tracked, backbone.layer3.4.conv2.weight, backbone.layer3.4.bn2.weight, backbone.layer3.4.bn2.bias, backbone.layer3.4.bn2.running_mean, backbone.layer3.4.bn2.running_var, backbone.layer3.4.bn2.num_batches_tracked, backbone.layer3.4.conv3.weight, backbone.layer3.4.bn3.weight, backbone.layer3.4.bn3.bias, backbone.layer3.4.bn3.running_mean, backbone.layer3.4.bn3.running_var, backbone.layer3.4.bn3.num_batches_tracked, backbone.layer3.5.conv1.weight, backbone.layer3.5.bn1.weight, backbone.layer3.5.bn1.bias, backbone.layer3.5.bn1.running_mean, backbone.layer3.5.bn1.running_var, backbone.layer3.5.bn1.num_batches_tracked, backbone.layer3.5.conv2.weight, backbone.layer3.5.bn2.weight, backbone.layer3.5.bn2.bias, backbone.layer3.5.bn2.running_mean, backbone.layer3.5.bn2.running_var, backbone.layer3.5.bn2.num_batches_tracked, backbone.layer3.5.conv3.weight, backbone.layer3.5.bn3.weight, backbone.layer3.5.bn3.bias, backbone.layer3.5.bn3.running_mean, backbone.layer3.5.bn3.running_var, backbone.layer3.5.bn3.num_batches_tracked, backbone.layer4.0.conv1.weight, backbone.layer4.0.bn1.weight, backbone.layer4.0.bn1.bias, backbone.layer4.0.bn1.running_mean, backbone.layer4.0.bn1.running_var, backbone.layer4.0.bn1.num_batches_tracked, backbone.layer4.0.conv2.weight, backbone.layer4.0.bn2.weight, backbone.layer4.0.bn2.bias, backbone.layer4.0.bn2.running_mean, backbone.layer4.0.bn2.running_var, backbone.layer4.0.bn2.num_batches_tracked, backbone.layer4.0.conv3.weight, backbone.layer4.0.bn3.weight, backbone.layer4.0.bn3.bias, backbone.layer4.0.bn3.running_mean, backbone.layer4.0.bn3.running_var, backbone.layer4.0.bn3.num_batches_tracked, backbone.layer4.0.downsample.0.weight, backbone.layer4.0.downsample.1.weight, backbone.layer4.0.downsample.1.bias, backbone.layer4.0.downsample.1.running_mean, backbone.layer4.0.downsample.1.running_var, backbone.layer4.0.downsample.1.num_batches_tracked, backbone.layer4.1.conv1.weight, backbone.layer4.1.bn1.weight, backbone.layer4.1.bn1.bias, backbone.layer4.1.bn1.running_mean, backbone.layer4.1.bn1.running_var, backbone.layer4.1.bn1.num_batches_tracked, backbone.layer4.1.conv2.weight, backbone.layer4.1.bn2.weight, backbone.layer4.1.bn2.bias, backbone.layer4.1.bn2.running_mean, backbone.layer4.1.bn2.running_var, backbone.layer4.1.bn2.num_batches_tracked, backbone.layer4.1.conv3.weight, backbone.layer4.1.bn3.weight, backbone.layer4.1.bn3.bias, backbone.layer4.1.bn3.running_mean, backbone.layer4.1.bn3.running_var, backbone.layer4.1.bn3.num_batches_tracked, backbone.layer4.2.conv1.weight, backbone.layer4.2.bn1.weight, backbone.layer4.2.bn1.bias, backbone.layer4.2.bn1.running_mean, backbone.layer4.2.bn1.running_var, backbone.layer4.2.bn1.num_batches_tracked, backbone.layer4.2.conv2.weight, backbone.layer4.2.bn2.weight, backbone.layer4.2.bn2.bias, backbone.layer4.2.bn2.running_mean, backbone.layer4.2.bn2.running_var, backbone.layer4.2.bn2.num_batches_tracked, backbone.layer4.2.conv3.weight, backbone.layer4.2.bn3.weight, backbone.layer4.2.bn3.bias, backbone.layer4.2.bn3.running_mean, backbone.layer4.2.bn3.running_var, backbone.layer4.2.bn3.num_batches_tracked, neck.lateral_convs.0.conv.weight, neck.lateral_convs.0.conv.bias, neck.lateral_convs.1.conv.weight, neck.lateral_convs.1.conv.bias, neck.lateral_convs.2.conv.weight, neck.lateral_convs.2.conv.bias, neck.lateral_convs.3.conv.weight, neck.lateral_convs.3.conv.bias, neck.fpn_convs.0.conv.weight, neck.fpn_convs.0.conv.bias, neck.fpn_convs.1.conv.weight, neck.fpn_convs.1.conv.bias, neck.fpn_convs.2.conv.weight, neck.fpn_convs.2.conv.bias, neck.fpn_convs.3.conv.weight, neck.fpn_convs.3.conv.bias, mask_feat_head.convs_all_levels.0.conv0.conv.weight, mask_feat_head.convs_all_levels.0.conv0.gn.weight, mask_feat_head.convs_all_levels.0.conv0.gn.bias, mask_feat_head.convs_all_levels.1.conv0.conv.weight, mask_feat_head.convs_all_levels.1.conv0.gn.weight, mask_feat_head.convs_all_levels.1.conv0.gn.bias, mask_feat_head.convs_all_levels.2.conv0.conv.weight, mask_feat_head.convs_all_levels.2.conv0.gn.weight, mask_feat_head.convs_all_levels.2.conv0.gn.bias, mask_feat_head.convs_all_levels.2.conv1.conv.weight, mask_feat_head.convs_all_levels.2.conv1.gn.weight, mask_feat_head.convs_all_levels.2.conv1.gn.bias, mask_feat_head.convs_all_levels.3.conv0.conv.weight, mask_feat_head.convs_all_levels.3.conv0.gn.weight, mask_feat_head.convs_all_levels.3.conv0.gn.bias, mask_feat_head.convs_all_levels.3.conv1.conv.weight, mask_feat_head.convs_all_levels.3.conv1.gn.weight, mask_feat_head.convs_all_levels.3.conv1.gn.bias, mask_feat_head.convs_all_levels.3.conv2.conv.weight, mask_feat_head.convs_all_levels.3.conv2.gn.weight, mask_feat_head.convs_all_levels.3.conv2.gn.bias, mask_feat_head.conv_pred.0.conv.weight, mask_feat_head.conv_pred.0.gn.weight, mask_feat_head.conv_pred.0.gn.bias, bbox_head.cate_convs.0.conv.weight, bbox_head.cate_convs.0.gn.weight, bbox_head.cate_convs.0.gn.bias, bbox_head.cate_convs.1.conv.weight, bbox_head.cate_convs.1.gn.weight, bbox_head.cate_convs.1.gn.bias, bbox_head.cate_convs.2.conv.weight, bbox_head.cate_convs.2.gn.weight, bbox_head.cate_convs.2.gn.bias, bbox_head.cate_convs.3.conv.weight, bbox_head.cate_convs.3.gn.weight, bbox_head.cate_convs.3.gn.bias, bbox_head.kernel_convs.0.conv.weight, bbox_head.kernel_convs.0.gn.weight, bbox_head.kernel_convs.0.gn.bias, bbox_head.kernel_convs.1.conv.weight, bbox_head.kernel_convs.1.gn.weight, bbox_head.kernel_convs.1.gn.bias, bbox_head.kernel_convs.2.conv.weight, bbox_head.kernel_convs.2.gn.weight, bbox_head.kernel_convs.2.gn.bias, bbox_head.kernel_convs.3.conv.weight, bbox_head.kernel_convs.3.gn.weight, bbox_head.kernel_convs.3.gn.bias, bbox_head.solo_cate.weight, bbox_head.solo_cate.bias, bbox_head.solo_kernel.weight, bbox_head.solo_kernel.bias

missing keys in source state_dict: conv1.weight, bn1.weight, bn1.bias, bn1.running_mean, bn1.running_var, layer1.0.conv1.weight, layer1.0.bn1.weight, layer1.0.bn1.bias, layer1.0.bn1.running_mean, layer1.0.bn1.running_var, layer1.0.conv2.weight, layer1.0.bn2.weight, layer1.0.bn2.bias, layer1.0.bn2.running_mean, layer1.0.bn2.running_var, layer1.0.conv3.weight, layer1.0.bn3.weight, layer1.0.bn3.bias, layer1.0.bn3.running_mean, layer1.0.bn3.running_var, layer1.0.downsample.0.weight, layer1.0.downsample.1.weight, layer1.0.downsample.1.bias, layer1.0.downsample.1.running_mean, layer1.0.downsample.1.running_var, layer1.1.conv1.weight, layer1.1.bn1.weight, layer1.1.bn1.bias, layer1.1.bn1.running_mean, layer1.1.bn1.running_var, layer1.1.conv2.weight, layer1.1.bn2.weight, layer1.1.bn2.bias, layer1.1.bn2.running_mean, layer1.1.bn2.running_var, layer1.1.conv3.weight, layer1.1.bn3.weight, layer1.1.bn3.bias, layer1.1.bn3.running_mean, layer1.1.bn3.running_var, layer1.2.conv1.weight, layer1.2.bn1.weight, layer1.2.bn1.bias, layer1.2.bn1.running_mean, layer1.2.bn1.running_var, layer1.2.conv2.weight, layer1.2.bn2.weight, layer1.2.bn2.bias, layer1.2.bn2.running_mean, layer1.2.bn2.running_var, layer1.2.conv3.weight, layer1.2.bn3.weight, layer1.2.bn3.bias, layer1.2.bn3.running_mean, layer1.2.bn3.running_var, layer2.0.conv1.weight, layer2.0.bn1.weight, layer2.0.bn1.bias, layer2.0.bn1.running_mean, layer2.0.bn1.running_var, layer2.0.conv2.weight, layer2.0.bn2.weight, layer2.0.bn2.bias, layer2.0.bn2.running_mean, layer2.0.bn2.running_var, layer2.0.conv3.weight, layer2.0.bn3.weight, layer2.0.bn3.bias, layer2.0.bn3.running_mean, layer2.0.bn3.running_var, layer2.0.downsample.0.weight, layer2.0.downsample.1.weight, layer2.0.downsample.1.bias, layer2.0.downsample.1.running_mean, layer2.0.downsample.1.running_var, layer2.1.conv1.weight, layer2.1.bn1.weight, layer2.1.bn1.bias, layer2.1.bn1.running_mean, layer2.1.bn1.running_var, layer2.1.conv2.weight, layer2.1.bn2.weight, layer2.1.bn2.bias, layer2.1.bn2.running_mean, layer2.1.bn2.running_var, layer2.1.conv3.weight, layer2.1.bn3.weight, layer2.1.bn3.bias, layer2.1.bn3.running_mean, layer2.1.bn3.running_var, layer2.2.conv1.weight, layer2.2.bn1.weight, layer2.2.bn1.bias, layer2.2.bn1.running_mean, layer2.2.bn1.running_var, layer2.2.conv2.weight, layer2.2.bn2.weight, layer2.2.bn2.bias, layer2.2.bn2.running_mean, layer2.2.bn2.running_var, layer2.2.conv3.weight, layer2.2.bn3.weight, layer2.2.bn3.bias, layer2.2.bn3.running_mean, layer2.2.bn3.running_var, layer2.3.conv1.weight, layer2.3.bn1.weight, layer2.3.bn1.bias, layer2.3.bn1.running_mean, layer2.3.bn1.running_var, layer2.3.conv2.weight, layer2.3.bn2.weight, layer2.3.bn2.bias, layer2.3.bn2.running_mean, layer2.3.bn2.running_var, layer2.3.conv3.weight, layer2.3.bn3.weight, layer2.3.bn3.bias, layer2.3.bn3.running_mean, layer2.3.bn3.running_var, layer3.0.conv1.weight, layer3.0.bn1.weight, layer3.0.bn1.bias, layer3.0.bn1.running_mean, layer3.0.bn1.running_var, layer3.0.conv2.weight, layer3.0.bn2.weight, layer3.0.bn2.bias, layer3.0.bn2.running_mean, layer3.0.bn2.running_var, layer3.0.conv3.weight, layer3.0.bn3.weight, layer3.0.bn3.bias, layer3.0.bn3.running_mean, layer3.0.bn3.running_var, layer3.0.downsample.0.weight, layer3.0.downsample.1.weight, layer3.0.downsample.1.bias, layer3.0.downsample.1.running_mean, layer3.0.downsample.1.running_var, layer3.1.conv1.weight, layer3.1.bn1.weight, layer3.1.bn1.bias, layer3.1.bn1.running_mean, layer3.1.bn1.running_var, layer3.1.conv2.weight, layer3.1.bn2.weight, layer3.1.bn2.bias, layer3.1.bn2.running_mean, layer3.1.bn2.running_var, layer3.1.conv3.weight, layer3.1.bn3.weight, layer3.1.bn3.bias, layer3.1.bn3.running_mean, layer3.1.bn3.running_var, layer3.2.conv1.weight, layer3.2.bn1.weight, layer3.2.bn1.bias, layer3.2.bn1.running_mean, layer3.2.bn1.running_var, layer3.2.conv2.weight, layer3.2.bn2.weight, layer3.2.bn2.bias, layer3.2.bn2.running_mean, layer3.2.bn2.running_var, layer3.2.conv3.weight, layer3.2.bn3.weight, layer3.2.bn3.bias, layer3.2.bn3.running_mean, layer3.2.bn3.running_var, layer3.3.conv1.weight, layer3.3.bn1.weight, layer3.3.bn1.bias, layer3.3.bn1.running_mean, layer3.3.bn1.running_var, layer3.3.conv2.weight, layer3.3.bn2.weight, layer3.3.bn2.bias, layer3.3.bn2.running_mean, layer3.3.bn2.running_var, layer3.3.conv3.weight, layer3.3.bn3.weight, layer3.3.bn3.bias, layer3.3.bn3.running_mean, layer3.3.bn3.running_var, layer3.4.conv1.weight, layer3.4.bn1.weight, layer3.4.bn1.bias, layer3.4.bn1.running_mean, layer3.4.bn1.running_var, layer3.4.conv2.weight, layer3.4.bn2.weight, layer3.4.bn2.bias, layer3.4.bn2.running_mean, layer3.4.bn2.running_var, layer3.4.conv3.weight, layer3.4.bn3.weight, layer3.4.bn3.bias, layer3.4.bn3.running_mean, layer3.4.bn3.running_var, layer3.5.conv1.weight, layer3.5.bn1.weight, layer3.5.bn1.bias, layer3.5.bn1.running_mean, layer3.5.bn1.running_var, layer3.5.conv2.weight, layer3.5.bn2.weight, layer3.5.bn2.bias, layer3.5.bn2.running_mean, layer3.5.bn2.running_var, layer3.5.conv3.weight, layer3.5.bn3.weight, layer3.5.bn3.bias, layer3.5.bn3.running_mean, layer3.5.bn3.running_var, layer4.0.conv1.weight, layer4.0.bn1.weight, layer4.0.bn1.bias, layer4.0.bn1.running_mean, layer4.0.bn1.running_var, layer4.0.conv2.weight, layer4.0.bn2.weight, layer4.0.bn2.bias, layer4.0.bn2.running_mean, layer4.0.bn2.running_var, layer4.0.conv3.weight, layer4.0.bn3.weight, layer4.0.bn3.bias, layer4.0.bn3.running_mean, layer4.0.bn3.running_var, layer4.0.downsample.0.weight, layer4.0.downsample.1.weight, layer4.0.downsample.1.bias, layer4.0.downsample.1.running_mean, layer4.0.downsample.1.running_var, layer4.1.conv1.weight, layer4.1.bn1.weight, layer4.1.bn1.bias, layer4.1.bn1.running_mean, layer4.1.bn1.running_var, layer4.1.conv2.weight, layer4.1.bn2.weight, layer4.1.bn2.bias, layer4.1.bn2.running_mean, layer4.1.bn2.running_var, layer4.1.conv3.weight, layer4.1.bn3.weight, layer4.1.bn3.bias, layer4.1.bn3.running_mean, layer4.1.bn3.running_var, layer4.2.conv1.weight, layer4.2.bn1.weight, layer4.2.bn1.bias, layer4.2.bn1.running_mean, layer4.2.bn1.running_var, layer4.2.conv2.weight, layer4.2.bn2.weight, layer4.2.bn2.bias, layer4.2.bn2.running_mean, layer4.2.bn2.running_var, layer4.2.conv3.weight, layer4.2.bn3.weight, layer4.2.bn3.bias, layer4.2.bn3.running_mean, layer4.2.bn3.running_var

2021-07-22 03:21:31,657 - mmdet - INFO - Start running, host: root@efe7fbebbac3, work_dir: /home/zq/work/SOLO/work_dirs/solov2_release_r50_fpn_8gpu_3x_workflow
2021-07-22 03:21:31,657 - mmdet - INFO - workflow: [('train', 1), ('val', 1)], max: 36 epochs
loading annotations into memory...
Done (t=0.02s)
creating index...
index created!
{'type': 'CocoDataset', 'ann_file': 'data/annotation/merge/merge_train_coco.json', 'img_prefix': 'data/road/train/', 'pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'LoadAnnotations', 'with_bbox': True, 'with_mask': True}, {'type': 'Resize', 'img_scale': [(1333, 800), (1333, 768), (1333, 736), (1333, 704), (1333, 672), (1333, 640)], 'multiscale_mode': 'value', 'keep_ratio': True}, {'type': 'RandomFlip', 'flip_ratio': 0.5}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'DefaultFormatBundle'}, {'type': 'Collect', 'keys': ['img', 'gt_bboxes', 'gt_labels', 'gt_masks']}]}
loading annotations into memory...
Done (t=0.00s)
creating index...
index created!
/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:2494: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
2021-07-22 03:21:46,912 - mmdet - INFO - Epoch [1][50/673]	lr: 0.00107, eta: 2:02:55, time: 0.305, data_time: 0.017, memory: 4327, loss_ins: 0.8642, loss_cate: 0.4309, loss: 1.2952
2021-07-22 03:22:01,755 - mmdet - INFO - Epoch [1][100/673]	lr: 0.00206, eta: 2:01:01, time: 0.297, data_time: 0.011, memory: 4327, loss_ins: 0.6382, loss_cate: 0.3752, loss: 1.0134
2021-07-22 03:22:16,596 - mmdet - INFO - Epoch [1][150/673]	lr: 0.00305, eta: 2:00:13, time: 0.297, data_time: 0.011, memory: 4327, loss_ins: 0.5804, loss_cate: 0.6223, loss: 1.2027
2021-07-22 03:22:31,487 - mmdet - INFO - Epoch [1][200/673]	lr: 0.00404, eta: 1:59:47, time: 0.298, data_time: 0.011, memory: 4327, loss_ins: 0.5721, loss_cate: 0.5589, loss: 1.1310
2021-07-22 03:22:46,204 - mmdet - INFO - Epoch [1][250/673]	lr: 0.00503, eta: 1:59:09, time: 0.294, data_time: 0.012, memory: 4327, loss_ins: 0.6187, loss_cate: 0.5501, loss: 1.1688
2021-07-22 03:23:01,246 - mmdet - INFO - Epoch [1][300/673]	lr: 0.00602, eta: 1:59:05, time: 0.301, data_time: 0.012, memory: 4327, loss_ins: 0.6274, loss_cate: 0.3322, loss: 0.9596
2021-07-22 03:23:15,987 - mmdet - INFO - Epoch [1][350/673]	lr: 0.00701, eta: 1:58:37, time: 0.295, data_time: 0.012, memory: 4327, loss_ins: 0.6137, loss_cate: 0.2891, loss: 0.9027
2021-07-22 03:23:31,010 - mmdet - INFO - Epoch [1][400/673]	lr: 0.00800, eta: 1:58:29, time: 0.300, data_time: 0.012, memory: 4328, loss_ins: 0.6463, loss_cate: 0.5511, loss: 1.1973
2021-07-22 03:23:45,575 - mmdet - INFO - Epoch [1][450/673]	lr: 0.00899, eta: 1:57:55, time: 0.291, data_time: 0.011, memory: 4328, loss_ins: 0.5580, loss_cate: 0.3678, loss: 0.9257
2021-07-22 03:24:00,721 - mmdet - INFO - Epoch [1][500/673]	lr: 0.00998, eta: 1:57:53, time: 0.303, data_time: 0.012, memory: 4328, loss_ins: 0.6015, loss_cate: 0.3086, loss: 0.9101
2021-07-22 03:24:15,337 - mmdet - INFO - Epoch [1][550/673]	lr: 0.01000, eta: 1:57:26, time: 0.292, data_time: 0.011, memory: 4328, loss_ins: 0.4840, loss_cate: 0.2800, loss: 0.7639
2021-07-22 03:24:30,346 - mmdet - INFO - Epoch [1][600/673]	lr: 0.01000, eta: 1:57:16, time: 0.300, data_time: 0.012, memory: 4328, loss_ins: 0.6733, loss_cate: 0.2760, loss: 0.9492
2021-07-22 03:24:45,553 - mmdet - INFO - Epoch [1][650/673]	lr: 0.01000, eta: 1:57:13, time: 0.304, data_time: 0.012, memory: 4328, loss_ins: 0.4713, loss_cate: 0.2419, loss: 0.7132
Traceback (most recent call last):
  File "tools/train.py", line 133, in <module>
    main()
  File "tools/train.py", line 129, in main
    timestamp=timestamp)
  File "/home/zq/work/SOLO/mmdet/apis/train.py", line 111, in train_detector
    timestamp=timestamp)
  File "/home/zq/work/SOLO/mmdet/apis/train.py", line 297, in _non_dist_train
    runner.run(data_loaders, cfg.workflow, cfg.total_epochs)
  File "/opt/conda/lib/python3.6/site-packages/mmcv/runner/runner.py", line 364, in run
    epoch_runner(data_loaders[i], **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/mmcv/runner/runner.py", line 292, in val
    self.model, data_batch, train_mode=False, **kwargs)
  File "/home/zq/work/SOLO/mmdet/apis/train.py", line 78, in batch_processor
    losses = model(**data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py", line 150, in forward
    return self.module(*inputs[0], **kwargs[0])
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/zq/work/SOLO/mmdet/core/fp16/decorators.py", line 49, in new_func
    return old_func(*args, **kwargs)
  File "/home/zq/work/SOLO/mmdet/models/detectors/base.py", line 142, in forward
    return self.forward_train(img, img_meta, **kwargs)
TypeError: forward_train() missing 2 required positional arguments: 'gt_bboxes' and 'gt_labels'
2021-07-23 00:20:57,351 - mmdet - INFO - Distributed training: False
2021-07-23 00:20:57,351 - mmdet - INFO - MMDetection Version: 1.0.0+c7b294a
2021-07-23 00:20:57,351 - mmdet - INFO - Config:
# model settings
model = dict(
    type='SOLOv2',
    pretrained='torchvision://resnet50',
    backbone=dict(
        type='ResNet',
        depth=50,
        num_stages=4,
        out_indices=(0, 1, 2, 3),  # C2, C3, C4, C5
        frozen_stages=1,
        style='pytorch'),
    neck=dict(
        type='FPN',
        in_channels=[256, 512, 1024, 2048],
        out_channels=256,
        start_level=0,
        num_outs=5),
    bbox_head=dict(
        type='SOLOv2Head',
        num_classes=2,
        in_channels=256,
        stacked_convs=4,
        seg_feat_channels=512,
        strides=[8, 8, 16, 32, 32],
        scale_ranges=((1, 96), (48, 192), (96, 384), (192, 768), (384, 2048)),
        # scale_ranges=((1, 250), (125, 500), (250, 1000), (500, 2000)),
        sigma=0.2,
        num_grids=[40, 36, 24, 16, 12],
        ins_out_channels=256,
        loss_ins=dict(
            type='DiceLoss',
            use_sigmoid=True,
            loss_weight=3.0),
        # loss_weight=10.0),
        loss_cate=dict(
            type='FocalLoss',
            use_sigmoid=True,
            gamma=2.0,
            alpha=0.25,
            loss_weight=1.0)),
    mask_feat_head=dict(
        type='MaskFeatHead',
        in_channels=256,
        out_channels=128,
        start_level=0,
        end_level=3,
        num_classes=256,
        norm_cfg=dict(type='GN', num_groups=32, requires_grad=True)),
)
# training and testing settings
train_cfg = dict()
test_cfg = dict(
    nms_pre=500,
    score_thr=0.1,
    mask_thr=0.5,
    update_thr=0.05,
    kernel='gaussian',  # gaussian/linear
    sigma=2.0,
    max_per_img=100)
# dataset settings
dataset_type = 'CocoDataset'
data_root = 'data/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),
    dict(type='Resize',
         img_scale=[(1333, 800), (1333, 768), (1333, 736),
                    (1333, 704), (1333, 672), (1333, 640)],
         multiscale_mode='value',
         keep_ratio=True),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(type='Normalize', **img_norm_cfg),
    dict(type='Pad', size_divisor=32),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks']),
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(1333, 800),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(type='Normalize', **img_norm_cfg),
            dict(type='Pad', size_divisor=32),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img']),
        ])
]
data = dict(
    imgs_per_gpu=2,
    workers_per_gpu=2,
    train=dict(
        type=dataset_type,
        ann_file=data_root + 'annotation/merge/merge_train_coco.json',
        img_prefix=data_root + 'road/train/',
        pipeline=train_pipeline),
    val=dict(
        type=dataset_type,
        ann_file=data_root + 'annotation/merge/merge_val_coco.json',
        img_prefix=data_root + 'road/val/',
        pipeline=test_pipeline),
    test=dict(
        type=dataset_type,
        ann_file=data_root + 'annotation/merge/merge_val_coco.json',
        img_prefix=data_root + 'road/val/',
        pipeline=test_pipeline))
# optimizer
optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0001)
optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))
# learning policy
lr_config = dict(
    policy='step',
    warmup='linear',
    warmup_iters=500,
    warmup_ratio=0.01,
    step=[27, 33])
checkpoint_config = dict(interval=1)
# yapf:disable
log_config = dict(
    interval=50,
    hooks=[
        dict(type='TextLoggerHook'),
        # dict(type='TensorboardLoggerHook')
    ])
# yapf:enable
# runtime settings
total_epochs = 36
device_ids = range(8)
dist_params = dict(backend='nccl')
log_level = 'INFO'
work_dir = './work_dirs/solov2_release_r50_fpn_8gpu_3x'
# work_dir = './work_dirs/solov2_release_r50_fpn_8gpu_3x_scale'
# work_dir = './work_dirs/solov2_release_r50_fpn_8gpu_3x_weight'
# work_dir = './work_dirs/solov2_release_r50_fpn_8gpu_3x_workflow'
# work_dir = './work_dirs/solov2_release_r50_fpn_8gpu_3x_validate'

load_from = None
# load_from = './work_dirs/solov2_release_r50_fpn_8gpu_3x_scale/epoch_7.pth'
resume_from = None
workflow = [('train', 1)]

2021-07-23 00:20:57,731 - mmdet - INFO - load model from: torchvision://resnet50
2021-07-23 00:21:00,029 - mmdet - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: backbone.conv1.weight, backbone.bn1.weight, backbone.bn1.bias, backbone.bn1.running_mean, backbone.bn1.running_var, backbone.bn1.num_batches_tracked, backbone.layer1.0.conv1.weight, backbone.layer1.0.bn1.weight, backbone.layer1.0.bn1.bias, backbone.layer1.0.bn1.running_mean, backbone.layer1.0.bn1.running_var, backbone.layer1.0.bn1.num_batches_tracked, backbone.layer1.0.conv2.weight, backbone.layer1.0.bn2.weight, backbone.layer1.0.bn2.bias, backbone.layer1.0.bn2.running_mean, backbone.layer1.0.bn2.running_var, backbone.layer1.0.bn2.num_batches_tracked, backbone.layer1.0.conv3.weight, backbone.layer1.0.bn3.weight, backbone.layer1.0.bn3.bias, backbone.layer1.0.bn3.running_mean, backbone.layer1.0.bn3.running_var, backbone.layer1.0.bn3.num_batches_tracked, backbone.layer1.0.downsample.0.weight, backbone.layer1.0.downsample.1.weight, backbone.layer1.0.downsample.1.bias, backbone.layer1.0.downsample.1.running_mean, backbone.layer1.0.downsample.1.running_var, backbone.layer1.0.downsample.1.num_batches_tracked, backbone.layer1.1.conv1.weight, backbone.layer1.1.bn1.weight, backbone.layer1.1.bn1.bias, backbone.layer1.1.bn1.running_mean, backbone.layer1.1.bn1.running_var, backbone.layer1.1.bn1.num_batches_tracked, backbone.layer1.1.conv2.weight, backbone.layer1.1.bn2.weight, backbone.layer1.1.bn2.bias, backbone.layer1.1.bn2.running_mean, backbone.layer1.1.bn2.running_var, backbone.layer1.1.bn2.num_batches_tracked, backbone.layer1.1.conv3.weight, backbone.layer1.1.bn3.weight, backbone.layer1.1.bn3.bias, backbone.layer1.1.bn3.running_mean, backbone.layer1.1.bn3.running_var, backbone.layer1.1.bn3.num_batches_tracked, backbone.layer1.2.conv1.weight, backbone.layer1.2.bn1.weight, backbone.layer1.2.bn1.bias, backbone.layer1.2.bn1.running_mean, backbone.layer1.2.bn1.running_var, backbone.layer1.2.bn1.num_batches_tracked, backbone.layer1.2.conv2.weight, backbone.layer1.2.bn2.weight, backbone.layer1.2.bn2.bias, backbone.layer1.2.bn2.running_mean, backbone.layer1.2.bn2.running_var, backbone.layer1.2.bn2.num_batches_tracked, backbone.layer1.2.conv3.weight, backbone.layer1.2.bn3.weight, backbone.layer1.2.bn3.bias, backbone.layer1.2.bn3.running_mean, backbone.layer1.2.bn3.running_var, backbone.layer1.2.bn3.num_batches_tracked, backbone.layer2.0.conv1.weight, backbone.layer2.0.bn1.weight, backbone.layer2.0.bn1.bias, backbone.layer2.0.bn1.running_mean, backbone.layer2.0.bn1.running_var, backbone.layer2.0.bn1.num_batches_tracked, backbone.layer2.0.conv2.weight, backbone.layer2.0.bn2.weight, backbone.layer2.0.bn2.bias, backbone.layer2.0.bn2.running_mean, backbone.layer2.0.bn2.running_var, backbone.layer2.0.bn2.num_batches_tracked, backbone.layer2.0.conv3.weight, backbone.layer2.0.bn3.weight, backbone.layer2.0.bn3.bias, backbone.layer2.0.bn3.running_mean, backbone.layer2.0.bn3.running_var, backbone.layer2.0.bn3.num_batches_tracked, backbone.layer2.0.downsample.0.weight, backbone.layer2.0.downsample.1.weight, backbone.layer2.0.downsample.1.bias, backbone.layer2.0.downsample.1.running_mean, backbone.layer2.0.downsample.1.running_var, backbone.layer2.0.downsample.1.num_batches_tracked, backbone.layer2.1.conv1.weight, backbone.layer2.1.bn1.weight, backbone.layer2.1.bn1.bias, backbone.layer2.1.bn1.running_mean, backbone.layer2.1.bn1.running_var, backbone.layer2.1.bn1.num_batches_tracked, backbone.layer2.1.conv2.weight, backbone.layer2.1.bn2.weight, backbone.layer2.1.bn2.bias, backbone.layer2.1.bn2.running_mean, backbone.layer2.1.bn2.running_var, backbone.layer2.1.bn2.num_batches_tracked, backbone.layer2.1.conv3.weight, backbone.layer2.1.bn3.weight, backbone.layer2.1.bn3.bias, backbone.layer2.1.bn3.running_mean, backbone.layer2.1.bn3.running_var, backbone.layer2.1.bn3.num_batches_tracked, backbone.layer2.2.conv1.weight, backbone.layer2.2.bn1.weight, backbone.layer2.2.bn1.bias, backbone.layer2.2.bn1.running_mean, backbone.layer2.2.bn1.running_var, backbone.layer2.2.bn1.num_batches_tracked, backbone.layer2.2.conv2.weight, backbone.layer2.2.bn2.weight, backbone.layer2.2.bn2.bias, backbone.layer2.2.bn2.running_mean, backbone.layer2.2.bn2.running_var, backbone.layer2.2.bn2.num_batches_tracked, backbone.layer2.2.conv3.weight, backbone.layer2.2.bn3.weight, backbone.layer2.2.bn3.bias, backbone.layer2.2.bn3.running_mean, backbone.layer2.2.bn3.running_var, backbone.layer2.2.bn3.num_batches_tracked, backbone.layer2.3.conv1.weight, backbone.layer2.3.bn1.weight, backbone.layer2.3.bn1.bias, backbone.layer2.3.bn1.running_mean, backbone.layer2.3.bn1.running_var, backbone.layer2.3.bn1.num_batches_tracked, backbone.layer2.3.conv2.weight, backbone.layer2.3.bn2.weight, backbone.layer2.3.bn2.bias, backbone.layer2.3.bn2.running_mean, backbone.layer2.3.bn2.running_var, backbone.layer2.3.bn2.num_batches_tracked, backbone.layer2.3.conv3.weight, backbone.layer2.3.bn3.weight, backbone.layer2.3.bn3.bias, backbone.layer2.3.bn3.running_mean, backbone.layer2.3.bn3.running_var, backbone.layer2.3.bn3.num_batches_tracked, backbone.layer3.0.conv1.weight, backbone.layer3.0.bn1.weight, backbone.layer3.0.bn1.bias, backbone.layer3.0.bn1.running_mean, backbone.layer3.0.bn1.running_var, backbone.layer3.0.bn1.num_batches_tracked, backbone.layer3.0.conv2.weight, backbone.layer3.0.bn2.weight, backbone.layer3.0.bn2.bias, backbone.layer3.0.bn2.running_mean, backbone.layer3.0.bn2.running_var, backbone.layer3.0.bn2.num_batches_tracked, backbone.layer3.0.conv3.weight, backbone.layer3.0.bn3.weight, backbone.layer3.0.bn3.bias, backbone.layer3.0.bn3.running_mean, backbone.layer3.0.bn3.running_var, backbone.layer3.0.bn3.num_batches_tracked, backbone.layer3.0.downsample.0.weight, backbone.layer3.0.downsample.1.weight, backbone.layer3.0.downsample.1.bias, backbone.layer3.0.downsample.1.running_mean, backbone.layer3.0.downsample.1.running_var, backbone.layer3.0.downsample.1.num_batches_tracked, backbone.layer3.1.conv1.weight, backbone.layer3.1.bn1.weight, backbone.layer3.1.bn1.bias, backbone.layer3.1.bn1.running_mean, backbone.layer3.1.bn1.running_var, backbone.layer3.1.bn1.num_batches_tracked, backbone.layer3.1.conv2.weight, backbone.layer3.1.bn2.weight, backbone.layer3.1.bn2.bias, backbone.layer3.1.bn2.running_mean, backbone.layer3.1.bn2.running_var, backbone.layer3.1.bn2.num_batches_tracked, backbone.layer3.1.conv3.weight, backbone.layer3.1.bn3.weight, backbone.layer3.1.bn3.bias, backbone.layer3.1.bn3.running_mean, backbone.layer3.1.bn3.running_var, backbone.layer3.1.bn3.num_batches_tracked, backbone.layer3.2.conv1.weight, backbone.layer3.2.bn1.weight, backbone.layer3.2.bn1.bias, backbone.layer3.2.bn1.running_mean, backbone.layer3.2.bn1.running_var, backbone.layer3.2.bn1.num_batches_tracked, backbone.layer3.2.conv2.weight, backbone.layer3.2.bn2.weight, backbone.layer3.2.bn2.bias, backbone.layer3.2.bn2.running_mean, backbone.layer3.2.bn2.running_var, backbone.layer3.2.bn2.num_batches_tracked, backbone.layer3.2.conv3.weight, backbone.layer3.2.bn3.weight, backbone.layer3.2.bn3.bias, backbone.layer3.2.bn3.running_mean, backbone.layer3.2.bn3.running_var, backbone.layer3.2.bn3.num_batches_tracked, backbone.layer3.3.conv1.weight, backbone.layer3.3.bn1.weight, backbone.layer3.3.bn1.bias, backbone.layer3.3.bn1.running_mean, backbone.layer3.3.bn1.running_var, backbone.layer3.3.bn1.num_batches_tracked, backbone.layer3.3.conv2.weight, backbone.layer3.3.bn2.weight, backbone.layer3.3.bn2.bias, backbone.layer3.3.bn2.running_mean, backbone.layer3.3.bn2.running_var, backbone.layer3.3.bn2.num_batches_tracked, backbone.layer3.3.conv3.weight, backbone.layer3.3.bn3.weight, backbone.layer3.3.bn3.bias, backbone.layer3.3.bn3.running_mean, backbone.layer3.3.bn3.running_var, backbone.layer3.3.bn3.num_batches_tracked, backbone.layer3.4.conv1.weight, backbone.layer3.4.bn1.weight, backbone.layer3.4.bn1.bias, backbone.layer3.4.bn1.running_mean, backbone.layer3.4.bn1.running_var, backbone.layer3.4.bn1.num_batches_tracked, backbone.layer3.4.conv2.weight, backbone.layer3.4.bn2.weight, backbone.layer3.4.bn2.bias, backbone.layer3.4.bn2.running_mean, backbone.layer3.4.bn2.running_var, backbone.layer3.4.bn2.num_batches_tracked, backbone.layer3.4.conv3.weight, backbone.layer3.4.bn3.weight, backbone.layer3.4.bn3.bias, backbone.layer3.4.bn3.running_mean, backbone.layer3.4.bn3.running_var, backbone.layer3.4.bn3.num_batches_tracked, backbone.layer3.5.conv1.weight, backbone.layer3.5.bn1.weight, backbone.layer3.5.bn1.bias, backbone.layer3.5.bn1.running_mean, backbone.layer3.5.bn1.running_var, backbone.layer3.5.bn1.num_batches_tracked, backbone.layer3.5.conv2.weight, backbone.layer3.5.bn2.weight, backbone.layer3.5.bn2.bias, backbone.layer3.5.bn2.running_mean, backbone.layer3.5.bn2.running_var, backbone.layer3.5.bn2.num_batches_tracked, backbone.layer3.5.conv3.weight, backbone.layer3.5.bn3.weight, backbone.layer3.5.bn3.bias, backbone.layer3.5.bn3.running_mean, backbone.layer3.5.bn3.running_var, backbone.layer3.5.bn3.num_batches_tracked, backbone.layer4.0.conv1.weight, backbone.layer4.0.bn1.weight, backbone.layer4.0.bn1.bias, backbone.layer4.0.bn1.running_mean, backbone.layer4.0.bn1.running_var, backbone.layer4.0.bn1.num_batches_tracked, backbone.layer4.0.conv2.weight, backbone.layer4.0.bn2.weight, backbone.layer4.0.bn2.bias, backbone.layer4.0.bn2.running_mean, backbone.layer4.0.bn2.running_var, backbone.layer4.0.bn2.num_batches_tracked, backbone.layer4.0.conv3.weight, backbone.layer4.0.bn3.weight, backbone.layer4.0.bn3.bias, backbone.layer4.0.bn3.running_mean, backbone.layer4.0.bn3.running_var, backbone.layer4.0.bn3.num_batches_tracked, backbone.layer4.0.downsample.0.weight, backbone.layer4.0.downsample.1.weight, backbone.layer4.0.downsample.1.bias, backbone.layer4.0.downsample.1.running_mean, backbone.layer4.0.downsample.1.running_var, backbone.layer4.0.downsample.1.num_batches_tracked, backbone.layer4.1.conv1.weight, backbone.layer4.1.bn1.weight, backbone.layer4.1.bn1.bias, backbone.layer4.1.bn1.running_mean, backbone.layer4.1.bn1.running_var, backbone.layer4.1.bn1.num_batches_tracked, backbone.layer4.1.conv2.weight, backbone.layer4.1.bn2.weight, backbone.layer4.1.bn2.bias, backbone.layer4.1.bn2.running_mean, backbone.layer4.1.bn2.running_var, backbone.layer4.1.bn2.num_batches_tracked, backbone.layer4.1.conv3.weight, backbone.layer4.1.bn3.weight, backbone.layer4.1.bn3.bias, backbone.layer4.1.bn3.running_mean, backbone.layer4.1.bn3.running_var, backbone.layer4.1.bn3.num_batches_tracked, backbone.layer4.2.conv1.weight, backbone.layer4.2.bn1.weight, backbone.layer4.2.bn1.bias, backbone.layer4.2.bn1.running_mean, backbone.layer4.2.bn1.running_var, backbone.layer4.2.bn1.num_batches_tracked, backbone.layer4.2.conv2.weight, backbone.layer4.2.bn2.weight, backbone.layer4.2.bn2.bias, backbone.layer4.2.bn2.running_mean, backbone.layer4.2.bn2.running_var, backbone.layer4.2.bn2.num_batches_tracked, backbone.layer4.2.conv3.weight, backbone.layer4.2.bn3.weight, backbone.layer4.2.bn3.bias, backbone.layer4.2.bn3.running_mean, backbone.layer4.2.bn3.running_var, backbone.layer4.2.bn3.num_batches_tracked, neck.lateral_convs.0.conv.weight, neck.lateral_convs.0.conv.bias, neck.lateral_convs.1.conv.weight, neck.lateral_convs.1.conv.bias, neck.lateral_convs.2.conv.weight, neck.lateral_convs.2.conv.bias, neck.lateral_convs.3.conv.weight, neck.lateral_convs.3.conv.bias, neck.fpn_convs.0.conv.weight, neck.fpn_convs.0.conv.bias, neck.fpn_convs.1.conv.weight, neck.fpn_convs.1.conv.bias, neck.fpn_convs.2.conv.weight, neck.fpn_convs.2.conv.bias, neck.fpn_convs.3.conv.weight, neck.fpn_convs.3.conv.bias, mask_feat_head.convs_all_levels.0.conv0.conv.weight, mask_feat_head.convs_all_levels.0.conv0.gn.weight, mask_feat_head.convs_all_levels.0.conv0.gn.bias, mask_feat_head.convs_all_levels.1.conv0.conv.weight, mask_feat_head.convs_all_levels.1.conv0.gn.weight, mask_feat_head.convs_all_levels.1.conv0.gn.bias, mask_feat_head.convs_all_levels.2.conv0.conv.weight, mask_feat_head.convs_all_levels.2.conv0.gn.weight, mask_feat_head.convs_all_levels.2.conv0.gn.bias, mask_feat_head.convs_all_levels.2.conv1.conv.weight, mask_feat_head.convs_all_levels.2.conv1.gn.weight, mask_feat_head.convs_all_levels.2.conv1.gn.bias, mask_feat_head.convs_all_levels.3.conv0.conv.weight, mask_feat_head.convs_all_levels.3.conv0.gn.weight, mask_feat_head.convs_all_levels.3.conv0.gn.bias, mask_feat_head.convs_all_levels.3.conv1.conv.weight, mask_feat_head.convs_all_levels.3.conv1.gn.weight, mask_feat_head.convs_all_levels.3.conv1.gn.bias, mask_feat_head.convs_all_levels.3.conv2.conv.weight, mask_feat_head.convs_all_levels.3.conv2.gn.weight, mask_feat_head.convs_all_levels.3.conv2.gn.bias, mask_feat_head.conv_pred.0.conv.weight, mask_feat_head.conv_pred.0.gn.weight, mask_feat_head.conv_pred.0.gn.bias, bbox_head.cate_convs.0.conv.weight, bbox_head.cate_convs.0.gn.weight, bbox_head.cate_convs.0.gn.bias, bbox_head.cate_convs.1.conv.weight, bbox_head.cate_convs.1.gn.weight, bbox_head.cate_convs.1.gn.bias, bbox_head.cate_convs.2.conv.weight, bbox_head.cate_convs.2.gn.weight, bbox_head.cate_convs.2.gn.bias, bbox_head.cate_convs.3.conv.weight, bbox_head.cate_convs.3.gn.weight, bbox_head.cate_convs.3.gn.bias, bbox_head.kernel_convs.0.conv.weight, bbox_head.kernel_convs.0.gn.weight, bbox_head.kernel_convs.0.gn.bias, bbox_head.kernel_convs.1.conv.weight, bbox_head.kernel_convs.1.gn.weight, bbox_head.kernel_convs.1.gn.bias, bbox_head.kernel_convs.2.conv.weight, bbox_head.kernel_convs.2.gn.weight, bbox_head.kernel_convs.2.gn.bias, bbox_head.kernel_convs.3.conv.weight, bbox_head.kernel_convs.3.gn.weight, bbox_head.kernel_convs.3.gn.bias, bbox_head.solo_cate.weight, bbox_head.solo_cate.bias, bbox_head.solo_kernel.weight, bbox_head.solo_kernel.bias

missing keys in source state_dict: conv1.weight, bn1.weight, bn1.bias, bn1.running_mean, bn1.running_var, layer1.0.conv1.weight, layer1.0.bn1.weight, layer1.0.bn1.bias, layer1.0.bn1.running_mean, layer1.0.bn1.running_var, layer1.0.conv2.weight, layer1.0.bn2.weight, layer1.0.bn2.bias, layer1.0.bn2.running_mean, layer1.0.bn2.running_var, layer1.0.conv3.weight, layer1.0.bn3.weight, layer1.0.bn3.bias, layer1.0.bn3.running_mean, layer1.0.bn3.running_var, layer1.0.downsample.0.weight, layer1.0.downsample.1.weight, layer1.0.downsample.1.bias, layer1.0.downsample.1.running_mean, layer1.0.downsample.1.running_var, layer1.1.conv1.weight, layer1.1.bn1.weight, layer1.1.bn1.bias, layer1.1.bn1.running_mean, layer1.1.bn1.running_var, layer1.1.conv2.weight, layer1.1.bn2.weight, layer1.1.bn2.bias, layer1.1.bn2.running_mean, layer1.1.bn2.running_var, layer1.1.conv3.weight, layer1.1.bn3.weight, layer1.1.bn3.bias, layer1.1.bn3.running_mean, layer1.1.bn3.running_var, layer1.2.conv1.weight, layer1.2.bn1.weight, layer1.2.bn1.bias, layer1.2.bn1.running_mean, layer1.2.bn1.running_var, layer1.2.conv2.weight, layer1.2.bn2.weight, layer1.2.bn2.bias, layer1.2.bn2.running_mean, layer1.2.bn2.running_var, layer1.2.conv3.weight, layer1.2.bn3.weight, layer1.2.bn3.bias, layer1.2.bn3.running_mean, layer1.2.bn3.running_var, layer2.0.conv1.weight, layer2.0.bn1.weight, layer2.0.bn1.bias, layer2.0.bn1.running_mean, layer2.0.bn1.running_var, layer2.0.conv2.weight, layer2.0.bn2.weight, layer2.0.bn2.bias, layer2.0.bn2.running_mean, layer2.0.bn2.running_var, layer2.0.conv3.weight, layer2.0.bn3.weight, layer2.0.bn3.bias, layer2.0.bn3.running_mean, layer2.0.bn3.running_var, layer2.0.downsample.0.weight, layer2.0.downsample.1.weight, layer2.0.downsample.1.bias, layer2.0.downsample.1.running_mean, layer2.0.downsample.1.running_var, layer2.1.conv1.weight, layer2.1.bn1.weight, layer2.1.bn1.bias, layer2.1.bn1.running_mean, layer2.1.bn1.running_var, layer2.1.conv2.weight, layer2.1.bn2.weight, layer2.1.bn2.bias, layer2.1.bn2.running_mean, layer2.1.bn2.running_var, layer2.1.conv3.weight, layer2.1.bn3.weight, layer2.1.bn3.bias, layer2.1.bn3.running_mean, layer2.1.bn3.running_var, layer2.2.conv1.weight, layer2.2.bn1.weight, layer2.2.bn1.bias, layer2.2.bn1.running_mean, layer2.2.bn1.running_var, layer2.2.conv2.weight, layer2.2.bn2.weight, layer2.2.bn2.bias, layer2.2.bn2.running_mean, layer2.2.bn2.running_var, layer2.2.conv3.weight, layer2.2.bn3.weight, layer2.2.bn3.bias, layer2.2.bn3.running_mean, layer2.2.bn3.running_var, layer2.3.conv1.weight, layer2.3.bn1.weight, layer2.3.bn1.bias, layer2.3.bn1.running_mean, layer2.3.bn1.running_var, layer2.3.conv2.weight, layer2.3.bn2.weight, layer2.3.bn2.bias, layer2.3.bn2.running_mean, layer2.3.bn2.running_var, layer2.3.conv3.weight, layer2.3.bn3.weight, layer2.3.bn3.bias, layer2.3.bn3.running_mean, layer2.3.bn3.running_var, layer3.0.conv1.weight, layer3.0.bn1.weight, layer3.0.bn1.bias, layer3.0.bn1.running_mean, layer3.0.bn1.running_var, layer3.0.conv2.weight, layer3.0.bn2.weight, layer3.0.bn2.bias, layer3.0.bn2.running_mean, layer3.0.bn2.running_var, layer3.0.conv3.weight, layer3.0.bn3.weight, layer3.0.bn3.bias, layer3.0.bn3.running_mean, layer3.0.bn3.running_var, layer3.0.downsample.0.weight, layer3.0.downsample.1.weight, layer3.0.downsample.1.bias, layer3.0.downsample.1.running_mean, layer3.0.downsample.1.running_var, layer3.1.conv1.weight, layer3.1.bn1.weight, layer3.1.bn1.bias, layer3.1.bn1.running_mean, layer3.1.bn1.running_var, layer3.1.conv2.weight, layer3.1.bn2.weight, layer3.1.bn2.bias, layer3.1.bn2.running_mean, layer3.1.bn2.running_var, layer3.1.conv3.weight, layer3.1.bn3.weight, layer3.1.bn3.bias, layer3.1.bn3.running_mean, layer3.1.bn3.running_var, layer3.2.conv1.weight, layer3.2.bn1.weight, layer3.2.bn1.bias, layer3.2.bn1.running_mean, layer3.2.bn1.running_var, layer3.2.conv2.weight, layer3.2.bn2.weight, layer3.2.bn2.bias, layer3.2.bn2.running_mean, layer3.2.bn2.running_var, layer3.2.conv3.weight, layer3.2.bn3.weight, layer3.2.bn3.bias, layer3.2.bn3.running_mean, layer3.2.bn3.running_var, layer3.3.conv1.weight, layer3.3.bn1.weight, layer3.3.bn1.bias, layer3.3.bn1.running_mean, layer3.3.bn1.running_var, layer3.3.conv2.weight, layer3.3.bn2.weight, layer3.3.bn2.bias, layer3.3.bn2.running_mean, layer3.3.bn2.running_var, layer3.3.conv3.weight, layer3.3.bn3.weight, layer3.3.bn3.bias, layer3.3.bn3.running_mean, layer3.3.bn3.running_var, layer3.4.conv1.weight, layer3.4.bn1.weight, layer3.4.bn1.bias, layer3.4.bn1.running_mean, layer3.4.bn1.running_var, layer3.4.conv2.weight, layer3.4.bn2.weight, layer3.4.bn2.bias, layer3.4.bn2.running_mean, layer3.4.bn2.running_var, layer3.4.conv3.weight, layer3.4.bn3.weight, layer3.4.bn3.bias, layer3.4.bn3.running_mean, layer3.4.bn3.running_var, layer3.5.conv1.weight, layer3.5.bn1.weight, layer3.5.bn1.bias, layer3.5.bn1.running_mean, layer3.5.bn1.running_var, layer3.5.conv2.weight, layer3.5.bn2.weight, layer3.5.bn2.bias, layer3.5.bn2.running_mean, layer3.5.bn2.running_var, layer3.5.conv3.weight, layer3.5.bn3.weight, layer3.5.bn3.bias, layer3.5.bn3.running_mean, layer3.5.bn3.running_var, layer4.0.conv1.weight, layer4.0.bn1.weight, layer4.0.bn1.bias, layer4.0.bn1.running_mean, layer4.0.bn1.running_var, layer4.0.conv2.weight, layer4.0.bn2.weight, layer4.0.bn2.bias, layer4.0.bn2.running_mean, layer4.0.bn2.running_var, layer4.0.conv3.weight, layer4.0.bn3.weight, layer4.0.bn3.bias, layer4.0.bn3.running_mean, layer4.0.bn3.running_var, layer4.0.downsample.0.weight, layer4.0.downsample.1.weight, layer4.0.downsample.1.bias, layer4.0.downsample.1.running_mean, layer4.0.downsample.1.running_var, layer4.1.conv1.weight, layer4.1.bn1.weight, layer4.1.bn1.bias, layer4.1.bn1.running_mean, layer4.1.bn1.running_var, layer4.1.conv2.weight, layer4.1.bn2.weight, layer4.1.bn2.bias, layer4.1.bn2.running_mean, layer4.1.bn2.running_var, layer4.1.conv3.weight, layer4.1.bn3.weight, layer4.1.bn3.bias, layer4.1.bn3.running_mean, layer4.1.bn3.running_var, layer4.2.conv1.weight, layer4.2.bn1.weight, layer4.2.bn1.bias, layer4.2.bn1.running_mean, layer4.2.bn1.running_var, layer4.2.conv2.weight, layer4.2.bn2.weight, layer4.2.bn2.bias, layer4.2.bn2.running_mean, layer4.2.bn2.running_var, layer4.2.conv3.weight, layer4.2.bn3.weight, layer4.2.bn3.bias, layer4.2.bn3.running_mean, layer4.2.bn3.running_var

2021-07-23 00:21:00,229 - mmdet - INFO - Start running, host: root@efe7fbebbac3, work_dir: /home/zq/work/SOLO/work_dirs/solov2_release_r50_fpn_8gpu_3x
2021-07-23 00:21:00,230 - mmdet - INFO - workflow: [('train', 1)], max: 36 epochs
loading annotations into memory...
Done (t=0.02s)
creating index...
index created!
{'type': 'CocoDataset', 'ann_file': 'data/annotation/merge/merge_train_coco.json', 'img_prefix': 'data/road/train/', 'pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'LoadAnnotations', 'with_bbox': True, 'with_mask': True}, {'type': 'Resize', 'img_scale': [(1333, 800), (1333, 768), (1333, 736), (1333, 704), (1333, 672), (1333, 640)], 'multiscale_mode': 'value', 'keep_ratio': True}, {'type': 'RandomFlip', 'flip_ratio': 0.5}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'DefaultFormatBundle'}, {'type': 'Collect', 'keys': ['img', 'gt_bboxes', 'gt_labels', 'gt_masks']}]}
/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:2494: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
2021-07-23 00:21:15,474 - mmdet - INFO - Epoch [1][50/673]	lr: 0.00107, eta: 2:02:50, time: 0.305, data_time: 0.018, memory: 4237, loss_ins: 1.3771, loss_cate: 0.4647, loss: 1.8418
2021-07-23 00:21:30,113 - mmdet - INFO - Epoch [1][100/673]	lr: 0.00206, eta: 2:00:09, time: 0.293, data_time: 0.012, memory: 4238, loss_ins: 1.3524, loss_cate: 0.4841, loss: 1.8365
2021-07-23 00:21:44,766 - mmdet - INFO - Epoch [1][150/673]	lr: 0.00305, eta: 1:59:08, time: 0.293, data_time: 0.012, memory: 4331, loss_ins: 1.3293, loss_cate: 0.5721, loss: 1.9014
2021-07-23 00:21:59,441 - mmdet - INFO - Epoch [1][200/673]	lr: 0.00404, eta: 1:58:33, time: 0.293, data_time: 0.012, memory: 4331, loss_ins: 1.2956, loss_cate: 0.3029, loss: 1.5985
2021-07-23 00:22:14,318 - mmdet - INFO - Epoch [1][250/673]	lr: 0.00503, eta: 1:58:25, time: 0.298, data_time: 0.012, memory: 4331, loss_ins: 1.3704, loss_cate: 0.5625, loss: 1.9329
2021-07-23 00:22:29,285 - mmdet - INFO - Epoch [1][300/673]	lr: 0.00602, eta: 1:58:22, time: 0.299, data_time: 0.012, memory: 4401, loss_ins: 1.2588, loss_cate: 0.6598, loss: 1.9186
2021-07-23 00:22:44,258 - mmdet - INFO - Epoch [1][350/673]	lr: 0.00701, eta: 1:58:16, time: 0.299, data_time: 0.012, memory: 4401, loss_ins: 1.3854, loss_cate: 0.8035, loss: 2.1889
2021-07-23 00:22:58,952 - mmdet - INFO - Epoch [1][400/673]	lr: 0.00800, eta: 1:57:52, time: 0.294, data_time: 0.012, memory: 4401, loss_ins: 1.3581, loss_cate: 0.8772, loss: 2.2353
2021-07-23 00:23:14,028 - mmdet - INFO - Epoch [1][450/673]	lr: 0.00899, eta: 1:57:49, time: 0.302, data_time: 0.012, memory: 4401, loss_ins: 1.4042, loss_cate: 0.5108, loss: 1.9149
2021-07-23 00:23:28,747 - mmdet - INFO - Epoch [1][500/673]	lr: 0.00998, eta: 1:57:27, time: 0.294, data_time: 0.011, memory: 4401, loss_ins: 1.3467, loss_cate: 0.3867, loss: 1.7335
2021-07-23 00:23:43,658 - mmdet - INFO - Epoch [1][550/673]	lr: 0.01000, eta: 1:57:15, time: 0.298, data_time: 0.011, memory: 4401, loss_ins: 1.3182, loss_cate: 0.3111, loss: 1.6293
2021-07-23 00:23:58,572 - mmdet - INFO - Epoch [1][600/673]	lr: 0.01000, eta: 1:57:02, time: 0.298, data_time: 0.011, memory: 4401, loss_ins: 1.3765, loss_cate: 0.2566, loss: 1.6331
2021-07-23 00:24:13,378 - mmdet - INFO - Epoch [1][650/673]	lr: 0.01000, eta: 1:56:46, time: 0.296, data_time: 0.012, memory: 4401, loss_ins: 1.3536, loss_cate: 0.3659, loss: 1.7195
2021-07-23 00:24:37,498 - mmdet - INFO - Epoch [2][50/673]	lr: 0.01000, eta: 1:52:56, time: 0.306, data_time: 0.018, memory: 4401, loss_ins: 1.3162, loss_cate: 0.2517, loss: 1.5679
2021-07-23 00:24:52,250 - mmdet - INFO - Epoch [2][100/673]	lr: 0.01000, eta: 1:52:52, time: 0.295, data_time: 0.013, memory: 4401, loss_ins: 1.2905, loss_cate: 0.2826, loss: 1.5730
2021-07-23 00:25:07,009 - mmdet - INFO - Epoch [2][150/673]	lr: 0.01000, eta: 1:52:46, time: 0.295, data_time: 0.012, memory: 4401, loss_ins: 1.3816, loss_cate: 0.2783, loss: 1.6599
2021-07-23 00:25:21,699 - mmdet - INFO - Epoch [2][200/673]	lr: 0.01000, eta: 1:52:38, time: 0.294, data_time: 0.011, memory: 4401, loss_ins: 1.2989, loss_cate: 0.2643, loss: 1.5632
2021-07-23 00:25:36,741 - mmdet - INFO - Epoch [2][250/673]	lr: 0.01000, eta: 1:52:38, time: 0.301, data_time: 0.011, memory: 4401, loss_ins: 1.3884, loss_cate: 0.3402, loss: 1.7286
2021-07-23 00:25:51,747 - mmdet - INFO - Epoch [2][300/673]	lr: 0.01000, eta: 1:52:36, time: 0.300, data_time: 0.011, memory: 4401, loss_ins: 1.3741, loss_cate: 0.5943, loss: 1.9684
2021-07-23 00:26:06,803 - mmdet - INFO - Epoch [2][350/673]	lr: 0.01000, eta: 1:52:33, time: 0.301, data_time: 0.012, memory: 4401, loss_ins: 1.3006, loss_cate: 0.3159, loss: 1.6165
2021-07-23 00:26:21,382 - mmdet - INFO - Epoch [2][400/673]	lr: 0.01000, eta: 1:52:19, time: 0.292, data_time: 0.010, memory: 4401, loss_ins: 1.3293, loss_cate: 0.2734, loss: 1.6027
2021-07-23 00:26:36,427 - mmdet - INFO - Epoch [2][450/673]	lr: 0.01000, eta: 1:52:15, time: 0.301, data_time: 0.010, memory: 4401, loss_ins: 1.3067, loss_cate: 0.2979, loss: 1.6046
2021-07-23 00:26:51,823 - mmdet - INFO - Epoch [2][500/673]	lr: 0.01000, eta: 1:52:16, time: 0.308, data_time: 0.012, memory: 4401, loss_ins: 1.3796, loss_cate: 0.2730, loss: 1.6526
2021-07-23 00:27:07,088 - mmdet - INFO - Epoch [2][550/673]	lr: 0.01000, eta: 1:52:14, time: 0.305, data_time: 0.013, memory: 4401, loss_ins: 1.4492, loss_cate: 0.3265, loss: 1.7757
2021-07-23 00:27:21,893 - mmdet - INFO - Epoch [2][600/673]	lr: 0.01000, eta: 1:52:02, time: 0.296, data_time: 0.012, memory: 4401, loss_ins: 1.3558, loss_cate: 0.2781, loss: 1.6339
2021-07-23 00:27:36,683 - mmdet - INFO - Epoch [2][650/673]	lr: 0.01000, eta: 1:51:50, time: 0.296, data_time: 0.011, memory: 4401, loss_ins: 1.2907, loss_cate: 0.2498, loss: 1.5405
2021-07-23 00:28:00,881 - mmdet - INFO - Epoch [3][50/673]	lr: 0.01000, eta: 1:49:51, time: 0.308, data_time: 0.018, memory: 4401, loss_ins: 1.3483, loss_cate: 0.2606, loss: 1.6089
2021-07-23 00:28:15,901 - mmdet - INFO - Epoch [3][100/673]	lr: 0.01000, eta: 1:49:46, time: 0.300, data_time: 0.013, memory: 4401, loss_ins: 1.2840, loss_cate: 0.2416, loss: 1.5257
2021-07-23 00:28:30,903 - mmdet - INFO - Epoch [3][150/673]	lr: 0.01000, eta: 1:49:40, time: 0.300, data_time: 0.013, memory: 4401, loss_ins: 1.3389, loss_cate: 0.2352, loss: 1.5741
2021-07-23 00:28:45,679 - mmdet - INFO - Epoch [3][200/673]	lr: 0.01000, eta: 1:49:29, time: 0.296, data_time: 0.013, memory: 4401, loss_ins: 1.3087, loss_cate: 0.2395, loss: 1.5482
2021-07-23 00:29:00,501 - mmdet - INFO - Epoch [3][250/673]	lr: 0.01000, eta: 1:49:20, time: 0.296, data_time: 0.013, memory: 4401, loss_ins: 1.2815, loss_cate: 0.2406, loss: 1.5220
2021-07-23 00:29:15,453 - mmdet - INFO - Epoch [3][300/673]	lr: 0.01000, eta: 1:49:12, time: 0.299, data_time: 0.013, memory: 4401, loss_ins: 1.3106, loss_cate: 0.2265, loss: 1.5371
2021-07-23 00:29:30,460 - mmdet - INFO - Epoch [3][350/673]	lr: 0.01000, eta: 1:49:04, time: 0.300, data_time: 0.013, memory: 4401, loss_ins: 1.3741, loss_cate: 0.2595, loss: 1.6336
2021-07-23 00:29:45,568 - mmdet - INFO - Epoch [3][400/673]	lr: 0.01000, eta: 1:48:57, time: 0.302, data_time: 0.013, memory: 4442, loss_ins: 1.3423, loss_cate: 0.2458, loss: 1.5881
2021-07-23 00:30:00,507 - mmdet - INFO - Epoch [3][450/673]	lr: 0.01000, eta: 1:48:47, time: 0.299, data_time: 0.014, memory: 4442, loss_ins: 1.3706, loss_cate: 0.2369, loss: 1.6074
2021-07-23 00:30:15,318 - mmdet - INFO - Epoch [3][500/673]	lr: 0.01000, eta: 1:48:36, time: 0.296, data_time: 0.013, memory: 4442, loss_ins: 1.4515, loss_cate: 0.2680, loss: 1.7196
2021-07-23 00:30:30,499 - mmdet - INFO - Epoch [3][550/673]	lr: 0.01000, eta: 1:48:29, time: 0.304, data_time: 0.014, memory: 4442, loss_ins: 1.3929, loss_cate: 0.2480, loss: 1.6408
2021-07-23 00:30:45,417 - mmdet - INFO - Epoch [3][600/673]	lr: 0.01000, eta: 1:48:18, time: 0.298, data_time: 0.015, memory: 4442, loss_ins: 1.3757, loss_cate: 0.2349, loss: 1.6107
2021-07-23 00:31:00,233 - mmdet - INFO - Epoch [3][650/673]	lr: 0.01000, eta: 1:48:06, time: 0.296, data_time: 0.014, memory: 4442, loss_ins: 1.3219, loss_cate: 0.2359, loss: 1.5579
2021-07-23 00:31:24,487 - mmdet - INFO - Epoch [4][50/673]	lr: 0.01000, eta: 1:46:41, time: 0.307, data_time: 0.020, memory: 4442, loss_ins: 1.3514, loss_cate: 0.2290, loss: 1.5803
2021-07-23 00:31:39,376 - mmdet - INFO - Epoch [4][100/673]	lr: 0.01000, eta: 1:46:31, time: 0.298, data_time: 0.015, memory: 4442, loss_ins: 1.3382, loss_cate: 0.2384, loss: 1.5767
2021-07-23 00:31:54,087 - mmdet - INFO - Epoch [4][150/673]	lr: 0.01000, eta: 1:46:19, time: 0.294, data_time: 0.014, memory: 4442, loss_ins: 1.2721, loss_cate: 0.2161, loss: 1.4882
2021-07-23 00:32:09,077 - mmdet - INFO - Epoch [4][200/673]	lr: 0.01000, eta: 1:46:10, time: 0.300, data_time: 0.014, memory: 4442, loss_ins: 1.3204, loss_cate: 0.2243, loss: 1.5447
2021-07-23 00:32:24,216 - mmdet - INFO - Epoch [4][250/673]	lr: 0.01000, eta: 1:46:02, time: 0.303, data_time: 0.015, memory: 4442, loss_ins: 1.3190, loss_cate: 0.2295, loss: 1.5485
2021-07-23 00:32:38,893 - mmdet - INFO - Epoch [4][300/673]	lr: 0.01000, eta: 1:45:49, time: 0.294, data_time: 0.014, memory: 4442, loss_ins: 1.3147, loss_cate: 0.2330, loss: 1.5477
2021-07-23 00:32:54,138 - mmdet - INFO - Epoch [4][350/673]	lr: 0.01000, eta: 1:45:42, time: 0.305, data_time: 0.014, memory: 4442, loss_ins: 1.4111, loss_cate: 0.2427, loss: 1.6538
2021-07-23 00:33:09,143 - mmdet - INFO - Epoch [4][400/673]	lr: 0.01000, eta: 1:45:32, time: 0.300, data_time: 0.014, memory: 4442, loss_ins: 1.4164, loss_cate: 0.2928, loss: 1.7092
2021-07-23 00:33:23,945 - mmdet - INFO - Epoch [4][450/673]	lr: 0.01000, eta: 1:45:20, time: 0.296, data_time: 0.013, memory: 4442, loss_ins: 1.3157, loss_cate: 0.2311, loss: 1.5468
2021-07-23 00:33:38,911 - mmdet - INFO - Epoch [4][500/673]	lr: 0.01000, eta: 1:45:09, time: 0.299, data_time: 0.014, memory: 4442, loss_ins: 1.3129, loss_cate: 0.2097, loss: 1.5226
2021-07-23 00:33:54,169 - mmdet - INFO - Epoch [4][550/673]	lr: 0.01000, eta: 1:45:01, time: 0.305, data_time: 0.014, memory: 4442, loss_ins: 1.2817, loss_cate: 0.1981, loss: 1.4798
2021-07-23 00:34:08,876 - mmdet - INFO - Epoch [4][600/673]	lr: 0.01000, eta: 1:44:48, time: 0.294, data_time: 0.013, memory: 4442, loss_ins: 1.3778, loss_cate: 0.2382, loss: 1.6160
2021-07-23 00:34:23,675 - mmdet - INFO - Epoch [4][650/673]	lr: 0.01000, eta: 1:44:35, time: 0.296, data_time: 0.015, memory: 4442, loss_ins: 1.3253, loss_cate: 0.2371, loss: 1.5624
2021-07-23 00:34:47,404 - mmdet - INFO - Epoch [5][50/673]	lr: 0.01000, eta: 1:43:26, time: 0.302, data_time: 0.017, memory: 4442, loss_ins: 1.3752, loss_cate: 0.2280, loss: 1.6032
2021-07-23 00:35:02,105 - mmdet - INFO - Epoch [5][100/673]	lr: 0.01000, eta: 1:43:13, time: 0.294, data_time: 0.013, memory: 4442, loss_ins: 1.3084, loss_cate: 0.1989, loss: 1.5072
2021-07-23 00:35:17,139 - mmdet - INFO - Epoch [5][150/673]	lr: 0.01000, eta: 1:43:03, time: 0.301, data_time: 0.013, memory: 4442, loss_ins: 1.3541, loss_cate: 0.2260, loss: 1.5801
2021-07-23 00:35:32,001 - mmdet - INFO - Epoch [5][200/673]	lr: 0.01000, eta: 1:42:52, time: 0.297, data_time: 0.013, memory: 4442, loss_ins: 1.3634, loss_cate: 0.2278, loss: 1.5912
2021-07-23 00:35:46,709 - mmdet - INFO - Epoch [5][250/673]	lr: 0.01000, eta: 1:42:39, time: 0.294, data_time: 0.012, memory: 4442, loss_ins: 1.3832, loss_cate: 0.2182, loss: 1.6014
2021-07-23 00:36:01,664 - mmdet - INFO - Epoch [5][300/673]	lr: 0.01000, eta: 1:42:28, time: 0.299, data_time: 0.012, memory: 4442, loss_ins: 1.3771, loss_cate: 0.2492, loss: 1.6263
2021-07-23 00:36:16,204 - mmdet - INFO - Epoch [5][350/673]	lr: 0.01000, eta: 1:42:14, time: 0.291, data_time: 0.012, memory: 4442, loss_ins: 1.3365, loss_cate: 0.2185, loss: 1.5550
2021-07-23 00:36:30,584 - mmdet - INFO - Epoch [5][400/673]	lr: 0.01000, eta: 1:41:59, time: 0.288, data_time: 0.012, memory: 4442, loss_ins: 1.2553, loss_cate: 0.2073, loss: 1.4626
2021-07-23 00:36:45,474 - mmdet - INFO - Epoch [5][450/673]	lr: 0.01000, eta: 1:41:47, time: 0.298, data_time: 0.013, memory: 4442, loss_ins: 1.3186, loss_cate: 0.1956, loss: 1.5142
2021-07-23 00:37:00,575 - mmdet - INFO - Epoch [5][500/673]	lr: 0.01000, eta: 1:41:37, time: 0.302, data_time: 0.013, memory: 4442, loss_ins: 1.3462, loss_cate: 0.2035, loss: 1.5497
2021-07-23 00:37:15,615 - mmdet - INFO - Epoch [5][550/673]	lr: 0.01000, eta: 1:41:26, time: 0.301, data_time: 0.013, memory: 4442, loss_ins: 1.3972, loss_cate: 0.2238, loss: 1.6210
2021-07-23 00:37:30,481 - mmdet - INFO - Epoch [5][600/673]	lr: 0.01000, eta: 1:41:14, time: 0.297, data_time: 0.012, memory: 4442, loss_ins: 1.2243, loss_cate: 0.2066, loss: 1.4310
2021-07-23 00:37:45,387 - mmdet - INFO - Epoch [5][650/673]	lr: 0.01000, eta: 1:41:02, time: 0.298, data_time: 0.013, memory: 4442, loss_ins: 1.3647, loss_cate: 0.1976, loss: 1.5623
2021-07-23 00:38:09,314 - mmdet - INFO - Epoch [6][50/673]	lr: 0.01000, eta: 1:40:04, time: 0.305, data_time: 0.020, memory: 4442, loss_ins: 1.3861, loss_cate: 0.2137, loss: 1.5998
2021-07-23 00:38:24,548 - mmdet - INFO - Epoch [6][100/673]	lr: 0.01000, eta: 1:39:55, time: 0.305, data_time: 0.015, memory: 4442, loss_ins: 1.2886, loss_cate: 0.1972, loss: 1.4857
2021-07-23 00:38:39,768 - mmdet - INFO - Epoch [6][150/673]	lr: 0.01000, eta: 1:39:45, time: 0.304, data_time: 0.015, memory: 4442, loss_ins: 1.3425, loss_cate: 0.1920, loss: 1.5345
2021-07-23 00:38:54,955 - mmdet - INFO - Epoch [6][200/673]	lr: 0.01000, eta: 1:39:35, time: 0.304, data_time: 0.015, memory: 4442, loss_ins: 1.3639, loss_cate: 0.2029, loss: 1.5669
2021-07-23 00:39:09,886 - mmdet - INFO - Epoch [6][250/673]	lr: 0.01000, eta: 1:39:23, time: 0.299, data_time: 0.014, memory: 4442, loss_ins: 1.3601, loss_cate: 0.1988, loss: 1.5589
2021-07-23 00:39:24,492 - mmdet - INFO - Epoch [6][300/673]	lr: 0.01000, eta: 1:39:09, time: 0.292, data_time: 0.014, memory: 4442, loss_ins: 1.2666, loss_cate: 0.1832, loss: 1.4498
2021-07-23 00:39:39,887 - mmdet - INFO - Epoch [6][350/673]	lr: 0.01000, eta: 1:39:00, time: 0.308, data_time: 0.015, memory: 4442, loss_ins: 1.3728, loss_cate: 0.2097, loss: 1.5826
2021-07-23 00:39:55,004 - mmdet - INFO - Epoch [6][400/673]	lr: 0.01000, eta: 1:38:49, time: 0.302, data_time: 0.014, memory: 4442, loss_ins: 1.2858, loss_cate: 0.1916, loss: 1.4774
2021-07-23 00:40:10,030 - mmdet - INFO - Epoch [6][450/673]	lr: 0.01000, eta: 1:38:37, time: 0.301, data_time: 0.014, memory: 4442, loss_ins: 1.3814, loss_cate: 0.2043, loss: 1.5857
2021-07-23 00:40:24,957 - mmdet - INFO - Epoch [6][500/673]	lr: 0.01000, eta: 1:38:25, time: 0.299, data_time: 0.014, memory: 4442, loss_ins: 1.4143, loss_cate: 0.2099, loss: 1.6241
2021-07-23 00:40:39,967 - mmdet - INFO - Epoch [6][550/673]	lr: 0.01000, eta: 1:38:13, time: 0.300, data_time: 0.013, memory: 4442, loss_ins: 1.3861, loss_cate: 0.1968, loss: 1.5829
2021-07-23 00:40:54,926 - mmdet - INFO - Epoch [6][600/673]	lr: 0.01000, eta: 1:38:01, time: 0.299, data_time: 0.014, memory: 4442, loss_ins: 1.3591, loss_cate: 0.2093, loss: 1.5684
2021-07-23 00:41:09,812 - mmdet - INFO - Epoch [6][650/673]	lr: 0.01000, eta: 1:37:48, time: 0.298, data_time: 0.014, memory: 4442, loss_ins: 1.3503, loss_cate: 0.2187, loss: 1.5690
2021-07-23 00:41:33,783 - mmdet - INFO - Epoch [7][50/673]	lr: 0.01000, eta: 1:36:57, time: 0.303, data_time: 0.019, memory: 4442, loss_ins: 1.2966, loss_cate: 0.1817, loss: 1.4783
2021-07-23 00:41:48,841 - mmdet - INFO - Epoch [7][100/673]	lr: 0.01000, eta: 1:36:46, time: 0.301, data_time: 0.013, memory: 4442, loss_ins: 1.3850, loss_cate: 0.2031, loss: 1.5881
2021-07-23 00:42:03,788 - mmdet - INFO - Epoch [7][150/673]	lr: 0.01000, eta: 1:36:34, time: 0.299, data_time: 0.013, memory: 4442, loss_ins: 1.4462, loss_cate: 0.2215, loss: 1.6676
2021-07-23 00:42:18,893 - mmdet - INFO - Epoch [7][200/673]	lr: 0.01000, eta: 1:36:22, time: 0.302, data_time: 0.013, memory: 4442, loss_ins: 1.3196, loss_cate: 0.1881, loss: 1.5077
2021-07-23 00:42:33,814 - mmdet - INFO - Epoch [7][250/673]	lr: 0.01000, eta: 1:36:10, time: 0.298, data_time: 0.013, memory: 4442, loss_ins: 1.3490, loss_cate: 0.1990, loss: 1.5479
2021-07-23 00:42:48,754 - mmdet - INFO - Epoch [7][300/673]	lr: 0.01000, eta: 1:35:58, time: 0.299, data_time: 0.013, memory: 4442, loss_ins: 1.3514, loss_cate: 0.1858, loss: 1.5372
2021-07-23 00:43:03,900 - mmdet - INFO - Epoch [7][350/673]	lr: 0.01000, eta: 1:35:46, time: 0.303, data_time: 0.013, memory: 4442, loss_ins: 1.3153, loss_cate: 0.1935, loss: 1.5088
2021-07-23 00:43:18,738 - mmdet - INFO - Epoch [7][400/673]	lr: 0.01000, eta: 1:35:33, time: 0.297, data_time: 0.013, memory: 4442, loss_ins: 1.3551, loss_cate: 0.1937, loss: 1.5488
2021-07-23 00:43:33,829 - mmdet - INFO - Epoch [7][450/673]	lr: 0.01000, eta: 1:35:22, time: 0.302, data_time: 0.013, memory: 4442, loss_ins: 1.4125, loss_cate: 0.2110, loss: 1.6235
2021-07-23 00:43:48,472 - mmdet - INFO - Epoch [7][500/673]	lr: 0.01000, eta: 1:35:08, time: 0.293, data_time: 0.013, memory: 4442, loss_ins: 1.2708, loss_cate: 0.1820, loss: 1.4528
2021-07-23 00:44:03,478 - mmdet - INFO - Epoch [7][550/673]	lr: 0.01000, eta: 1:34:55, time: 0.300, data_time: 0.013, memory: 4442, loss_ins: 1.3077, loss_cate: 0.1815, loss: 1.4892
2021-07-23 00:44:18,707 - mmdet - INFO - Epoch [7][600/673]	lr: 0.01000, eta: 1:34:44, time: 0.305, data_time: 0.013, memory: 4442, loss_ins: 1.4106, loss_cate: 0.1918, loss: 1.6024
2021-07-23 00:44:33,461 - mmdet - INFO - Epoch [7][650/673]	lr: 0.01000, eta: 1:34:31, time: 0.295, data_time: 0.013, memory: 4442, loss_ins: 1.3688, loss_cate: 0.2012, loss: 1.5700
2021-07-23 00:44:57,560 - mmdet - INFO - Epoch [8][50/673]	lr: 0.01000, eta: 1:33:45, time: 0.305, data_time: 0.020, memory: 4442, loss_ins: 1.3518, loss_cate: 0.1812, loss: 1.5330
2021-07-23 00:45:12,379 - mmdet - INFO - Epoch [8][100/673]	lr: 0.01000, eta: 1:33:32, time: 0.296, data_time: 0.012, memory: 4442, loss_ins: 1.3257, loss_cate: 0.1900, loss: 1.5157
2021-07-23 00:45:27,537 - mmdet - INFO - Epoch [8][150/673]	lr: 0.01000, eta: 1:33:20, time: 0.303, data_time: 0.013, memory: 4442, loss_ins: 1.3670, loss_cate: 0.2051, loss: 1.5721
2021-07-23 00:45:42,151 - mmdet - INFO - Epoch [8][200/673]	lr: 0.01000, eta: 1:33:07, time: 0.292, data_time: 0.012, memory: 4442, loss_ins: 1.3451, loss_cate: 0.2076, loss: 1.5527
2021-07-23 00:45:57,106 - mmdet - INFO - Epoch [8][250/673]	lr: 0.01000, eta: 1:32:54, time: 0.299, data_time: 0.012, memory: 4442, loss_ins: 1.3056, loss_cate: 0.1982, loss: 1.5038
2021-07-23 00:46:12,121 - mmdet - INFO - Epoch [8][300/673]	lr: 0.01000, eta: 1:32:42, time: 0.300, data_time: 0.012, memory: 4442, loss_ins: 1.2447, loss_cate: 0.1745, loss: 1.4192
2021-07-23 00:46:27,043 - mmdet - INFO - Epoch [8][350/673]	lr: 0.01000, eta: 1:32:29, time: 0.298, data_time: 0.012, memory: 4442, loss_ins: 1.3462, loss_cate: 0.1775, loss: 1.5238
2021-07-23 00:46:41,689 - mmdet - INFO - Epoch [8][400/673]	lr: 0.01000, eta: 1:32:15, time: 0.293, data_time: 0.011, memory: 4442, loss_ins: 1.2729, loss_cate: 0.1712, loss: 1.4440
2021-07-23 00:46:56,550 - mmdet - INFO - Epoch [8][450/673]	lr: 0.01000, eta: 1:32:02, time: 0.297, data_time: 0.011, memory: 4442, loss_ins: 1.3629, loss_cate: 0.1874, loss: 1.5504
2021-07-23 00:47:11,786 - mmdet - INFO - Epoch [8][500/673]	lr: 0.01000, eta: 1:31:50, time: 0.305, data_time: 0.013, memory: 4442, loss_ins: 1.3641, loss_cate: 0.1886, loss: 1.5527
2021-07-23 00:47:26,973 - mmdet - INFO - Epoch [8][550/673]	lr: 0.01000, eta: 1:31:38, time: 0.304, data_time: 0.013, memory: 4442, loss_ins: 1.4099, loss_cate: 0.1910, loss: 1.6010
2021-07-23 00:47:41,999 - mmdet - INFO - Epoch [8][600/673]	lr: 0.01000, eta: 1:31:26, time: 0.301, data_time: 0.013, memory: 4442, loss_ins: 1.3342, loss_cate: 0.1919, loss: 1.5260
2021-07-23 00:47:56,902 - mmdet - INFO - Epoch [8][650/673]	lr: 0.01000, eta: 1:31:13, time: 0.298, data_time: 0.013, memory: 4442, loss_ins: 1.3748, loss_cate: 0.1902, loss: 1.5650
2021-07-23 00:48:20,922 - mmdet - INFO - Epoch [9][50/673]	lr: 0.01000, eta: 1:30:31, time: 0.304, data_time: 0.018, memory: 4442, loss_ins: 1.3987, loss_cate: 0.1985, loss: 1.5972
2021-07-23 00:48:36,104 - mmdet - INFO - Epoch [9][100/673]	lr: 0.01000, eta: 1:30:19, time: 0.304, data_time: 0.013, memory: 4442, loss_ins: 1.3226, loss_cate: 0.1771, loss: 1.4997
2021-07-23 00:48:51,175 - mmdet - INFO - Epoch [9][150/673]	lr: 0.01000, eta: 1:30:07, time: 0.301, data_time: 0.012, memory: 4442, loss_ins: 1.2875, loss_cate: 0.1669, loss: 1.4544
2021-07-23 00:49:06,048 - mmdet - INFO - Epoch [9][200/673]	lr: 0.01000, eta: 1:29:53, time: 0.297, data_time: 0.012, memory: 4442, loss_ins: 1.3014, loss_cate: 0.1713, loss: 1.4726
2021-07-23 00:49:21,074 - mmdet - INFO - Epoch [9][250/673]	lr: 0.01000, eta: 1:29:41, time: 0.301, data_time: 0.012, memory: 4442, loss_ins: 1.3598, loss_cate: 0.1980, loss: 1.5578
2021-07-23 00:49:36,281 - mmdet - INFO - Epoch [9][300/673]	lr: 0.01000, eta: 1:29:29, time: 0.304, data_time: 0.012, memory: 4442, loss_ins: 1.3940, loss_cate: 0.1805, loss: 1.5745
2021-07-23 00:49:51,424 - mmdet - INFO - Epoch [9][350/673]	lr: 0.01000, eta: 1:29:16, time: 0.303, data_time: 0.012, memory: 4442, loss_ins: 1.3809, loss_cate: 0.1883, loss: 1.5692
2021-07-23 00:50:06,466 - mmdet - INFO - Epoch [9][400/673]	lr: 0.01000, eta: 1:29:04, time: 0.301, data_time: 0.012, memory: 4442, loss_ins: 1.4027, loss_cate: 0.1966, loss: 1.5993
2021-07-23 00:50:21,409 - mmdet - INFO - Epoch [9][450/673]	lr: 0.01000, eta: 1:28:51, time: 0.299, data_time: 0.013, memory: 4442, loss_ins: 1.3444, loss_cate: 0.1572, loss: 1.5016
2021-07-23 00:50:36,133 - mmdet - INFO - Epoch [9][500/673]	lr: 0.01000, eta: 1:28:37, time: 0.294, data_time: 0.011, memory: 4442, loss_ins: 1.3165, loss_cate: 0.1750, loss: 1.4915
2021-07-23 00:50:50,850 - mmdet - INFO - Epoch [9][550/673]	lr: 0.01000, eta: 1:28:23, time: 0.294, data_time: 0.011, memory: 4442, loss_ins: 1.3738, loss_cate: 0.1886, loss: 1.5624
2021-07-23 00:51:05,902 - mmdet - INFO - Epoch [9][600/673]	lr: 0.01000, eta: 1:28:10, time: 0.301, data_time: 0.012, memory: 4442, loss_ins: 1.2748, loss_cate: 0.1820, loss: 1.4569
2021-07-23 00:51:20,805 - mmdet - INFO - Epoch [9][650/673]	lr: 0.01000, eta: 1:27:57, time: 0.298, data_time: 0.012, memory: 4442, loss_ins: 1.3293, loss_cate: 0.1711, loss: 1.5004
2021-07-23 00:51:45,268 - mmdet - INFO - Epoch [10][50/673]	lr: 0.01000, eta: 1:27:19, time: 0.309, data_time: 0.018, memory: 4442, loss_ins: 1.3142, loss_cate: 0.1646, loss: 1.4788
2021-07-23 00:52:00,259 - mmdet - INFO - Epoch [10][100/673]	lr: 0.01000, eta: 1:27:06, time: 0.300, data_time: 0.013, memory: 4442, loss_ins: 1.3040, loss_cate: 0.1765, loss: 1.4805
2021-07-23 00:52:15,050 - mmdet - INFO - Epoch [10][150/673]	lr: 0.01000, eta: 1:26:52, time: 0.296, data_time: 0.012, memory: 4442, loss_ins: 1.3395, loss_cate: 0.1878, loss: 1.5273
2021-07-23 00:52:30,231 - mmdet - INFO - Epoch [10][200/673]	lr: 0.01000, eta: 1:26:40, time: 0.304, data_time: 0.013, memory: 4442, loss_ins: 1.3279, loss_cate: 0.1748, loss: 1.5028
2021-07-23 00:52:45,031 - mmdet - INFO - Epoch [10][250/673]	lr: 0.01000, eta: 1:26:27, time: 0.296, data_time: 0.012, memory: 4442, loss_ins: 1.3250, loss_cate: 0.1700, loss: 1.4950
2021-07-23 00:53:00,186 - mmdet - INFO - Epoch [10][300/673]	lr: 0.01000, eta: 1:26:14, time: 0.303, data_time: 0.013, memory: 4442, loss_ins: 1.3851, loss_cate: 0.1787, loss: 1.5639
2021-07-23 00:53:15,142 - mmdet - INFO - Epoch [10][350/673]	lr: 0.01000, eta: 1:26:01, time: 0.299, data_time: 0.013, memory: 4442, loss_ins: 1.4152, loss_cate: 0.1735, loss: 1.5887
2021-07-23 00:53:30,204 - mmdet - INFO - Epoch [10][400/673]	lr: 0.01000, eta: 1:25:48, time: 0.301, data_time: 0.012, memory: 4442, loss_ins: 1.3149, loss_cate: 0.1681, loss: 1.4830
2021-07-23 00:53:45,247 - mmdet - INFO - Epoch [10][450/673]	lr: 0.01000, eta: 1:25:35, time: 0.301, data_time: 0.012, memory: 4442, loss_ins: 1.3812, loss_cate: 0.1732, loss: 1.5545
2021-07-23 00:54:00,182 - mmdet - INFO - Epoch [10][500/673]	lr: 0.01000, eta: 1:25:22, time: 0.299, data_time: 0.011, memory: 4442, loss_ins: 1.3700, loss_cate: 0.1790, loss: 1.5490
2021-07-23 00:54:14,910 - mmdet - INFO - Epoch [10][550/673]	lr: 0.01000, eta: 1:25:08, time: 0.295, data_time: 0.011, memory: 4442, loss_ins: 1.3421, loss_cate: 0.1841, loss: 1.5263
2021-07-23 00:54:29,850 - mmdet - INFO - Epoch [10][600/673]	lr: 0.01000, eta: 1:24:55, time: 0.299, data_time: 0.012, memory: 4442, loss_ins: 1.3249, loss_cate: 0.1708, loss: 1.4957
2021-07-23 00:54:44,666 - mmdet - INFO - Epoch [10][650/673]	lr: 0.01000, eta: 1:24:41, time: 0.296, data_time: 0.012, memory: 4442, loss_ins: 1.3881, loss_cate: 0.1680, loss: 1.5561
2021-07-23 00:55:08,873 - mmdet - INFO - Epoch [11][50/673]	lr: 0.01000, eta: 1:24:04, time: 0.305, data_time: 0.016, memory: 4442, loss_ins: 1.3938, loss_cate: 0.1761, loss: 1.5699
2021-07-23 00:55:24,266 - mmdet - INFO - Epoch [11][100/673]	lr: 0.01000, eta: 1:23:52, time: 0.308, data_time: 0.013, memory: 4442, loss_ins: 1.3616, loss_cate: 0.1664, loss: 1.5280
2021-07-23 00:55:39,246 - mmdet - INFO - Epoch [11][150/673]	lr: 0.01000, eta: 1:23:39, time: 0.300, data_time: 0.012, memory: 4442, loss_ins: 1.4406, loss_cate: 0.1906, loss: 1.6312
2021-07-23 00:55:53,934 - mmdet - INFO - Epoch [11][200/673]	lr: 0.01000, eta: 1:23:25, time: 0.294, data_time: 0.011, memory: 4442, loss_ins: 1.2344, loss_cate: 0.1588, loss: 1.3931
2021-07-23 00:56:08,570 - mmdet - INFO - Epoch [11][250/673]	lr: 0.01000, eta: 1:23:11, time: 0.293, data_time: 0.010, memory: 4442, loss_ins: 1.3168, loss_cate: 0.1725, loss: 1.4894
2021-07-23 00:56:23,526 - mmdet - INFO - Epoch [11][300/673]	lr: 0.01000, eta: 1:22:58, time: 0.299, data_time: 0.012, memory: 4442, loss_ins: 1.3539, loss_cate: 0.1662, loss: 1.5201
2021-07-23 00:56:38,348 - mmdet - INFO - Epoch [11][350/673]	lr: 0.01000, eta: 1:22:44, time: 0.296, data_time: 0.011, memory: 4442, loss_ins: 1.3395, loss_cate: 0.1793, loss: 1.5188
2021-07-23 00:56:53,290 - mmdet - INFO - Epoch [11][400/673]	lr: 0.01000, eta: 1:22:31, time: 0.299, data_time: 0.011, memory: 4442, loss_ins: 1.2875, loss_cate: 0.1546, loss: 1.4421
2021-07-23 00:57:08,115 - mmdet - INFO - Epoch [11][450/673]	lr: 0.01000, eta: 1:22:17, time: 0.297, data_time: 0.011, memory: 4442, loss_ins: 1.3382, loss_cate: 0.1776, loss: 1.5158
2021-07-23 00:57:22,911 - mmdet - INFO - Epoch [11][500/673]	lr: 0.01000, eta: 1:22:04, time: 0.296, data_time: 0.012, memory: 4442, loss_ins: 1.4058, loss_cate: 0.1789, loss: 1.5847
2021-07-23 00:57:37,879 - mmdet - INFO - Epoch [11][550/673]	lr: 0.01000, eta: 1:21:50, time: 0.299, data_time: 0.012, memory: 4442, loss_ins: 1.3724, loss_cate: 0.1813, loss: 1.5537
2021-07-23 00:57:52,956 - mmdet - INFO - Epoch [11][600/673]	lr: 0.01000, eta: 1:21:37, time: 0.302, data_time: 0.011, memory: 4442, loss_ins: 1.3747, loss_cate: 0.1908, loss: 1.5655
2021-07-23 00:58:07,976 - mmdet - INFO - Epoch [11][650/673]	lr: 0.01000, eta: 1:21:24, time: 0.300, data_time: 0.011, memory: 4442, loss_ins: 1.3556, loss_cate: 0.1777, loss: 1.5334
2021-07-23 00:58:31,759 - mmdet - INFO - Epoch [12][50/673]	lr: 0.01000, eta: 1:20:49, time: 0.303, data_time: 0.018, memory: 4442, loss_ins: 1.3618, loss_cate: 0.1805, loss: 1.5423
2021-07-23 00:58:46,909 - mmdet - INFO - Epoch [12][100/673]	lr: 0.01000, eta: 1:20:36, time: 0.303, data_time: 0.012, memory: 4442, loss_ins: 1.3412, loss_cate: 0.1695, loss: 1.5107
2021-07-23 00:59:02,111 - mmdet - INFO - Epoch [12][150/673]	lr: 0.01000, eta: 1:20:23, time: 0.304, data_time: 0.013, memory: 4442, loss_ins: 1.4083, loss_cate: 0.1692, loss: 1.5775
2021-07-23 00:59:16,732 - mmdet - INFO - Epoch [12][200/673]	lr: 0.01000, eta: 1:20:09, time: 0.292, data_time: 0.012, memory: 4442, loss_ins: 1.2743, loss_cate: 0.1622, loss: 1.4366
2021-07-23 00:59:31,779 - mmdet - INFO - Epoch [12][250/673]	lr: 0.01000, eta: 1:19:56, time: 0.301, data_time: 0.010, memory: 4442, loss_ins: 1.2624, loss_cate: 0.1676, loss: 1.4300
2021-07-23 00:59:47,104 - mmdet - INFO - Epoch [12][300/673]	lr: 0.01000, eta: 1:19:43, time: 0.307, data_time: 0.011, memory: 4442, loss_ins: 1.3216, loss_cate: 0.1715, loss: 1.4931
2021-07-23 01:00:02,162 - mmdet - INFO - Epoch [12][350/673]	lr: 0.01000, eta: 1:19:30, time: 0.301, data_time: 0.012, memory: 4442, loss_ins: 1.3219, loss_cate: 0.1653, loss: 1.4871
2021-07-23 01:00:17,011 - mmdet - INFO - Epoch [12][400/673]	lr: 0.01000, eta: 1:19:16, time: 0.297, data_time: 0.011, memory: 4442, loss_ins: 1.3906, loss_cate: 0.1679, loss: 1.5586
2021-07-23 01:00:31,617 - mmdet - INFO - Epoch [12][450/673]	lr: 0.01000, eta: 1:19:02, time: 0.292, data_time: 0.011, memory: 4442, loss_ins: 1.3416, loss_cate: 0.1741, loss: 1.5157
2021-07-23 01:00:46,778 - mmdet - INFO - Epoch [12][500/673]	lr: 0.01000, eta: 1:18:49, time: 0.303, data_time: 0.013, memory: 4442, loss_ins: 1.3277, loss_cate: 0.1680, loss: 1.4958
2021-07-23 01:01:02,138 - mmdet - INFO - Epoch [12][550/673]	lr: 0.01000, eta: 1:18:36, time: 0.307, data_time: 0.012, memory: 4442, loss_ins: 1.3442, loss_cate: 0.1659, loss: 1.5101
2021-07-23 01:01:17,270 - mmdet - INFO - Epoch [12][600/673]	lr: 0.01000, eta: 1:18:23, time: 0.303, data_time: 0.012, memory: 4442, loss_ins: 1.3419, loss_cate: 0.1614, loss: 1.5033
2021-07-23 01:01:32,443 - mmdet - INFO - Epoch [12][650/673]	lr: 0.01000, eta: 1:18:10, time: 0.303, data_time: 0.012, memory: 4442, loss_ins: 1.3499, loss_cate: 0.1632, loss: 1.5131
2021-07-23 01:01:56,798 - mmdet - INFO - Epoch [13][50/673]	lr: 0.01000, eta: 1:17:38, time: 0.309, data_time: 0.018, memory: 4442, loss_ins: 1.3226, loss_cate: 0.1617, loss: 1.4843
2021-07-23 01:02:11,573 - mmdet - INFO - Epoch [13][100/673]	lr: 0.01000, eta: 1:17:24, time: 0.296, data_time: 0.012, memory: 4442, loss_ins: 1.3499, loss_cate: 0.1774, loss: 1.5273
2021-07-23 01:02:26,360 - mmdet - INFO - Epoch [13][150/673]	lr: 0.01000, eta: 1:17:10, time: 0.296, data_time: 0.013, memory: 4442, loss_ins: 1.2980, loss_cate: 0.1563, loss: 1.4542
2021-07-23 01:02:41,396 - mmdet - INFO - Epoch [13][200/673]	lr: 0.01000, eta: 1:16:56, time: 0.301, data_time: 0.013, memory: 4442, loss_ins: 1.4018, loss_cate: 0.1572, loss: 1.5590
2021-07-23 01:02:56,322 - mmdet - INFO - Epoch [13][250/673]	lr: 0.01000, eta: 1:16:43, time: 0.299, data_time: 0.012, memory: 4442, loss_ins: 1.3091, loss_cate: 0.1647, loss: 1.4737
2021-07-23 01:03:11,369 - mmdet - INFO - Epoch [13][300/673]	lr: 0.01000, eta: 1:16:29, time: 0.301, data_time: 0.013, memory: 4442, loss_ins: 1.3498, loss_cate: 0.1560, loss: 1.5058
2021-07-23 01:03:26,455 - mmdet - INFO - Epoch [13][350/673]	lr: 0.01000, eta: 1:16:16, time: 0.302, data_time: 0.013, memory: 4442, loss_ins: 1.3397, loss_cate: 0.1723, loss: 1.5120
2021-07-23 01:03:41,640 - mmdet - INFO - Epoch [13][400/673]	lr: 0.01000, eta: 1:16:03, time: 0.304, data_time: 0.013, memory: 4442, loss_ins: 1.3587, loss_cate: 0.1705, loss: 1.5292
2021-07-23 01:03:56,711 - mmdet - INFO - Epoch [13][450/673]	lr: 0.01000, eta: 1:15:50, time: 0.301, data_time: 0.013, memory: 4442, loss_ins: 1.3833, loss_cate: 0.1553, loss: 1.5386
2021-07-23 01:04:11,643 - mmdet - INFO - Epoch [13][500/673]	lr: 0.01000, eta: 1:15:36, time: 0.299, data_time: 0.013, memory: 4442, loss_ins: 1.3413, loss_cate: 0.1674, loss: 1.5087
2021-07-23 01:04:26,109 - mmdet - INFO - Epoch [13][550/673]	lr: 0.01000, eta: 1:15:21, time: 0.289, data_time: 0.013, memory: 4442, loss_ins: 1.3172, loss_cate: 0.1717, loss: 1.4889
2021-07-23 01:04:41,248 - mmdet - INFO - Epoch [13][600/673]	lr: 0.01000, eta: 1:15:08, time: 0.303, data_time: 0.013, memory: 4442, loss_ins: 1.3383, loss_cate: 0.1548, loss: 1.4931
2021-07-23 01:04:56,161 - mmdet - INFO - Epoch [13][650/673]	lr: 0.01000, eta: 1:14:54, time: 0.298, data_time: 0.013, memory: 4442, loss_ins: 1.3288, loss_cate: 0.1594, loss: 1.4881
2021-07-23 01:05:20,441 - mmdet - INFO - Epoch [14][50/673]	lr: 0.01000, eta: 1:14:23, time: 0.311, data_time: 0.019, memory: 4442, loss_ins: 1.4063, loss_cate: 0.1669, loss: 1.5732
2021-07-23 01:05:35,668 - mmdet - INFO - Epoch [14][100/673]	lr: 0.01000, eta: 1:14:10, time: 0.305, data_time: 0.013, memory: 4442, loss_ins: 1.3568, loss_cate: 0.1735, loss: 1.5303
2021-07-23 01:05:50,557 - mmdet - INFO - Epoch [14][150/673]	lr: 0.01000, eta: 1:13:56, time: 0.298, data_time: 0.013, memory: 4442, loss_ins: 1.3340, loss_cate: 0.1548, loss: 1.4888
2021-07-23 01:06:05,755 - mmdet - INFO - Epoch [14][200/673]	lr: 0.01000, eta: 1:13:43, time: 0.304, data_time: 0.013, memory: 4442, loss_ins: 1.3659, loss_cate: 0.1579, loss: 1.5238
2021-07-23 01:06:20,729 - mmdet - INFO - Epoch [14][250/673]	lr: 0.01000, eta: 1:13:29, time: 0.299, data_time: 0.013, memory: 4442, loss_ins: 1.2922, loss_cate: 0.1569, loss: 1.4492
2021-07-23 01:06:35,651 - mmdet - INFO - Epoch [14][300/673]	lr: 0.01000, eta: 1:13:16, time: 0.298, data_time: 0.012, memory: 4442, loss_ins: 1.3584, loss_cate: 0.1566, loss: 1.5150
2021-07-23 01:06:50,261 - mmdet - INFO - Epoch [14][350/673]	lr: 0.01000, eta: 1:13:01, time: 0.292, data_time: 0.013, memory: 4442, loss_ins: 1.3053, loss_cate: 0.1658, loss: 1.4712
2021-07-23 01:07:05,367 - mmdet - INFO - Epoch [14][400/673]	lr: 0.01000, eta: 1:12:48, time: 0.302, data_time: 0.012, memory: 4442, loss_ins: 1.3374, loss_cate: 0.1525, loss: 1.4899
2021-07-23 01:07:20,367 - mmdet - INFO - Epoch [14][450/673]	lr: 0.01000, eta: 1:12:34, time: 0.300, data_time: 0.013, memory: 4442, loss_ins: 1.3979, loss_cate: 0.1622, loss: 1.5601
2021-07-23 01:07:35,228 - mmdet - INFO - Epoch [14][500/673]	lr: 0.01000, eta: 1:12:20, time: 0.297, data_time: 0.012, memory: 4442, loss_ins: 1.3126, loss_cate: 0.1631, loss: 1.4758
2021-07-23 01:07:50,154 - mmdet - INFO - Epoch [14][550/673]	lr: 0.01000, eta: 1:12:07, time: 0.299, data_time: 0.012, memory: 4442, loss_ins: 1.3666, loss_cate: 0.1663, loss: 1.5329
2021-07-23 01:08:05,357 - mmdet - INFO - Epoch [14][600/673]	lr: 0.01000, eta: 1:11:53, time: 0.304, data_time: 0.013, memory: 4442, loss_ins: 1.3178, loss_cate: 0.1500, loss: 1.4679
2021-07-23 01:08:20,554 - mmdet - INFO - Epoch [14][650/673]	lr: 0.01000, eta: 1:11:40, time: 0.304, data_time: 0.012, memory: 4442, loss_ins: 1.4109, loss_cate: 0.1649, loss: 1.5758
2021-07-23 01:08:44,461 - mmdet - INFO - Epoch [15][50/673]	lr: 0.01000, eta: 1:11:09, time: 0.304, data_time: 0.017, memory: 4442, loss_ins: 1.3950, loss_cate: 0.1665, loss: 1.5616
2021-07-23 01:08:59,448 - mmdet - INFO - Epoch [15][100/673]	lr: 0.01000, eta: 1:10:56, time: 0.300, data_time: 0.012, memory: 4442, loss_ins: 1.3728, loss_cate: 0.1529, loss: 1.5257
2021-07-23 01:09:14,520 - mmdet - INFO - Epoch [15][150/673]	lr: 0.01000, eta: 1:10:42, time: 0.301, data_time: 0.011, memory: 4442, loss_ins: 1.2990, loss_cate: 0.1605, loss: 1.4595
2021-07-23 01:09:29,384 - mmdet - INFO - Epoch [15][200/673]	lr: 0.01000, eta: 1:10:28, time: 0.297, data_time: 0.011, memory: 4442, loss_ins: 1.3380, loss_cate: 0.1489, loss: 1.4869
2021-07-23 01:09:44,320 - mmdet - INFO - Epoch [15][250/673]	lr: 0.01000, eta: 1:10:15, time: 0.299, data_time: 0.010, memory: 4442, loss_ins: 1.3287, loss_cate: 0.1516, loss: 1.4803
2021-07-23 01:09:59,262 - mmdet - INFO - Epoch [15][300/673]	lr: 0.01000, eta: 1:10:01, time: 0.299, data_time: 0.009, memory: 4442, loss_ins: 1.4207, loss_cate: 0.1587, loss: 1.5794
2021-07-23 01:10:14,075 - mmdet - INFO - Epoch [15][350/673]	lr: 0.01000, eta: 1:09:47, time: 0.296, data_time: 0.010, memory: 4442, loss_ins: 1.2973, loss_cate: 0.1583, loss: 1.4555
2021-07-23 01:10:29,526 - mmdet - INFO - Epoch [15][400/673]	lr: 0.01000, eta: 1:09:34, time: 0.309, data_time: 0.011, memory: 4442, loss_ins: 1.3659, loss_cate: 0.1497, loss: 1.5155
2021-07-23 01:10:44,613 - mmdet - INFO - Epoch [15][450/673]	lr: 0.01000, eta: 1:09:20, time: 0.302, data_time: 0.010, memory: 4442, loss_ins: 1.3784, loss_cate: 0.1674, loss: 1.5458
2021-07-23 01:10:59,690 - mmdet - INFO - Epoch [15][500/673]	lr: 0.01000, eta: 1:09:06, time: 0.302, data_time: 0.011, memory: 4442, loss_ins: 1.3732, loss_cate: 0.1636, loss: 1.5368
2021-07-23 01:11:14,758 - mmdet - INFO - Epoch [15][550/673]	lr: 0.01000, eta: 1:08:53, time: 0.301, data_time: 0.012, memory: 4442, loss_ins: 1.3227, loss_cate: 0.1504, loss: 1.4731
2021-07-23 01:11:29,702 - mmdet - INFO - Epoch [15][600/673]	lr: 0.01000, eta: 1:08:39, time: 0.299, data_time: 0.011, memory: 4442, loss_ins: 1.3609, loss_cate: 0.1564, loss: 1.5173
2021-07-23 01:11:44,443 - mmdet - INFO - Epoch [15][650/673]	lr: 0.01000, eta: 1:08:25, time: 0.295, data_time: 0.012, memory: 4442, loss_ins: 1.3214, loss_cate: 0.1533, loss: 1.4747
2021-07-23 01:12:08,801 - mmdet - INFO - Epoch [16][50/673]	lr: 0.01000, eta: 1:07:56, time: 0.308, data_time: 0.020, memory: 4442, loss_ins: 1.4037, loss_cate: 0.1700, loss: 1.5737
2021-07-23 01:12:24,167 - mmdet - INFO - Epoch [16][100/673]	lr: 0.01000, eta: 1:07:42, time: 0.307, data_time: 0.015, memory: 4442, loss_ins: 1.4287, loss_cate: 0.1620, loss: 1.5907
2021-07-23 01:12:39,187 - mmdet - INFO - Epoch [16][150/673]	lr: 0.01000, eta: 1:07:29, time: 0.300, data_time: 0.013, memory: 4442, loss_ins: 1.2898, loss_cate: 0.1426, loss: 1.4324
2021-07-23 01:12:54,074 - mmdet - INFO - Epoch [16][200/673]	lr: 0.01000, eta: 1:07:15, time: 0.298, data_time: 0.013, memory: 4442, loss_ins: 1.2777, loss_cate: 0.1414, loss: 1.4191
2021-07-23 01:13:09,079 - mmdet - INFO - Epoch [16][250/673]	lr: 0.01000, eta: 1:07:01, time: 0.300, data_time: 0.012, memory: 4442, loss_ins: 1.3459, loss_cate: 0.1553, loss: 1.5012
2021-07-23 01:13:24,047 - mmdet - INFO - Epoch [16][300/673]	lr: 0.01000, eta: 1:06:47, time: 0.299, data_time: 0.012, memory: 4442, loss_ins: 1.3495, loss_cate: 0.1563, loss: 1.5058
2021-07-23 01:13:39,225 - mmdet - INFO - Epoch [16][350/673]	lr: 0.01000, eta: 1:06:33, time: 0.304, data_time: 0.012, memory: 4442, loss_ins: 1.4286, loss_cate: 0.1587, loss: 1.5873
2021-07-23 01:13:54,167 - mmdet - INFO - Epoch [16][400/673]	lr: 0.01000, eta: 1:06:20, time: 0.299, data_time: 0.013, memory: 4442, loss_ins: 1.4319, loss_cate: 0.1604, loss: 1.5923
2021-07-23 01:14:09,271 - mmdet - INFO - Epoch [16][450/673]	lr: 0.01000, eta: 1:06:06, time: 0.302, data_time: 0.012, memory: 4442, loss_ins: 1.3003, loss_cate: 0.1313, loss: 1.4316
2021-07-23 01:14:23,858 - mmdet - INFO - Epoch [16][500/673]	lr: 0.01000, eta: 1:05:52, time: 0.292, data_time: 0.012, memory: 4442, loss_ins: 1.2477, loss_cate: 0.1313, loss: 1.3791
2021-07-23 01:14:39,016 - mmdet - INFO - Epoch [16][550/673]	lr: 0.01000, eta: 1:05:38, time: 0.303, data_time: 0.012, memory: 4442, loss_ins: 1.2646, loss_cate: 0.1320, loss: 1.3966
2021-07-23 01:14:54,073 - mmdet - INFO - Epoch [16][600/673]	lr: 0.01000, eta: 1:05:24, time: 0.301, data_time: 0.013, memory: 4442, loss_ins: 1.3538, loss_cate: 0.1620, loss: 1.5158
2021-07-23 01:15:09,264 - mmdet - INFO - Epoch [16][650/673]	lr: 0.01000, eta: 1:05:10, time: 0.304, data_time: 0.013, memory: 4442, loss_ins: 1.3762, loss_cate: 0.1470, loss: 1.5232
2021-07-23 01:15:33,280 - mmdet - INFO - Epoch [17][50/673]	lr: 0.01000, eta: 1:04:42, time: 0.305, data_time: 0.020, memory: 4442, loss_ins: 1.2973, loss_cate: 0.1542, loss: 1.4516
2021-07-23 01:15:48,379 - mmdet - INFO - Epoch [17][100/673]	lr: 0.01000, eta: 1:04:28, time: 0.302, data_time: 0.015, memory: 4442, loss_ins: 1.3656, loss_cate: 0.1458, loss: 1.5113
2021-07-23 01:16:03,512 - mmdet - INFO - Epoch [17][150/673]	lr: 0.01000, eta: 1:04:15, time: 0.303, data_time: 0.014, memory: 4442, loss_ins: 1.3992, loss_cate: 0.1655, loss: 1.5647
2021-07-23 01:16:18,821 - mmdet - INFO - Epoch [17][200/673]	lr: 0.01000, eta: 1:04:01, time: 0.306, data_time: 0.014, memory: 4442, loss_ins: 1.2976, loss_cate: 0.1519, loss: 1.4495
2021-07-23 01:16:33,896 - mmdet - INFO - Epoch [17][250/673]	lr: 0.01000, eta: 1:03:47, time: 0.301, data_time: 0.015, memory: 4442, loss_ins: 1.3207, loss_cate: 0.1600, loss: 1.4806
2021-07-23 01:16:48,941 - mmdet - INFO - Epoch [17][300/673]	lr: 0.01000, eta: 1:03:33, time: 0.301, data_time: 0.014, memory: 4442, loss_ins: 1.3130, loss_cate: 0.1527, loss: 1.4657
2021-07-23 01:17:03,586 - mmdet - INFO - Epoch [17][350/673]	lr: 0.01000, eta: 1:03:19, time: 0.293, data_time: 0.014, memory: 4442, loss_ins: 1.3573, loss_cate: 0.1563, loss: 1.5136
2021-07-23 01:17:18,723 - mmdet - INFO - Epoch [17][400/673]	lr: 0.01000, eta: 1:03:05, time: 0.303, data_time: 0.014, memory: 4442, loss_ins: 1.3478, loss_cate: 0.1449, loss: 1.4928
2021-07-23 01:17:33,800 - mmdet - INFO - Epoch [17][450/673]	lr: 0.01000, eta: 1:02:52, time: 0.302, data_time: 0.014, memory: 4442, loss_ins: 1.3769, loss_cate: 0.1593, loss: 1.5362
2021-07-23 01:17:49,004 - mmdet - INFO - Epoch [17][500/673]	lr: 0.01000, eta: 1:02:38, time: 0.304, data_time: 0.014, memory: 4442, loss_ins: 1.3592, loss_cate: 0.1465, loss: 1.5057
2021-07-23 01:18:03,945 - mmdet - INFO - Epoch [17][550/673]	lr: 0.01000, eta: 1:02:24, time: 0.299, data_time: 0.013, memory: 4442, loss_ins: 1.3359, loss_cate: 0.1413, loss: 1.4772
2021-07-23 01:18:18,948 - mmdet - INFO - Epoch [17][600/673]	lr: 0.01000, eta: 1:02:10, time: 0.300, data_time: 0.013, memory: 4442, loss_ins: 1.3763, loss_cate: 0.1494, loss: 1.5257
2021-07-23 01:18:34,247 - mmdet - INFO - Epoch [17][650/673]	lr: 0.01000, eta: 1:01:56, time: 0.306, data_time: 0.014, memory: 4442, loss_ins: 1.3596, loss_cate: 0.1468, loss: 1.5064
2021-07-23 01:18:58,443 - mmdet - INFO - Epoch [18][50/673]	lr: 0.01000, eta: 1:01:29, time: 0.308, data_time: 0.019, memory: 4442, loss_ins: 1.3877, loss_cate: 0.1445, loss: 1.5321
2021-07-23 01:19:13,417 - mmdet - INFO - Epoch [18][100/673]	lr: 0.01000, eta: 1:01:15, time: 0.299, data_time: 0.014, memory: 4442, loss_ins: 1.2997, loss_cate: 0.1460, loss: 1.4457
2021-07-23 01:19:28,741 - mmdet - INFO - Epoch [18][150/673]	lr: 0.01000, eta: 1:01:01, time: 0.306, data_time: 0.014, memory: 4442, loss_ins: 1.3962, loss_cate: 0.1431, loss: 1.5393
2021-07-23 01:19:43,966 - mmdet - INFO - Epoch [18][200/673]	lr: 0.01000, eta: 1:00:48, time: 0.305, data_time: 0.014, memory: 4442, loss_ins: 1.2952, loss_cate: 0.1529, loss: 1.4481
2021-07-23 01:19:59,160 - mmdet - INFO - Epoch [18][250/673]	lr: 0.01000, eta: 1:00:34, time: 0.304, data_time: 0.014, memory: 4442, loss_ins: 1.4070, loss_cate: 0.1505, loss: 1.5575
2021-07-23 01:20:14,101 - mmdet - INFO - Epoch [18][300/673]	lr: 0.01000, eta: 1:00:20, time: 0.299, data_time: 0.012, memory: 4442, loss_ins: 1.3063, loss_cate: 0.1393, loss: 1.4455
2021-07-23 01:20:29,407 - mmdet - INFO - Epoch [18][350/673]	lr: 0.01000, eta: 1:00:06, time: 0.306, data_time: 0.014, memory: 4442, loss_ins: 1.3454, loss_cate: 0.1361, loss: 1.4814
2021-07-23 01:20:44,258 - mmdet - INFO - Epoch [18][400/673]	lr: 0.01000, eta: 0:59:52, time: 0.297, data_time: 0.013, memory: 4442, loss_ins: 1.3260, loss_cate: 0.1481, loss: 1.4741
2021-07-23 01:20:59,637 - mmdet - INFO - Epoch [18][450/673]	lr: 0.01000, eta: 0:59:38, time: 0.308, data_time: 0.015, memory: 4442, loss_ins: 1.3861, loss_cate: 0.1434, loss: 1.5295
2021-07-23 01:21:14,529 - mmdet - INFO - Epoch [18][500/673]	lr: 0.01000, eta: 0:59:24, time: 0.298, data_time: 0.013, memory: 4442, loss_ins: 1.3158, loss_cate: 0.1534, loss: 1.4692
2021-07-23 01:21:29,704 - mmdet - INFO - Epoch [18][550/673]	lr: 0.01000, eta: 0:59:11, time: 0.303, data_time: 0.014, memory: 4442, loss_ins: 1.3774, loss_cate: 0.1380, loss: 1.5153
2021-07-23 01:21:44,651 - mmdet - INFO - Epoch [18][600/673]	lr: 0.01000, eta: 0:58:56, time: 0.299, data_time: 0.014, memory: 4442, loss_ins: 1.3806, loss_cate: 0.1489, loss: 1.5295
2021-07-23 01:21:59,737 - mmdet - INFO - Epoch [18][650/673]	lr: 0.01000, eta: 0:58:43, time: 0.302, data_time: 0.013, memory: 4442, loss_ins: 1.3627, loss_cate: 0.1447, loss: 1.5074
2021-07-23 01:22:23,821 - mmdet - INFO - Epoch [19][50/673]	lr: 0.01000, eta: 0:58:16, time: 0.306, data_time: 0.018, memory: 4442, loss_ins: 1.3836, loss_cate: 0.1471, loss: 1.5307
2021-07-23 01:22:38,918 - mmdet - INFO - Epoch [19][100/673]	lr: 0.01000, eta: 0:58:02, time: 0.302, data_time: 0.014, memory: 4442, loss_ins: 1.3680, loss_cate: 0.1401, loss: 1.5081
2021-07-23 01:22:53,908 - mmdet - INFO - Epoch [19][150/673]	lr: 0.01000, eta: 0:57:48, time: 0.300, data_time: 0.012, memory: 4442, loss_ins: 1.2580, loss_cate: 0.1276, loss: 1.3856
2021-07-23 01:23:09,054 - mmdet - INFO - Epoch [19][200/673]	lr: 0.01000, eta: 0:57:34, time: 0.303, data_time: 0.012, memory: 4442, loss_ins: 1.3919, loss_cate: 0.1470, loss: 1.5389
2021-07-23 01:23:24,460 - mmdet - INFO - Epoch [19][250/673]	lr: 0.01000, eta: 0:57:20, time: 0.308, data_time: 0.013, memory: 4442, loss_ins: 1.3914, loss_cate: 0.1521, loss: 1.5435
2021-07-23 01:23:39,769 - mmdet - INFO - Epoch [19][300/673]	lr: 0.01000, eta: 0:57:06, time: 0.306, data_time: 0.014, memory: 4442, loss_ins: 1.3152, loss_cate: 0.1330, loss: 1.4481
2021-07-23 01:23:55,070 - mmdet - INFO - Epoch [19][350/673]	lr: 0.01000, eta: 0:56:53, time: 0.306, data_time: 0.013, memory: 4442, loss_ins: 1.2941, loss_cate: 0.1345, loss: 1.4286
2021-07-23 01:24:10,043 - mmdet - INFO - Epoch [19][400/673]	lr: 0.01000, eta: 0:56:39, time: 0.299, data_time: 0.011, memory: 4442, loss_ins: 1.3539, loss_cate: 0.1433, loss: 1.4972
2021-07-23 01:24:25,260 - mmdet - INFO - Epoch [19][450/673]	lr: 0.01000, eta: 0:56:25, time: 0.304, data_time: 0.011, memory: 4442, loss_ins: 1.3527, loss_cate: 0.1580, loss: 1.5107
2021-07-23 01:24:40,213 - mmdet - INFO - Epoch [19][500/673]	lr: 0.01000, eta: 0:56:11, time: 0.299, data_time: 0.013, memory: 4442, loss_ins: 1.2814, loss_cate: 0.1408, loss: 1.4222
2021-07-23 01:24:55,493 - mmdet - INFO - Epoch [19][550/673]	lr: 0.01000, eta: 0:55:57, time: 0.306, data_time: 0.013, memory: 4442, loss_ins: 1.2435, loss_cate: 0.1319, loss: 1.3754
2021-07-23 01:25:10,219 - mmdet - INFO - Epoch [19][600/673]	lr: 0.01000, eta: 0:55:42, time: 0.294, data_time: 0.012, memory: 4442, loss_ins: 1.4005, loss_cate: 0.1683, loss: 1.5687
2021-07-23 01:25:25,456 - mmdet - INFO - Epoch [19][650/673]	lr: 0.01000, eta: 0:55:29, time: 0.305, data_time: 0.012, memory: 4442, loss_ins: 1.4114, loss_cate: 0.1475, loss: 1.5589
2021-07-23 01:25:49,414 - mmdet - INFO - Epoch [20][50/673]	lr: 0.01000, eta: 0:55:02, time: 0.297, data_time: 0.017, memory: 4442, loss_ins: 1.2876, loss_cate: 0.1202, loss: 1.4077
2021-07-23 01:26:04,468 - mmdet - INFO - Epoch [20][100/673]	lr: 0.01000, eta: 0:54:48, time: 0.301, data_time: 0.012, memory: 4442, loss_ins: 1.3958, loss_cate: 0.1443, loss: 1.5401
2021-07-23 01:26:19,461 - mmdet - INFO - Epoch [20][150/673]	lr: 0.01000, eta: 0:54:34, time: 0.300, data_time: 0.012, memory: 4442, loss_ins: 1.2896, loss_cate: 0.1276, loss: 1.4172
2021-07-23 01:26:34,674 - mmdet - INFO - Epoch [20][200/673]	lr: 0.01000, eta: 0:54:20, time: 0.304, data_time: 0.012, memory: 4442, loss_ins: 1.4338, loss_cate: 0.1402, loss: 1.5740
2021-07-23 01:26:49,742 - mmdet - INFO - Epoch [20][250/673]	lr: 0.01000, eta: 0:54:06, time: 0.301, data_time: 0.012, memory: 4442, loss_ins: 1.4562, loss_cate: 0.1459, loss: 1.6021
2021-07-23 01:27:04,562 - mmdet - INFO - Epoch [20][300/673]	lr: 0.01000, eta: 0:53:52, time: 0.296, data_time: 0.012, memory: 4442, loss_ins: 1.3352, loss_cate: 0.1493, loss: 1.4845
2021-07-23 01:27:19,650 - mmdet - INFO - Epoch [20][350/673]	lr: 0.01000, eta: 0:53:38, time: 0.302, data_time: 0.013, memory: 4442, loss_ins: 1.3355, loss_cate: 0.1448, loss: 1.4803
2021-07-23 01:27:34,927 - mmdet - INFO - Epoch [20][400/673]	lr: 0.01000, eta: 0:53:24, time: 0.306, data_time: 0.012, memory: 4442, loss_ins: 1.3881, loss_cate: 0.1496, loss: 1.5378
2021-07-23 01:27:49,803 - mmdet - INFO - Epoch [20][450/673]	lr: 0.01000, eta: 0:53:09, time: 0.298, data_time: 0.012, memory: 4442, loss_ins: 1.3886, loss_cate: 0.1447, loss: 1.5333
2021-07-23 01:28:04,733 - mmdet - INFO - Epoch [20][500/673]	lr: 0.01000, eta: 0:52:55, time: 0.299, data_time: 0.013, memory: 4442, loss_ins: 1.3891, loss_cate: 0.1533, loss: 1.5424
2021-07-23 01:28:19,464 - mmdet - INFO - Epoch [20][550/673]	lr: 0.01000, eta: 0:52:41, time: 0.295, data_time: 0.012, memory: 4442, loss_ins: 1.2669, loss_cate: 0.1402, loss: 1.4071
2021-07-23 01:28:34,383 - mmdet - INFO - Epoch [20][600/673]	lr: 0.01000, eta: 0:52:27, time: 0.298, data_time: 0.012, memory: 4442, loss_ins: 1.3584, loss_cate: 0.1462, loss: 1.5046
2021-07-23 01:28:49,372 - mmdet - INFO - Epoch [20][650/673]	lr: 0.01000, eta: 0:52:13, time: 0.300, data_time: 0.013, memory: 4442, loss_ins: 1.2899, loss_cate: 0.1367, loss: 1.4266
2021-07-23 01:29:13,811 - mmdet - INFO - Epoch [21][50/673]	lr: 0.01000, eta: 0:51:47, time: 0.309, data_time: 0.019, memory: 4442, loss_ins: 1.3500, loss_cate: 0.1426, loss: 1.4926
2021-07-23 01:29:28,882 - mmdet - INFO - Epoch [21][100/673]	lr: 0.01000, eta: 0:51:33, time: 0.301, data_time: 0.014, memory: 4442, loss_ins: 1.3414, loss_cate: 0.1469, loss: 1.4883
2021-07-23 01:29:43,764 - mmdet - INFO - Epoch [21][150/673]	lr: 0.01000, eta: 0:51:19, time: 0.298, data_time: 0.013, memory: 4442, loss_ins: 1.3759, loss_cate: 0.1296, loss: 1.5055
2021-07-23 01:29:58,949 - mmdet - INFO - Epoch [21][200/673]	lr: 0.01000, eta: 0:51:05, time: 0.304, data_time: 0.014, memory: 4442, loss_ins: 1.4201, loss_cate: 0.1388, loss: 1.5588
2021-07-23 01:30:13,833 - mmdet - INFO - Epoch [21][250/673]	lr: 0.01000, eta: 0:50:50, time: 0.298, data_time: 0.013, memory: 4442, loss_ins: 1.3832, loss_cate: 0.1413, loss: 1.5244
2021-07-23 01:30:28,745 - mmdet - INFO - Epoch [21][300/673]	lr: 0.01000, eta: 0:50:36, time: 0.298, data_time: 0.012, memory: 4442, loss_ins: 1.3137, loss_cate: 0.1351, loss: 1.4488
2021-07-23 01:30:44,069 - mmdet - INFO - Epoch [21][350/673]	lr: 0.01000, eta: 0:50:22, time: 0.306, data_time: 0.012, memory: 4442, loss_ins: 1.4040, loss_cate: 0.1474, loss: 1.5514
2021-07-23 01:30:59,087 - mmdet - INFO - Epoch [21][400/673]	lr: 0.01000, eta: 0:50:08, time: 0.300, data_time: 0.014, memory: 4442, loss_ins: 1.3038, loss_cate: 0.1422, loss: 1.4460
2021-07-23 01:31:14,198 - mmdet - INFO - Epoch [21][450/673]	lr: 0.01000, eta: 0:49:54, time: 0.302, data_time: 0.013, memory: 4442, loss_ins: 1.3047, loss_cate: 0.1309, loss: 1.4356
2021-07-23 01:31:29,210 - mmdet - INFO - Epoch [21][500/673]	lr: 0.01000, eta: 0:49:40, time: 0.300, data_time: 0.012, memory: 4442, loss_ins: 1.2755, loss_cate: 0.1282, loss: 1.4037
2021-07-23 01:31:43,763 - mmdet - INFO - Epoch [21][550/673]	lr: 0.01000, eta: 0:49:26, time: 0.291, data_time: 0.013, memory: 4442, loss_ins: 1.2972, loss_cate: 0.1448, loss: 1.4420
2021-07-23 01:31:58,758 - mmdet - INFO - Epoch [21][600/673]	lr: 0.01000, eta: 0:49:11, time: 0.300, data_time: 0.013, memory: 4442, loss_ins: 1.3732, loss_cate: 0.1257, loss: 1.4989
2021-07-23 01:32:13,823 - mmdet - INFO - Epoch [21][650/673]	lr: 0.01000, eta: 0:48:57, time: 0.301, data_time: 0.014, memory: 4442, loss_ins: 1.3459, loss_cate: 0.1391, loss: 1.4849
2021-07-23 01:32:38,380 - mmdet - INFO - Epoch [22][50/673]	lr: 0.01000, eta: 0:48:32, time: 0.311, data_time: 0.021, memory: 4442, loss_ins: 1.3262, loss_cate: 0.1342, loss: 1.4604
2021-07-23 01:32:53,778 - mmdet - INFO - Epoch [22][100/673]	lr: 0.01000, eta: 0:48:18, time: 0.308, data_time: 0.017, memory: 4442, loss_ins: 1.4576, loss_cate: 0.1481, loss: 1.6057
2021-07-23 01:33:09,211 - mmdet - INFO - Epoch [22][150/673]	lr: 0.01000, eta: 0:48:04, time: 0.309, data_time: 0.017, memory: 4442, loss_ins: 1.3582, loss_cate: 0.1223, loss: 1.4805
2021-07-23 01:33:24,454 - mmdet - INFO - Epoch [22][200/673]	lr: 0.01000, eta: 0:47:50, time: 0.305, data_time: 0.016, memory: 4442, loss_ins: 1.3539, loss_cate: 0.1361, loss: 1.4900
2021-07-23 01:33:39,675 - mmdet - INFO - Epoch [22][250/673]	lr: 0.01000, eta: 0:47:36, time: 0.304, data_time: 0.014, memory: 4442, loss_ins: 1.3420, loss_cate: 0.1299, loss: 1.4719
2021-07-23 01:33:54,962 - mmdet - INFO - Epoch [22][300/673]	lr: 0.01000, eta: 0:47:22, time: 0.306, data_time: 0.015, memory: 4442, loss_ins: 1.3058, loss_cate: 0.1398, loss: 1.4456
2021-07-23 01:34:09,989 - mmdet - INFO - Epoch [22][350/673]	lr: 0.01000, eta: 0:47:08, time: 0.301, data_time: 0.013, memory: 4442, loss_ins: 1.3418, loss_cate: 0.1406, loss: 1.4824
2021-07-23 01:34:25,158 - mmdet - INFO - Epoch [22][400/673]	lr: 0.01000, eta: 0:46:54, time: 0.303, data_time: 0.015, memory: 4442, loss_ins: 1.3864, loss_cate: 0.1522, loss: 1.5386
2021-07-23 01:34:40,061 - mmdet - INFO - Epoch [22][450/673]	lr: 0.01000, eta: 0:46:40, time: 0.298, data_time: 0.012, memory: 4442, loss_ins: 1.2648, loss_cate: 0.1296, loss: 1.3944
2021-07-23 01:34:54,970 - mmdet - INFO - Epoch [22][500/673]	lr: 0.01000, eta: 0:46:26, time: 0.298, data_time: 0.014, memory: 4442, loss_ins: 1.3318, loss_cate: 0.1384, loss: 1.4702
2021-07-23 01:35:10,132 - mmdet - INFO - Epoch [22][550/673]	lr: 0.01000, eta: 0:46:11, time: 0.303, data_time: 0.013, memory: 4442, loss_ins: 1.2861, loss_cate: 0.1306, loss: 1.4167
2021-07-23 01:35:25,349 - mmdet - INFO - Epoch [22][600/673]	lr: 0.01000, eta: 0:45:57, time: 0.304, data_time: 0.014, memory: 4442, loss_ins: 1.3475, loss_cate: 0.1340, loss: 1.4815
2021-07-23 01:35:40,740 - mmdet - INFO - Epoch [22][650/673]	lr: 0.01000, eta: 0:45:43, time: 0.308, data_time: 0.015, memory: 4442, loss_ins: 1.3589, loss_cate: 0.1366, loss: 1.4955
2021-07-23 01:36:05,194 - mmdet - INFO - Epoch [23][50/673]	lr: 0.01000, eta: 0:45:19, time: 0.308, data_time: 0.020, memory: 4442, loss_ins: 1.3049, loss_cate: 0.1250, loss: 1.4299
2021-07-23 01:36:20,064 - mmdet - INFO - Epoch [23][100/673]	lr: 0.01000, eta: 0:45:04, time: 0.297, data_time: 0.015, memory: 4442, loss_ins: 1.3536, loss_cate: 0.1256, loss: 1.4792
2021-07-23 01:36:35,132 - mmdet - INFO - Epoch [23][150/673]	lr: 0.01000, eta: 0:44:50, time: 0.301, data_time: 0.014, memory: 4442, loss_ins: 1.3122, loss_cate: 0.1267, loss: 1.4389
2021-07-23 01:36:50,274 - mmdet - INFO - Epoch [23][200/673]	lr: 0.01000, eta: 0:44:36, time: 0.303, data_time: 0.013, memory: 4442, loss_ins: 1.3731, loss_cate: 0.1416, loss: 1.5147
2021-07-23 01:37:05,364 - mmdet - INFO - Epoch [23][250/673]	lr: 0.01000, eta: 0:44:22, time: 0.302, data_time: 0.014, memory: 4442, loss_ins: 1.3807, loss_cate: 0.1311, loss: 1.5117
2021-07-23 01:37:20,269 - mmdet - INFO - Epoch [23][300/673]	lr: 0.01000, eta: 0:44:08, time: 0.298, data_time: 0.015, memory: 4442, loss_ins: 1.3789, loss_cate: 0.1451, loss: 1.5240
2021-07-23 01:37:35,649 - mmdet - INFO - Epoch [23][350/673]	lr: 0.01000, eta: 0:43:54, time: 0.308, data_time: 0.015, memory: 4442, loss_ins: 1.3422, loss_cate: 0.1316, loss: 1.4738
2021-07-23 01:37:50,959 - mmdet - INFO - Epoch [23][400/673]	lr: 0.01000, eta: 0:43:40, time: 0.306, data_time: 0.015, memory: 4442, loss_ins: 1.4017, loss_cate: 0.1270, loss: 1.5287
2021-07-23 01:38:05,687 - mmdet - INFO - Epoch [23][450/673]	lr: 0.01000, eta: 0:43:25, time: 0.295, data_time: 0.014, memory: 4442, loss_ins: 1.2990, loss_cate: 0.1309, loss: 1.4299
2021-07-23 01:38:20,838 - mmdet - INFO - Epoch [23][500/673]	lr: 0.01000, eta: 0:43:11, time: 0.303, data_time: 0.015, memory: 4442, loss_ins: 1.3327, loss_cate: 0.1286, loss: 1.4613
2021-07-23 01:38:36,057 - mmdet - INFO - Epoch [23][550/673]	lr: 0.01000, eta: 0:42:57, time: 0.304, data_time: 0.015, memory: 4442, loss_ins: 1.3724, loss_cate: 0.1328, loss: 1.5052
2021-07-23 01:38:51,003 - mmdet - INFO - Epoch [23][600/673]	lr: 0.01000, eta: 0:42:43, time: 0.299, data_time: 0.014, memory: 4442, loss_ins: 1.3252, loss_cate: 0.1180, loss: 1.4432
2021-07-23 01:39:05,915 - mmdet - INFO - Epoch [23][650/673]	lr: 0.01000, eta: 0:42:28, time: 0.298, data_time: 0.013, memory: 4442, loss_ins: 1.2838, loss_cate: 0.1288, loss: 1.4125
2021-07-23 01:39:29,915 - mmdet - INFO - Epoch [24][50/673]	lr: 0.01000, eta: 0:42:04, time: 0.303, data_time: 0.016, memory: 4442, loss_ins: 1.3673, loss_cate: 0.1250, loss: 1.4923
2021-07-23 01:39:45,003 - mmdet - INFO - Epoch [24][100/673]	lr: 0.01000, eta: 0:41:49, time: 0.302, data_time: 0.013, memory: 4442, loss_ins: 1.2860, loss_cate: 0.1348, loss: 1.4208
2021-07-23 01:39:59,721 - mmdet - INFO - Epoch [24][150/673]	lr: 0.01000, eta: 0:41:35, time: 0.294, data_time: 0.013, memory: 4442, loss_ins: 1.3613, loss_cate: 0.1347, loss: 1.4960
2021-07-23 01:40:14,728 - mmdet - INFO - Epoch [24][200/673]	lr: 0.01000, eta: 0:41:21, time: 0.300, data_time: 0.012, memory: 4442, loss_ins: 1.4060, loss_cate: 0.1287, loss: 1.5348
2021-07-23 01:40:29,805 - mmdet - INFO - Epoch [24][250/673]	lr: 0.01000, eta: 0:41:07, time: 0.302, data_time: 0.012, memory: 4442, loss_ins: 1.4054, loss_cate: 0.1350, loss: 1.5404
2021-07-23 01:40:45,081 - mmdet - INFO - Epoch [24][300/673]	lr: 0.01000, eta: 0:40:53, time: 0.306, data_time: 0.014, memory: 4442, loss_ins: 1.3598, loss_cate: 0.1349, loss: 1.4947
2021-07-23 01:41:00,146 - mmdet - INFO - Epoch [24][350/673]	lr: 0.01000, eta: 0:40:38, time: 0.301, data_time: 0.013, memory: 4442, loss_ins: 1.3327, loss_cate: 0.1312, loss: 1.4639
2021-07-23 01:41:14,833 - mmdet - INFO - Epoch [24][400/673]	lr: 0.01000, eta: 0:40:24, time: 0.294, data_time: 0.013, memory: 4442, loss_ins: 1.2284, loss_cate: 0.1138, loss: 1.3423
2021-07-23 01:41:29,869 - mmdet - INFO - Epoch [24][450/673]	lr: 0.01000, eta: 0:40:10, time: 0.301, data_time: 0.014, memory: 4442, loss_ins: 1.3494, loss_cate: 0.1446, loss: 1.4940
2021-07-23 01:41:45,141 - mmdet - INFO - Epoch [24][500/673]	lr: 0.01000, eta: 0:39:55, time: 0.305, data_time: 0.014, memory: 4442, loss_ins: 1.4172, loss_cate: 0.1388, loss: 1.5560
2021-07-23 01:41:59,603 - mmdet - INFO - Epoch [24][550/673]	lr: 0.01000, eta: 0:39:41, time: 0.289, data_time: 0.013, memory: 4442, loss_ins: 1.2569, loss_cate: 0.1232, loss: 1.3802
2021-07-23 01:42:14,915 - mmdet - INFO - Epoch [24][600/673]	lr: 0.01000, eta: 0:39:27, time: 0.306, data_time: 0.014, memory: 4442, loss_ins: 1.4023, loss_cate: 0.1301, loss: 1.5324
2021-07-23 01:42:29,782 - mmdet - INFO - Epoch [24][650/673]	lr: 0.01000, eta: 0:39:12, time: 0.297, data_time: 0.013, memory: 4442, loss_ins: 1.3102, loss_cate: 0.1342, loss: 1.4445
2021-07-23 01:42:54,038 - mmdet - INFO - Epoch [25][50/673]	lr: 0.01000, eta: 0:38:48, time: 0.308, data_time: 0.019, memory: 4442, loss_ins: 1.3453, loss_cate: 0.1250, loss: 1.4703
2021-07-23 01:43:09,136 - mmdet - INFO - Epoch [25][100/673]	lr: 0.01000, eta: 0:38:34, time: 0.302, data_time: 0.015, memory: 4442, loss_ins: 1.3362, loss_cate: 0.1244, loss: 1.4605
2021-07-23 01:43:24,080 - mmdet - INFO - Epoch [25][150/673]	lr: 0.01000, eta: 0:38:20, time: 0.299, data_time: 0.013, memory: 4442, loss_ins: 1.3426, loss_cate: 0.1349, loss: 1.4775
2021-07-23 01:43:38,936 - mmdet - INFO - Epoch [25][200/673]	lr: 0.01000, eta: 0:38:06, time: 0.297, data_time: 0.014, memory: 4442, loss_ins: 1.3986, loss_cate: 0.1510, loss: 1.5496
2021-07-23 01:43:53,857 - mmdet - INFO - Epoch [25][250/673]	lr: 0.01000, eta: 0:37:51, time: 0.298, data_time: 0.014, memory: 4442, loss_ins: 1.3187, loss_cate: 0.1326, loss: 1.4513
2021-07-23 01:44:08,805 - mmdet - INFO - Epoch [25][300/673]	lr: 0.01000, eta: 0:37:37, time: 0.299, data_time: 0.014, memory: 4442, loss_ins: 1.3526, loss_cate: 0.1195, loss: 1.4721
2021-07-23 01:44:24,035 - mmdet - INFO - Epoch [25][350/673]	lr: 0.01000, eta: 0:37:23, time: 0.305, data_time: 0.015, memory: 4442, loss_ins: 1.3781, loss_cate: 0.1270, loss: 1.5051
2021-07-23 01:44:39,100 - mmdet - INFO - Epoch [25][400/673]	lr: 0.01000, eta: 0:37:08, time: 0.301, data_time: 0.013, memory: 4442, loss_ins: 1.3517, loss_cate: 0.1301, loss: 1.4818
2021-07-23 01:44:54,130 - mmdet - INFO - Epoch [25][450/673]	lr: 0.01000, eta: 0:36:54, time: 0.301, data_time: 0.014, memory: 4442, loss_ins: 1.3159, loss_cate: 0.1252, loss: 1.4412
2021-07-23 01:45:08,879 - mmdet - INFO - Epoch [25][500/673]	lr: 0.01000, eta: 0:36:40, time: 0.295, data_time: 0.013, memory: 4442, loss_ins: 1.2779, loss_cate: 0.1221, loss: 1.4000
2021-07-23 01:45:24,040 - mmdet - INFO - Epoch [25][550/673]	lr: 0.01000, eta: 0:36:25, time: 0.303, data_time: 0.015, memory: 4442, loss_ins: 1.3601, loss_cate: 0.1202, loss: 1.4803
2021-07-23 01:45:38,997 - mmdet - INFO - Epoch [25][600/673]	lr: 0.01000, eta: 0:36:11, time: 0.299, data_time: 0.014, memory: 4442, loss_ins: 1.3331, loss_cate: 0.1265, loss: 1.4595
2021-07-23 01:45:54,060 - mmdet - INFO - Epoch [25][650/673]	lr: 0.01000, eta: 0:35:57, time: 0.301, data_time: 0.015, memory: 4442, loss_ins: 1.3990, loss_cate: 0.1178, loss: 1.5168
2021-07-23 01:46:18,099 - mmdet - INFO - Epoch [26][50/673]	lr: 0.01000, eta: 0:35:33, time: 0.303, data_time: 0.018, memory: 4442, loss_ins: 1.3300, loss_cate: 0.1146, loss: 1.4446
2021-07-23 01:46:33,186 - mmdet - INFO - Epoch [26][100/673]	lr: 0.01000, eta: 0:35:19, time: 0.302, data_time: 0.013, memory: 4442, loss_ins: 1.3071, loss_cate: 0.1174, loss: 1.4244
2021-07-23 01:46:48,068 - mmdet - INFO - Epoch [26][150/673]	lr: 0.01000, eta: 0:35:04, time: 0.298, data_time: 0.013, memory: 4442, loss_ins: 1.3229, loss_cate: 0.1272, loss: 1.4501
2021-07-23 01:47:03,210 - mmdet - INFO - Epoch [26][200/673]	lr: 0.01000, eta: 0:34:50, time: 0.303, data_time: 0.013, memory: 4442, loss_ins: 1.3345, loss_cate: 0.1231, loss: 1.4576
2021-07-23 01:47:18,007 - mmdet - INFO - Epoch [26][250/673]	lr: 0.01000, eta: 0:34:36, time: 0.296, data_time: 0.012, memory: 4442, loss_ins: 1.3557, loss_cate: 0.1247, loss: 1.4804
2021-07-23 01:47:33,173 - mmdet - INFO - Epoch [26][300/673]	lr: 0.01000, eta: 0:34:22, time: 0.303, data_time: 0.012, memory: 4442, loss_ins: 1.4007, loss_cate: 0.1331, loss: 1.5338
2021-07-23 01:47:48,127 - mmdet - INFO - Epoch [26][350/673]	lr: 0.01000, eta: 0:34:07, time: 0.299, data_time: 0.013, memory: 4442, loss_ins: 1.3651, loss_cate: 0.1391, loss: 1.5042
2021-07-23 01:48:02,944 - mmdet - INFO - Epoch [26][400/673]	lr: 0.01000, eta: 0:33:53, time: 0.296, data_time: 0.013, memory: 4442, loss_ins: 1.3407, loss_cate: 0.1335, loss: 1.4743
2021-07-23 01:48:17,684 - mmdet - INFO - Epoch [26][450/673]	lr: 0.01000, eta: 0:33:38, time: 0.295, data_time: 0.012, memory: 4442, loss_ins: 1.3249, loss_cate: 0.1235, loss: 1.4484
2021-07-23 01:48:32,923 - mmdet - INFO - Epoch [26][500/673]	lr: 0.01000, eta: 0:33:24, time: 0.305, data_time: 0.013, memory: 4442, loss_ins: 1.3394, loss_cate: 0.1312, loss: 1.4706
2021-07-23 01:48:47,814 - mmdet - INFO - Epoch [26][550/673]	lr: 0.01000, eta: 0:33:10, time: 0.298, data_time: 0.012, memory: 4442, loss_ins: 1.3267, loss_cate: 0.1297, loss: 1.4564
2021-07-23 01:49:02,729 - mmdet - INFO - Epoch [26][600/673]	lr: 0.01000, eta: 0:32:55, time: 0.298, data_time: 0.012, memory: 4442, loss_ins: 1.3711, loss_cate: 0.1279, loss: 1.4989
2021-07-23 01:49:17,864 - mmdet - INFO - Epoch [26][650/673]	lr: 0.01000, eta: 0:32:41, time: 0.303, data_time: 0.012, memory: 4442, loss_ins: 1.3742, loss_cate: 0.1268, loss: 1.5011
2021-07-23 01:49:41,997 - mmdet - INFO - Epoch [27][50/673]	lr: 0.01000, eta: 0:32:18, time: 0.306, data_time: 0.018, memory: 4442, loss_ins: 1.3634, loss_cate: 0.1165, loss: 1.4800
2021-07-23 01:49:56,875 - mmdet - INFO - Epoch [27][100/673]	lr: 0.01000, eta: 0:32:03, time: 0.298, data_time: 0.013, memory: 4442, loss_ins: 1.2980, loss_cate: 0.1136, loss: 1.4116
2021-07-23 01:50:11,498 - mmdet - INFO - Epoch [27][150/673]	lr: 0.01000, eta: 0:31:49, time: 0.292, data_time: 0.012, memory: 4442, loss_ins: 1.3463, loss_cate: 0.1206, loss: 1.4669
2021-07-23 01:50:26,445 - mmdet - INFO - Epoch [27][200/673]	lr: 0.01000, eta: 0:31:34, time: 0.299, data_time: 0.012, memory: 4442, loss_ins: 1.3938, loss_cate: 0.1143, loss: 1.5080
2021-07-23 01:50:41,640 - mmdet - INFO - Epoch [27][250/673]	lr: 0.01000, eta: 0:31:20, time: 0.304, data_time: 0.013, memory: 4442, loss_ins: 1.3057, loss_cate: 0.1193, loss: 1.4251
2021-07-23 01:50:56,586 - mmdet - INFO - Epoch [27][300/673]	lr: 0.01000, eta: 0:31:06, time: 0.299, data_time: 0.013, memory: 4442, loss_ins: 1.3096, loss_cate: 0.1108, loss: 1.4204
2021-07-23 01:51:11,601 - mmdet - INFO - Epoch [27][350/673]	lr: 0.01000, eta: 0:30:52, time: 0.300, data_time: 0.012, memory: 4442, loss_ins: 1.3646, loss_cate: 0.1422, loss: 1.5069
2021-07-23 01:51:26,741 - mmdet - INFO - Epoch [27][400/673]	lr: 0.01000, eta: 0:30:37, time: 0.303, data_time: 0.013, memory: 4442, loss_ins: 1.3648, loss_cate: 0.1333, loss: 1.4981
2021-07-23 01:51:41,894 - mmdet - INFO - Epoch [27][450/673]	lr: 0.01000, eta: 0:30:23, time: 0.303, data_time: 0.013, memory: 4442, loss_ins: 1.3866, loss_cate: 0.1184, loss: 1.5051
2021-07-23 01:51:56,921 - mmdet - INFO - Epoch [27][500/673]	lr: 0.01000, eta: 0:30:09, time: 0.301, data_time: 0.013, memory: 4442, loss_ins: 1.3511, loss_cate: 0.1274, loss: 1.4785
2021-07-23 01:52:11,873 - mmdet - INFO - Epoch [27][550/673]	lr: 0.01000, eta: 0:29:54, time: 0.299, data_time: 0.012, memory: 4442, loss_ins: 1.3559, loss_cate: 0.1357, loss: 1.4916
2021-07-23 01:52:26,632 - mmdet - INFO - Epoch [27][600/673]	lr: 0.01000, eta: 0:29:40, time: 0.295, data_time: 0.012, memory: 4442, loss_ins: 1.3837, loss_cate: 0.1360, loss: 1.5196
2021-07-23 01:52:41,643 - mmdet - INFO - Epoch [27][650/673]	lr: 0.01000, eta: 0:29:25, time: 0.300, data_time: 0.013, memory: 4442, loss_ins: 1.3487, loss_cate: 0.1212, loss: 1.4699
2021-07-23 01:53:05,242 - mmdet - INFO - Epoch [28][50/673]	lr: 0.00100, eta: 0:29:02, time: 0.298, data_time: 0.018, memory: 4442, loss_ins: 1.3523, loss_cate: 0.1242, loss: 1.4764
2021-07-23 01:53:20,244 - mmdet - INFO - Epoch [28][100/673]	lr: 0.00100, eta: 0:28:48, time: 0.300, data_time: 0.013, memory: 4442, loss_ins: 1.3786, loss_cate: 0.1098, loss: 1.4884
2021-07-23 01:53:35,169 - mmdet - INFO - Epoch [28][150/673]	lr: 0.00100, eta: 0:28:33, time: 0.298, data_time: 0.013, memory: 4442, loss_ins: 1.2249, loss_cate: 0.0933, loss: 1.3182
2021-07-23 01:53:50,467 - mmdet - INFO - Epoch [28][200/673]	lr: 0.00100, eta: 0:28:19, time: 0.306, data_time: 0.014, memory: 4442, loss_ins: 1.3776, loss_cate: 0.1202, loss: 1.4979
2021-07-23 01:54:05,569 - mmdet - INFO - Epoch [28][250/673]	lr: 0.00100, eta: 0:28:05, time: 0.302, data_time: 0.013, memory: 4442, loss_ins: 1.3136, loss_cate: 0.0992, loss: 1.4129
2021-07-23 01:54:20,736 - mmdet - INFO - Epoch [28][300/673]	lr: 0.00100, eta: 0:27:51, time: 0.303, data_time: 0.014, memory: 4442, loss_ins: 1.3853, loss_cate: 0.1216, loss: 1.5069
2021-07-23 01:54:35,902 - mmdet - INFO - Epoch [28][350/673]	lr: 0.00100, eta: 0:27:36, time: 0.303, data_time: 0.015, memory: 4442, loss_ins: 1.3885, loss_cate: 0.1160, loss: 1.5045
2021-07-23 01:54:50,860 - mmdet - INFO - Epoch [28][400/673]	lr: 0.00100, eta: 0:27:22, time: 0.299, data_time: 0.013, memory: 4442, loss_ins: 1.3406, loss_cate: 0.1120, loss: 1.4526
2021-07-23 01:55:05,912 - mmdet - INFO - Epoch [28][450/673]	lr: 0.00100, eta: 0:27:08, time: 0.301, data_time: 0.013, memory: 4442, loss_ins: 1.3805, loss_cate: 0.1063, loss: 1.4869
2021-07-23 01:55:21,088 - mmdet - INFO - Epoch [28][500/673]	lr: 0.00100, eta: 0:26:53, time: 0.304, data_time: 0.014, memory: 4442, loss_ins: 1.3443, loss_cate: 0.1041, loss: 1.4484
2021-07-23 01:55:36,118 - mmdet - INFO - Epoch [28][550/673]	lr: 0.00100, eta: 0:26:39, time: 0.301, data_time: 0.014, memory: 4442, loss_ins: 1.2901, loss_cate: 0.1032, loss: 1.3934
2021-07-23 01:55:51,483 - mmdet - INFO - Epoch [28][600/673]	lr: 0.00100, eta: 0:26:25, time: 0.307, data_time: 0.013, memory: 4442, loss_ins: 1.4099, loss_cate: 0.1137, loss: 1.5236
2021-07-23 01:56:06,810 - mmdet - INFO - Epoch [28][650/673]	lr: 0.00100, eta: 0:26:10, time: 0.307, data_time: 0.014, memory: 4442, loss_ins: 1.3619, loss_cate: 0.1038, loss: 1.4657
2021-07-23 01:56:31,095 - mmdet - INFO - Epoch [29][50/673]	lr: 0.00100, eta: 0:25:47, time: 0.308, data_time: 0.019, memory: 4442, loss_ins: 1.3636, loss_cate: 0.1025, loss: 1.4661
2021-07-23 01:56:46,236 - mmdet - INFO - Epoch [29][100/673]	lr: 0.00100, eta: 0:25:33, time: 0.303, data_time: 0.014, memory: 4442, loss_ins: 1.3159, loss_cate: 0.0978, loss: 1.4137
2021-07-23 01:57:01,999 - mmdet - INFO - Epoch [29][150/673]	lr: 0.00100, eta: 0:25:19, time: 0.315, data_time: 0.014, memory: 4442, loss_ins: 1.3496, loss_cate: 0.0982, loss: 1.4478
2021-07-23 01:57:18,291 - mmdet - INFO - Epoch [29][200/673]	lr: 0.00100, eta: 0:25:05, time: 0.326, data_time: 0.013, memory: 4442, loss_ins: 1.4166, loss_cate: 0.1176, loss: 1.5342
2021-07-23 01:57:33,115 - mmdet - INFO - Epoch [29][250/673]	lr: 0.00100, eta: 0:24:50, time: 0.296, data_time: 0.012, memory: 4442, loss_ins: 1.3348, loss_cate: 0.1070, loss: 1.4418
2021-07-23 01:57:48,502 - mmdet - INFO - Epoch [29][300/673]	lr: 0.00100, eta: 0:24:36, time: 0.308, data_time: 0.014, memory: 4442, loss_ins: 1.3478, loss_cate: 0.0968, loss: 1.4447
2021-07-23 01:58:03,727 - mmdet - INFO - Epoch [29][350/673]	lr: 0.00100, eta: 0:24:22, time: 0.305, data_time: 0.014, memory: 4442, loss_ins: 1.3053, loss_cate: 0.1085, loss: 1.4138
2021-07-23 01:58:19,078 - mmdet - INFO - Epoch [29][400/673]	lr: 0.00100, eta: 0:24:08, time: 0.307, data_time: 0.015, memory: 4442, loss_ins: 1.3518, loss_cate: 0.1263, loss: 1.4781
2021-07-23 01:58:33,923 - mmdet - INFO - Epoch [29][450/673]	lr: 0.00100, eta: 0:23:53, time: 0.297, data_time: 0.014, memory: 4442, loss_ins: 1.3446, loss_cate: 0.1077, loss: 1.4523
2021-07-23 01:58:49,046 - mmdet - INFO - Epoch [29][500/673]	lr: 0.00100, eta: 0:23:39, time: 0.302, data_time: 0.013, memory: 4442, loss_ins: 1.3226, loss_cate: 0.0960, loss: 1.4186
2021-07-23 01:59:04,159 - mmdet - INFO - Epoch [29][550/673]	lr: 0.00100, eta: 0:23:24, time: 0.302, data_time: 0.014, memory: 4442, loss_ins: 1.3431, loss_cate: 0.1004, loss: 1.4435
2021-07-23 01:59:19,145 - mmdet - INFO - Epoch [29][600/673]	lr: 0.00100, eta: 0:23:10, time: 0.300, data_time: 0.014, memory: 4442, loss_ins: 1.2360, loss_cate: 0.1021, loss: 1.3381
2021-07-23 01:59:34,241 - mmdet - INFO - Epoch [29][650/673]	lr: 0.00100, eta: 0:22:55, time: 0.302, data_time: 0.014, memory: 4442, loss_ins: 1.4045, loss_cate: 0.1075, loss: 1.5120
2021-07-23 01:59:58,995 - mmdet - INFO - Epoch [30][50/673]	lr: 0.00100, eta: 0:22:33, time: 0.313, data_time: 0.020, memory: 4442, loss_ins: 1.3820, loss_cate: 0.0874, loss: 1.4694
2021-07-23 02:00:14,412 - mmdet - INFO - Epoch [30][100/673]	lr: 0.00100, eta: 0:22:19, time: 0.308, data_time: 0.016, memory: 4442, loss_ins: 1.3499, loss_cate: 0.1024, loss: 1.4523
2021-07-23 02:00:29,543 - mmdet - INFO - Epoch [30][150/673]	lr: 0.00100, eta: 0:22:04, time: 0.303, data_time: 0.015, memory: 4442, loss_ins: 1.2903, loss_cate: 0.0918, loss: 1.3821
2021-07-23 02:00:44,466 - mmdet - INFO - Epoch [30][200/673]	lr: 0.00100, eta: 0:21:50, time: 0.298, data_time: 0.014, memory: 4442, loss_ins: 1.3147, loss_cate: 0.1031, loss: 1.4178
2021-07-23 02:00:59,741 - mmdet - INFO - Epoch [30][250/673]	lr: 0.00100, eta: 0:21:35, time: 0.305, data_time: 0.015, memory: 4442, loss_ins: 1.3616, loss_cate: 0.1177, loss: 1.4793
2021-07-23 02:01:15,131 - mmdet - INFO - Epoch [30][300/673]	lr: 0.00100, eta: 0:21:21, time: 0.308, data_time: 0.014, memory: 4442, loss_ins: 1.4173, loss_cate: 0.1051, loss: 1.5224
2021-07-23 02:01:30,664 - mmdet - INFO - Epoch [30][350/673]	lr: 0.00100, eta: 0:21:07, time: 0.311, data_time: 0.013, memory: 4442, loss_ins: 1.3512, loss_cate: 0.1014, loss: 1.4526
2021-07-23 02:01:45,708 - mmdet - INFO - Epoch [30][400/673]	lr: 0.00100, eta: 0:20:52, time: 0.301, data_time: 0.015, memory: 4442, loss_ins: 1.2808, loss_cate: 0.1142, loss: 1.3950
2021-07-23 02:02:00,662 - mmdet - INFO - Epoch [30][450/673]	lr: 0.00100, eta: 0:20:38, time: 0.299, data_time: 0.013, memory: 4442, loss_ins: 1.3741, loss_cate: 0.1047, loss: 1.4788
2021-07-23 02:02:15,717 - mmdet - INFO - Epoch [30][500/673]	lr: 0.00100, eta: 0:20:24, time: 0.301, data_time: 0.014, memory: 4442, loss_ins: 1.3305, loss_cate: 0.1030, loss: 1.4335
2021-07-23 02:02:30,826 - mmdet - INFO - Epoch [30][550/673]	lr: 0.00100, eta: 0:20:09, time: 0.302, data_time: 0.014, memory: 4442, loss_ins: 1.3529, loss_cate: 0.1011, loss: 1.4540
2021-07-23 02:02:45,966 - mmdet - INFO - Epoch [30][600/673]	lr: 0.00100, eta: 0:19:55, time: 0.303, data_time: 0.013, memory: 4442, loss_ins: 1.3384, loss_cate: 0.1003, loss: 1.4387
2021-07-23 02:03:01,199 - mmdet - INFO - Epoch [30][650/673]	lr: 0.00100, eta: 0:19:40, time: 0.305, data_time: 0.014, memory: 4442, loss_ins: 1.3314, loss_cate: 0.0929, loss: 1.4243
2021-07-23 02:03:25,214 - mmdet - INFO - Epoch [31][50/673]	lr: 0.00100, eta: 0:19:18, time: 0.300, data_time: 0.017, memory: 4442, loss_ins: 1.2654, loss_cate: 0.1021, loss: 1.3675
2021-07-23 02:03:40,215 - mmdet - INFO - Epoch [31][100/673]	lr: 0.00100, eta: 0:19:03, time: 0.300, data_time: 0.012, memory: 4442, loss_ins: 1.3531, loss_cate: 0.1092, loss: 1.4623
2021-07-23 02:03:55,003 - mmdet - INFO - Epoch [31][150/673]	lr: 0.00100, eta: 0:18:49, time: 0.296, data_time: 0.013, memory: 4442, loss_ins: 1.3795, loss_cate: 0.0974, loss: 1.4769
2021-07-23 02:04:10,407 - mmdet - INFO - Epoch [31][200/673]	lr: 0.00100, eta: 0:18:35, time: 0.308, data_time: 0.014, memory: 4442, loss_ins: 1.3298, loss_cate: 0.1030, loss: 1.4329
2021-07-23 02:04:25,664 - mmdet - INFO - Epoch [31][250/673]	lr: 0.00100, eta: 0:18:20, time: 0.305, data_time: 0.013, memory: 4442, loss_ins: 1.4249, loss_cate: 0.1075, loss: 1.5324
2021-07-23 02:04:40,596 - mmdet - INFO - Epoch [31][300/673]	lr: 0.00100, eta: 0:18:06, time: 0.299, data_time: 0.012, memory: 4442, loss_ins: 1.3090, loss_cate: 0.1020, loss: 1.4110
2021-07-23 02:04:55,910 - mmdet - INFO - Epoch [31][350/673]	lr: 0.00100, eta: 0:17:51, time: 0.306, data_time: 0.012, memory: 4442, loss_ins: 1.3501, loss_cate: 0.0995, loss: 1.4496
2021-07-23 02:05:11,001 - mmdet - INFO - Epoch [31][400/673]	lr: 0.00100, eta: 0:17:37, time: 0.302, data_time: 0.013, memory: 4442, loss_ins: 1.3466, loss_cate: 0.0954, loss: 1.4419
2021-07-23 02:05:26,246 - mmdet - INFO - Epoch [31][450/673]	lr: 0.00100, eta: 0:17:23, time: 0.305, data_time: 0.012, memory: 4442, loss_ins: 1.3806, loss_cate: 0.0983, loss: 1.4788
2021-07-23 02:05:41,518 - mmdet - INFO - Epoch [31][500/673]	lr: 0.00100, eta: 0:17:08, time: 0.305, data_time: 0.012, memory: 4442, loss_ins: 1.3673, loss_cate: 0.0914, loss: 1.4586
2021-07-23 02:05:56,169 - mmdet - INFO - Epoch [31][550/673]	lr: 0.00100, eta: 0:16:54, time: 0.293, data_time: 0.012, memory: 4442, loss_ins: 1.3225, loss_cate: 0.1099, loss: 1.4324
2021-07-23 02:06:11,238 - mmdet - INFO - Epoch [31][600/673]	lr: 0.00100, eta: 0:16:39, time: 0.301, data_time: 0.013, memory: 4442, loss_ins: 1.3560, loss_cate: 0.1151, loss: 1.4711
2021-07-23 02:06:26,306 - mmdet - INFO - Epoch [31][650/673]	lr: 0.00100, eta: 0:16:25, time: 0.301, data_time: 0.012, memory: 4442, loss_ins: 1.3314, loss_cate: 0.0944, loss: 1.4258
2021-07-23 02:06:50,804 - mmdet - INFO - Epoch [32][50/673]	lr: 0.00100, eta: 0:16:03, time: 0.312, data_time: 0.019, memory: 4442, loss_ins: 1.3398, loss_cate: 0.1005, loss: 1.4403
2021-07-23 02:07:06,213 - mmdet - INFO - Epoch [32][100/673]	lr: 0.00100, eta: 0:15:48, time: 0.308, data_time: 0.013, memory: 4442, loss_ins: 1.3235, loss_cate: 0.0926, loss: 1.4161
2021-07-23 02:07:21,504 - mmdet - INFO - Epoch [32][150/673]	lr: 0.00100, eta: 0:15:34, time: 0.306, data_time: 0.015, memory: 4442, loss_ins: 1.2533, loss_cate: 0.1013, loss: 1.3546
2021-07-23 02:07:36,743 - mmdet - INFO - Epoch [32][200/673]	lr: 0.00100, eta: 0:15:19, time: 0.305, data_time: 0.012, memory: 4442, loss_ins: 1.3731, loss_cate: 0.1068, loss: 1.4799
2021-07-23 02:07:51,895 - mmdet - INFO - Epoch [32][250/673]	lr: 0.00100, eta: 0:15:05, time: 0.303, data_time: 0.013, memory: 4442, loss_ins: 1.2978, loss_cate: 0.0840, loss: 1.3818
2021-07-23 02:08:07,145 - mmdet - INFO - Epoch [32][300/673]	lr: 0.00100, eta: 0:14:50, time: 0.305, data_time: 0.013, memory: 4442, loss_ins: 1.3645, loss_cate: 0.1055, loss: 1.4700
2021-07-23 02:08:22,666 - mmdet - INFO - Epoch [32][350/673]	lr: 0.00100, eta: 0:14:36, time: 0.310, data_time: 0.013, memory: 4442, loss_ins: 1.3447, loss_cate: 0.1022, loss: 1.4468
2021-07-23 02:08:37,650 - mmdet - INFO - Epoch [32][400/673]	lr: 0.00100, eta: 0:14:22, time: 0.300, data_time: 0.013, memory: 4442, loss_ins: 1.3762, loss_cate: 0.0988, loss: 1.4750
2021-07-23 02:08:52,959 - mmdet - INFO - Epoch [32][450/673]	lr: 0.00100, eta: 0:14:07, time: 0.306, data_time: 0.013, memory: 4442, loss_ins: 1.4441, loss_cate: 0.0973, loss: 1.5414
2021-07-23 02:09:08,190 - mmdet - INFO - Epoch [32][500/673]	lr: 0.00100, eta: 0:13:53, time: 0.305, data_time: 0.013, memory: 4442, loss_ins: 1.3262, loss_cate: 0.0900, loss: 1.4162
2021-07-23 02:09:23,562 - mmdet - INFO - Epoch [32][550/673]	lr: 0.00100, eta: 0:13:38, time: 0.307, data_time: 0.013, memory: 4442, loss_ins: 1.3201, loss_cate: 0.1037, loss: 1.4238
2021-07-23 02:09:38,854 - mmdet - INFO - Epoch [32][600/673]	lr: 0.00100, eta: 0:13:24, time: 0.306, data_time: 0.013, memory: 4442, loss_ins: 1.3178, loss_cate: 0.1003, loss: 1.4181
2021-07-23 02:09:53,927 - mmdet - INFO - Epoch [32][650/673]	lr: 0.00100, eta: 0:13:09, time: 0.301, data_time: 0.012, memory: 4442, loss_ins: 1.3871, loss_cate: 0.1099, loss: 1.4969
2021-07-23 02:10:18,087 - mmdet - INFO - Epoch [33][50/673]	lr: 0.00100, eta: 0:12:47, time: 0.308, data_time: 0.019, memory: 4442, loss_ins: 1.2976, loss_cate: 0.1010, loss: 1.3986
2021-07-23 02:10:32,834 - mmdet - INFO - Epoch [33][100/673]	lr: 0.00100, eta: 0:12:33, time: 0.295, data_time: 0.013, memory: 4442, loss_ins: 1.3262, loss_cate: 0.0937, loss: 1.4199
2021-07-23 02:10:47,875 - mmdet - INFO - Epoch [33][150/673]	lr: 0.00100, eta: 0:12:18, time: 0.301, data_time: 0.013, memory: 4442, loss_ins: 1.3858, loss_cate: 0.1128, loss: 1.4986
2021-07-23 02:11:02,915 - mmdet - INFO - Epoch [33][200/673]	lr: 0.00100, eta: 0:12:04, time: 0.301, data_time: 0.013, memory: 4442, loss_ins: 1.3403, loss_cate: 0.1040, loss: 1.4444
2021-07-23 02:11:18,285 - mmdet - INFO - Epoch [33][250/673]	lr: 0.00100, eta: 0:11:50, time: 0.307, data_time: 0.014, memory: 4442, loss_ins: 1.3774, loss_cate: 0.0983, loss: 1.4758
2021-07-23 02:11:33,168 - mmdet - INFO - Epoch [33][300/673]	lr: 0.00100, eta: 0:11:35, time: 0.298, data_time: 0.013, memory: 4442, loss_ins: 1.3250, loss_cate: 0.1058, loss: 1.4307
2021-07-23 02:11:47,960 - mmdet - INFO - Epoch [33][350/673]	lr: 0.00100, eta: 0:11:21, time: 0.296, data_time: 0.013, memory: 4442, loss_ins: 1.2507, loss_cate: 0.0954, loss: 1.3461
2021-07-23 02:12:03,014 - mmdet - INFO - Epoch [33][400/673]	lr: 0.00100, eta: 0:11:06, time: 0.301, data_time: 0.013, memory: 4442, loss_ins: 1.3903, loss_cate: 0.1071, loss: 1.4975
2021-07-23 02:12:18,396 - mmdet - INFO - Epoch [33][450/673]	lr: 0.00100, eta: 0:10:52, time: 0.308, data_time: 0.014, memory: 4442, loss_ins: 1.3767, loss_cate: 0.0932, loss: 1.4699
2021-07-23 02:12:33,373 - mmdet - INFO - Epoch [33][500/673]	lr: 0.00100, eta: 0:10:37, time: 0.300, data_time: 0.013, memory: 4442, loss_ins: 1.3310, loss_cate: 0.0939, loss: 1.4249
2021-07-23 02:12:48,624 - mmdet - INFO - Epoch [33][550/673]	lr: 0.00100, eta: 0:10:23, time: 0.305, data_time: 0.013, memory: 4442, loss_ins: 1.3451, loss_cate: 0.0941, loss: 1.4392
2021-07-23 02:13:03,705 - mmdet - INFO - Epoch [33][600/673]	lr: 0.00100, eta: 0:10:08, time: 0.302, data_time: 0.014, memory: 4442, loss_ins: 1.3443, loss_cate: 0.1115, loss: 1.4558
2021-07-23 02:13:18,937 - mmdet - INFO - Epoch [33][650/673]	lr: 0.00100, eta: 0:09:54, time: 0.305, data_time: 0.013, memory: 4442, loss_ins: 1.4140, loss_cate: 0.1004, loss: 1.5144
2021-07-23 02:13:43,256 - mmdet - INFO - Epoch [34][50/673]	lr: 0.00010, eta: 0:09:32, time: 0.312, data_time: 0.018, memory: 4442, loss_ins: 1.2825, loss_cate: 0.1018, loss: 1.3843
2021-07-23 02:13:58,530 - mmdet - INFO - Epoch [34][100/673]	lr: 0.00010, eta: 0:09:17, time: 0.305, data_time: 0.013, memory: 4442, loss_ins: 1.3329, loss_cate: 0.1026, loss: 1.4355
2021-07-23 02:14:13,183 - mmdet - INFO - Epoch [34][150/673]	lr: 0.00010, eta: 0:09:03, time: 0.293, data_time: 0.012, memory: 4442, loss_ins: 1.3063, loss_cate: 0.0948, loss: 1.4012
2021-07-23 02:14:28,210 - mmdet - INFO - Epoch [34][200/673]	lr: 0.00010, eta: 0:08:48, time: 0.301, data_time: 0.012, memory: 4442, loss_ins: 1.3829, loss_cate: 0.0935, loss: 1.4765
2021-07-23 02:14:43,112 - mmdet - INFO - Epoch [34][250/673]	lr: 0.00010, eta: 0:08:34, time: 0.298, data_time: 0.011, memory: 4442, loss_ins: 1.3205, loss_cate: 0.0968, loss: 1.4174
2021-07-23 02:14:58,372 - mmdet - INFO - Epoch [34][300/673]	lr: 0.00010, eta: 0:08:19, time: 0.305, data_time: 0.012, memory: 4442, loss_ins: 1.3641, loss_cate: 0.0879, loss: 1.4520
2021-07-23 02:15:13,184 - mmdet - INFO - Epoch [34][350/673]	lr: 0.00010, eta: 0:08:05, time: 0.296, data_time: 0.012, memory: 4442, loss_ins: 1.2862, loss_cate: 0.1052, loss: 1.3914
2021-07-23 02:15:28,224 - mmdet - INFO - Epoch [34][400/673]	lr: 0.00010, eta: 0:07:50, time: 0.301, data_time: 0.012, memory: 4442, loss_ins: 1.3558, loss_cate: 0.1067, loss: 1.4626
2021-07-23 02:15:43,180 - mmdet - INFO - Epoch [34][450/673]	lr: 0.00010, eta: 0:07:36, time: 0.299, data_time: 0.011, memory: 4442, loss_ins: 1.3912, loss_cate: 0.0996, loss: 1.4908
2021-07-23 02:15:57,870 - mmdet - INFO - Epoch [34][500/673]	lr: 0.00010, eta: 0:07:21, time: 0.294, data_time: 0.011, memory: 4442, loss_ins: 1.2892, loss_cate: 0.0892, loss: 1.3784
2021-07-23 02:16:13,055 - mmdet - INFO - Epoch [34][550/673]	lr: 0.00010, eta: 0:07:07, time: 0.304, data_time: 0.012, memory: 4442, loss_ins: 1.3519, loss_cate: 0.0908, loss: 1.4427
2021-07-23 02:16:28,246 - mmdet - INFO - Epoch [34][600/673]	lr: 0.00010, eta: 0:06:52, time: 0.304, data_time: 0.013, memory: 4442, loss_ins: 1.3683, loss_cate: 0.1101, loss: 1.4784
2021-07-23 02:16:43,352 - mmdet - INFO - Epoch [34][650/673]	lr: 0.00010, eta: 0:06:38, time: 0.302, data_time: 0.012, memory: 4442, loss_ins: 1.3423, loss_cate: 0.1040, loss: 1.4463
2021-07-23 02:17:07,074 - mmdet - INFO - Epoch [35][50/673]	lr: 0.00010, eta: 0:06:16, time: 0.300, data_time: 0.019, memory: 4442, loss_ins: 1.3484, loss_cate: 0.0969, loss: 1.4453
2021-07-23 02:17:21,903 - mmdet - INFO - Epoch [35][100/673]	lr: 0.00010, eta: 0:06:02, time: 0.297, data_time: 0.014, memory: 4442, loss_ins: 1.2809, loss_cate: 0.0951, loss: 1.3759
2021-07-23 02:17:36,734 - mmdet - INFO - Epoch [35][150/673]	lr: 0.00010, eta: 0:05:47, time: 0.297, data_time: 0.012, memory: 4442, loss_ins: 1.4420, loss_cate: 0.0988, loss: 1.5408
2021-07-23 02:17:51,841 - mmdet - INFO - Epoch [35][200/673]	lr: 0.00010, eta: 0:05:33, time: 0.302, data_time: 0.013, memory: 4442, loss_ins: 1.3222, loss_cate: 0.0928, loss: 1.4150
2021-07-23 02:18:06,587 - mmdet - INFO - Epoch [35][250/673]	lr: 0.00010, eta: 0:05:18, time: 0.295, data_time: 0.013, memory: 4442, loss_ins: 1.2891, loss_cate: 0.1019, loss: 1.3911
2021-07-23 02:18:21,456 - mmdet - INFO - Epoch [35][300/673]	lr: 0.00010, eta: 0:05:04, time: 0.297, data_time: 0.013, memory: 4442, loss_ins: 1.3795, loss_cate: 0.1142, loss: 1.4937
2021-07-23 02:18:36,391 - mmdet - INFO - Epoch [35][350/673]	lr: 0.00010, eta: 0:04:49, time: 0.299, data_time: 0.012, memory: 4442, loss_ins: 1.3165, loss_cate: 0.0952, loss: 1.4117
2021-07-23 02:18:51,433 - mmdet - INFO - Epoch [35][400/673]	lr: 0.00010, eta: 0:04:35, time: 0.301, data_time: 0.012, memory: 4442, loss_ins: 1.3174, loss_cate: 0.0884, loss: 1.4058
2021-07-23 02:19:06,578 - mmdet - INFO - Epoch [35][450/673]	lr: 0.00010, eta: 0:04:20, time: 0.303, data_time: 0.013, memory: 4442, loss_ins: 1.3346, loss_cate: 0.0936, loss: 1.4282
2021-07-23 02:19:21,707 - mmdet - INFO - Epoch [35][500/673]	lr: 0.00010, eta: 0:04:06, time: 0.303, data_time: 0.013, memory: 4442, loss_ins: 1.4427, loss_cate: 0.0950, loss: 1.5377
2021-07-23 02:19:36,580 - mmdet - INFO - Epoch [35][550/673]	lr: 0.00010, eta: 0:03:51, time: 0.297, data_time: 0.012, memory: 4442, loss_ins: 1.3676, loss_cate: 0.0977, loss: 1.4653
2021-07-23 02:19:51,516 - mmdet - INFO - Epoch [35][600/673]	lr: 0.00010, eta: 0:03:36, time: 0.299, data_time: 0.011, memory: 4442, loss_ins: 1.3240, loss_cate: 0.0962, loss: 1.4202
2021-07-23 02:20:06,646 - mmdet - INFO - Epoch [35][650/673]	lr: 0.00010, eta: 0:03:22, time: 0.303, data_time: 0.013, memory: 4442, loss_ins: 1.2557, loss_cate: 0.0878, loss: 1.3435
2021-07-23 02:20:30,368 - mmdet - INFO - Epoch [36][50/673]	lr: 0.00010, eta: 0:03:01, time: 0.299, data_time: 0.018, memory: 4442, loss_ins: 1.2916, loss_cate: 0.0879, loss: 1.3795
2021-07-23 02:20:45,530 - mmdet - INFO - Epoch [36][100/673]	lr: 0.00010, eta: 0:02:46, time: 0.303, data_time: 0.014, memory: 4442, loss_ins: 1.4002, loss_cate: 0.0907, loss: 1.4909
2021-07-23 02:21:00,849 - mmdet - INFO - Epoch [36][150/673]	lr: 0.00010, eta: 0:02:32, time: 0.306, data_time: 0.014, memory: 4442, loss_ins: 1.3404, loss_cate: 0.0912, loss: 1.4316
2021-07-23 02:21:16,055 - mmdet - INFO - Epoch [36][200/673]	lr: 0.00010, eta: 0:02:17, time: 0.304, data_time: 0.014, memory: 4442, loss_ins: 1.2704, loss_cate: 0.0986, loss: 1.3690
2021-07-23 02:21:31,197 - mmdet - INFO - Epoch [36][250/673]	lr: 0.00010, eta: 0:02:02, time: 0.303, data_time: 0.013, memory: 4442, loss_ins: 1.3363, loss_cate: 0.1015, loss: 1.4378
2021-07-23 02:21:45,916 - mmdet - INFO - Epoch [36][300/673]	lr: 0.00010, eta: 0:01:48, time: 0.294, data_time: 0.013, memory: 4442, loss_ins: 1.3231, loss_cate: 0.0894, loss: 1.4125
2021-07-23 02:22:01,314 - mmdet - INFO - Epoch [36][350/673]	lr: 0.00010, eta: 0:01:33, time: 0.308, data_time: 0.014, memory: 4442, loss_ins: 1.3553, loss_cate: 0.0913, loss: 1.4465
2021-07-23 02:22:16,453 - mmdet - INFO - Epoch [36][400/673]	lr: 0.00010, eta: 0:01:19, time: 0.303, data_time: 0.013, memory: 4442, loss_ins: 1.3998, loss_cate: 0.0910, loss: 1.4908
2021-07-23 02:22:31,202 - mmdet - INFO - Epoch [36][450/673]	lr: 0.00010, eta: 0:01:04, time: 0.295, data_time: 0.013, memory: 4442, loss_ins: 1.2535, loss_cate: 0.0993, loss: 1.3528
2021-07-23 02:22:46,193 - mmdet - INFO - Epoch [36][500/673]	lr: 0.00010, eta: 0:00:50, time: 0.300, data_time: 0.013, memory: 4442, loss_ins: 1.3280, loss_cate: 0.1012, loss: 1.4292
2021-07-23 02:23:01,387 - mmdet - INFO - Epoch [36][550/673]	lr: 0.00010, eta: 0:00:35, time: 0.304, data_time: 0.013, memory: 4442, loss_ins: 1.4014, loss_cate: 0.0969, loss: 1.4983
2021-07-23 02:23:16,666 - mmdet - INFO - Epoch [36][600/673]	lr: 0.00010, eta: 0:00:21, time: 0.306, data_time: 0.013, memory: 4442, loss_ins: 1.4323, loss_cate: 0.1062, loss: 1.5385
2021-07-23 02:23:31,666 - mmdet - INFO - Epoch [36][650/673]	lr: 0.00010, eta: 0:00:06, time: 0.300, data_time: 0.013, memory: 4442, loss_ins: 1.3487, loss_cate: 0.0949, loss: 1.4436
2021-07-23 03:14:49,159 - mmdet - INFO - Distributed training: False
2021-07-23 03:14:49,159 - mmdet - INFO - MMDetection Version: 1.0.0+c7b294a
2021-07-23 03:14:49,159 - mmdet - INFO - Config:
# model settings
model = dict(
    type='SOLOv2',
    pretrained='torchvision://resnet50',
    backbone=dict(
        type='ResNet',
        depth=50,
        num_stages=4,
        out_indices=(0, 1, 2, 3),  # C2, C3, C4, C5
        frozen_stages=1,
        style='pytorch'),
    neck=dict(
        type='FPN',
        in_channels=[256, 512, 1024, 2048],
        out_channels=256,
        start_level=0,
        num_outs=5),
    bbox_head=dict(
        type='SOLOv2Head',
        num_classes=2,
        in_channels=256,
        stacked_convs=4,
        seg_feat_channels=512,
        strides=[8, 8, 16, 32, 32],
        scale_ranges=((1, 96), (48, 192), (96, 384), (192, 768), (384, 2048)),
        # scale_ranges=((1, 250), (125, 500), (250, 1000), (500, 2000)),
        sigma=0.2,
        num_grids=[40, 36, 24, 16, 12],
        ins_out_channels=256,
        loss_ins=dict(
            type='DiceLoss',
            use_sigmoid=True,
            loss_weight=3.0),
        # loss_weight=10.0),
        loss_cate=dict(
            type='FocalLoss',
            use_sigmoid=True,
            gamma=2.0,
            alpha=0.25,
            loss_weight=1.0)),
    mask_feat_head=dict(
        type='MaskFeatHead',
        in_channels=256,
        out_channels=128,
        start_level=0,
        end_level=3,
        num_classes=256,
        norm_cfg=dict(type='GN', num_groups=32, requires_grad=True)),
)
# training and testing settings
train_cfg = dict()
test_cfg = dict(
    nms_pre=500,
    score_thr=0.1,
    mask_thr=0.5,
    update_thr=0.05,
    kernel='gaussian',  # gaussian/linear
    sigma=2.0,
    max_per_img=100)
# dataset settings
dataset_type = 'CocoDataset'
data_root = 'data/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),
    dict(type='Resize',
         img_scale=[(1333, 800), (1333, 768), (1333, 736),
                    (1333, 704), (1333, 672), (1333, 640)],
         multiscale_mode='value',
         keep_ratio=True),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(type='Normalize', **img_norm_cfg),
    dict(type='Pad', size_divisor=32),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks']),
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(1333, 800),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(type='Normalize', **img_norm_cfg),
            dict(type='Pad', size_divisor=32),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img']),
        ])
]
data = dict(
    imgs_per_gpu=2,
    workers_per_gpu=2,
    train=dict(
        type=dataset_type,
        ann_file=data_root + 'annotation/merge/merge_train_coco.json',
        img_prefix=data_root + 'road/train/',
        pipeline=train_pipeline),
    val=dict(
        type=dataset_type,
        ann_file=data_root + 'annotation/merge/merge_val_coco.json',
        img_prefix=data_root + 'road/val/',
        pipeline=test_pipeline),
    test=dict(
        type=dataset_type,
        ann_file=data_root + 'annotation/merge/merge_val_coco.json',
        img_prefix=data_root + 'road/val/',
        pipeline=test_pipeline))
# optimizer
optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0001)
optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))
# learning policy
lr_config = dict(
    policy='step',
    warmup='linear',
    warmup_iters=500,
    warmup_ratio=0.01,
    step=[27, 33])
checkpoint_config = dict(interval=1)
# yapf:disable
log_config = dict(
    interval=50,
    hooks=[
        dict(type='TextLoggerHook'),
        # dict(type='TensorboardLoggerHook')
    ])
# yapf:enable
# runtime settings
total_epochs = 36
device_ids = range(8)
dist_params = dict(backend='nccl')
log_level = 'INFO'
work_dir = './work_dirs/solov2_release_r50_fpn_8gpu_3x'
# work_dir = './work_dirs/solov2_release_r50_fpn_8gpu_3x_scale'
# work_dir = './work_dirs/solov2_release_r50_fpn_8gpu_3x_weight'
# work_dir = './work_dirs/solov2_release_r50_fpn_8gpu_3x_workflow'
# work_dir = './work_dirs/solov2_release_r50_fpn_8gpu_3x_validate'

load_from = None
# load_from = './work_dirs/solov2_release_r50_fpn_8gpu_3x_scale/epoch_7.pth'
resume_from = None
workflow = [('train', 1)]

2021-07-23 03:14:49,535 - mmdet - INFO - load model from: torchvision://resnet50
2021-07-23 03:14:51,856 - mmdet - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: backbone.conv1.weight, backbone.bn1.weight, backbone.bn1.bias, backbone.bn1.running_mean, backbone.bn1.running_var, backbone.bn1.num_batches_tracked, backbone.layer1.0.conv1.weight, backbone.layer1.0.bn1.weight, backbone.layer1.0.bn1.bias, backbone.layer1.0.bn1.running_mean, backbone.layer1.0.bn1.running_var, backbone.layer1.0.bn1.num_batches_tracked, backbone.layer1.0.conv2.weight, backbone.layer1.0.bn2.weight, backbone.layer1.0.bn2.bias, backbone.layer1.0.bn2.running_mean, backbone.layer1.0.bn2.running_var, backbone.layer1.0.bn2.num_batches_tracked, backbone.layer1.0.conv3.weight, backbone.layer1.0.bn3.weight, backbone.layer1.0.bn3.bias, backbone.layer1.0.bn3.running_mean, backbone.layer1.0.bn3.running_var, backbone.layer1.0.bn3.num_batches_tracked, backbone.layer1.0.downsample.0.weight, backbone.layer1.0.downsample.1.weight, backbone.layer1.0.downsample.1.bias, backbone.layer1.0.downsample.1.running_mean, backbone.layer1.0.downsample.1.running_var, backbone.layer1.0.downsample.1.num_batches_tracked, backbone.layer1.1.conv1.weight, backbone.layer1.1.bn1.weight, backbone.layer1.1.bn1.bias, backbone.layer1.1.bn1.running_mean, backbone.layer1.1.bn1.running_var, backbone.layer1.1.bn1.num_batches_tracked, backbone.layer1.1.conv2.weight, backbone.layer1.1.bn2.weight, backbone.layer1.1.bn2.bias, backbone.layer1.1.bn2.running_mean, backbone.layer1.1.bn2.running_var, backbone.layer1.1.bn2.num_batches_tracked, backbone.layer1.1.conv3.weight, backbone.layer1.1.bn3.weight, backbone.layer1.1.bn3.bias, backbone.layer1.1.bn3.running_mean, backbone.layer1.1.bn3.running_var, backbone.layer1.1.bn3.num_batches_tracked, backbone.layer1.2.conv1.weight, backbone.layer1.2.bn1.weight, backbone.layer1.2.bn1.bias, backbone.layer1.2.bn1.running_mean, backbone.layer1.2.bn1.running_var, backbone.layer1.2.bn1.num_batches_tracked, backbone.layer1.2.conv2.weight, backbone.layer1.2.bn2.weight, backbone.layer1.2.bn2.bias, backbone.layer1.2.bn2.running_mean, backbone.layer1.2.bn2.running_var, backbone.layer1.2.bn2.num_batches_tracked, backbone.layer1.2.conv3.weight, backbone.layer1.2.bn3.weight, backbone.layer1.2.bn3.bias, backbone.layer1.2.bn3.running_mean, backbone.layer1.2.bn3.running_var, backbone.layer1.2.bn3.num_batches_tracked, backbone.layer2.0.conv1.weight, backbone.layer2.0.bn1.weight, backbone.layer2.0.bn1.bias, backbone.layer2.0.bn1.running_mean, backbone.layer2.0.bn1.running_var, backbone.layer2.0.bn1.num_batches_tracked, backbone.layer2.0.conv2.weight, backbone.layer2.0.bn2.weight, backbone.layer2.0.bn2.bias, backbone.layer2.0.bn2.running_mean, backbone.layer2.0.bn2.running_var, backbone.layer2.0.bn2.num_batches_tracked, backbone.layer2.0.conv3.weight, backbone.layer2.0.bn3.weight, backbone.layer2.0.bn3.bias, backbone.layer2.0.bn3.running_mean, backbone.layer2.0.bn3.running_var, backbone.layer2.0.bn3.num_batches_tracked, backbone.layer2.0.downsample.0.weight, backbone.layer2.0.downsample.1.weight, backbone.layer2.0.downsample.1.bias, backbone.layer2.0.downsample.1.running_mean, backbone.layer2.0.downsample.1.running_var, backbone.layer2.0.downsample.1.num_batches_tracked, backbone.layer2.1.conv1.weight, backbone.layer2.1.bn1.weight, backbone.layer2.1.bn1.bias, backbone.layer2.1.bn1.running_mean, backbone.layer2.1.bn1.running_var, backbone.layer2.1.bn1.num_batches_tracked, backbone.layer2.1.conv2.weight, backbone.layer2.1.bn2.weight, backbone.layer2.1.bn2.bias, backbone.layer2.1.bn2.running_mean, backbone.layer2.1.bn2.running_var, backbone.layer2.1.bn2.num_batches_tracked, backbone.layer2.1.conv3.weight, backbone.layer2.1.bn3.weight, backbone.layer2.1.bn3.bias, backbone.layer2.1.bn3.running_mean, backbone.layer2.1.bn3.running_var, backbone.layer2.1.bn3.num_batches_tracked, backbone.layer2.2.conv1.weight, backbone.layer2.2.bn1.weight, backbone.layer2.2.bn1.bias, backbone.layer2.2.bn1.running_mean, backbone.layer2.2.bn1.running_var, backbone.layer2.2.bn1.num_batches_tracked, backbone.layer2.2.conv2.weight, backbone.layer2.2.bn2.weight, backbone.layer2.2.bn2.bias, backbone.layer2.2.bn2.running_mean, backbone.layer2.2.bn2.running_var, backbone.layer2.2.bn2.num_batches_tracked, backbone.layer2.2.conv3.weight, backbone.layer2.2.bn3.weight, backbone.layer2.2.bn3.bias, backbone.layer2.2.bn3.running_mean, backbone.layer2.2.bn3.running_var, backbone.layer2.2.bn3.num_batches_tracked, backbone.layer2.3.conv1.weight, backbone.layer2.3.bn1.weight, backbone.layer2.3.bn1.bias, backbone.layer2.3.bn1.running_mean, backbone.layer2.3.bn1.running_var, backbone.layer2.3.bn1.num_batches_tracked, backbone.layer2.3.conv2.weight, backbone.layer2.3.bn2.weight, backbone.layer2.3.bn2.bias, backbone.layer2.3.bn2.running_mean, backbone.layer2.3.bn2.running_var, backbone.layer2.3.bn2.num_batches_tracked, backbone.layer2.3.conv3.weight, backbone.layer2.3.bn3.weight, backbone.layer2.3.bn3.bias, backbone.layer2.3.bn3.running_mean, backbone.layer2.3.bn3.running_var, backbone.layer2.3.bn3.num_batches_tracked, backbone.layer3.0.conv1.weight, backbone.layer3.0.bn1.weight, backbone.layer3.0.bn1.bias, backbone.layer3.0.bn1.running_mean, backbone.layer3.0.bn1.running_var, backbone.layer3.0.bn1.num_batches_tracked, backbone.layer3.0.conv2.weight, backbone.layer3.0.bn2.weight, backbone.layer3.0.bn2.bias, backbone.layer3.0.bn2.running_mean, backbone.layer3.0.bn2.running_var, backbone.layer3.0.bn2.num_batches_tracked, backbone.layer3.0.conv3.weight, backbone.layer3.0.bn3.weight, backbone.layer3.0.bn3.bias, backbone.layer3.0.bn3.running_mean, backbone.layer3.0.bn3.running_var, backbone.layer3.0.bn3.num_batches_tracked, backbone.layer3.0.downsample.0.weight, backbone.layer3.0.downsample.1.weight, backbone.layer3.0.downsample.1.bias, backbone.layer3.0.downsample.1.running_mean, backbone.layer3.0.downsample.1.running_var, backbone.layer3.0.downsample.1.num_batches_tracked, backbone.layer3.1.conv1.weight, backbone.layer3.1.bn1.weight, backbone.layer3.1.bn1.bias, backbone.layer3.1.bn1.running_mean, backbone.layer3.1.bn1.running_var, backbone.layer3.1.bn1.num_batches_tracked, backbone.layer3.1.conv2.weight, backbone.layer3.1.bn2.weight, backbone.layer3.1.bn2.bias, backbone.layer3.1.bn2.running_mean, backbone.layer3.1.bn2.running_var, backbone.layer3.1.bn2.num_batches_tracked, backbone.layer3.1.conv3.weight, backbone.layer3.1.bn3.weight, backbone.layer3.1.bn3.bias, backbone.layer3.1.bn3.running_mean, backbone.layer3.1.bn3.running_var, backbone.layer3.1.bn3.num_batches_tracked, backbone.layer3.2.conv1.weight, backbone.layer3.2.bn1.weight, backbone.layer3.2.bn1.bias, backbone.layer3.2.bn1.running_mean, backbone.layer3.2.bn1.running_var, backbone.layer3.2.bn1.num_batches_tracked, backbone.layer3.2.conv2.weight, backbone.layer3.2.bn2.weight, backbone.layer3.2.bn2.bias, backbone.layer3.2.bn2.running_mean, backbone.layer3.2.bn2.running_var, backbone.layer3.2.bn2.num_batches_tracked, backbone.layer3.2.conv3.weight, backbone.layer3.2.bn3.weight, backbone.layer3.2.bn3.bias, backbone.layer3.2.bn3.running_mean, backbone.layer3.2.bn3.running_var, backbone.layer3.2.bn3.num_batches_tracked, backbone.layer3.3.conv1.weight, backbone.layer3.3.bn1.weight, backbone.layer3.3.bn1.bias, backbone.layer3.3.bn1.running_mean, backbone.layer3.3.bn1.running_var, backbone.layer3.3.bn1.num_batches_tracked, backbone.layer3.3.conv2.weight, backbone.layer3.3.bn2.weight, backbone.layer3.3.bn2.bias, backbone.layer3.3.bn2.running_mean, backbone.layer3.3.bn2.running_var, backbone.layer3.3.bn2.num_batches_tracked, backbone.layer3.3.conv3.weight, backbone.layer3.3.bn3.weight, backbone.layer3.3.bn3.bias, backbone.layer3.3.bn3.running_mean, backbone.layer3.3.bn3.running_var, backbone.layer3.3.bn3.num_batches_tracked, backbone.layer3.4.conv1.weight, backbone.layer3.4.bn1.weight, backbone.layer3.4.bn1.bias, backbone.layer3.4.bn1.running_mean, backbone.layer3.4.bn1.running_var, backbone.layer3.4.bn1.num_batches_tracked, backbone.layer3.4.conv2.weight, backbone.layer3.4.bn2.weight, backbone.layer3.4.bn2.bias, backbone.layer3.4.bn2.running_mean, backbone.layer3.4.bn2.running_var, backbone.layer3.4.bn2.num_batches_tracked, backbone.layer3.4.conv3.weight, backbone.layer3.4.bn3.weight, backbone.layer3.4.bn3.bias, backbone.layer3.4.bn3.running_mean, backbone.layer3.4.bn3.running_var, backbone.layer3.4.bn3.num_batches_tracked, backbone.layer3.5.conv1.weight, backbone.layer3.5.bn1.weight, backbone.layer3.5.bn1.bias, backbone.layer3.5.bn1.running_mean, backbone.layer3.5.bn1.running_var, backbone.layer3.5.bn1.num_batches_tracked, backbone.layer3.5.conv2.weight, backbone.layer3.5.bn2.weight, backbone.layer3.5.bn2.bias, backbone.layer3.5.bn2.running_mean, backbone.layer3.5.bn2.running_var, backbone.layer3.5.bn2.num_batches_tracked, backbone.layer3.5.conv3.weight, backbone.layer3.5.bn3.weight, backbone.layer3.5.bn3.bias, backbone.layer3.5.bn3.running_mean, backbone.layer3.5.bn3.running_var, backbone.layer3.5.bn3.num_batches_tracked, backbone.layer4.0.conv1.weight, backbone.layer4.0.bn1.weight, backbone.layer4.0.bn1.bias, backbone.layer4.0.bn1.running_mean, backbone.layer4.0.bn1.running_var, backbone.layer4.0.bn1.num_batches_tracked, backbone.layer4.0.conv2.weight, backbone.layer4.0.bn2.weight, backbone.layer4.0.bn2.bias, backbone.layer4.0.bn2.running_mean, backbone.layer4.0.bn2.running_var, backbone.layer4.0.bn2.num_batches_tracked, backbone.layer4.0.conv3.weight, backbone.layer4.0.bn3.weight, backbone.layer4.0.bn3.bias, backbone.layer4.0.bn3.running_mean, backbone.layer4.0.bn3.running_var, backbone.layer4.0.bn3.num_batches_tracked, backbone.layer4.0.downsample.0.weight, backbone.layer4.0.downsample.1.weight, backbone.layer4.0.downsample.1.bias, backbone.layer4.0.downsample.1.running_mean, backbone.layer4.0.downsample.1.running_var, backbone.layer4.0.downsample.1.num_batches_tracked, backbone.layer4.1.conv1.weight, backbone.layer4.1.bn1.weight, backbone.layer4.1.bn1.bias, backbone.layer4.1.bn1.running_mean, backbone.layer4.1.bn1.running_var, backbone.layer4.1.bn1.num_batches_tracked, backbone.layer4.1.conv2.weight, backbone.layer4.1.bn2.weight, backbone.layer4.1.bn2.bias, backbone.layer4.1.bn2.running_mean, backbone.layer4.1.bn2.running_var, backbone.layer4.1.bn2.num_batches_tracked, backbone.layer4.1.conv3.weight, backbone.layer4.1.bn3.weight, backbone.layer4.1.bn3.bias, backbone.layer4.1.bn3.running_mean, backbone.layer4.1.bn3.running_var, backbone.layer4.1.bn3.num_batches_tracked, backbone.layer4.2.conv1.weight, backbone.layer4.2.bn1.weight, backbone.layer4.2.bn1.bias, backbone.layer4.2.bn1.running_mean, backbone.layer4.2.bn1.running_var, backbone.layer4.2.bn1.num_batches_tracked, backbone.layer4.2.conv2.weight, backbone.layer4.2.bn2.weight, backbone.layer4.2.bn2.bias, backbone.layer4.2.bn2.running_mean, backbone.layer4.2.bn2.running_var, backbone.layer4.2.bn2.num_batches_tracked, backbone.layer4.2.conv3.weight, backbone.layer4.2.bn3.weight, backbone.layer4.2.bn3.bias, backbone.layer4.2.bn3.running_mean, backbone.layer4.2.bn3.running_var, backbone.layer4.2.bn3.num_batches_tracked, neck.lateral_convs.0.conv.weight, neck.lateral_convs.0.conv.bias, neck.lateral_convs.1.conv.weight, neck.lateral_convs.1.conv.bias, neck.lateral_convs.2.conv.weight, neck.lateral_convs.2.conv.bias, neck.lateral_convs.3.conv.weight, neck.lateral_convs.3.conv.bias, neck.fpn_convs.0.conv.weight, neck.fpn_convs.0.conv.bias, neck.fpn_convs.1.conv.weight, neck.fpn_convs.1.conv.bias, neck.fpn_convs.2.conv.weight, neck.fpn_convs.2.conv.bias, neck.fpn_convs.3.conv.weight, neck.fpn_convs.3.conv.bias, mask_feat_head.convs_all_levels.0.conv0.conv.weight, mask_feat_head.convs_all_levels.0.conv0.gn.weight, mask_feat_head.convs_all_levels.0.conv0.gn.bias, mask_feat_head.convs_all_levels.1.conv0.conv.weight, mask_feat_head.convs_all_levels.1.conv0.gn.weight, mask_feat_head.convs_all_levels.1.conv0.gn.bias, mask_feat_head.convs_all_levels.2.conv0.conv.weight, mask_feat_head.convs_all_levels.2.conv0.gn.weight, mask_feat_head.convs_all_levels.2.conv0.gn.bias, mask_feat_head.convs_all_levels.2.conv1.conv.weight, mask_feat_head.convs_all_levels.2.conv1.gn.weight, mask_feat_head.convs_all_levels.2.conv1.gn.bias, mask_feat_head.convs_all_levels.3.conv0.conv.weight, mask_feat_head.convs_all_levels.3.conv0.gn.weight, mask_feat_head.convs_all_levels.3.conv0.gn.bias, mask_feat_head.convs_all_levels.3.conv1.conv.weight, mask_feat_head.convs_all_levels.3.conv1.gn.weight, mask_feat_head.convs_all_levels.3.conv1.gn.bias, mask_feat_head.convs_all_levels.3.conv2.conv.weight, mask_feat_head.convs_all_levels.3.conv2.gn.weight, mask_feat_head.convs_all_levels.3.conv2.gn.bias, mask_feat_head.conv_pred.0.conv.weight, mask_feat_head.conv_pred.0.gn.weight, mask_feat_head.conv_pred.0.gn.bias, bbox_head.cate_convs.0.conv.weight, bbox_head.cate_convs.0.gn.weight, bbox_head.cate_convs.0.gn.bias, bbox_head.cate_convs.1.conv.weight, bbox_head.cate_convs.1.gn.weight, bbox_head.cate_convs.1.gn.bias, bbox_head.cate_convs.2.conv.weight, bbox_head.cate_convs.2.gn.weight, bbox_head.cate_convs.2.gn.bias, bbox_head.cate_convs.3.conv.weight, bbox_head.cate_convs.3.gn.weight, bbox_head.cate_convs.3.gn.bias, bbox_head.kernel_convs.0.conv.weight, bbox_head.kernel_convs.0.gn.weight, bbox_head.kernel_convs.0.gn.bias, bbox_head.kernel_convs.1.conv.weight, bbox_head.kernel_convs.1.gn.weight, bbox_head.kernel_convs.1.gn.bias, bbox_head.kernel_convs.2.conv.weight, bbox_head.kernel_convs.2.gn.weight, bbox_head.kernel_convs.2.gn.bias, bbox_head.kernel_convs.3.conv.weight, bbox_head.kernel_convs.3.gn.weight, bbox_head.kernel_convs.3.gn.bias, bbox_head.solo_cate.weight, bbox_head.solo_cate.bias, bbox_head.solo_kernel.weight, bbox_head.solo_kernel.bias

missing keys in source state_dict: conv1.weight, bn1.weight, bn1.bias, bn1.running_mean, bn1.running_var, layer1.0.conv1.weight, layer1.0.bn1.weight, layer1.0.bn1.bias, layer1.0.bn1.running_mean, layer1.0.bn1.running_var, layer1.0.conv2.weight, layer1.0.bn2.weight, layer1.0.bn2.bias, layer1.0.bn2.running_mean, layer1.0.bn2.running_var, layer1.0.conv3.weight, layer1.0.bn3.weight, layer1.0.bn3.bias, layer1.0.bn3.running_mean, layer1.0.bn3.running_var, layer1.0.downsample.0.weight, layer1.0.downsample.1.weight, layer1.0.downsample.1.bias, layer1.0.downsample.1.running_mean, layer1.0.downsample.1.running_var, layer1.1.conv1.weight, layer1.1.bn1.weight, layer1.1.bn1.bias, layer1.1.bn1.running_mean, layer1.1.bn1.running_var, layer1.1.conv2.weight, layer1.1.bn2.weight, layer1.1.bn2.bias, layer1.1.bn2.running_mean, layer1.1.bn2.running_var, layer1.1.conv3.weight, layer1.1.bn3.weight, layer1.1.bn3.bias, layer1.1.bn3.running_mean, layer1.1.bn3.running_var, layer1.2.conv1.weight, layer1.2.bn1.weight, layer1.2.bn1.bias, layer1.2.bn1.running_mean, layer1.2.bn1.running_var, layer1.2.conv2.weight, layer1.2.bn2.weight, layer1.2.bn2.bias, layer1.2.bn2.running_mean, layer1.2.bn2.running_var, layer1.2.conv3.weight, layer1.2.bn3.weight, layer1.2.bn3.bias, layer1.2.bn3.running_mean, layer1.2.bn3.running_var, layer2.0.conv1.weight, layer2.0.bn1.weight, layer2.0.bn1.bias, layer2.0.bn1.running_mean, layer2.0.bn1.running_var, layer2.0.conv2.weight, layer2.0.bn2.weight, layer2.0.bn2.bias, layer2.0.bn2.running_mean, layer2.0.bn2.running_var, layer2.0.conv3.weight, layer2.0.bn3.weight, layer2.0.bn3.bias, layer2.0.bn3.running_mean, layer2.0.bn3.running_var, layer2.0.downsample.0.weight, layer2.0.downsample.1.weight, layer2.0.downsample.1.bias, layer2.0.downsample.1.running_mean, layer2.0.downsample.1.running_var, layer2.1.conv1.weight, layer2.1.bn1.weight, layer2.1.bn1.bias, layer2.1.bn1.running_mean, layer2.1.bn1.running_var, layer2.1.conv2.weight, layer2.1.bn2.weight, layer2.1.bn2.bias, layer2.1.bn2.running_mean, layer2.1.bn2.running_var, layer2.1.conv3.weight, layer2.1.bn3.weight, layer2.1.bn3.bias, layer2.1.bn3.running_mean, layer2.1.bn3.running_var, layer2.2.conv1.weight, layer2.2.bn1.weight, layer2.2.bn1.bias, layer2.2.bn1.running_mean, layer2.2.bn1.running_var, layer2.2.conv2.weight, layer2.2.bn2.weight, layer2.2.bn2.bias, layer2.2.bn2.running_mean, layer2.2.bn2.running_var, layer2.2.conv3.weight, layer2.2.bn3.weight, layer2.2.bn3.bias, layer2.2.bn3.running_mean, layer2.2.bn3.running_var, layer2.3.conv1.weight, layer2.3.bn1.weight, layer2.3.bn1.bias, layer2.3.bn1.running_mean, layer2.3.bn1.running_var, layer2.3.conv2.weight, layer2.3.bn2.weight, layer2.3.bn2.bias, layer2.3.bn2.running_mean, layer2.3.bn2.running_var, layer2.3.conv3.weight, layer2.3.bn3.weight, layer2.3.bn3.bias, layer2.3.bn3.running_mean, layer2.3.bn3.running_var, layer3.0.conv1.weight, layer3.0.bn1.weight, layer3.0.bn1.bias, layer3.0.bn1.running_mean, layer3.0.bn1.running_var, layer3.0.conv2.weight, layer3.0.bn2.weight, layer3.0.bn2.bias, layer3.0.bn2.running_mean, layer3.0.bn2.running_var, layer3.0.conv3.weight, layer3.0.bn3.weight, layer3.0.bn3.bias, layer3.0.bn3.running_mean, layer3.0.bn3.running_var, layer3.0.downsample.0.weight, layer3.0.downsample.1.weight, layer3.0.downsample.1.bias, layer3.0.downsample.1.running_mean, layer3.0.downsample.1.running_var, layer3.1.conv1.weight, layer3.1.bn1.weight, layer3.1.bn1.bias, layer3.1.bn1.running_mean, layer3.1.bn1.running_var, layer3.1.conv2.weight, layer3.1.bn2.weight, layer3.1.bn2.bias, layer3.1.bn2.running_mean, layer3.1.bn2.running_var, layer3.1.conv3.weight, layer3.1.bn3.weight, layer3.1.bn3.bias, layer3.1.bn3.running_mean, layer3.1.bn3.running_var, layer3.2.conv1.weight, layer3.2.bn1.weight, layer3.2.bn1.bias, layer3.2.bn1.running_mean, layer3.2.bn1.running_var, layer3.2.conv2.weight, layer3.2.bn2.weight, layer3.2.bn2.bias, layer3.2.bn2.running_mean, layer3.2.bn2.running_var, layer3.2.conv3.weight, layer3.2.bn3.weight, layer3.2.bn3.bias, layer3.2.bn3.running_mean, layer3.2.bn3.running_var, layer3.3.conv1.weight, layer3.3.bn1.weight, layer3.3.bn1.bias, layer3.3.bn1.running_mean, layer3.3.bn1.running_var, layer3.3.conv2.weight, layer3.3.bn2.weight, layer3.3.bn2.bias, layer3.3.bn2.running_mean, layer3.3.bn2.running_var, layer3.3.conv3.weight, layer3.3.bn3.weight, layer3.3.bn3.bias, layer3.3.bn3.running_mean, layer3.3.bn3.running_var, layer3.4.conv1.weight, layer3.4.bn1.weight, layer3.4.bn1.bias, layer3.4.bn1.running_mean, layer3.4.bn1.running_var, layer3.4.conv2.weight, layer3.4.bn2.weight, layer3.4.bn2.bias, layer3.4.bn2.running_mean, layer3.4.bn2.running_var, layer3.4.conv3.weight, layer3.4.bn3.weight, layer3.4.bn3.bias, layer3.4.bn3.running_mean, layer3.4.bn3.running_var, layer3.5.conv1.weight, layer3.5.bn1.weight, layer3.5.bn1.bias, layer3.5.bn1.running_mean, layer3.5.bn1.running_var, layer3.5.conv2.weight, layer3.5.bn2.weight, layer3.5.bn2.bias, layer3.5.bn2.running_mean, layer3.5.bn2.running_var, layer3.5.conv3.weight, layer3.5.bn3.weight, layer3.5.bn3.bias, layer3.5.bn3.running_mean, layer3.5.bn3.running_var, layer4.0.conv1.weight, layer4.0.bn1.weight, layer4.0.bn1.bias, layer4.0.bn1.running_mean, layer4.0.bn1.running_var, layer4.0.conv2.weight, layer4.0.bn2.weight, layer4.0.bn2.bias, layer4.0.bn2.running_mean, layer4.0.bn2.running_var, layer4.0.conv3.weight, layer4.0.bn3.weight, layer4.0.bn3.bias, layer4.0.bn3.running_mean, layer4.0.bn3.running_var, layer4.0.downsample.0.weight, layer4.0.downsample.1.weight, layer4.0.downsample.1.bias, layer4.0.downsample.1.running_mean, layer4.0.downsample.1.running_var, layer4.1.conv1.weight, layer4.1.bn1.weight, layer4.1.bn1.bias, layer4.1.bn1.running_mean, layer4.1.bn1.running_var, layer4.1.conv2.weight, layer4.1.bn2.weight, layer4.1.bn2.bias, layer4.1.bn2.running_mean, layer4.1.bn2.running_var, layer4.1.conv3.weight, layer4.1.bn3.weight, layer4.1.bn3.bias, layer4.1.bn3.running_mean, layer4.1.bn3.running_var, layer4.2.conv1.weight, layer4.2.bn1.weight, layer4.2.bn1.bias, layer4.2.bn1.running_mean, layer4.2.bn1.running_var, layer4.2.conv2.weight, layer4.2.bn2.weight, layer4.2.bn2.bias, layer4.2.bn2.running_mean, layer4.2.bn2.running_var, layer4.2.conv3.weight, layer4.2.bn3.weight, layer4.2.bn3.bias, layer4.2.bn3.running_mean, layer4.2.bn3.running_var

2021-07-23 03:14:52,167 - mmdet - INFO - Start running, host: root@efe7fbebbac3, work_dir: /home/zq/work/SOLO/work_dirs/solov2_release_r50_fpn_8gpu_3x
2021-07-23 03:14:52,167 - mmdet - INFO - workflow: [('train', 1)], max: 36 epochs
loading annotations into memory...
Done (t=0.02s)
creating index...
index created!
{'type': 'CocoDataset', 'ann_file': 'data/annotation/merge/merge_train_coco.json', 'img_prefix': 'data/road/train/', 'pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'LoadAnnotations', 'with_bbox': True, 'with_mask': True}, {'type': 'Resize', 'img_scale': [(1333, 800), (1333, 768), (1333, 736), (1333, 704), (1333, 672), (1333, 640)], 'multiscale_mode': 'value', 'keep_ratio': True}, {'type': 'RandomFlip', 'flip_ratio': 0.5}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'DefaultFormatBundle'}, {'type': 'Collect', 'keys': ['img', 'gt_bboxes', 'gt_labels', 'gt_masks']}]}
/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:2494: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
2021-07-23 03:15:07,260 - mmdet - INFO - Epoch [1][50/673]	lr: 0.00107, eta: 2:01:37, time: 0.302, data_time: 0.020, memory: 4312, loss_ins: 1.3763, loss_cate: 0.4132, loss: 1.7895
2021-07-23 03:15:21,748 - mmdet - INFO - Epoch [1][100/673]	lr: 0.00206, eta: 1:58:56, time: 0.290, data_time: 0.014, memory: 4312, loss_ins: 1.3196, loss_cate: 0.4277, loss: 1.7473
2021-07-23 03:15:36,468 - mmdet - INFO - Epoch [1][150/673]	lr: 0.00305, eta: 1:58:30, time: 0.294, data_time: 0.014, memory: 4312, loss_ins: 1.3811, loss_cate: 0.4849, loss: 1.8660
2021-07-23 03:15:51,341 - mmdet - INFO - Epoch [1][200/673]	lr: 0.00404, eta: 1:58:28, time: 0.297, data_time: 0.013, memory: 4312, loss_ins: 1.3458, loss_cate: 0.3413, loss: 1.6871
2021-07-23 03:16:05,934 - mmdet - INFO - Epoch [1][250/673]	lr: 0.00503, eta: 1:57:54, time: 0.292, data_time: 0.012, memory: 4312, loss_ins: 1.3585, loss_cate: 0.3298, loss: 1.6883
2021-07-23 03:16:20,959 - mmdet - INFO - Epoch [1][300/673]	lr: 0.00602, eta: 1:58:01, time: 0.300, data_time: 0.013, memory: 4312, loss_ins: 1.3386, loss_cate: 0.3254, loss: 1.6639
2021-07-23 03:16:35,566 - mmdet - INFO - Epoch [1][350/673]	lr: 0.00701, eta: 1:57:33, time: 0.292, data_time: 0.013, memory: 4312, loss_ins: 1.2859, loss_cate: 0.3068, loss: 1.5927
2021-07-23 03:16:50,547 - mmdet - INFO - Epoch [1][400/673]	lr: 0.00800, eta: 1:57:31, time: 0.300, data_time: 0.014, memory: 4312, loss_ins: 1.3570, loss_cate: 0.3035, loss: 1.6606
2021-07-23 03:17:05,550 - mmdet - INFO - Epoch [1][450/673]	lr: 0.00899, eta: 1:57:27, time: 0.300, data_time: 0.014, memory: 4312, loss_ins: 1.3582, loss_cate: 0.4018, loss: 1.7600
2021-07-23 03:17:20,260 - mmdet - INFO - Epoch [1][500/673]	lr: 0.00998, eta: 1:57:07, time: 0.294, data_time: 0.013, memory: 4382, loss_ins: 1.3665, loss_cate: 1.4316, loss: 2.7980
2021-07-23 03:17:35,214 - mmdet - INFO - Epoch [1][550/673]	lr: 0.01000, eta: 1:56:59, time: 0.299, data_time: 0.014, memory: 4382, loss_ins: 1.3605, loss_cate: 0.8193, loss: 2.1798
2021-07-23 03:17:50,214 - mmdet - INFO - Epoch [1][600/673]	lr: 0.01000, eta: 1:56:51, time: 0.300, data_time: 0.014, memory: 4382, loss_ins: 1.3650, loss_cate: 0.9319, loss: 2.2969
2021-07-23 03:18:05,070 - mmdet - INFO - Epoch [1][650/673]	lr: 0.01000, eta: 1:56:37, time: 0.297, data_time: 0.013, memory: 4382, loss_ins: 1.3437, loss_cate: 0.5046, loss: 1.8483
2021-07-23 03:18:29,256 - mmdet - INFO - Epoch [2][50/673]	lr: 0.01000, eta: 1:52:43, time: 0.303, data_time: 0.019, memory: 4382, loss_ins: 1.3468, loss_cate: 0.3731, loss: 1.7199
2021-07-23 03:18:44,235 - mmdet - INFO - Epoch [2][100/673]	lr: 0.01000, eta: 1:52:46, time: 0.300, data_time: 0.013, memory: 4382, loss_ins: 1.3763, loss_cate: 0.3012, loss: 1.6775
2021-07-23 03:18:59,484 - mmdet - INFO - Epoch [2][150/673]	lr: 0.01000, eta: 1:52:55, time: 0.305, data_time: 0.014, memory: 4382, loss_ins: 1.3921, loss_cate: 0.2941, loss: 1.6863
2021-07-23 03:19:14,531 - mmdet - INFO - Epoch [2][200/673]	lr: 0.01000, eta: 1:52:56, time: 0.301, data_time: 0.012, memory: 4382, loss_ins: 1.2411, loss_cate: 0.2766, loss: 1.5177
2021-07-23 03:19:29,504 - mmdet - INFO - Epoch [2][250/673]	lr: 0.01000, eta: 1:52:53, time: 0.299, data_time: 0.013, memory: 4382, loss_ins: 1.3473, loss_cate: 0.2921, loss: 1.6394
2021-07-23 03:19:44,482 - mmdet - INFO - Epoch [2][300/673]	lr: 0.01000, eta: 1:52:49, time: 0.300, data_time: 0.013, memory: 4382, loss_ins: 1.2933, loss_cate: 0.2474, loss: 1.5407
2021-07-23 03:19:59,389 - mmdet - INFO - Epoch [2][350/673]	lr: 0.01000, eta: 1:52:43, time: 0.298, data_time: 0.012, memory: 4382, loss_ins: 1.3241, loss_cate: 0.2744, loss: 1.5984
2021-07-23 03:20:14,372 - mmdet - INFO - Epoch [2][400/673]	lr: 0.01000, eta: 1:52:37, time: 0.300, data_time: 0.012, memory: 4382, loss_ins: 1.3422, loss_cate: 0.2629, loss: 1.6051
2021-07-23 03:20:29,527 - mmdet - INFO - Epoch [2][450/673]	lr: 0.01000, eta: 1:52:34, time: 0.303, data_time: 0.012, memory: 4382, loss_ins: 1.3937, loss_cate: 0.2429, loss: 1.6365
2021-07-23 03:20:44,557 - mmdet - INFO - Epoch [2][500/673]	lr: 0.01000, eta: 1:52:28, time: 0.301, data_time: 0.012, memory: 4382, loss_ins: 1.3608, loss_cate: 0.2388, loss: 1.5996
2021-07-23 03:20:59,660 - mmdet - INFO - Epoch [2][550/673]	lr: 0.01000, eta: 1:52:22, time: 0.302, data_time: 0.012, memory: 4382, loss_ins: 1.3704, loss_cate: 0.3358, loss: 1.7061
2021-07-23 03:21:14,745 - mmdet - INFO - Epoch [2][600/673]	lr: 0.01000, eta: 1:52:15, time: 0.302, data_time: 0.013, memory: 4382, loss_ins: 1.4186, loss_cate: 0.2837, loss: 1.7023
2021-07-23 03:21:29,685 - mmdet - INFO - Epoch [2][650/673]	lr: 0.01000, eta: 1:52:05, time: 0.299, data_time: 0.012, memory: 4382, loss_ins: 1.3341, loss_cate: 0.2413, loss: 1.5754
2021-07-23 03:21:53,628 - mmdet - INFO - Epoch [3][50/673]	lr: 0.01000, eta: 1:49:57, time: 0.298, data_time: 0.018, memory: 4382, loss_ins: 1.2699, loss_cate: 0.2201, loss: 1.4901
2021-07-23 03:22:08,361 - mmdet - INFO - Epoch [3][100/673]	lr: 0.01000, eta: 1:49:47, time: 0.295, data_time: 0.013, memory: 4382, loss_ins: 1.3560, loss_cate: 0.2371, loss: 1.5931
2021-07-23 03:22:23,680 - mmdet - INFO - Epoch [3][150/673]	lr: 0.01000, eta: 1:49:45, time: 0.306, data_time: 0.014, memory: 4382, loss_ins: 1.3638, loss_cate: 0.2634, loss: 1.6272
2021-07-23 03:22:38,589 - mmdet - INFO - Epoch [3][200/673]	lr: 0.01000, eta: 1:49:37, time: 0.298, data_time: 0.013, memory: 4382, loss_ins: 1.2785, loss_cate: 0.2410, loss: 1.5195
2021-07-23 03:22:53,542 - mmdet - INFO - Epoch [3][250/673]	lr: 0.01000, eta: 1:49:29, time: 0.299, data_time: 0.013, memory: 4382, loss_ins: 1.3157, loss_cate: 0.2407, loss: 1.5564
2021-07-23 03:23:08,368 - mmdet - INFO - Epoch [3][300/673]	lr: 0.01000, eta: 1:49:19, time: 0.296, data_time: 0.013, memory: 4382, loss_ins: 1.3813, loss_cate: 0.2743, loss: 1.6556
2021-07-23 03:23:23,078 - mmdet - INFO - Epoch [3][350/673]	lr: 0.01000, eta: 1:49:07, time: 0.294, data_time: 0.013, memory: 4382, loss_ins: 1.3023, loss_cate: 0.2364, loss: 1.5387
2021-07-23 03:23:38,252 - mmdet - INFO - Epoch [3][400/673]	lr: 0.01000, eta: 1:49:01, time: 0.303, data_time: 0.013, memory: 4382, loss_ins: 1.3889, loss_cate: 0.2315, loss: 1.6205
2021-07-23 03:23:53,208 - mmdet - INFO - Epoch [3][450/673]	lr: 0.01000, eta: 1:48:51, time: 0.299, data_time: 0.013, memory: 4382, loss_ins: 1.3729, loss_cate: 0.2262, loss: 1.5991
2021-07-23 03:24:08,161 - mmdet - INFO - Epoch [3][500/673]	lr: 0.01000, eta: 1:48:41, time: 0.299, data_time: 0.013, memory: 4382, loss_ins: 1.2924, loss_cate: 0.2092, loss: 1.5016
2021-07-23 03:24:23,506 - mmdet - INFO - Epoch [3][550/673]	lr: 0.01000, eta: 1:48:36, time: 0.307, data_time: 0.013, memory: 4382, loss_ins: 1.3998, loss_cate: 0.2451, loss: 1.6449
2021-07-23 03:24:38,450 - mmdet - INFO - Epoch [3][600/673]	lr: 0.01000, eta: 1:48:25, time: 0.299, data_time: 0.013, memory: 4382, loss_ins: 1.3371, loss_cate: 0.2193, loss: 1.5563
2021-07-23 03:24:53,344 - mmdet - INFO - Epoch [3][650/673]	lr: 0.01000, eta: 1:48:14, time: 0.298, data_time: 0.012, memory: 4382, loss_ins: 1.2985, loss_cate: 0.2255, loss: 1.5241
2021-07-23 03:25:17,080 - mmdet - INFO - Epoch [4][50/673]	lr: 0.01000, eta: 1:46:44, time: 0.298, data_time: 0.018, memory: 4382, loss_ins: 1.3106, loss_cate: 0.2114, loss: 1.5220
2021-07-23 03:25:31,592 - mmdet - INFO - Epoch [4][100/673]	lr: 0.01000, eta: 1:46:30, time: 0.290, data_time: 0.013, memory: 4382, loss_ins: 1.2828, loss_cate: 0.2164, loss: 1.4991
2021-07-23 03:25:46,440 - mmdet - INFO - Epoch [4][150/673]	lr: 0.01000, eta: 1:46:20, time: 0.297, data_time: 0.013, memory: 4382, loss_ins: 1.3198, loss_cate: 0.2158, loss: 1.5357
2021-07-23 03:26:01,273 - mmdet - INFO - Epoch [4][200/673]	lr: 0.01000, eta: 1:46:09, time: 0.297, data_time: 0.013, memory: 4382, loss_ins: 1.3525, loss_cate: 0.2069, loss: 1.5595
2021-07-23 03:26:16,177 - mmdet - INFO - Epoch [4][250/673]	lr: 0.01000, eta: 1:45:59, time: 0.298, data_time: 0.013, memory: 4382, loss_ins: 1.4047, loss_cate: 0.2115, loss: 1.6162
2021-07-23 03:26:31,083 - mmdet - INFO - Epoch [4][300/673]	lr: 0.01000, eta: 1:45:48, time: 0.298, data_time: 0.013, memory: 4382, loss_ins: 1.3064, loss_cate: 0.2126, loss: 1.5190
2021-07-23 03:26:45,958 - mmdet - INFO - Epoch [4][350/673]	lr: 0.01000, eta: 1:45:37, time: 0.297, data_time: 0.011, memory: 4382, loss_ins: 1.3995, loss_cate: 0.2133, loss: 1.6128
2021-07-23 03:27:00,411 - mmdet - INFO - Epoch [4][400/673]	lr: 0.01000, eta: 1:45:22, time: 0.289, data_time: 0.011, memory: 4382, loss_ins: 1.3079, loss_cate: 0.2223, loss: 1.5302
2021-07-23 03:27:15,212 - mmdet - INFO - Epoch [4][450/673]	lr: 0.01000, eta: 1:45:10, time: 0.296, data_time: 0.012, memory: 4382, loss_ins: 1.2729, loss_cate: 0.1856, loss: 1.4585
2021-07-23 03:27:30,144 - mmdet - INFO - Epoch [4][500/673]	lr: 0.01000, eta: 1:45:00, time: 0.299, data_time: 0.013, memory: 4382, loss_ins: 1.3292, loss_cate: 0.2065, loss: 1.5357
2021-07-23 03:27:45,123 - mmdet - INFO - Epoch [4][550/673]	lr: 0.01000, eta: 1:44:49, time: 0.300, data_time: 0.012, memory: 4382, loss_ins: 1.3219, loss_cate: 0.2001, loss: 1.5219
2021-07-23 03:28:00,321 - mmdet - INFO - Epoch [4][600/673]	lr: 0.01000, eta: 1:44:40, time: 0.304, data_time: 0.013, memory: 4382, loss_ins: 1.4159, loss_cate: 0.2368, loss: 1.6527
2021-07-23 03:28:15,535 - mmdet - INFO - Epoch [4][650/673]	lr: 0.01000, eta: 1:44:31, time: 0.304, data_time: 0.014, memory: 4382, loss_ins: 1.4580, loss_cate: 0.2140, loss: 1.6720
2021-07-23 03:28:39,490 - mmdet - INFO - Epoch [5][50/673]	lr: 0.01000, eta: 1:43:22, time: 0.304, data_time: 0.020, memory: 4382, loss_ins: 1.2692, loss_cate: 0.1930, loss: 1.4622
2021-07-23 03:28:54,747 - mmdet - INFO - Epoch [5][100/673]	lr: 0.01000, eta: 1:43:14, time: 0.305, data_time: 0.015, memory: 4382, loss_ins: 1.3958, loss_cate: 0.1986, loss: 1.5943
2021-07-23 03:29:09,629 - mmdet - INFO - Epoch [5][150/673]	lr: 0.01000, eta: 1:43:03, time: 0.298, data_time: 0.013, memory: 4382, loss_ins: 1.3069, loss_cate: 0.2108, loss: 1.5176
2021-07-23 03:29:24,451 - mmdet - INFO - Epoch [5][200/673]	lr: 0.01000, eta: 1:42:51, time: 0.296, data_time: 0.013, memory: 4382, loss_ins: 1.3387, loss_cate: 0.2009, loss: 1.5396
2021-07-23 03:29:39,316 - mmdet - INFO - Epoch [5][250/673]	lr: 0.01000, eta: 1:42:40, time: 0.297, data_time: 0.013, memory: 4382, loss_ins: 1.2956, loss_cate: 0.1982, loss: 1.4938
2021-07-23 03:29:54,398 - mmdet - INFO - Epoch [5][300/673]	lr: 0.01000, eta: 1:42:30, time: 0.302, data_time: 0.014, memory: 4382, loss_ins: 1.4110, loss_cate: 0.1925, loss: 1.6035
2021-07-23 03:30:09,685 - mmdet - INFO - Epoch [5][350/673]	lr: 0.01000, eta: 1:42:21, time: 0.306, data_time: 0.013, memory: 4382, loss_ins: 1.4039, loss_cate: 0.2055, loss: 1.6094
2021-07-23 03:30:24,837 - mmdet - INFO - Epoch [5][400/673]	lr: 0.01000, eta: 1:42:11, time: 0.303, data_time: 0.012, memory: 4382, loss_ins: 1.4081, loss_cate: 0.1954, loss: 1.6035
2021-07-23 03:30:39,812 - mmdet - INFO - Epoch [5][450/673]	lr: 0.01000, eta: 1:41:59, time: 0.299, data_time: 0.013, memory: 4382, loss_ins: 1.3549, loss_cate: 0.2139, loss: 1.5688
2021-07-23 03:30:54,861 - mmdet - INFO - Epoch [5][500/673]	lr: 0.01000, eta: 1:41:49, time: 0.301, data_time: 0.013, memory: 4382, loss_ins: 1.2752, loss_cate: 0.1832, loss: 1.4584
2021-07-23 03:31:10,116 - mmdet - INFO - Epoch [5][550/673]	lr: 0.01000, eta: 1:41:39, time: 0.305, data_time: 0.014, memory: 4382, loss_ins: 1.3931, loss_cate: 0.1895, loss: 1.5826
2021-07-23 03:31:25,195 - mmdet - INFO - Epoch [5][600/673]	lr: 0.01000, eta: 1:41:28, time: 0.302, data_time: 0.013, memory: 4382, loss_ins: 1.3464, loss_cate: 0.1833, loss: 1.5297
2021-07-23 03:31:40,436 - mmdet - INFO - Epoch [5][650/673]	lr: 0.01000, eta: 1:41:18, time: 0.305, data_time: 0.013, memory: 4382, loss_ins: 1.3774, loss_cate: 0.1974, loss: 1.5748
2021-07-23 03:32:04,422 - mmdet - INFO - Epoch [6][50/673]	lr: 0.01000, eta: 1:40:18, time: 0.301, data_time: 0.017, memory: 4382, loss_ins: 1.2715, loss_cate: 0.1835, loss: 1.4550
2021-07-23 03:32:19,365 - mmdet - INFO - Epoch [6][100/673]	lr: 0.01000, eta: 1:40:07, time: 0.299, data_time: 0.014, memory: 4382, loss_ins: 1.3115, loss_cate: 0.1783, loss: 1.4899
2021-07-23 03:32:34,708 - mmdet - INFO - Epoch [6][150/673]	lr: 0.01000, eta: 1:39:58, time: 0.307, data_time: 0.014, memory: 4382, loss_ins: 1.3413, loss_cate: 0.1931, loss: 1.5344
2021-07-23 03:32:49,682 - mmdet - INFO - Epoch [6][200/673]	lr: 0.01000, eta: 1:39:46, time: 0.299, data_time: 0.013, memory: 4382, loss_ins: 1.2555, loss_cate: 0.1757, loss: 1.4312
2021-07-23 03:33:04,815 - mmdet - INFO - Epoch [6][250/673]	lr: 0.01000, eta: 1:39:35, time: 0.303, data_time: 0.014, memory: 4382, loss_ins: 1.3069, loss_cate: 0.1773, loss: 1.4841
2021-07-23 03:33:19,874 - mmdet - INFO - Epoch [6][300/673]	lr: 0.01000, eta: 1:39:24, time: 0.301, data_time: 0.013, memory: 4382, loss_ins: 1.3419, loss_cate: 0.1859, loss: 1.5278
2021-07-23 03:33:35,200 - mmdet - INFO - Epoch [6][350/673]	lr: 0.01000, eta: 1:39:14, time: 0.306, data_time: 0.013, memory: 4382, loss_ins: 1.3406, loss_cate: 0.1953, loss: 1.5359
2021-07-23 03:33:50,351 - mmdet - INFO - Epoch [6][400/673]	lr: 0.01000, eta: 1:39:03, time: 0.303, data_time: 0.013, memory: 4382, loss_ins: 1.2711, loss_cate: 0.1964, loss: 1.4675
Process Process-12:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.6/multiprocessing/process.py", line 261, in _bootstrap
    util._exit_function()
  File "/opt/conda/lib/python3.6/multiprocessing/util.py", line 322, in _exit_function
    _run_finalizers()
  File "/opt/conda/lib/python3.6/multiprocessing/util.py", line 262, in _run_finalizers
    finalizer()
  File "/opt/conda/lib/python3.6/multiprocessing/util.py", line 186, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/opt/conda/lib/python3.6/multiprocessing/queues.py", line 191, in _finalize_join
    thread.join()
  File "/opt/conda/lib/python3.6/threading.py", line 1056, in join
    self._wait_for_tstate_lock()
  File "/opt/conda/lib/python3.6/threading.py", line 1072, in _wait_for_tstate_lock
    elif lock.acquire(block, timeout):
KeyboardInterrupt
Process Process-11:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.6/multiprocessing/process.py", line 261, in _bootstrap
    util._exit_function()
  File "/opt/conda/lib/python3.6/multiprocessing/util.py", line 322, in _exit_function
    _run_finalizers()
  File "/opt/conda/lib/python3.6/multiprocessing/util.py", line 262, in _run_finalizers
    finalizer()
  File "/opt/conda/lib/python3.6/multiprocessing/util.py", line 186, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/opt/conda/lib/python3.6/multiprocessing/queues.py", line 191, in _finalize_join
    thread.join()
  File "/opt/conda/lib/python3.6/threading.py", line 1056, in join
    self._wait_for_tstate_lock()
  File "/opt/conda/lib/python3.6/threading.py", line 1072, in _wait_for_tstate_lock
    elif lock.acquire(block, timeout):
KeyboardInterrupt
Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f4822163710>>
Traceback (most recent call last):
  File "/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 926, in __del__
    self._shutdown_workers()
  File "/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 906, in _shutdown_workers
    w.join()
  File "/opt/conda/lib/python3.6/multiprocessing/process.py", line 124, in join
    res = self._popen.wait(timeout)
  File "/opt/conda/lib/python3.6/multiprocessing/popen_fork.py", line 50, in wait
    return self.poll(os.WNOHANG if timeout == 0.0 else 0)
  File "/opt/conda/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
KeyboardInterrupt: 
Traceback (most recent call last):
  File "tools/train.py", line 133, in <module>
    main()
  File "tools/train.py", line 129, in main
    timestamp=timestamp)
  File "/home/zq/work/SOLO/mmdet/apis/train.py", line 111, in train_detector
    timestamp=timestamp)
  File "/home/zq/work/SOLO/mmdet/apis/train.py", line 297, in _non_dist_train
    runner.run(data_loaders, cfg.workflow, cfg.total_epochs)
  File "/opt/conda/lib/python3.6/site-packages/mmcv/runner/runner.py", line 364, in run
    epoch_runner(data_loaders[i], **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/mmcv/runner/runner.py", line 275, in train
    self.call_hook('after_train_iter')
  File "/opt/conda/lib/python3.6/site-packages/mmcv/runner/runner.py", line 231, in call_hook
    getattr(hook, fn_name)(self)
  File "/opt/conda/lib/python3.6/site-packages/mmcv/runner/hooks/optimizer.py", line 20, in after_train_iter
    self.clip_grads(runner.model.parameters())
  File "/opt/conda/lib/python3.6/site-packages/mmcv/runner/hooks/optimizer.py", line 14, in clip_grads
    filter(lambda p: p.requires_grad, params), **self.grad_clip)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/utils/clip_grad.py", line 33, in clip_grad_norm_
    total_norm += param_norm.item() ** norm_type
KeyboardInterrupt
2021-07-23 03:34:37,018 - mmdet - INFO - Distributed training: False
2021-07-23 03:34:37,019 - mmdet - INFO - MMDetection Version: 1.0.0+c7b294a
2021-07-23 03:34:37,019 - mmdet - INFO - Config:
# model settings
model = dict(
    type='SOLOv2',
    pretrained='torchvision://resnet50',
    backbone=dict(
        type='ResNet',
        depth=50,
        num_stages=4,
        out_indices=(0, 1, 2, 3),  # C2, C3, C4, C5
        frozen_stages=1,
        style='pytorch'),
    neck=dict(
        type='FPN',
        in_channels=[256, 512, 1024, 2048],
        out_channels=256,
        start_level=0,
        num_outs=5),
    bbox_head=dict(
        type='SOLOv2Head',
        num_classes=2,
        in_channels=256,
        stacked_convs=4,
        seg_feat_channels=512,
        strides=[8, 8, 16, 32, 32],
        # scale_ranges=((1, 96), (48, 192), (96, 384), (192, 768), (384, 2048)),
        scale_ranges=((1, 250), (125, 500), (250, 1000), (500, 2000)),
        sigma=0.2,
        num_grids=[40, 36, 24, 16, 12],
        ins_out_channels=256,
        loss_ins=dict(
            type='DiceLoss',
            use_sigmoid=True,
            loss_weight=3.0),
        # loss_weight=10.0),
        loss_cate=dict(
            type='FocalLoss',
            use_sigmoid=True,
            gamma=2.0,
            alpha=0.25,
            loss_weight=1.0)),
    mask_feat_head=dict(
        type='MaskFeatHead',
        in_channels=256,
        out_channels=128,
        start_level=0,
        end_level=3,
        num_classes=256,
        norm_cfg=dict(type='GN', num_groups=32, requires_grad=True)),
)
# training and testing settings
train_cfg = dict()
test_cfg = dict(
    nms_pre=500,
    score_thr=0.1,
    mask_thr=0.5,
    update_thr=0.05,
    kernel='gaussian',  # gaussian/linear
    sigma=2.0,
    max_per_img=100)
# dataset settings
dataset_type = 'CocoDataset'
data_root = 'data/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),
    dict(type='Resize',
         img_scale=[(1333, 800), (1333, 768), (1333, 736),
                    (1333, 704), (1333, 672), (1333, 640)],
         multiscale_mode='value',
         keep_ratio=True),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(type='Normalize', **img_norm_cfg),
    dict(type='Pad', size_divisor=32),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks']),
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(1333, 800),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(type='Normalize', **img_norm_cfg),
            dict(type='Pad', size_divisor=32),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img']),
        ])
]
data = dict(
    imgs_per_gpu=2,
    workers_per_gpu=2,
    train=dict(
        type=dataset_type,
        ann_file=data_root + 'annotation/merge/merge_train_coco.json',
        img_prefix=data_root + 'road/train/',
        pipeline=train_pipeline),
    val=dict(
        type=dataset_type,
        ann_file=data_root + 'annotation/merge/merge_val_coco.json',
        img_prefix=data_root + 'road/val/',
        pipeline=test_pipeline),
    test=dict(
        type=dataset_type,
        ann_file=data_root + 'annotation/merge/merge_val_coco.json',
        img_prefix=data_root + 'road/val/',
        pipeline=test_pipeline))
# optimizer
optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0001)
optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))
# learning policy
lr_config = dict(
    policy='step',
    warmup='linear',
    warmup_iters=500,
    warmup_ratio=0.01,
    step=[27, 33])
checkpoint_config = dict(interval=1)
# yapf:disable
log_config = dict(
    interval=50,
    hooks=[
        dict(type='TextLoggerHook'),
        # dict(type='TensorboardLoggerHook')
    ])
# yapf:enable
# runtime settings
total_epochs = 36
device_ids = range(8)
dist_params = dict(backend='nccl')
log_level = 'INFO'
work_dir = './work_dirs/solov2_release_r50_fpn_8gpu_3x'
# work_dir = './work_dirs/solov2_release_r50_fpn_8gpu_3x_scale'
# work_dir = './work_dirs/solov2_release_r50_fpn_8gpu_3x_weight'
# work_dir = './work_dirs/solov2_release_r50_fpn_8gpu_3x_workflow'
# work_dir = './work_dirs/solov2_release_r50_fpn_8gpu_3x_validate'

load_from = None
resume_from = None
workflow = [('train', 1)]

2021-07-23 03:34:37,396 - mmdet - INFO - load model from: torchvision://resnet50
2021-07-23 03:34:39,688 - mmdet - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: backbone.conv1.weight, backbone.bn1.weight, backbone.bn1.bias, backbone.bn1.running_mean, backbone.bn1.running_var, backbone.bn1.num_batches_tracked, backbone.layer1.0.conv1.weight, backbone.layer1.0.bn1.weight, backbone.layer1.0.bn1.bias, backbone.layer1.0.bn1.running_mean, backbone.layer1.0.bn1.running_var, backbone.layer1.0.bn1.num_batches_tracked, backbone.layer1.0.conv2.weight, backbone.layer1.0.bn2.weight, backbone.layer1.0.bn2.bias, backbone.layer1.0.bn2.running_mean, backbone.layer1.0.bn2.running_var, backbone.layer1.0.bn2.num_batches_tracked, backbone.layer1.0.conv3.weight, backbone.layer1.0.bn3.weight, backbone.layer1.0.bn3.bias, backbone.layer1.0.bn3.running_mean, backbone.layer1.0.bn3.running_var, backbone.layer1.0.bn3.num_batches_tracked, backbone.layer1.0.downsample.0.weight, backbone.layer1.0.downsample.1.weight, backbone.layer1.0.downsample.1.bias, backbone.layer1.0.downsample.1.running_mean, backbone.layer1.0.downsample.1.running_var, backbone.layer1.0.downsample.1.num_batches_tracked, backbone.layer1.1.conv1.weight, backbone.layer1.1.bn1.weight, backbone.layer1.1.bn1.bias, backbone.layer1.1.bn1.running_mean, backbone.layer1.1.bn1.running_var, backbone.layer1.1.bn1.num_batches_tracked, backbone.layer1.1.conv2.weight, backbone.layer1.1.bn2.weight, backbone.layer1.1.bn2.bias, backbone.layer1.1.bn2.running_mean, backbone.layer1.1.bn2.running_var, backbone.layer1.1.bn2.num_batches_tracked, backbone.layer1.1.conv3.weight, backbone.layer1.1.bn3.weight, backbone.layer1.1.bn3.bias, backbone.layer1.1.bn3.running_mean, backbone.layer1.1.bn3.running_var, backbone.layer1.1.bn3.num_batches_tracked, backbone.layer1.2.conv1.weight, backbone.layer1.2.bn1.weight, backbone.layer1.2.bn1.bias, backbone.layer1.2.bn1.running_mean, backbone.layer1.2.bn1.running_var, backbone.layer1.2.bn1.num_batches_tracked, backbone.layer1.2.conv2.weight, backbone.layer1.2.bn2.weight, backbone.layer1.2.bn2.bias, backbone.layer1.2.bn2.running_mean, backbone.layer1.2.bn2.running_var, backbone.layer1.2.bn2.num_batches_tracked, backbone.layer1.2.conv3.weight, backbone.layer1.2.bn3.weight, backbone.layer1.2.bn3.bias, backbone.layer1.2.bn3.running_mean, backbone.layer1.2.bn3.running_var, backbone.layer1.2.bn3.num_batches_tracked, backbone.layer2.0.conv1.weight, backbone.layer2.0.bn1.weight, backbone.layer2.0.bn1.bias, backbone.layer2.0.bn1.running_mean, backbone.layer2.0.bn1.running_var, backbone.layer2.0.bn1.num_batches_tracked, backbone.layer2.0.conv2.weight, backbone.layer2.0.bn2.weight, backbone.layer2.0.bn2.bias, backbone.layer2.0.bn2.running_mean, backbone.layer2.0.bn2.running_var, backbone.layer2.0.bn2.num_batches_tracked, backbone.layer2.0.conv3.weight, backbone.layer2.0.bn3.weight, backbone.layer2.0.bn3.bias, backbone.layer2.0.bn3.running_mean, backbone.layer2.0.bn3.running_var, backbone.layer2.0.bn3.num_batches_tracked, backbone.layer2.0.downsample.0.weight, backbone.layer2.0.downsample.1.weight, backbone.layer2.0.downsample.1.bias, backbone.layer2.0.downsample.1.running_mean, backbone.layer2.0.downsample.1.running_var, backbone.layer2.0.downsample.1.num_batches_tracked, backbone.layer2.1.conv1.weight, backbone.layer2.1.bn1.weight, backbone.layer2.1.bn1.bias, backbone.layer2.1.bn1.running_mean, backbone.layer2.1.bn1.running_var, backbone.layer2.1.bn1.num_batches_tracked, backbone.layer2.1.conv2.weight, backbone.layer2.1.bn2.weight, backbone.layer2.1.bn2.bias, backbone.layer2.1.bn2.running_mean, backbone.layer2.1.bn2.running_var, backbone.layer2.1.bn2.num_batches_tracked, backbone.layer2.1.conv3.weight, backbone.layer2.1.bn3.weight, backbone.layer2.1.bn3.bias, backbone.layer2.1.bn3.running_mean, backbone.layer2.1.bn3.running_var, backbone.layer2.1.bn3.num_batches_tracked, backbone.layer2.2.conv1.weight, backbone.layer2.2.bn1.weight, backbone.layer2.2.bn1.bias, backbone.layer2.2.bn1.running_mean, backbone.layer2.2.bn1.running_var, backbone.layer2.2.bn1.num_batches_tracked, backbone.layer2.2.conv2.weight, backbone.layer2.2.bn2.weight, backbone.layer2.2.bn2.bias, backbone.layer2.2.bn2.running_mean, backbone.layer2.2.bn2.running_var, backbone.layer2.2.bn2.num_batches_tracked, backbone.layer2.2.conv3.weight, backbone.layer2.2.bn3.weight, backbone.layer2.2.bn3.bias, backbone.layer2.2.bn3.running_mean, backbone.layer2.2.bn3.running_var, backbone.layer2.2.bn3.num_batches_tracked, backbone.layer2.3.conv1.weight, backbone.layer2.3.bn1.weight, backbone.layer2.3.bn1.bias, backbone.layer2.3.bn1.running_mean, backbone.layer2.3.bn1.running_var, backbone.layer2.3.bn1.num_batches_tracked, backbone.layer2.3.conv2.weight, backbone.layer2.3.bn2.weight, backbone.layer2.3.bn2.bias, backbone.layer2.3.bn2.running_mean, backbone.layer2.3.bn2.running_var, backbone.layer2.3.bn2.num_batches_tracked, backbone.layer2.3.conv3.weight, backbone.layer2.3.bn3.weight, backbone.layer2.3.bn3.bias, backbone.layer2.3.bn3.running_mean, backbone.layer2.3.bn3.running_var, backbone.layer2.3.bn3.num_batches_tracked, backbone.layer3.0.conv1.weight, backbone.layer3.0.bn1.weight, backbone.layer3.0.bn1.bias, backbone.layer3.0.bn1.running_mean, backbone.layer3.0.bn1.running_var, backbone.layer3.0.bn1.num_batches_tracked, backbone.layer3.0.conv2.weight, backbone.layer3.0.bn2.weight, backbone.layer3.0.bn2.bias, backbone.layer3.0.bn2.running_mean, backbone.layer3.0.bn2.running_var, backbone.layer3.0.bn2.num_batches_tracked, backbone.layer3.0.conv3.weight, backbone.layer3.0.bn3.weight, backbone.layer3.0.bn3.bias, backbone.layer3.0.bn3.running_mean, backbone.layer3.0.bn3.running_var, backbone.layer3.0.bn3.num_batches_tracked, backbone.layer3.0.downsample.0.weight, backbone.layer3.0.downsample.1.weight, backbone.layer3.0.downsample.1.bias, backbone.layer3.0.downsample.1.running_mean, backbone.layer3.0.downsample.1.running_var, backbone.layer3.0.downsample.1.num_batches_tracked, backbone.layer3.1.conv1.weight, backbone.layer3.1.bn1.weight, backbone.layer3.1.bn1.bias, backbone.layer3.1.bn1.running_mean, backbone.layer3.1.bn1.running_var, backbone.layer3.1.bn1.num_batches_tracked, backbone.layer3.1.conv2.weight, backbone.layer3.1.bn2.weight, backbone.layer3.1.bn2.bias, backbone.layer3.1.bn2.running_mean, backbone.layer3.1.bn2.running_var, backbone.layer3.1.bn2.num_batches_tracked, backbone.layer3.1.conv3.weight, backbone.layer3.1.bn3.weight, backbone.layer3.1.bn3.bias, backbone.layer3.1.bn3.running_mean, backbone.layer3.1.bn3.running_var, backbone.layer3.1.bn3.num_batches_tracked, backbone.layer3.2.conv1.weight, backbone.layer3.2.bn1.weight, backbone.layer3.2.bn1.bias, backbone.layer3.2.bn1.running_mean, backbone.layer3.2.bn1.running_var, backbone.layer3.2.bn1.num_batches_tracked, backbone.layer3.2.conv2.weight, backbone.layer3.2.bn2.weight, backbone.layer3.2.bn2.bias, backbone.layer3.2.bn2.running_mean, backbone.layer3.2.bn2.running_var, backbone.layer3.2.bn2.num_batches_tracked, backbone.layer3.2.conv3.weight, backbone.layer3.2.bn3.weight, backbone.layer3.2.bn3.bias, backbone.layer3.2.bn3.running_mean, backbone.layer3.2.bn3.running_var, backbone.layer3.2.bn3.num_batches_tracked, backbone.layer3.3.conv1.weight, backbone.layer3.3.bn1.weight, backbone.layer3.3.bn1.bias, backbone.layer3.3.bn1.running_mean, backbone.layer3.3.bn1.running_var, backbone.layer3.3.bn1.num_batches_tracked, backbone.layer3.3.conv2.weight, backbone.layer3.3.bn2.weight, backbone.layer3.3.bn2.bias, backbone.layer3.3.bn2.running_mean, backbone.layer3.3.bn2.running_var, backbone.layer3.3.bn2.num_batches_tracked, backbone.layer3.3.conv3.weight, backbone.layer3.3.bn3.weight, backbone.layer3.3.bn3.bias, backbone.layer3.3.bn3.running_mean, backbone.layer3.3.bn3.running_var, backbone.layer3.3.bn3.num_batches_tracked, backbone.layer3.4.conv1.weight, backbone.layer3.4.bn1.weight, backbone.layer3.4.bn1.bias, backbone.layer3.4.bn1.running_mean, backbone.layer3.4.bn1.running_var, backbone.layer3.4.bn1.num_batches_tracked, backbone.layer3.4.conv2.weight, backbone.layer3.4.bn2.weight, backbone.layer3.4.bn2.bias, backbone.layer3.4.bn2.running_mean, backbone.layer3.4.bn2.running_var, backbone.layer3.4.bn2.num_batches_tracked, backbone.layer3.4.conv3.weight, backbone.layer3.4.bn3.weight, backbone.layer3.4.bn3.bias, backbone.layer3.4.bn3.running_mean, backbone.layer3.4.bn3.running_var, backbone.layer3.4.bn3.num_batches_tracked, backbone.layer3.5.conv1.weight, backbone.layer3.5.bn1.weight, backbone.layer3.5.bn1.bias, backbone.layer3.5.bn1.running_mean, backbone.layer3.5.bn1.running_var, backbone.layer3.5.bn1.num_batches_tracked, backbone.layer3.5.conv2.weight, backbone.layer3.5.bn2.weight, backbone.layer3.5.bn2.bias, backbone.layer3.5.bn2.running_mean, backbone.layer3.5.bn2.running_var, backbone.layer3.5.bn2.num_batches_tracked, backbone.layer3.5.conv3.weight, backbone.layer3.5.bn3.weight, backbone.layer3.5.bn3.bias, backbone.layer3.5.bn3.running_mean, backbone.layer3.5.bn3.running_var, backbone.layer3.5.bn3.num_batches_tracked, backbone.layer4.0.conv1.weight, backbone.layer4.0.bn1.weight, backbone.layer4.0.bn1.bias, backbone.layer4.0.bn1.running_mean, backbone.layer4.0.bn1.running_var, backbone.layer4.0.bn1.num_batches_tracked, backbone.layer4.0.conv2.weight, backbone.layer4.0.bn2.weight, backbone.layer4.0.bn2.bias, backbone.layer4.0.bn2.running_mean, backbone.layer4.0.bn2.running_var, backbone.layer4.0.bn2.num_batches_tracked, backbone.layer4.0.conv3.weight, backbone.layer4.0.bn3.weight, backbone.layer4.0.bn3.bias, backbone.layer4.0.bn3.running_mean, backbone.layer4.0.bn3.running_var, backbone.layer4.0.bn3.num_batches_tracked, backbone.layer4.0.downsample.0.weight, backbone.layer4.0.downsample.1.weight, backbone.layer4.0.downsample.1.bias, backbone.layer4.0.downsample.1.running_mean, backbone.layer4.0.downsample.1.running_var, backbone.layer4.0.downsample.1.num_batches_tracked, backbone.layer4.1.conv1.weight, backbone.layer4.1.bn1.weight, backbone.layer4.1.bn1.bias, backbone.layer4.1.bn1.running_mean, backbone.layer4.1.bn1.running_var, backbone.layer4.1.bn1.num_batches_tracked, backbone.layer4.1.conv2.weight, backbone.layer4.1.bn2.weight, backbone.layer4.1.bn2.bias, backbone.layer4.1.bn2.running_mean, backbone.layer4.1.bn2.running_var, backbone.layer4.1.bn2.num_batches_tracked, backbone.layer4.1.conv3.weight, backbone.layer4.1.bn3.weight, backbone.layer4.1.bn3.bias, backbone.layer4.1.bn3.running_mean, backbone.layer4.1.bn3.running_var, backbone.layer4.1.bn3.num_batches_tracked, backbone.layer4.2.conv1.weight, backbone.layer4.2.bn1.weight, backbone.layer4.2.bn1.bias, backbone.layer4.2.bn1.running_mean, backbone.layer4.2.bn1.running_var, backbone.layer4.2.bn1.num_batches_tracked, backbone.layer4.2.conv2.weight, backbone.layer4.2.bn2.weight, backbone.layer4.2.bn2.bias, backbone.layer4.2.bn2.running_mean, backbone.layer4.2.bn2.running_var, backbone.layer4.2.bn2.num_batches_tracked, backbone.layer4.2.conv3.weight, backbone.layer4.2.bn3.weight, backbone.layer4.2.bn3.bias, backbone.layer4.2.bn3.running_mean, backbone.layer4.2.bn3.running_var, backbone.layer4.2.bn3.num_batches_tracked, neck.lateral_convs.0.conv.weight, neck.lateral_convs.0.conv.bias, neck.lateral_convs.1.conv.weight, neck.lateral_convs.1.conv.bias, neck.lateral_convs.2.conv.weight, neck.lateral_convs.2.conv.bias, neck.lateral_convs.3.conv.weight, neck.lateral_convs.3.conv.bias, neck.fpn_convs.0.conv.weight, neck.fpn_convs.0.conv.bias, neck.fpn_convs.1.conv.weight, neck.fpn_convs.1.conv.bias, neck.fpn_convs.2.conv.weight, neck.fpn_convs.2.conv.bias, neck.fpn_convs.3.conv.weight, neck.fpn_convs.3.conv.bias, mask_feat_head.convs_all_levels.0.conv0.conv.weight, mask_feat_head.convs_all_levels.0.conv0.gn.weight, mask_feat_head.convs_all_levels.0.conv0.gn.bias, mask_feat_head.convs_all_levels.1.conv0.conv.weight, mask_feat_head.convs_all_levels.1.conv0.gn.weight, mask_feat_head.convs_all_levels.1.conv0.gn.bias, mask_feat_head.convs_all_levels.2.conv0.conv.weight, mask_feat_head.convs_all_levels.2.conv0.gn.weight, mask_feat_head.convs_all_levels.2.conv0.gn.bias, mask_feat_head.convs_all_levels.2.conv1.conv.weight, mask_feat_head.convs_all_levels.2.conv1.gn.weight, mask_feat_head.convs_all_levels.2.conv1.gn.bias, mask_feat_head.convs_all_levels.3.conv0.conv.weight, mask_feat_head.convs_all_levels.3.conv0.gn.weight, mask_feat_head.convs_all_levels.3.conv0.gn.bias, mask_feat_head.convs_all_levels.3.conv1.conv.weight, mask_feat_head.convs_all_levels.3.conv1.gn.weight, mask_feat_head.convs_all_levels.3.conv1.gn.bias, mask_feat_head.convs_all_levels.3.conv2.conv.weight, mask_feat_head.convs_all_levels.3.conv2.gn.weight, mask_feat_head.convs_all_levels.3.conv2.gn.bias, mask_feat_head.conv_pred.0.conv.weight, mask_feat_head.conv_pred.0.gn.weight, mask_feat_head.conv_pred.0.gn.bias, bbox_head.cate_convs.0.conv.weight, bbox_head.cate_convs.0.gn.weight, bbox_head.cate_convs.0.gn.bias, bbox_head.cate_convs.1.conv.weight, bbox_head.cate_convs.1.gn.weight, bbox_head.cate_convs.1.gn.bias, bbox_head.cate_convs.2.conv.weight, bbox_head.cate_convs.2.gn.weight, bbox_head.cate_convs.2.gn.bias, bbox_head.cate_convs.3.conv.weight, bbox_head.cate_convs.3.gn.weight, bbox_head.cate_convs.3.gn.bias, bbox_head.kernel_convs.0.conv.weight, bbox_head.kernel_convs.0.gn.weight, bbox_head.kernel_convs.0.gn.bias, bbox_head.kernel_convs.1.conv.weight, bbox_head.kernel_convs.1.gn.weight, bbox_head.kernel_convs.1.gn.bias, bbox_head.kernel_convs.2.conv.weight, bbox_head.kernel_convs.2.gn.weight, bbox_head.kernel_convs.2.gn.bias, bbox_head.kernel_convs.3.conv.weight, bbox_head.kernel_convs.3.gn.weight, bbox_head.kernel_convs.3.gn.bias, bbox_head.solo_cate.weight, bbox_head.solo_cate.bias, bbox_head.solo_kernel.weight, bbox_head.solo_kernel.bias

missing keys in source state_dict: conv1.weight, bn1.weight, bn1.bias, bn1.running_mean, bn1.running_var, layer1.0.conv1.weight, layer1.0.bn1.weight, layer1.0.bn1.bias, layer1.0.bn1.running_mean, layer1.0.bn1.running_var, layer1.0.conv2.weight, layer1.0.bn2.weight, layer1.0.bn2.bias, layer1.0.bn2.running_mean, layer1.0.bn2.running_var, layer1.0.conv3.weight, layer1.0.bn3.weight, layer1.0.bn3.bias, layer1.0.bn3.running_mean, layer1.0.bn3.running_var, layer1.0.downsample.0.weight, layer1.0.downsample.1.weight, layer1.0.downsample.1.bias, layer1.0.downsample.1.running_mean, layer1.0.downsample.1.running_var, layer1.1.conv1.weight, layer1.1.bn1.weight, layer1.1.bn1.bias, layer1.1.bn1.running_mean, layer1.1.bn1.running_var, layer1.1.conv2.weight, layer1.1.bn2.weight, layer1.1.bn2.bias, layer1.1.bn2.running_mean, layer1.1.bn2.running_var, layer1.1.conv3.weight, layer1.1.bn3.weight, layer1.1.bn3.bias, layer1.1.bn3.running_mean, layer1.1.bn3.running_var, layer1.2.conv1.weight, layer1.2.bn1.weight, layer1.2.bn1.bias, layer1.2.bn1.running_mean, layer1.2.bn1.running_var, layer1.2.conv2.weight, layer1.2.bn2.weight, layer1.2.bn2.bias, layer1.2.bn2.running_mean, layer1.2.bn2.running_var, layer1.2.conv3.weight, layer1.2.bn3.weight, layer1.2.bn3.bias, layer1.2.bn3.running_mean, layer1.2.bn3.running_var, layer2.0.conv1.weight, layer2.0.bn1.weight, layer2.0.bn1.bias, layer2.0.bn1.running_mean, layer2.0.bn1.running_var, layer2.0.conv2.weight, layer2.0.bn2.weight, layer2.0.bn2.bias, layer2.0.bn2.running_mean, layer2.0.bn2.running_var, layer2.0.conv3.weight, layer2.0.bn3.weight, layer2.0.bn3.bias, layer2.0.bn3.running_mean, layer2.0.bn3.running_var, layer2.0.downsample.0.weight, layer2.0.downsample.1.weight, layer2.0.downsample.1.bias, layer2.0.downsample.1.running_mean, layer2.0.downsample.1.running_var, layer2.1.conv1.weight, layer2.1.bn1.weight, layer2.1.bn1.bias, layer2.1.bn1.running_mean, layer2.1.bn1.running_var, layer2.1.conv2.weight, layer2.1.bn2.weight, layer2.1.bn2.bias, layer2.1.bn2.running_mean, layer2.1.bn2.running_var, layer2.1.conv3.weight, layer2.1.bn3.weight, layer2.1.bn3.bias, layer2.1.bn3.running_mean, layer2.1.bn3.running_var, layer2.2.conv1.weight, layer2.2.bn1.weight, layer2.2.bn1.bias, layer2.2.bn1.running_mean, layer2.2.bn1.running_var, layer2.2.conv2.weight, layer2.2.bn2.weight, layer2.2.bn2.bias, layer2.2.bn2.running_mean, layer2.2.bn2.running_var, layer2.2.conv3.weight, layer2.2.bn3.weight, layer2.2.bn3.bias, layer2.2.bn3.running_mean, layer2.2.bn3.running_var, layer2.3.conv1.weight, layer2.3.bn1.weight, layer2.3.bn1.bias, layer2.3.bn1.running_mean, layer2.3.bn1.running_var, layer2.3.conv2.weight, layer2.3.bn2.weight, layer2.3.bn2.bias, layer2.3.bn2.running_mean, layer2.3.bn2.running_var, layer2.3.conv3.weight, layer2.3.bn3.weight, layer2.3.bn3.bias, layer2.3.bn3.running_mean, layer2.3.bn3.running_var, layer3.0.conv1.weight, layer3.0.bn1.weight, layer3.0.bn1.bias, layer3.0.bn1.running_mean, layer3.0.bn1.running_var, layer3.0.conv2.weight, layer3.0.bn2.weight, layer3.0.bn2.bias, layer3.0.bn2.running_mean, layer3.0.bn2.running_var, layer3.0.conv3.weight, layer3.0.bn3.weight, layer3.0.bn3.bias, layer3.0.bn3.running_mean, layer3.0.bn3.running_var, layer3.0.downsample.0.weight, layer3.0.downsample.1.weight, layer3.0.downsample.1.bias, layer3.0.downsample.1.running_mean, layer3.0.downsample.1.running_var, layer3.1.conv1.weight, layer3.1.bn1.weight, layer3.1.bn1.bias, layer3.1.bn1.running_mean, layer3.1.bn1.running_var, layer3.1.conv2.weight, layer3.1.bn2.weight, layer3.1.bn2.bias, layer3.1.bn2.running_mean, layer3.1.bn2.running_var, layer3.1.conv3.weight, layer3.1.bn3.weight, layer3.1.bn3.bias, layer3.1.bn3.running_mean, layer3.1.bn3.running_var, layer3.2.conv1.weight, layer3.2.bn1.weight, layer3.2.bn1.bias, layer3.2.bn1.running_mean, layer3.2.bn1.running_var, layer3.2.conv2.weight, layer3.2.bn2.weight, layer3.2.bn2.bias, layer3.2.bn2.running_mean, layer3.2.bn2.running_var, layer3.2.conv3.weight, layer3.2.bn3.weight, layer3.2.bn3.bias, layer3.2.bn3.running_mean, layer3.2.bn3.running_var, layer3.3.conv1.weight, layer3.3.bn1.weight, layer3.3.bn1.bias, layer3.3.bn1.running_mean, layer3.3.bn1.running_var, layer3.3.conv2.weight, layer3.3.bn2.weight, layer3.3.bn2.bias, layer3.3.bn2.running_mean, layer3.3.bn2.running_var, layer3.3.conv3.weight, layer3.3.bn3.weight, layer3.3.bn3.bias, layer3.3.bn3.running_mean, layer3.3.bn3.running_var, layer3.4.conv1.weight, layer3.4.bn1.weight, layer3.4.bn1.bias, layer3.4.bn1.running_mean, layer3.4.bn1.running_var, layer3.4.conv2.weight, layer3.4.bn2.weight, layer3.4.bn2.bias, layer3.4.bn2.running_mean, layer3.4.bn2.running_var, layer3.4.conv3.weight, layer3.4.bn3.weight, layer3.4.bn3.bias, layer3.4.bn3.running_mean, layer3.4.bn3.running_var, layer3.5.conv1.weight, layer3.5.bn1.weight, layer3.5.bn1.bias, layer3.5.bn1.running_mean, layer3.5.bn1.running_var, layer3.5.conv2.weight, layer3.5.bn2.weight, layer3.5.bn2.bias, layer3.5.bn2.running_mean, layer3.5.bn2.running_var, layer3.5.conv3.weight, layer3.5.bn3.weight, layer3.5.bn3.bias, layer3.5.bn3.running_mean, layer3.5.bn3.running_var, layer4.0.conv1.weight, layer4.0.bn1.weight, layer4.0.bn1.bias, layer4.0.bn1.running_mean, layer4.0.bn1.running_var, layer4.0.conv2.weight, layer4.0.bn2.weight, layer4.0.bn2.bias, layer4.0.bn2.running_mean, layer4.0.bn2.running_var, layer4.0.conv3.weight, layer4.0.bn3.weight, layer4.0.bn3.bias, layer4.0.bn3.running_mean, layer4.0.bn3.running_var, layer4.0.downsample.0.weight, layer4.0.downsample.1.weight, layer4.0.downsample.1.bias, layer4.0.downsample.1.running_mean, layer4.0.downsample.1.running_var, layer4.1.conv1.weight, layer4.1.bn1.weight, layer4.1.bn1.bias, layer4.1.bn1.running_mean, layer4.1.bn1.running_var, layer4.1.conv2.weight, layer4.1.bn2.weight, layer4.1.bn2.bias, layer4.1.bn2.running_mean, layer4.1.bn2.running_var, layer4.1.conv3.weight, layer4.1.bn3.weight, layer4.1.bn3.bias, layer4.1.bn3.running_mean, layer4.1.bn3.running_var, layer4.2.conv1.weight, layer4.2.bn1.weight, layer4.2.bn1.bias, layer4.2.bn1.running_mean, layer4.2.bn1.running_var, layer4.2.conv2.weight, layer4.2.bn2.weight, layer4.2.bn2.bias, layer4.2.bn2.running_mean, layer4.2.bn2.running_var, layer4.2.conv3.weight, layer4.2.bn3.weight, layer4.2.bn3.bias, layer4.2.bn3.running_mean, layer4.2.bn3.running_var

2021-07-23 03:34:39,887 - mmdet - INFO - Start running, host: root@efe7fbebbac3, work_dir: /home/zq/work/SOLO/work_dirs/solov2_release_r50_fpn_8gpu_3x
2021-07-23 03:34:39,887 - mmdet - INFO - workflow: [('train', 1)], max: 36 epochs
loading annotations into memory...
Done (t=0.02s)
creating index...
index created!
{'type': 'CocoDataset', 'ann_file': 'data/annotation/merge/merge_train_coco.json', 'img_prefix': 'data/road/train/', 'pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'LoadAnnotations', 'with_bbox': True, 'with_mask': True}, {'type': 'Resize', 'img_scale': [(1333, 800), (1333, 768), (1333, 736), (1333, 704), (1333, 672), (1333, 640)], 'multiscale_mode': 'value', 'keep_ratio': True}, {'type': 'RandomFlip', 'flip_ratio': 0.5}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'DefaultFormatBundle'}, {'type': 'Collect', 'keys': ['img', 'gt_bboxes', 'gt_labels', 'gt_masks']}]}
/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:2494: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
2021-07-23 03:34:55,823 - mmdet - INFO - Epoch [1][50/673]	lr: 0.00107, eta: 2:08:24, time: 0.319, data_time: 0.019, memory: 4435, loss_ins: 1.2458, loss_cate: 0.5204, loss: 1.7662
2021-07-23 03:35:10,904 - mmdet - INFO - Epoch [1][100/673]	lr: 0.00206, eta: 2:04:43, time: 0.302, data_time: 0.013, memory: 4435, loss_ins: 1.3233, loss_cate: 0.5876, loss: 1.9109
2021-07-23 03:35:26,564 - mmdet - INFO - Epoch [1][150/673]	lr: 0.00305, eta: 2:04:52, time: 0.313, data_time: 0.012, memory: 4435, loss_ins: 1.2950, loss_cate: 0.5417, loss: 1.8367
2021-07-23 03:35:42,010 - mmdet - INFO - Epoch [1][200/673]	lr: 0.00404, eta: 2:04:23, time: 0.309, data_time: 0.012, memory: 4435, loss_ins: 1.3354, loss_cate: 0.5036, loss: 1.8390
2021-07-23 03:35:57,563 - mmdet - INFO - Epoch [1][250/673]	lr: 0.00503, eta: 2:04:09, time: 0.311, data_time: 0.012, memory: 4435, loss_ins: 1.3039, loss_cate: 0.4315, loss: 1.7355
2021-07-23 03:36:12,971 - mmdet - INFO - Epoch [1][300/673]	lr: 0.00602, eta: 2:03:44, time: 0.308, data_time: 0.013, memory: 4435, loss_ins: 1.2946, loss_cate: 0.9676, loss: 2.2621
2021-07-23 03:36:28,321 - mmdet - INFO - Epoch [1][350/673]	lr: 0.00701, eta: 2:03:17, time: 0.307, data_time: 0.013, memory: 4435, loss_ins: 1.2822, loss_cate: 1.2576, loss: 2.5398
2021-07-23 03:36:43,706 - mmdet - INFO - Epoch [1][400/673]	lr: 0.00800, eta: 2:02:55, time: 0.308, data_time: 0.013, memory: 4435, loss_ins: 1.3441, loss_cate: 0.6686, loss: 2.0126
2021-07-23 03:36:58,903 - mmdet - INFO - Epoch [1][450/673]	lr: 0.00899, eta: 2:02:25, time: 0.304, data_time: 0.013, memory: 4435, loss_ins: 1.2521, loss_cate: 0.3881, loss: 1.6402
2021-07-23 03:37:14,723 - mmdet - INFO - Epoch [1][500/673]	lr: 0.00998, eta: 2:02:27, time: 0.316, data_time: 0.014, memory: 4435, loss_ins: 1.3620, loss_cate: 0.3922, loss: 1.7542
2021-07-23 03:37:30,087 - mmdet - INFO - Epoch [1][550/673]	lr: 0.01000, eta: 2:02:07, time: 0.307, data_time: 0.013, memory: 4435, loss_ins: 1.3031, loss_cate: 0.3365, loss: 1.6396
2021-07-23 03:37:45,251 - mmdet - INFO - Epoch [1][600/673]	lr: 0.01000, eta: 2:01:39, time: 0.303, data_time: 0.013, memory: 4435, loss_ins: 1.2393, loss_cate: 0.3689, loss: 1.6081
2021-07-23 03:38:01,081 - mmdet - INFO - Epoch [1][650/673]	lr: 0.01000, eta: 2:01:37, time: 0.317, data_time: 0.014, memory: 4435, loss_ins: 1.3363, loss_cate: 0.3536, loss: 1.6899
2021-07-23 03:38:25,611 - mmdet - INFO - Epoch [2][50/673]	lr: 0.01000, eta: 1:57:23, time: 0.309, data_time: 0.016, memory: 4435, loss_ins: 1.2429, loss_cate: 0.5762, loss: 1.8191
2021-07-23 03:38:40,986 - mmdet - INFO - Epoch [2][100/673]	lr: 0.01000, eta: 1:57:20, time: 0.308, data_time: 0.012, memory: 4435, loss_ins: 1.3134, loss_cate: 0.4592, loss: 1.7726
2021-07-23 03:38:56,282 - mmdet - INFO - Epoch [2][150/673]	lr: 0.01000, eta: 1:57:13, time: 0.306, data_time: 0.013, memory: 4435, loss_ins: 1.2575, loss_cate: 0.3785, loss: 1.6361
2021-07-23 03:39:11,591 - mmdet - INFO - Epoch [2][200/673]	lr: 0.01000, eta: 1:57:06, time: 0.306, data_time: 0.013, memory: 4435, loss_ins: 1.2957, loss_cate: 0.3922, loss: 1.6879
2021-07-23 03:39:26,875 - mmdet - INFO - Epoch [2][250/673]	lr: 0.01000, eta: 1:56:57, time: 0.306, data_time: 0.013, memory: 4435, loss_ins: 1.2774, loss_cate: 0.3809, loss: 1.6584
2021-07-23 03:39:42,143 - mmdet - INFO - Epoch [2][300/673]	lr: 0.01000, eta: 1:56:47, time: 0.305, data_time: 0.012, memory: 4435, loss_ins: 1.2815, loss_cate: 0.3710, loss: 1.6525
2021-07-23 03:39:57,495 - mmdet - INFO - Epoch [2][350/673]	lr: 0.01000, eta: 1:56:38, time: 0.307, data_time: 0.013, memory: 4435, loss_ins: 1.3691, loss_cate: 0.3566, loss: 1.7256
2021-07-23 03:40:13,067 - mmdet - INFO - Epoch [2][400/673]	lr: 0.01000, eta: 1:56:34, time: 0.311, data_time: 0.013, memory: 4435, loss_ins: 1.3623, loss_cate: 0.3786, loss: 1.7409
2021-07-23 03:40:28,688 - mmdet - INFO - Epoch [2][450/673]	lr: 0.01000, eta: 1:56:29, time: 0.312, data_time: 0.013, memory: 4435, loss_ins: 1.2523, loss_cate: 0.3338, loss: 1.5861
2021-07-23 03:40:44,553 - mmdet - INFO - Epoch [2][500/673]	lr: 0.01000, eta: 1:56:29, time: 0.317, data_time: 0.013, memory: 4435, loss_ins: 1.2463, loss_cate: 0.3596, loss: 1.6059
2021-07-23 03:41:00,120 - mmdet - INFO - Epoch [2][550/673]	lr: 0.01000, eta: 1:56:21, time: 0.311, data_time: 0.012, memory: 4435, loss_ins: 1.3939, loss_cate: 0.3890, loss: 1.7829
2021-07-23 03:41:15,716 - mmdet - INFO - Epoch [2][600/673]	lr: 0.01000, eta: 1:56:14, time: 0.312, data_time: 0.012, memory: 4435, loss_ins: 1.3522, loss_cate: 0.3342, loss: 1.6864
2021-07-23 03:41:31,005 - mmdet - INFO - Epoch [2][650/673]	lr: 0.01000, eta: 1:56:00, time: 0.306, data_time: 0.012, memory: 4435, loss_ins: 1.3666, loss_cate: 0.3592, loss: 1.7258
2021-07-23 03:41:55,769 - mmdet - INFO - Epoch [3][50/673]	lr: 0.01000, eta: 1:53:51, time: 0.313, data_time: 0.018, memory: 4435, loss_ins: 1.2938, loss_cate: 0.3373, loss: 1.6311
2021-07-23 03:42:11,023 - mmdet - INFO - Epoch [3][100/673]	lr: 0.01000, eta: 1:53:41, time: 0.305, data_time: 0.014, memory: 4435, loss_ins: 1.3791, loss_cate: 0.3195, loss: 1.6986
2021-07-23 03:42:26,334 - mmdet - INFO - Epoch [3][150/673]	lr: 0.01000, eta: 1:53:31, time: 0.306, data_time: 0.013, memory: 4435, loss_ins: 1.3313, loss_cate: 0.3233, loss: 1.6546
2021-07-23 03:42:41,912 - mmdet - INFO - Epoch [3][200/673]	lr: 0.01000, eta: 1:53:25, time: 0.312, data_time: 0.013, memory: 4435, loss_ins: 1.2675, loss_cate: 0.3096, loss: 1.5771
2021-07-23 03:42:57,163 - mmdet - INFO - Epoch [3][250/673]	lr: 0.01000, eta: 1:53:13, time: 0.305, data_time: 0.013, memory: 4435, loss_ins: 1.3387, loss_cate: 0.3133, loss: 1.6520
2021-07-23 03:43:12,437 - mmdet - INFO - Epoch [3][300/673]	lr: 0.01000, eta: 1:53:02, time: 0.305, data_time: 0.013, memory: 4435, loss_ins: 1.3326, loss_cate: 0.3066, loss: 1.6392
2021-07-23 03:43:27,740 - mmdet - INFO - Epoch [3][350/673]	lr: 0.01000, eta: 1:52:51, time: 0.306, data_time: 0.013, memory: 4435, loss_ins: 1.2572, loss_cate: 0.2948, loss: 1.5520
2021-07-23 03:43:42,901 - mmdet - INFO - Epoch [3][400/673]	lr: 0.01000, eta: 1:52:37, time: 0.303, data_time: 0.013, memory: 4435, loss_ins: 1.3272, loss_cate: 0.3007, loss: 1.6279
2021-07-23 03:43:58,326 - mmdet - INFO - Epoch [3][450/673]	lr: 0.01000, eta: 1:52:27, time: 0.308, data_time: 0.012, memory: 4435, loss_ins: 1.2790, loss_cate: 0.2735, loss: 1.5525
2021-07-23 03:44:13,855 - mmdet - INFO - Epoch [3][500/673]	lr: 0.01000, eta: 1:52:18, time: 0.311, data_time: 0.013, memory: 4435, loss_ins: 1.2993, loss_cate: 0.2891, loss: 1.5884
2021-07-23 03:44:29,290 - mmdet - INFO - Epoch [3][550/673]	lr: 0.01000, eta: 1:52:08, time: 0.309, data_time: 0.013, memory: 4435, loss_ins: 1.2623, loss_cate: 0.2956, loss: 1.5579
2021-07-23 03:44:44,896 - mmdet - INFO - Epoch [3][600/673]	lr: 0.01000, eta: 1:51:59, time: 0.312, data_time: 0.014, memory: 4435, loss_ins: 1.2493, loss_cate: 0.2723, loss: 1.5216
2021-07-23 03:45:00,412 - mmdet - INFO - Epoch [3][650/673]	lr: 0.01000, eta: 1:51:48, time: 0.310, data_time: 0.013, memory: 4435, loss_ins: 1.3192, loss_cate: 0.2828, loss: 1.6021
2021-07-23 03:45:24,934 - mmdet - INFO - Epoch [4][50/673]	lr: 0.01000, eta: 1:50:15, time: 0.307, data_time: 0.018, memory: 4435, loss_ins: 1.2859, loss_cate: 0.2729, loss: 1.5588
2021-07-23 03:45:40,174 - mmdet - INFO - Epoch [4][100/673]	lr: 0.01000, eta: 1:50:03, time: 0.305, data_time: 0.012, memory: 4435, loss_ins: 1.3065, loss_cate: 0.2851, loss: 1.5915
2021-07-23 03:45:55,480 - mmdet - INFO - Epoch [4][150/673]	lr: 0.01000, eta: 1:49:52, time: 0.306, data_time: 0.013, memory: 4435, loss_ins: 1.2959, loss_cate: 0.2904, loss: 1.5863
2021-07-23 03:46:11,187 - mmdet - INFO - Epoch [4][200/673]	lr: 0.01000, eta: 1:49:45, time: 0.314, data_time: 0.013, memory: 4435, loss_ins: 1.2968, loss_cate: 0.2758, loss: 1.5726
2021-07-23 03:46:26,330 - mmdet - INFO - Epoch [4][250/673]	lr: 0.01000, eta: 1:49:32, time: 0.303, data_time: 0.012, memory: 4435, loss_ins: 1.2728, loss_cate: 0.2799, loss: 1.5527
2021-07-23 03:46:41,979 - mmdet - INFO - Epoch [4][300/673]	lr: 0.01000, eta: 1:49:23, time: 0.313, data_time: 0.012, memory: 4435, loss_ins: 1.3309, loss_cate: 0.2769, loss: 1.6078
2021-07-23 03:46:57,364 - mmdet - INFO - Epoch [4][350/673]	lr: 0.01000, eta: 1:49:12, time: 0.308, data_time: 0.013, memory: 4435, loss_ins: 1.2850, loss_cate: 0.2620, loss: 1.5471
2021-07-23 03:47:12,841 - mmdet - INFO - Epoch [4][400/673]	lr: 0.01000, eta: 1:49:01, time: 0.310, data_time: 0.013, memory: 4435, loss_ins: 1.2833, loss_cate: 0.2621, loss: 1.5454
2021-07-23 03:47:28,278 - mmdet - INFO - Epoch [4][450/673]	lr: 0.01000, eta: 1:48:50, time: 0.309, data_time: 0.013, memory: 4435, loss_ins: 1.3483, loss_cate: 0.2861, loss: 1.6344
2021-07-23 03:47:43,503 - mmdet - INFO - Epoch [4][500/673]	lr: 0.01000, eta: 1:48:37, time: 0.305, data_time: 0.013, memory: 4435, loss_ins: 1.2912, loss_cate: 0.2601, loss: 1.5513
2021-07-23 03:48:02,261 - mmdet - INFO - Epoch [4][550/673]	lr: 0.01000, eta: 1:48:54, time: 0.375, data_time: 0.013, memory: 4435, loss_ins: 1.3768, loss_cate: 0.2766, loss: 1.6535
2021-07-23 03:48:22,411 - mmdet - INFO - Epoch [4][600/673]	lr: 0.01000, eta: 1:49:20, time: 0.403, data_time: 0.013, memory: 4435, loss_ins: 1.2597, loss_cate: 0.2831, loss: 1.5428
2021-07-23 03:48:37,989 - mmdet - INFO - Epoch [4][650/673]	lr: 0.01000, eta: 1:49:08, time: 0.312, data_time: 0.013, memory: 4435, loss_ins: 1.3878, loss_cate: 0.2672, loss: 1.6550
2021-07-23 03:49:02,741 - mmdet - INFO - Epoch [5][50/673]	lr: 0.01000, eta: 1:47:53, time: 0.309, data_time: 0.017, memory: 4435, loss_ins: 1.3630, loss_cate: 0.2451, loss: 1.6081
2021-07-23 03:49:18,063 - mmdet - INFO - Epoch [5][100/673]	lr: 0.01000, eta: 1:47:40, time: 0.306, data_time: 0.013, memory: 4435, loss_ins: 1.2856, loss_cate: 0.2654, loss: 1.5510
2021-07-23 03:49:33,601 - mmdet - INFO - Epoch [5][150/673]	lr: 0.01000, eta: 1:47:29, time: 0.311, data_time: 0.013, memory: 4435, loss_ins: 1.3558, loss_cate: 0.2646, loss: 1.6204
2021-07-23 03:49:49,160 - mmdet - INFO - Epoch [5][200/673]	lr: 0.01000, eta: 1:47:17, time: 0.311, data_time: 0.013, memory: 4435, loss_ins: 1.2803, loss_cate: 0.2808, loss: 1.5611
2021-07-23 03:50:04,655 - mmdet - INFO - Epoch [5][250/673]	lr: 0.01000, eta: 1:47:05, time: 0.310, data_time: 0.013, memory: 4435, loss_ins: 1.3104, loss_cate: 0.2865, loss: 1.5969
2021-07-23 03:50:19,768 - mmdet - INFO - Epoch [5][300/673]	lr: 0.01000, eta: 1:46:50, time: 0.302, data_time: 0.012, memory: 4435, loss_ins: 1.2730, loss_cate: 0.3058, loss: 1.5788
2021-07-23 03:50:35,266 - mmdet - INFO - Epoch [5][350/673]	lr: 0.01000, eta: 1:46:38, time: 0.310, data_time: 0.013, memory: 4435, loss_ins: 1.2716, loss_cate: 0.2678, loss: 1.5395
2021-07-23 03:50:50,428 - mmdet - INFO - Epoch [5][400/673]	lr: 0.01000, eta: 1:46:23, time: 0.303, data_time: 0.012, memory: 4435, loss_ins: 1.3146, loss_cate: 0.2745, loss: 1.5890
2021-07-23 03:51:05,944 - mmdet - INFO - Epoch [5][450/673]	lr: 0.01000, eta: 1:46:11, time: 0.310, data_time: 0.013, memory: 4435, loss_ins: 1.2767, loss_cate: 0.2749, loss: 1.5516
2021-07-23 03:51:21,524 - mmdet - INFO - Epoch [5][500/673]	lr: 0.01000, eta: 1:45:59, time: 0.312, data_time: 0.013, memory: 4435, loss_ins: 1.3594, loss_cate: 0.2648, loss: 1.6242
2021-07-23 03:51:36,770 - mmdet - INFO - Epoch [5][550/673]	lr: 0.01000, eta: 1:45:45, time: 0.305, data_time: 0.013, memory: 4435, loss_ins: 1.3147, loss_cate: 0.2889, loss: 1.6036
2021-07-23 03:51:52,276 - mmdet - INFO - Epoch [5][600/673]	lr: 0.01000, eta: 1:45:32, time: 0.310, data_time: 0.012, memory: 4435, loss_ins: 1.3349, loss_cate: 0.2545, loss: 1.5894
2021-07-23 03:52:07,600 - mmdet - INFO - Epoch [5][650/673]	lr: 0.01000, eta: 1:45:18, time: 0.306, data_time: 0.013, memory: 4435, loss_ins: 1.2558, loss_cate: 0.2438, loss: 1.4997
2021-07-23 03:52:32,462 - mmdet - INFO - Epoch [6][50/673]	lr: 0.01000, eta: 1:44:19, time: 0.319, data_time: 0.020, memory: 4435, loss_ins: 1.3906, loss_cate: 0.2905, loss: 1.6811
Process Process-11:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.6/multiprocessing/process.py", line 261, in _bootstrap
    util._exit_function()
  File "/opt/conda/lib/python3.6/multiprocessing/util.py", line 322, in _exit_function
    _run_finalizers()
  File "/opt/conda/lib/python3.6/multiprocessing/util.py", line 262, in _run_finalizers
    finalizer()
  File "/opt/conda/lib/python3.6/multiprocessing/util.py", line 186, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/opt/conda/lib/python3.6/multiprocessing/queues.py", line 191, in _finalize_join
    thread.join()
  File "/opt/conda/lib/python3.6/threading.py", line 1056, in join
    self._wait_for_tstate_lock()
  File "/opt/conda/lib/python3.6/threading.py", line 1072, in _wait_for_tstate_lock
    elif lock.acquire(block, timeout):
KeyboardInterrupt
Process Process-12:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.6/multiprocessing/process.py", line 261, in _bootstrap
    util._exit_function()
  File "/opt/conda/lib/python3.6/multiprocessing/util.py", line 322, in _exit_function
    _run_finalizers()
  File "/opt/conda/lib/python3.6/multiprocessing/util.py", line 262, in _run_finalizers
    finalizer()
  File "/opt/conda/lib/python3.6/multiprocessing/util.py", line 186, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/opt/conda/lib/python3.6/multiprocessing/queues.py", line 191, in _finalize_join
    thread.join()
  File "/opt/conda/lib/python3.6/threading.py", line 1056, in join
    self._wait_for_tstate_lock()
  File "/opt/conda/lib/python3.6/threading.py", line 1072, in _wait_for_tstate_lock
    elif lock.acquire(block, timeout):
KeyboardInterrupt
Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f7d97f74b38>>
Traceback (most recent call last):
  File "/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 926, in __del__
    self._shutdown_workers()
  File "/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 906, in _shutdown_workers
    w.join()
  File "/opt/conda/lib/python3.6/multiprocessing/process.py", line 124, in join
    res = self._popen.wait(timeout)
  File "/opt/conda/lib/python3.6/multiprocessing/popen_fork.py", line 50, in wait
    return self.poll(os.WNOHANG if timeout == 0.0 else 0)
  File "/opt/conda/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
KeyboardInterrupt: 
Traceback (most recent call last):
  File "tools/train.py", line 133, in <module>
    main()
  File "tools/train.py", line 129, in main
    timestamp=timestamp)
  File "/home/zq/work/SOLO/mmdet/apis/train.py", line 111, in train_detector
    timestamp=timestamp)
  File "/home/zq/work/SOLO/mmdet/apis/train.py", line 297, in _non_dist_train
    runner.run(data_loaders, cfg.workflow, cfg.total_epochs)
  File "/opt/conda/lib/python3.6/site-packages/mmcv/runner/runner.py", line 364, in run
    epoch_runner(data_loaders[i], **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/mmcv/runner/runner.py", line 275, in train
    self.call_hook('after_train_iter')
  File "/opt/conda/lib/python3.6/site-packages/mmcv/runner/runner.py", line 231, in call_hook
    getattr(hook, fn_name)(self)
  File "/opt/conda/lib/python3.6/site-packages/mmcv/runner/hooks/optimizer.py", line 18, in after_train_iter
    runner.outputs['loss'].backward()
  File "/opt/conda/lib/python3.6/site-packages/torch/tensor.py", line 150, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/opt/conda/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
KeyboardInterrupt
2021-07-23 06:37:32,709 - mmdet - INFO - Distributed training: False
2021-07-23 06:37:32,709 - mmdet - INFO - MMDetection Version: 1.0.0+c7b294a
2021-07-23 06:37:32,709 - mmdet - INFO - Config:
# model settings
model = dict(
    type='SOLOv2',
    pretrained='torchvision://resnet50',
    backbone=dict(
        type='ResNet',
        depth=50,
        num_stages=4,
        out_indices=(0, 1, 2, 3),  # C2, C3, C4, C5
        frozen_stages=1,
        style='pytorch'),
    neck=dict(
        type='FPN',
        in_channels=[256, 512, 1024, 2048],
        out_channels=256,
        start_level=0,
        num_outs=5),
    bbox_head=dict(
        type='SOLOv2Head',
        num_classes=2,
        in_channels=256,
        stacked_convs=4,
        seg_feat_channels=512,
        strides=[8, 8, 16, 32, 32],
        # scale_ranges=((1, 96), (48, 192), (96, 384), (192, 768), (384, 2048)),
        scale_ranges=((1, 250), (125, 500), (250, 1000), (500, 2000)),
        sigma=0.2,
        num_grids=[40, 36, 24, 16, 12],
        ins_out_channels=256,
        loss_ins=dict(
            type='DiceLoss',
            use_sigmoid=True,
            loss_weight=3.0),
        # loss_weight=10.0),
        loss_cate=dict(
            type='FocalLoss',
            use_sigmoid=True,
            gamma=2.0,
            alpha=0.25,
            loss_weight=1.0)),
    mask_feat_head=dict(
        type='MaskFeatHead',
        in_channels=256,
        out_channels=128,
        start_level=0,
        end_level=3,
        num_classes=256,
        norm_cfg=dict(type='GN', num_groups=32, requires_grad=True)),
)
# training and testing settings
train_cfg = dict()
test_cfg = dict(
    nms_pre=500,
    score_thr=0.1,
    mask_thr=0.5,
    update_thr=0.05,
    kernel='gaussian',  # gaussian/linear
    sigma=2.0,
    max_per_img=100)
# dataset settings
dataset_type = 'CocoDataset'
data_root = 'data/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),
    dict(type='Resize',
         img_scale=[(1333, 800), (1333, 768), (1333, 736),
                    (1333, 704), (1333, 672), (1333, 640)],
         multiscale_mode='value',
         keep_ratio=True),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(type='Normalize', **img_norm_cfg),
    dict(type='Pad', size_divisor=32),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks']),
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(1333, 800),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(type='Normalize', **img_norm_cfg),
            dict(type='Pad', size_divisor=32),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img']),
        ])
]
data = dict(
    imgs_per_gpu=2,
    workers_per_gpu=2,
    train=dict(
        type=dataset_type,
        ann_file=data_root + 'annotation/merge/merge_train_coco.json',
        img_prefix=data_root + 'road/train/',
        pipeline=train_pipeline),
    val=dict(
        type=dataset_type,
        ann_file=data_root + 'annotation/merge/merge_val_coco.json',
        img_prefix=data_root + 'road/val/',
        pipeline=test_pipeline),
    test=dict(
        type=dataset_type,
        ann_file=data_root + 'annotation/merge/merge_val_coco.json',
        img_prefix=data_root + 'road/val/',
        pipeline=test_pipeline))
# optimizer
optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0001)
optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))
# learning policy
lr_config = dict(
    policy='step',
    warmup='linear',
    warmup_iters=500,
    warmup_ratio=0.01,
    step=[27, 33])
checkpoint_config = dict(interval=1)
# yapf:disable
log_config = dict(
    interval=50,
    hooks=[
        dict(type='TextLoggerHook'),
        # dict(type='TensorboardLoggerHook')
    ])
# yapf:enable
# runtime settings
total_epochs = 36
device_ids = range(8)
dist_params = dict(backend='nccl')
log_level = 'INFO'
work_dir = './work_dirs/solov2_release_r50_fpn_8gpu_3x'
# work_dir = './work_dirs/solov2_release_r50_fpn_8gpu_3x_scale'
# work_dir = './work_dirs/solov2_release_r50_fpn_8gpu_3x_weight'
# work_dir = './work_dirs/solov2_release_r50_fpn_8gpu_3x_workflow'
# work_dir = './work_dirs/solov2_release_r50_fpn_8gpu_3x_validate'

load_from = None
resume_from = None
workflow = [('train', 1)]

2021-07-23 06:37:33,094 - mmdet - INFO - load model from: torchvision://resnet50
2021-07-23 06:37:35,375 - mmdet - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: backbone.conv1.weight, backbone.bn1.weight, backbone.bn1.bias, backbone.bn1.running_mean, backbone.bn1.running_var, backbone.bn1.num_batches_tracked, backbone.layer1.0.conv1.weight, backbone.layer1.0.bn1.weight, backbone.layer1.0.bn1.bias, backbone.layer1.0.bn1.running_mean, backbone.layer1.0.bn1.running_var, backbone.layer1.0.bn1.num_batches_tracked, backbone.layer1.0.conv2.weight, backbone.layer1.0.bn2.weight, backbone.layer1.0.bn2.bias, backbone.layer1.0.bn2.running_mean, backbone.layer1.0.bn2.running_var, backbone.layer1.0.bn2.num_batches_tracked, backbone.layer1.0.conv3.weight, backbone.layer1.0.bn3.weight, backbone.layer1.0.bn3.bias, backbone.layer1.0.bn3.running_mean, backbone.layer1.0.bn3.running_var, backbone.layer1.0.bn3.num_batches_tracked, backbone.layer1.0.downsample.0.weight, backbone.layer1.0.downsample.1.weight, backbone.layer1.0.downsample.1.bias, backbone.layer1.0.downsample.1.running_mean, backbone.layer1.0.downsample.1.running_var, backbone.layer1.0.downsample.1.num_batches_tracked, backbone.layer1.1.conv1.weight, backbone.layer1.1.bn1.weight, backbone.layer1.1.bn1.bias, backbone.layer1.1.bn1.running_mean, backbone.layer1.1.bn1.running_var, backbone.layer1.1.bn1.num_batches_tracked, backbone.layer1.1.conv2.weight, backbone.layer1.1.bn2.weight, backbone.layer1.1.bn2.bias, backbone.layer1.1.bn2.running_mean, backbone.layer1.1.bn2.running_var, backbone.layer1.1.bn2.num_batches_tracked, backbone.layer1.1.conv3.weight, backbone.layer1.1.bn3.weight, backbone.layer1.1.bn3.bias, backbone.layer1.1.bn3.running_mean, backbone.layer1.1.bn3.running_var, backbone.layer1.1.bn3.num_batches_tracked, backbone.layer1.2.conv1.weight, backbone.layer1.2.bn1.weight, backbone.layer1.2.bn1.bias, backbone.layer1.2.bn1.running_mean, backbone.layer1.2.bn1.running_var, backbone.layer1.2.bn1.num_batches_tracked, backbone.layer1.2.conv2.weight, backbone.layer1.2.bn2.weight, backbone.layer1.2.bn2.bias, backbone.layer1.2.bn2.running_mean, backbone.layer1.2.bn2.running_var, backbone.layer1.2.bn2.num_batches_tracked, backbone.layer1.2.conv3.weight, backbone.layer1.2.bn3.weight, backbone.layer1.2.bn3.bias, backbone.layer1.2.bn3.running_mean, backbone.layer1.2.bn3.running_var, backbone.layer1.2.bn3.num_batches_tracked, backbone.layer2.0.conv1.weight, backbone.layer2.0.bn1.weight, backbone.layer2.0.bn1.bias, backbone.layer2.0.bn1.running_mean, backbone.layer2.0.bn1.running_var, backbone.layer2.0.bn1.num_batches_tracked, backbone.layer2.0.conv2.weight, backbone.layer2.0.bn2.weight, backbone.layer2.0.bn2.bias, backbone.layer2.0.bn2.running_mean, backbone.layer2.0.bn2.running_var, backbone.layer2.0.bn2.num_batches_tracked, backbone.layer2.0.conv3.weight, backbone.layer2.0.bn3.weight, backbone.layer2.0.bn3.bias, backbone.layer2.0.bn3.running_mean, backbone.layer2.0.bn3.running_var, backbone.layer2.0.bn3.num_batches_tracked, backbone.layer2.0.downsample.0.weight, backbone.layer2.0.downsample.1.weight, backbone.layer2.0.downsample.1.bias, backbone.layer2.0.downsample.1.running_mean, backbone.layer2.0.downsample.1.running_var, backbone.layer2.0.downsample.1.num_batches_tracked, backbone.layer2.1.conv1.weight, backbone.layer2.1.bn1.weight, backbone.layer2.1.bn1.bias, backbone.layer2.1.bn1.running_mean, backbone.layer2.1.bn1.running_var, backbone.layer2.1.bn1.num_batches_tracked, backbone.layer2.1.conv2.weight, backbone.layer2.1.bn2.weight, backbone.layer2.1.bn2.bias, backbone.layer2.1.bn2.running_mean, backbone.layer2.1.bn2.running_var, backbone.layer2.1.bn2.num_batches_tracked, backbone.layer2.1.conv3.weight, backbone.layer2.1.bn3.weight, backbone.layer2.1.bn3.bias, backbone.layer2.1.bn3.running_mean, backbone.layer2.1.bn3.running_var, backbone.layer2.1.bn3.num_batches_tracked, backbone.layer2.2.conv1.weight, backbone.layer2.2.bn1.weight, backbone.layer2.2.bn1.bias, backbone.layer2.2.bn1.running_mean, backbone.layer2.2.bn1.running_var, backbone.layer2.2.bn1.num_batches_tracked, backbone.layer2.2.conv2.weight, backbone.layer2.2.bn2.weight, backbone.layer2.2.bn2.bias, backbone.layer2.2.bn2.running_mean, backbone.layer2.2.bn2.running_var, backbone.layer2.2.bn2.num_batches_tracked, backbone.layer2.2.conv3.weight, backbone.layer2.2.bn3.weight, backbone.layer2.2.bn3.bias, backbone.layer2.2.bn3.running_mean, backbone.layer2.2.bn3.running_var, backbone.layer2.2.bn3.num_batches_tracked, backbone.layer2.3.conv1.weight, backbone.layer2.3.bn1.weight, backbone.layer2.3.bn1.bias, backbone.layer2.3.bn1.running_mean, backbone.layer2.3.bn1.running_var, backbone.layer2.3.bn1.num_batches_tracked, backbone.layer2.3.conv2.weight, backbone.layer2.3.bn2.weight, backbone.layer2.3.bn2.bias, backbone.layer2.3.bn2.running_mean, backbone.layer2.3.bn2.running_var, backbone.layer2.3.bn2.num_batches_tracked, backbone.layer2.3.conv3.weight, backbone.layer2.3.bn3.weight, backbone.layer2.3.bn3.bias, backbone.layer2.3.bn3.running_mean, backbone.layer2.3.bn3.running_var, backbone.layer2.3.bn3.num_batches_tracked, backbone.layer3.0.conv1.weight, backbone.layer3.0.bn1.weight, backbone.layer3.0.bn1.bias, backbone.layer3.0.bn1.running_mean, backbone.layer3.0.bn1.running_var, backbone.layer3.0.bn1.num_batches_tracked, backbone.layer3.0.conv2.weight, backbone.layer3.0.bn2.weight, backbone.layer3.0.bn2.bias, backbone.layer3.0.bn2.running_mean, backbone.layer3.0.bn2.running_var, backbone.layer3.0.bn2.num_batches_tracked, backbone.layer3.0.conv3.weight, backbone.layer3.0.bn3.weight, backbone.layer3.0.bn3.bias, backbone.layer3.0.bn3.running_mean, backbone.layer3.0.bn3.running_var, backbone.layer3.0.bn3.num_batches_tracked, backbone.layer3.0.downsample.0.weight, backbone.layer3.0.downsample.1.weight, backbone.layer3.0.downsample.1.bias, backbone.layer3.0.downsample.1.running_mean, backbone.layer3.0.downsample.1.running_var, backbone.layer3.0.downsample.1.num_batches_tracked, backbone.layer3.1.conv1.weight, backbone.layer3.1.bn1.weight, backbone.layer3.1.bn1.bias, backbone.layer3.1.bn1.running_mean, backbone.layer3.1.bn1.running_var, backbone.layer3.1.bn1.num_batches_tracked, backbone.layer3.1.conv2.weight, backbone.layer3.1.bn2.weight, backbone.layer3.1.bn2.bias, backbone.layer3.1.bn2.running_mean, backbone.layer3.1.bn2.running_var, backbone.layer3.1.bn2.num_batches_tracked, backbone.layer3.1.conv3.weight, backbone.layer3.1.bn3.weight, backbone.layer3.1.bn3.bias, backbone.layer3.1.bn3.running_mean, backbone.layer3.1.bn3.running_var, backbone.layer3.1.bn3.num_batches_tracked, backbone.layer3.2.conv1.weight, backbone.layer3.2.bn1.weight, backbone.layer3.2.bn1.bias, backbone.layer3.2.bn1.running_mean, backbone.layer3.2.bn1.running_var, backbone.layer3.2.bn1.num_batches_tracked, backbone.layer3.2.conv2.weight, backbone.layer3.2.bn2.weight, backbone.layer3.2.bn2.bias, backbone.layer3.2.bn2.running_mean, backbone.layer3.2.bn2.running_var, backbone.layer3.2.bn2.num_batches_tracked, backbone.layer3.2.conv3.weight, backbone.layer3.2.bn3.weight, backbone.layer3.2.bn3.bias, backbone.layer3.2.bn3.running_mean, backbone.layer3.2.bn3.running_var, backbone.layer3.2.bn3.num_batches_tracked, backbone.layer3.3.conv1.weight, backbone.layer3.3.bn1.weight, backbone.layer3.3.bn1.bias, backbone.layer3.3.bn1.running_mean, backbone.layer3.3.bn1.running_var, backbone.layer3.3.bn1.num_batches_tracked, backbone.layer3.3.conv2.weight, backbone.layer3.3.bn2.weight, backbone.layer3.3.bn2.bias, backbone.layer3.3.bn2.running_mean, backbone.layer3.3.bn2.running_var, backbone.layer3.3.bn2.num_batches_tracked, backbone.layer3.3.conv3.weight, backbone.layer3.3.bn3.weight, backbone.layer3.3.bn3.bias, backbone.layer3.3.bn3.running_mean, backbone.layer3.3.bn3.running_var, backbone.layer3.3.bn3.num_batches_tracked, backbone.layer3.4.conv1.weight, backbone.layer3.4.bn1.weight, backbone.layer3.4.bn1.bias, backbone.layer3.4.bn1.running_mean, backbone.layer3.4.bn1.running_var, backbone.layer3.4.bn1.num_batches_tracked, backbone.layer3.4.conv2.weight, backbone.layer3.4.bn2.weight, backbone.layer3.4.bn2.bias, backbone.layer3.4.bn2.running_mean, backbone.layer3.4.bn2.running_var, backbone.layer3.4.bn2.num_batches_tracked, backbone.layer3.4.conv3.weight, backbone.layer3.4.bn3.weight, backbone.layer3.4.bn3.bias, backbone.layer3.4.bn3.running_mean, backbone.layer3.4.bn3.running_var, backbone.layer3.4.bn3.num_batches_tracked, backbone.layer3.5.conv1.weight, backbone.layer3.5.bn1.weight, backbone.layer3.5.bn1.bias, backbone.layer3.5.bn1.running_mean, backbone.layer3.5.bn1.running_var, backbone.layer3.5.bn1.num_batches_tracked, backbone.layer3.5.conv2.weight, backbone.layer3.5.bn2.weight, backbone.layer3.5.bn2.bias, backbone.layer3.5.bn2.running_mean, backbone.layer3.5.bn2.running_var, backbone.layer3.5.bn2.num_batches_tracked, backbone.layer3.5.conv3.weight, backbone.layer3.5.bn3.weight, backbone.layer3.5.bn3.bias, backbone.layer3.5.bn3.running_mean, backbone.layer3.5.bn3.running_var, backbone.layer3.5.bn3.num_batches_tracked, backbone.layer4.0.conv1.weight, backbone.layer4.0.bn1.weight, backbone.layer4.0.bn1.bias, backbone.layer4.0.bn1.running_mean, backbone.layer4.0.bn1.running_var, backbone.layer4.0.bn1.num_batches_tracked, backbone.layer4.0.conv2.weight, backbone.layer4.0.bn2.weight, backbone.layer4.0.bn2.bias, backbone.layer4.0.bn2.running_mean, backbone.layer4.0.bn2.running_var, backbone.layer4.0.bn2.num_batches_tracked, backbone.layer4.0.conv3.weight, backbone.layer4.0.bn3.weight, backbone.layer4.0.bn3.bias, backbone.layer4.0.bn3.running_mean, backbone.layer4.0.bn3.running_var, backbone.layer4.0.bn3.num_batches_tracked, backbone.layer4.0.downsample.0.weight, backbone.layer4.0.downsample.1.weight, backbone.layer4.0.downsample.1.bias, backbone.layer4.0.downsample.1.running_mean, backbone.layer4.0.downsample.1.running_var, backbone.layer4.0.downsample.1.num_batches_tracked, backbone.layer4.1.conv1.weight, backbone.layer4.1.bn1.weight, backbone.layer4.1.bn1.bias, backbone.layer4.1.bn1.running_mean, backbone.layer4.1.bn1.running_var, backbone.layer4.1.bn1.num_batches_tracked, backbone.layer4.1.conv2.weight, backbone.layer4.1.bn2.weight, backbone.layer4.1.bn2.bias, backbone.layer4.1.bn2.running_mean, backbone.layer4.1.bn2.running_var, backbone.layer4.1.bn2.num_batches_tracked, backbone.layer4.1.conv3.weight, backbone.layer4.1.bn3.weight, backbone.layer4.1.bn3.bias, backbone.layer4.1.bn3.running_mean, backbone.layer4.1.bn3.running_var, backbone.layer4.1.bn3.num_batches_tracked, backbone.layer4.2.conv1.weight, backbone.layer4.2.bn1.weight, backbone.layer4.2.bn1.bias, backbone.layer4.2.bn1.running_mean, backbone.layer4.2.bn1.running_var, backbone.layer4.2.bn1.num_batches_tracked, backbone.layer4.2.conv2.weight, backbone.layer4.2.bn2.weight, backbone.layer4.2.bn2.bias, backbone.layer4.2.bn2.running_mean, backbone.layer4.2.bn2.running_var, backbone.layer4.2.bn2.num_batches_tracked, backbone.layer4.2.conv3.weight, backbone.layer4.2.bn3.weight, backbone.layer4.2.bn3.bias, backbone.layer4.2.bn3.running_mean, backbone.layer4.2.bn3.running_var, backbone.layer4.2.bn3.num_batches_tracked, neck.lateral_convs.0.conv.weight, neck.lateral_convs.0.conv.bias, neck.lateral_convs.1.conv.weight, neck.lateral_convs.1.conv.bias, neck.lateral_convs.2.conv.weight, neck.lateral_convs.2.conv.bias, neck.lateral_convs.3.conv.weight, neck.lateral_convs.3.conv.bias, neck.fpn_convs.0.conv.weight, neck.fpn_convs.0.conv.bias, neck.fpn_convs.1.conv.weight, neck.fpn_convs.1.conv.bias, neck.fpn_convs.2.conv.weight, neck.fpn_convs.2.conv.bias, neck.fpn_convs.3.conv.weight, neck.fpn_convs.3.conv.bias, mask_feat_head.convs_all_levels.0.conv0.conv.weight, mask_feat_head.convs_all_levels.0.conv0.gn.weight, mask_feat_head.convs_all_levels.0.conv0.gn.bias, mask_feat_head.convs_all_levels.1.conv0.conv.weight, mask_feat_head.convs_all_levels.1.conv0.gn.weight, mask_feat_head.convs_all_levels.1.conv0.gn.bias, mask_feat_head.convs_all_levels.2.conv0.conv.weight, mask_feat_head.convs_all_levels.2.conv0.gn.weight, mask_feat_head.convs_all_levels.2.conv0.gn.bias, mask_feat_head.convs_all_levels.2.conv1.conv.weight, mask_feat_head.convs_all_levels.2.conv1.gn.weight, mask_feat_head.convs_all_levels.2.conv1.gn.bias, mask_feat_head.convs_all_levels.3.conv0.conv.weight, mask_feat_head.convs_all_levels.3.conv0.gn.weight, mask_feat_head.convs_all_levels.3.conv0.gn.bias, mask_feat_head.convs_all_levels.3.conv1.conv.weight, mask_feat_head.convs_all_levels.3.conv1.gn.weight, mask_feat_head.convs_all_levels.3.conv1.gn.bias, mask_feat_head.convs_all_levels.3.conv2.conv.weight, mask_feat_head.convs_all_levels.3.conv2.gn.weight, mask_feat_head.convs_all_levels.3.conv2.gn.bias, mask_feat_head.conv_pred.0.conv.weight, mask_feat_head.conv_pred.0.gn.weight, mask_feat_head.conv_pred.0.gn.bias, bbox_head.cate_convs.0.conv.weight, bbox_head.cate_convs.0.gn.weight, bbox_head.cate_convs.0.gn.bias, bbox_head.cate_convs.1.conv.weight, bbox_head.cate_convs.1.gn.weight, bbox_head.cate_convs.1.gn.bias, bbox_head.cate_convs.2.conv.weight, bbox_head.cate_convs.2.gn.weight, bbox_head.cate_convs.2.gn.bias, bbox_head.cate_convs.3.conv.weight, bbox_head.cate_convs.3.gn.weight, bbox_head.cate_convs.3.gn.bias, bbox_head.kernel_convs.0.conv.weight, bbox_head.kernel_convs.0.gn.weight, bbox_head.kernel_convs.0.gn.bias, bbox_head.kernel_convs.1.conv.weight, bbox_head.kernel_convs.1.gn.weight, bbox_head.kernel_convs.1.gn.bias, bbox_head.kernel_convs.2.conv.weight, bbox_head.kernel_convs.2.gn.weight, bbox_head.kernel_convs.2.gn.bias, bbox_head.kernel_convs.3.conv.weight, bbox_head.kernel_convs.3.gn.weight, bbox_head.kernel_convs.3.gn.bias, bbox_head.solo_cate.weight, bbox_head.solo_cate.bias, bbox_head.solo_kernel.weight, bbox_head.solo_kernel.bias

missing keys in source state_dict: conv1.weight, bn1.weight, bn1.bias, bn1.running_mean, bn1.running_var, layer1.0.conv1.weight, layer1.0.bn1.weight, layer1.0.bn1.bias, layer1.0.bn1.running_mean, layer1.0.bn1.running_var, layer1.0.conv2.weight, layer1.0.bn2.weight, layer1.0.bn2.bias, layer1.0.bn2.running_mean, layer1.0.bn2.running_var, layer1.0.conv3.weight, layer1.0.bn3.weight, layer1.0.bn3.bias, layer1.0.bn3.running_mean, layer1.0.bn3.running_var, layer1.0.downsample.0.weight, layer1.0.downsample.1.weight, layer1.0.downsample.1.bias, layer1.0.downsample.1.running_mean, layer1.0.downsample.1.running_var, layer1.1.conv1.weight, layer1.1.bn1.weight, layer1.1.bn1.bias, layer1.1.bn1.running_mean, layer1.1.bn1.running_var, layer1.1.conv2.weight, layer1.1.bn2.weight, layer1.1.bn2.bias, layer1.1.bn2.running_mean, layer1.1.bn2.running_var, layer1.1.conv3.weight, layer1.1.bn3.weight, layer1.1.bn3.bias, layer1.1.bn3.running_mean, layer1.1.bn3.running_var, layer1.2.conv1.weight, layer1.2.bn1.weight, layer1.2.bn1.bias, layer1.2.bn1.running_mean, layer1.2.bn1.running_var, layer1.2.conv2.weight, layer1.2.bn2.weight, layer1.2.bn2.bias, layer1.2.bn2.running_mean, layer1.2.bn2.running_var, layer1.2.conv3.weight, layer1.2.bn3.weight, layer1.2.bn3.bias, layer1.2.bn3.running_mean, layer1.2.bn3.running_var, layer2.0.conv1.weight, layer2.0.bn1.weight, layer2.0.bn1.bias, layer2.0.bn1.running_mean, layer2.0.bn1.running_var, layer2.0.conv2.weight, layer2.0.bn2.weight, layer2.0.bn2.bias, layer2.0.bn2.running_mean, layer2.0.bn2.running_var, layer2.0.conv3.weight, layer2.0.bn3.weight, layer2.0.bn3.bias, layer2.0.bn3.running_mean, layer2.0.bn3.running_var, layer2.0.downsample.0.weight, layer2.0.downsample.1.weight, layer2.0.downsample.1.bias, layer2.0.downsample.1.running_mean, layer2.0.downsample.1.running_var, layer2.1.conv1.weight, layer2.1.bn1.weight, layer2.1.bn1.bias, layer2.1.bn1.running_mean, layer2.1.bn1.running_var, layer2.1.conv2.weight, layer2.1.bn2.weight, layer2.1.bn2.bias, layer2.1.bn2.running_mean, layer2.1.bn2.running_var, layer2.1.conv3.weight, layer2.1.bn3.weight, layer2.1.bn3.bias, layer2.1.bn3.running_mean, layer2.1.bn3.running_var, layer2.2.conv1.weight, layer2.2.bn1.weight, layer2.2.bn1.bias, layer2.2.bn1.running_mean, layer2.2.bn1.running_var, layer2.2.conv2.weight, layer2.2.bn2.weight, layer2.2.bn2.bias, layer2.2.bn2.running_mean, layer2.2.bn2.running_var, layer2.2.conv3.weight, layer2.2.bn3.weight, layer2.2.bn3.bias, layer2.2.bn3.running_mean, layer2.2.bn3.running_var, layer2.3.conv1.weight, layer2.3.bn1.weight, layer2.3.bn1.bias, layer2.3.bn1.running_mean, layer2.3.bn1.running_var, layer2.3.conv2.weight, layer2.3.bn2.weight, layer2.3.bn2.bias, layer2.3.bn2.running_mean, layer2.3.bn2.running_var, layer2.3.conv3.weight, layer2.3.bn3.weight, layer2.3.bn3.bias, layer2.3.bn3.running_mean, layer2.3.bn3.running_var, layer3.0.conv1.weight, layer3.0.bn1.weight, layer3.0.bn1.bias, layer3.0.bn1.running_mean, layer3.0.bn1.running_var, layer3.0.conv2.weight, layer3.0.bn2.weight, layer3.0.bn2.bias, layer3.0.bn2.running_mean, layer3.0.bn2.running_var, layer3.0.conv3.weight, layer3.0.bn3.weight, layer3.0.bn3.bias, layer3.0.bn3.running_mean, layer3.0.bn3.running_var, layer3.0.downsample.0.weight, layer3.0.downsample.1.weight, layer3.0.downsample.1.bias, layer3.0.downsample.1.running_mean, layer3.0.downsample.1.running_var, layer3.1.conv1.weight, layer3.1.bn1.weight, layer3.1.bn1.bias, layer3.1.bn1.running_mean, layer3.1.bn1.running_var, layer3.1.conv2.weight, layer3.1.bn2.weight, layer3.1.bn2.bias, layer3.1.bn2.running_mean, layer3.1.bn2.running_var, layer3.1.conv3.weight, layer3.1.bn3.weight, layer3.1.bn3.bias, layer3.1.bn3.running_mean, layer3.1.bn3.running_var, layer3.2.conv1.weight, layer3.2.bn1.weight, layer3.2.bn1.bias, layer3.2.bn1.running_mean, layer3.2.bn1.running_var, layer3.2.conv2.weight, layer3.2.bn2.weight, layer3.2.bn2.bias, layer3.2.bn2.running_mean, layer3.2.bn2.running_var, layer3.2.conv3.weight, layer3.2.bn3.weight, layer3.2.bn3.bias, layer3.2.bn3.running_mean, layer3.2.bn3.running_var, layer3.3.conv1.weight, layer3.3.bn1.weight, layer3.3.bn1.bias, layer3.3.bn1.running_mean, layer3.3.bn1.running_var, layer3.3.conv2.weight, layer3.3.bn2.weight, layer3.3.bn2.bias, layer3.3.bn2.running_mean, layer3.3.bn2.running_var, layer3.3.conv3.weight, layer3.3.bn3.weight, layer3.3.bn3.bias, layer3.3.bn3.running_mean, layer3.3.bn3.running_var, layer3.4.conv1.weight, layer3.4.bn1.weight, layer3.4.bn1.bias, layer3.4.bn1.running_mean, layer3.4.bn1.running_var, layer3.4.conv2.weight, layer3.4.bn2.weight, layer3.4.bn2.bias, layer3.4.bn2.running_mean, layer3.4.bn2.running_var, layer3.4.conv3.weight, layer3.4.bn3.weight, layer3.4.bn3.bias, layer3.4.bn3.running_mean, layer3.4.bn3.running_var, layer3.5.conv1.weight, layer3.5.bn1.weight, layer3.5.bn1.bias, layer3.5.bn1.running_mean, layer3.5.bn1.running_var, layer3.5.conv2.weight, layer3.5.bn2.weight, layer3.5.bn2.bias, layer3.5.bn2.running_mean, layer3.5.bn2.running_var, layer3.5.conv3.weight, layer3.5.bn3.weight, layer3.5.bn3.bias, layer3.5.bn3.running_mean, layer3.5.bn3.running_var, layer4.0.conv1.weight, layer4.0.bn1.weight, layer4.0.bn1.bias, layer4.0.bn1.running_mean, layer4.0.bn1.running_var, layer4.0.conv2.weight, layer4.0.bn2.weight, layer4.0.bn2.bias, layer4.0.bn2.running_mean, layer4.0.bn2.running_var, layer4.0.conv3.weight, layer4.0.bn3.weight, layer4.0.bn3.bias, layer4.0.bn3.running_mean, layer4.0.bn3.running_var, layer4.0.downsample.0.weight, layer4.0.downsample.1.weight, layer4.0.downsample.1.bias, layer4.0.downsample.1.running_mean, layer4.0.downsample.1.running_var, layer4.1.conv1.weight, layer4.1.bn1.weight, layer4.1.bn1.bias, layer4.1.bn1.running_mean, layer4.1.bn1.running_var, layer4.1.conv2.weight, layer4.1.bn2.weight, layer4.1.bn2.bias, layer4.1.bn2.running_mean, layer4.1.bn2.running_var, layer4.1.conv3.weight, layer4.1.bn3.weight, layer4.1.bn3.bias, layer4.1.bn3.running_mean, layer4.1.bn3.running_var, layer4.2.conv1.weight, layer4.2.bn1.weight, layer4.2.bn1.bias, layer4.2.bn1.running_mean, layer4.2.bn1.running_var, layer4.2.conv2.weight, layer4.2.bn2.weight, layer4.2.bn2.bias, layer4.2.bn2.running_mean, layer4.2.bn2.running_var, layer4.2.conv3.weight, layer4.2.bn3.weight, layer4.2.bn3.bias, layer4.2.bn3.running_mean, layer4.2.bn3.running_var

2021-07-23 06:37:35,575 - mmdet - INFO - Start running, host: root@efe7fbebbac3, work_dir: /home/zq/work/SOLO/work_dirs/solov2_release_r50_fpn_8gpu_3x
2021-07-23 06:37:35,575 - mmdet - INFO - workflow: [('train', 1)], max: 36 epochs
loading annotations into memory...
Done (t=0.02s)
creating index...
index created!
{'type': 'CocoDataset', 'ann_file': 'data/annotation/merge/merge_train_coco.json', 'img_prefix': 'data/road/train/', 'pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'LoadAnnotations', 'with_bbox': True, 'with_mask': True}, {'type': 'Resize', 'img_scale': [(1333, 800), (1333, 768), (1333, 736), (1333, 704), (1333, 672), (1333, 640)], 'multiscale_mode': 'value', 'keep_ratio': True}, {'type': 'RandomFlip', 'flip_ratio': 0.5}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'DefaultFormatBundle'}, {'type': 'Collect', 'keys': ['img', 'gt_bboxes', 'gt_labels', 'gt_masks']}]}
/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:2494: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
2021-07-23 06:37:51,184 - mmdet - INFO - Epoch [1][50/673]	lr: 0.00107, eta: 2:05:46, time: 0.312, data_time: 0.018, memory: 4431, loss_ins: 1.3515, loss_cate: 0.5450, loss: 1.8965
2021-07-23 06:38:06,397 - mmdet - INFO - Epoch [1][100/673]	lr: 0.00206, eta: 2:03:56, time: 0.304, data_time: 0.013, memory: 4431, loss_ins: 1.2782, loss_cate: 0.4844, loss: 1.7626
2021-07-23 06:38:21,568 - mmdet - INFO - Epoch [1][150/673]	lr: 0.00305, eta: 2:03:02, time: 0.303, data_time: 0.011, memory: 4432, loss_ins: 1.2624, loss_cate: 0.6393, loss: 1.9018
2021-07-23 06:38:36,548 - mmdet - INFO - Epoch [1][200/673]	lr: 0.00404, eta: 2:02:04, time: 0.300, data_time: 0.011, memory: 4432, loss_ins: 1.3440, loss_cate: 0.3985, loss: 1.7425
2021-07-23 06:38:51,579 - mmdet - INFO - Epoch [1][250/673]	lr: 0.00503, eta: 2:01:29, time: 0.301, data_time: 0.011, memory: 4432, loss_ins: 1.3152, loss_cate: 0.3921, loss: 1.7073
2021-07-23 06:39:06,889 - mmdet - INFO - Epoch [1][300/673]	lr: 0.00602, eta: 2:01:22, time: 0.306, data_time: 0.011, memory: 4436, loss_ins: 1.3662, loss_cate: 1.0435, loss: 2.4097
2021-07-23 06:39:22,879 - mmdet - INFO - Epoch [1][350/673]	lr: 0.00701, eta: 2:02:00, time: 0.320, data_time: 0.013, memory: 4436, loss_ins: 1.2783, loss_cate: 0.5333, loss: 1.8116
2021-07-23 06:39:38,706 - mmdet - INFO - Epoch [1][400/673]	lr: 0.00800, eta: 2:02:14, time: 0.317, data_time: 0.012, memory: 4436, loss_ins: 1.3303, loss_cate: 0.4787, loss: 1.8090
2021-07-23 06:39:54,135 - mmdet - INFO - Epoch [1][450/673]	lr: 0.00899, eta: 2:02:01, time: 0.309, data_time: 0.012, memory: 4436, loss_ins: 1.3244, loss_cate: 0.4947, loss: 1.8191
2021-07-23 06:40:09,146 - mmdet - INFO - Epoch [1][500/673]	lr: 0.00998, eta: 2:01:27, time: 0.300, data_time: 0.012, memory: 4436, loss_ins: 1.2928, loss_cate: 0.4855, loss: 1.7783
2021-07-23 06:40:24,328 - mmdet - INFO - Epoch [1][550/673]	lr: 0.01000, eta: 2:01:04, time: 0.304, data_time: 0.013, memory: 4436, loss_ins: 1.2944, loss_cate: 0.3622, loss: 1.6567
2021-07-23 06:40:39,593 - mmdet - INFO - Epoch [1][600/673]	lr: 0.01000, eta: 2:00:46, time: 0.305, data_time: 0.013, memory: 4436, loss_ins: 1.2798, loss_cate: 0.3232, loss: 1.6030
2021-07-23 06:40:54,927 - mmdet - INFO - Epoch [1][650/673]	lr: 0.01000, eta: 2:00:31, time: 0.307, data_time: 0.013, memory: 4436, loss_ins: 1.3105, loss_cate: 0.3239, loss: 1.6344
2021-07-23 06:41:19,421 - mmdet - INFO - Epoch [2][50/673]	lr: 0.01000, eta: 1:56:24, time: 0.310, data_time: 0.017, memory: 4436, loss_ins: 1.2790, loss_cate: 0.4934, loss: 1.7724
2021-07-23 06:41:34,866 - mmdet - INFO - Epoch [2][100/673]	lr: 0.01000, eta: 1:56:27, time: 0.309, data_time: 0.013, memory: 4436, loss_ins: 1.3047, loss_cate: 0.4672, loss: 1.7719
2021-07-23 06:41:50,082 - mmdet - INFO - Epoch [2][150/673]	lr: 0.01000, eta: 1:56:21, time: 0.304, data_time: 0.012, memory: 4436, loss_ins: 1.3173, loss_cate: 0.3351, loss: 1.6524
2021-07-23 06:42:05,516 - mmdet - INFO - Epoch [2][200/673]	lr: 0.01000, eta: 1:56:20, time: 0.309, data_time: 0.013, memory: 4436, loss_ins: 1.3297, loss_cate: 0.3446, loss: 1.6743
2021-07-23 06:42:20,720 - mmdet - INFO - Epoch [2][250/673]	lr: 0.01000, eta: 1:56:12, time: 0.304, data_time: 0.012, memory: 4436, loss_ins: 1.2194, loss_cate: 0.2964, loss: 1.5159
2021-07-23 06:42:35,821 - mmdet - INFO - Epoch [2][300/673]	lr: 0.01000, eta: 1:56:00, time: 0.302, data_time: 0.012, memory: 4436, loss_ins: 1.2860, loss_cate: 0.2973, loss: 1.5832
2021-07-23 06:42:51,176 - mmdet - INFO - Epoch [2][350/673]	lr: 0.01000, eta: 1:55:54, time: 0.307, data_time: 0.012, memory: 4436, loss_ins: 1.3600, loss_cate: 0.3311, loss: 1.6911
2021-07-23 06:43:06,379 - mmdet - INFO - Epoch [2][400/673]	lr: 0.01000, eta: 1:55:44, time: 0.304, data_time: 0.012, memory: 4436, loss_ins: 1.2962, loss_cate: 0.3098, loss: 1.6060
2021-07-23 06:43:21,809 - mmdet - INFO - Epoch [2][450/673]	lr: 0.01000, eta: 1:55:37, time: 0.309, data_time: 0.013, memory: 4436, loss_ins: 1.3282, loss_cate: 0.3148, loss: 1.6430
2021-07-23 06:43:36,799 - mmdet - INFO - Epoch [2][500/673]	lr: 0.01000, eta: 1:55:22, time: 0.300, data_time: 0.012, memory: 4436, loss_ins: 1.2796, loss_cate: 0.2958, loss: 1.5753
2021-07-23 06:43:52,257 - mmdet - INFO - Epoch [2][550/673]	lr: 0.01000, eta: 1:55:15, time: 0.309, data_time: 0.012, memory: 4436, loss_ins: 1.3901, loss_cate: 0.3138, loss: 1.7039
2021-07-23 06:44:07,826 - mmdet - INFO - Epoch [2][600/673]	lr: 0.01000, eta: 1:55:10, time: 0.311, data_time: 0.012, memory: 4436, loss_ins: 1.3379, loss_cate: 0.2993, loss: 1.6372
2021-07-23 06:44:22,885 - mmdet - INFO - Epoch [2][650/673]	lr: 0.01000, eta: 1:54:55, time: 0.301, data_time: 0.012, memory: 4436, loss_ins: 1.2820, loss_cate: 0.3109, loss: 1.5929
2021-07-23 06:44:47,186 - mmdet - INFO - Epoch [3][50/673]	lr: 0.01000, eta: 1:52:48, time: 0.311, data_time: 0.020, memory: 4436, loss_ins: 1.3020, loss_cate: 0.4159, loss: 1.7178
2021-07-23 06:45:02,914 - mmdet - INFO - Epoch [3][100/673]	lr: 0.01000, eta: 1:52:48, time: 0.315, data_time: 0.015, memory: 4436, loss_ins: 1.3071, loss_cate: 0.3494, loss: 1.6565
2021-07-23 06:45:18,573 - mmdet - INFO - Epoch [3][150/673]	lr: 0.01000, eta: 1:52:45, time: 0.313, data_time: 0.014, memory: 4436, loss_ins: 1.4097, loss_cate: 0.3554, loss: 1.7651
2021-07-23 06:45:34,307 - mmdet - INFO - Epoch [3][200/673]	lr: 0.01000, eta: 1:52:43, time: 0.315, data_time: 0.013, memory: 4436, loss_ins: 1.3319, loss_cate: 0.3159, loss: 1.6478
2021-07-23 06:45:49,387 - mmdet - INFO - Epoch [3][250/673]	lr: 0.01000, eta: 1:52:30, time: 0.302, data_time: 0.012, memory: 4436, loss_ins: 1.2372, loss_cate: 0.3034, loss: 1.5406
2021-07-23 06:46:04,597 - mmdet - INFO - Epoch [3][300/673]	lr: 0.01000, eta: 1:52:19, time: 0.304, data_time: 0.012, memory: 4436, loss_ins: 1.2507, loss_cate: 0.2919, loss: 1.5427
2021-07-23 06:46:19,896 - mmdet - INFO - Epoch [3][350/673]	lr: 0.01000, eta: 1:52:09, time: 0.306, data_time: 0.013, memory: 4436, loss_ins: 1.2689, loss_cate: 0.2980, loss: 1.5669
2021-07-23 06:46:35,445 - mmdet - INFO - Epoch [3][400/673]	lr: 0.01000, eta: 1:52:02, time: 0.311, data_time: 0.012, memory: 4436, loss_ins: 1.3891, loss_cate: 0.3088, loss: 1.6979
2021-07-23 06:46:51,074 - mmdet - INFO - Epoch [3][450/673]	lr: 0.01000, eta: 1:51:56, time: 0.313, data_time: 0.013, memory: 4436, loss_ins: 1.2839, loss_cate: 0.3400, loss: 1.6239
2021-07-23 06:47:06,752 - mmdet - INFO - Epoch [3][500/673]	lr: 0.01000, eta: 1:51:49, time: 0.314, data_time: 0.013, memory: 4436, loss_ins: 1.3379, loss_cate: 0.4046, loss: 1.7425
2021-07-23 06:47:22,312 - mmdet - INFO - Epoch [3][550/673]	lr: 0.01000, eta: 1:51:41, time: 0.311, data_time: 0.013, memory: 4436, loss_ins: 1.3291, loss_cate: 0.3604, loss: 1.6895
2021-07-23 06:47:37,536 - mmdet - INFO - Epoch [3][600/673]	lr: 0.01000, eta: 1:51:29, time: 0.304, data_time: 0.012, memory: 4436, loss_ins: 1.2800, loss_cate: 0.3012, loss: 1.5812
2021-07-23 06:47:52,987 - mmdet - INFO - Epoch [3][650/673]	lr: 0.01000, eta: 1:51:19, time: 0.309, data_time: 0.013, memory: 4436, loss_ins: 1.2992, loss_cate: 0.2810, loss: 1.5801
2021-07-23 06:48:17,629 - mmdet - INFO - Epoch [4][50/673]	lr: 0.01000, eta: 1:49:48, time: 0.310, data_time: 0.021, memory: 4436, loss_ins: 1.3005, loss_cate: 0.3427, loss: 1.6432
2021-07-23 06:48:33,105 - mmdet - INFO - Epoch [4][100/673]	lr: 0.01000, eta: 1:49:39, time: 0.310, data_time: 0.016, memory: 4436, loss_ins: 1.3499, loss_cate: 0.2740, loss: 1.6239
2021-07-23 06:48:48,516 - mmdet - INFO - Epoch [4][150/673]	lr: 0.01000, eta: 1:49:30, time: 0.308, data_time: 0.016, memory: 4436, loss_ins: 1.3275, loss_cate: 0.2693, loss: 1.5969
2021-07-23 06:49:03,767 - mmdet - INFO - Epoch [4][200/673]	lr: 0.01000, eta: 1:49:18, time: 0.305, data_time: 0.014, memory: 4436, loss_ins: 1.3216, loss_cate: 0.2835, loss: 1.6051
2021-07-23 06:49:19,000 - mmdet - INFO - Epoch [4][250/673]	lr: 0.01000, eta: 1:49:07, time: 0.305, data_time: 0.014, memory: 4436, loss_ins: 1.3214, loss_cate: 0.2708, loss: 1.5922
2021-07-23 06:49:34,401 - mmdet - INFO - Epoch [4][300/673]	lr: 0.01000, eta: 1:48:56, time: 0.308, data_time: 0.015, memory: 4436, loss_ins: 1.3050, loss_cate: 0.2643, loss: 1.5693
2021-07-23 06:49:49,653 - mmdet - INFO - Epoch [4][350/673]	lr: 0.01000, eta: 1:48:45, time: 0.305, data_time: 0.016, memory: 4436, loss_ins: 1.2586, loss_cate: 0.2516, loss: 1.5102
2021-07-23 06:50:05,369 - mmdet - INFO - Epoch [4][400/673]	lr: 0.01000, eta: 1:48:37, time: 0.314, data_time: 0.014, memory: 4436, loss_ins: 1.2461, loss_cate: 0.2508, loss: 1.4969
2021-07-23 06:50:20,996 - mmdet - INFO - Epoch [4][450/673]	lr: 0.01000, eta: 1:48:28, time: 0.313, data_time: 0.014, memory: 4436, loss_ins: 1.2423, loss_cate: 0.2376, loss: 1.4799
2021-07-23 06:50:36,415 - mmdet - INFO - Epoch [4][500/673]	lr: 0.01000, eta: 1:48:17, time: 0.308, data_time: 0.014, memory: 4436, loss_ins: 1.3525, loss_cate: 0.2549, loss: 1.6074
2021-07-23 06:50:51,699 - mmdet - INFO - Epoch [4][550/673]	lr: 0.01000, eta: 1:48:05, time: 0.306, data_time: 0.014, memory: 4436, loss_ins: 1.2975, loss_cate: 0.2635, loss: 1.5610
2021-07-23 06:51:07,202 - mmdet - INFO - Epoch [4][600/673]	lr: 0.01000, eta: 1:47:54, time: 0.310, data_time: 0.014, memory: 4436, loss_ins: 1.3409, loss_cate: 0.2534, loss: 1.5943
2021-07-23 06:51:22,640 - mmdet - INFO - Epoch [4][650/673]	lr: 0.01000, eta: 1:47:43, time: 0.309, data_time: 0.014, memory: 4436, loss_ins: 1.2919, loss_cate: 0.2588, loss: 1.5507
2021-07-23 06:51:47,227 - mmdet - INFO - Epoch [5][50/673]	lr: 0.01000, eta: 1:46:30, time: 0.308, data_time: 0.018, memory: 4436, loss_ins: 1.3381, loss_cate: 0.2311, loss: 1.5691
2021-07-23 06:52:02,841 - mmdet - INFO - Epoch [5][100/673]	lr: 0.01000, eta: 1:46:21, time: 0.312, data_time: 0.014, memory: 4436, loss_ins: 1.3282, loss_cate: 0.2547, loss: 1.5829
2021-07-23 06:52:18,253 - mmdet - INFO - Epoch [5][150/673]	lr: 0.01000, eta: 1:46:10, time: 0.308, data_time: 0.015, memory: 4436, loss_ins: 1.3209, loss_cate: 0.2599, loss: 1.5808
2021-07-23 06:52:33,556 - mmdet - INFO - Epoch [5][200/673]	lr: 0.01000, eta: 1:45:58, time: 0.306, data_time: 0.014, memory: 4436, loss_ins: 1.3339, loss_cate: 0.2264, loss: 1.5603
2021-07-23 06:52:49,138 - mmdet - INFO - Epoch [5][250/673]	lr: 0.01000, eta: 1:45:48, time: 0.312, data_time: 0.014, memory: 4436, loss_ins: 1.3374, loss_cate: 0.2456, loss: 1.5830
Process Process-10:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.6/multiprocessing/process.py", line 261, in _bootstrap
    util._exit_function()
  File "/opt/conda/lib/python3.6/multiprocessing/util.py", line 322, in _exit_function
    _run_finalizers()
  File "/opt/conda/lib/python3.6/multiprocessing/util.py", line 262, in _run_finalizers
    finalizer()
  File "/opt/conda/lib/python3.6/multiprocessing/util.py", line 186, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/opt/conda/lib/python3.6/multiprocessing/queues.py", line 191, in _finalize_join
    thread.join()
  File "/opt/conda/lib/python3.6/threading.py", line 1056, in join
    self._wait_for_tstate_lock()
  File "/opt/conda/lib/python3.6/threading.py", line 1072, in _wait_for_tstate_lock
    elif lock.acquire(block, timeout):
KeyboardInterrupt
Process Process-9:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.6/multiprocessing/process.py", line 261, in _bootstrap
    util._exit_function()
  File "/opt/conda/lib/python3.6/multiprocessing/util.py", line 322, in _exit_function
    _run_finalizers()
  File "/opt/conda/lib/python3.6/multiprocessing/util.py", line 262, in _run_finalizers
    finalizer()
  File "/opt/conda/lib/python3.6/multiprocessing/util.py", line 186, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/opt/conda/lib/python3.6/multiprocessing/queues.py", line 191, in _finalize_join
    thread.join()
  File "/opt/conda/lib/python3.6/threading.py", line 1056, in join
    self._wait_for_tstate_lock()
  File "/opt/conda/lib/python3.6/threading.py", line 1072, in _wait_for_tstate_lock
    elif lock.acquire(block, timeout):
KeyboardInterrupt
Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f6b043e6e10>>
Traceback (most recent call last):
  File "/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 926, in __del__
    self._shutdown_workers()
  File "/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 906, in _shutdown_workers
    w.join()
  File "/opt/conda/lib/python3.6/multiprocessing/process.py", line 124, in join
    res = self._popen.wait(timeout)
  File "/opt/conda/lib/python3.6/multiprocessing/popen_fork.py", line 50, in wait
    return self.poll(os.WNOHANG if timeout == 0.0 else 0)
  File "/opt/conda/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
KeyboardInterrupt: 
Traceback (most recent call last):
  File "tools/train.py", line 133, in <module>
    main()
  File "tools/train.py", line 129, in main
    timestamp=timestamp)
  File "/home/zq/work/SOLO/mmdet/apis/train.py", line 111, in train_detector
    timestamp=timestamp)
  File "/home/zq/work/SOLO/mmdet/apis/train.py", line 297, in _non_dist_train
    runner.run(data_loaders, cfg.workflow, cfg.total_epochs)
  File "/opt/conda/lib/python3.6/site-packages/mmcv/runner/runner.py", line 364, in run
    epoch_runner(data_loaders[i], **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/mmcv/runner/runner.py", line 275, in train
    self.call_hook('after_train_iter')
  File "/opt/conda/lib/python3.6/site-packages/mmcv/runner/runner.py", line 231, in call_hook
    getattr(hook, fn_name)(self)
  File "/opt/conda/lib/python3.6/site-packages/mmcv/runner/hooks/optimizer.py", line 18, in after_train_iter
    runner.outputs['loss'].backward()
  File "/opt/conda/lib/python3.6/site-packages/torch/tensor.py", line 150, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/opt/conda/lib/python3.6/site-packages/torch/autograd/__init__.py", line 99, in backward
    allow_unreachable=True)  # allow_unreachable flag
KeyboardInterrupt
2021-07-23 06:54:01,556 - mmdet - INFO - Distributed training: False
2021-07-23 06:54:01,556 - mmdet - INFO - MMDetection Version: 1.0.0+c7b294a
2021-07-23 06:54:01,556 - mmdet - INFO - Config:
# model settings
model = dict(
    type='SOLOv2',
    pretrained='torchvision://resnet50',
    backbone=dict(
        type='ResNet',
        depth=50,
        num_stages=4,
        out_indices=(0, 1, 2, 3),  # C2, C3, C4, C5
        frozen_stages=1,
        style='pytorch'),
    neck=dict(
        type='FPN',
        in_channels=[256, 512, 1024, 2048],
        out_channels=256,
        start_level=0,
        num_outs=5),
    bbox_head=dict(
        type='SOLOv2Head',
        num_classes=2,
        in_channels=256,
        stacked_convs=4,
        seg_feat_channels=512,
        strides=[8, 8, 16, 32, 32],
        scale_ranges=((1, 96), (48, 192), (96, 384), (192, 768), (384, 2048)),
        # scale_ranges=((1, 250), (125, 500), (250, 1000), (500, 2000)),
        sigma=0.2,
        num_grids=[40, 36, 24, 16, 12],
        ins_out_channels=256,
        loss_ins=dict(
            type='DiceLoss',
            use_sigmoid=True,
            loss_weight=3.0),
        # loss_weight=10.0),
        loss_cate=dict(
            type='FocalLoss',
            use_sigmoid=True,
            gamma=2.0,
            alpha=0.25,
            loss_weight=1.0)),
    mask_feat_head=dict(
        type='MaskFeatHead',
        in_channels=256,
        out_channels=128,
        start_level=0,
        end_level=3,
        num_classes=256,
        norm_cfg=dict(type='GN', num_groups=32, requires_grad=True)),
)
# training and testing settings
train_cfg = dict()
test_cfg = dict(
    nms_pre=500,
    score_thr=0.1,
    mask_thr=0.5,
    update_thr=0.05,
    kernel='gaussian',  # gaussian/linear
    sigma=2.0,
    max_per_img=100)
# dataset settings
dataset_type = 'CocoDataset'
data_root = 'data/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),
    dict(type='Resize',
         img_scale=[(1333, 800), (1333, 768), (1333, 736),
                    (1333, 704), (1333, 672), (1333, 640)],
         multiscale_mode='value',
         keep_ratio=True),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(type='Normalize', **img_norm_cfg),
    dict(type='Pad', size_divisor=32),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks']),
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(1333, 800),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(type='Normalize', **img_norm_cfg),
            dict(type='Pad', size_divisor=32),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img']),
        ])
]
data = dict(
    imgs_per_gpu=2,
    workers_per_gpu=2,
    train=dict(
        type=dataset_type,
        ann_file=data_root + 'annotation/merge/merge_train_coco.json',
        img_prefix=data_root + 'road/train/',
        pipeline=train_pipeline),
    val=dict(
        type=dataset_type,
        ann_file=data_root + 'annotation/merge/merge_val_coco.json',
        img_prefix=data_root + 'road/val/',
        pipeline=test_pipeline),
    test=dict(
        type=dataset_type,
        ann_file=data_root + 'annotation/merge/merge_val_coco.json',
        img_prefix=data_root + 'road/val/',
        pipeline=test_pipeline))
# optimizer
optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0001)
optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))
# learning policy
lr_config = dict(
    policy='step',
    warmup='linear',
    warmup_iters=500,
    warmup_ratio=0.01,
    step=[27, 33])
checkpoint_config = dict(interval=1)
# yapf:disable
log_config = dict(
    interval=50,
    hooks=[
        dict(type='TextLoggerHook'),
        # dict(type='TensorboardLoggerHook')
    ])
# yapf:enable
# runtime settings
total_epochs = 36
device_ids = range(8)
dist_params = dict(backend='nccl')
log_level = 'INFO'
work_dir = './work_dirs/solov2_release_r50_fpn_8gpu_3x'
# work_dir = './work_dirs/solov2_release_r50_fpn_8gpu_3x_scale'
# work_dir = './work_dirs/solov2_release_r50_fpn_8gpu_3x_weight'
# work_dir = './work_dirs/solov2_release_r50_fpn_8gpu_3x_workflow'
# work_dir = './work_dirs/solov2_release_r50_fpn_8gpu_3x_validate'

load_from = None
resume_from = None
workflow = [('train', 1)]

2021-07-23 06:54:01,933 - mmdet - INFO - load model from: torchvision://resnet50
2021-07-23 06:54:04,238 - mmdet - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: backbone.conv1.weight, backbone.bn1.weight, backbone.bn1.bias, backbone.bn1.running_mean, backbone.bn1.running_var, backbone.bn1.num_batches_tracked, backbone.layer1.0.conv1.weight, backbone.layer1.0.bn1.weight, backbone.layer1.0.bn1.bias, backbone.layer1.0.bn1.running_mean, backbone.layer1.0.bn1.running_var, backbone.layer1.0.bn1.num_batches_tracked, backbone.layer1.0.conv2.weight, backbone.layer1.0.bn2.weight, backbone.layer1.0.bn2.bias, backbone.layer1.0.bn2.running_mean, backbone.layer1.0.bn2.running_var, backbone.layer1.0.bn2.num_batches_tracked, backbone.layer1.0.conv3.weight, backbone.layer1.0.bn3.weight, backbone.layer1.0.bn3.bias, backbone.layer1.0.bn3.running_mean, backbone.layer1.0.bn3.running_var, backbone.layer1.0.bn3.num_batches_tracked, backbone.layer1.0.downsample.0.weight, backbone.layer1.0.downsample.1.weight, backbone.layer1.0.downsample.1.bias, backbone.layer1.0.downsample.1.running_mean, backbone.layer1.0.downsample.1.running_var, backbone.layer1.0.downsample.1.num_batches_tracked, backbone.layer1.1.conv1.weight, backbone.layer1.1.bn1.weight, backbone.layer1.1.bn1.bias, backbone.layer1.1.bn1.running_mean, backbone.layer1.1.bn1.running_var, backbone.layer1.1.bn1.num_batches_tracked, backbone.layer1.1.conv2.weight, backbone.layer1.1.bn2.weight, backbone.layer1.1.bn2.bias, backbone.layer1.1.bn2.running_mean, backbone.layer1.1.bn2.running_var, backbone.layer1.1.bn2.num_batches_tracked, backbone.layer1.1.conv3.weight, backbone.layer1.1.bn3.weight, backbone.layer1.1.bn3.bias, backbone.layer1.1.bn3.running_mean, backbone.layer1.1.bn3.running_var, backbone.layer1.1.bn3.num_batches_tracked, backbone.layer1.2.conv1.weight, backbone.layer1.2.bn1.weight, backbone.layer1.2.bn1.bias, backbone.layer1.2.bn1.running_mean, backbone.layer1.2.bn1.running_var, backbone.layer1.2.bn1.num_batches_tracked, backbone.layer1.2.conv2.weight, backbone.layer1.2.bn2.weight, backbone.layer1.2.bn2.bias, backbone.layer1.2.bn2.running_mean, backbone.layer1.2.bn2.running_var, backbone.layer1.2.bn2.num_batches_tracked, backbone.layer1.2.conv3.weight, backbone.layer1.2.bn3.weight, backbone.layer1.2.bn3.bias, backbone.layer1.2.bn3.running_mean, backbone.layer1.2.bn3.running_var, backbone.layer1.2.bn3.num_batches_tracked, backbone.layer2.0.conv1.weight, backbone.layer2.0.bn1.weight, backbone.layer2.0.bn1.bias, backbone.layer2.0.bn1.running_mean, backbone.layer2.0.bn1.running_var, backbone.layer2.0.bn1.num_batches_tracked, backbone.layer2.0.conv2.weight, backbone.layer2.0.bn2.weight, backbone.layer2.0.bn2.bias, backbone.layer2.0.bn2.running_mean, backbone.layer2.0.bn2.running_var, backbone.layer2.0.bn2.num_batches_tracked, backbone.layer2.0.conv3.weight, backbone.layer2.0.bn3.weight, backbone.layer2.0.bn3.bias, backbone.layer2.0.bn3.running_mean, backbone.layer2.0.bn3.running_var, backbone.layer2.0.bn3.num_batches_tracked, backbone.layer2.0.downsample.0.weight, backbone.layer2.0.downsample.1.weight, backbone.layer2.0.downsample.1.bias, backbone.layer2.0.downsample.1.running_mean, backbone.layer2.0.downsample.1.running_var, backbone.layer2.0.downsample.1.num_batches_tracked, backbone.layer2.1.conv1.weight, backbone.layer2.1.bn1.weight, backbone.layer2.1.bn1.bias, backbone.layer2.1.bn1.running_mean, backbone.layer2.1.bn1.running_var, backbone.layer2.1.bn1.num_batches_tracked, backbone.layer2.1.conv2.weight, backbone.layer2.1.bn2.weight, backbone.layer2.1.bn2.bias, backbone.layer2.1.bn2.running_mean, backbone.layer2.1.bn2.running_var, backbone.layer2.1.bn2.num_batches_tracked, backbone.layer2.1.conv3.weight, backbone.layer2.1.bn3.weight, backbone.layer2.1.bn3.bias, backbone.layer2.1.bn3.running_mean, backbone.layer2.1.bn3.running_var, backbone.layer2.1.bn3.num_batches_tracked, backbone.layer2.2.conv1.weight, backbone.layer2.2.bn1.weight, backbone.layer2.2.bn1.bias, backbone.layer2.2.bn1.running_mean, backbone.layer2.2.bn1.running_var, backbone.layer2.2.bn1.num_batches_tracked, backbone.layer2.2.conv2.weight, backbone.layer2.2.bn2.weight, backbone.layer2.2.bn2.bias, backbone.layer2.2.bn2.running_mean, backbone.layer2.2.bn2.running_var, backbone.layer2.2.bn2.num_batches_tracked, backbone.layer2.2.conv3.weight, backbone.layer2.2.bn3.weight, backbone.layer2.2.bn3.bias, backbone.layer2.2.bn3.running_mean, backbone.layer2.2.bn3.running_var, backbone.layer2.2.bn3.num_batches_tracked, backbone.layer2.3.conv1.weight, backbone.layer2.3.bn1.weight, backbone.layer2.3.bn1.bias, backbone.layer2.3.bn1.running_mean, backbone.layer2.3.bn1.running_var, backbone.layer2.3.bn1.num_batches_tracked, backbone.layer2.3.conv2.weight, backbone.layer2.3.bn2.weight, backbone.layer2.3.bn2.bias, backbone.layer2.3.bn2.running_mean, backbone.layer2.3.bn2.running_var, backbone.layer2.3.bn2.num_batches_tracked, backbone.layer2.3.conv3.weight, backbone.layer2.3.bn3.weight, backbone.layer2.3.bn3.bias, backbone.layer2.3.bn3.running_mean, backbone.layer2.3.bn3.running_var, backbone.layer2.3.bn3.num_batches_tracked, backbone.layer3.0.conv1.weight, backbone.layer3.0.bn1.weight, backbone.layer3.0.bn1.bias, backbone.layer3.0.bn1.running_mean, backbone.layer3.0.bn1.running_var, backbone.layer3.0.bn1.num_batches_tracked, backbone.layer3.0.conv2.weight, backbone.layer3.0.bn2.weight, backbone.layer3.0.bn2.bias, backbone.layer3.0.bn2.running_mean, backbone.layer3.0.bn2.running_var, backbone.layer3.0.bn2.num_batches_tracked, backbone.layer3.0.conv3.weight, backbone.layer3.0.bn3.weight, backbone.layer3.0.bn3.bias, backbone.layer3.0.bn3.running_mean, backbone.layer3.0.bn3.running_var, backbone.layer3.0.bn3.num_batches_tracked, backbone.layer3.0.downsample.0.weight, backbone.layer3.0.downsample.1.weight, backbone.layer3.0.downsample.1.bias, backbone.layer3.0.downsample.1.running_mean, backbone.layer3.0.downsample.1.running_var, backbone.layer3.0.downsample.1.num_batches_tracked, backbone.layer3.1.conv1.weight, backbone.layer3.1.bn1.weight, backbone.layer3.1.bn1.bias, backbone.layer3.1.bn1.running_mean, backbone.layer3.1.bn1.running_var, backbone.layer3.1.bn1.num_batches_tracked, backbone.layer3.1.conv2.weight, backbone.layer3.1.bn2.weight, backbone.layer3.1.bn2.bias, backbone.layer3.1.bn2.running_mean, backbone.layer3.1.bn2.running_var, backbone.layer3.1.bn2.num_batches_tracked, backbone.layer3.1.conv3.weight, backbone.layer3.1.bn3.weight, backbone.layer3.1.bn3.bias, backbone.layer3.1.bn3.running_mean, backbone.layer3.1.bn3.running_var, backbone.layer3.1.bn3.num_batches_tracked, backbone.layer3.2.conv1.weight, backbone.layer3.2.bn1.weight, backbone.layer3.2.bn1.bias, backbone.layer3.2.bn1.running_mean, backbone.layer3.2.bn1.running_var, backbone.layer3.2.bn1.num_batches_tracked, backbone.layer3.2.conv2.weight, backbone.layer3.2.bn2.weight, backbone.layer3.2.bn2.bias, backbone.layer3.2.bn2.running_mean, backbone.layer3.2.bn2.running_var, backbone.layer3.2.bn2.num_batches_tracked, backbone.layer3.2.conv3.weight, backbone.layer3.2.bn3.weight, backbone.layer3.2.bn3.bias, backbone.layer3.2.bn3.running_mean, backbone.layer3.2.bn3.running_var, backbone.layer3.2.bn3.num_batches_tracked, backbone.layer3.3.conv1.weight, backbone.layer3.3.bn1.weight, backbone.layer3.3.bn1.bias, backbone.layer3.3.bn1.running_mean, backbone.layer3.3.bn1.running_var, backbone.layer3.3.bn1.num_batches_tracked, backbone.layer3.3.conv2.weight, backbone.layer3.3.bn2.weight, backbone.layer3.3.bn2.bias, backbone.layer3.3.bn2.running_mean, backbone.layer3.3.bn2.running_var, backbone.layer3.3.bn2.num_batches_tracked, backbone.layer3.3.conv3.weight, backbone.layer3.3.bn3.weight, backbone.layer3.3.bn3.bias, backbone.layer3.3.bn3.running_mean, backbone.layer3.3.bn3.running_var, backbone.layer3.3.bn3.num_batches_tracked, backbone.layer3.4.conv1.weight, backbone.layer3.4.bn1.weight, backbone.layer3.4.bn1.bias, backbone.layer3.4.bn1.running_mean, backbone.layer3.4.bn1.running_var, backbone.layer3.4.bn1.num_batches_tracked, backbone.layer3.4.conv2.weight, backbone.layer3.4.bn2.weight, backbone.layer3.4.bn2.bias, backbone.layer3.4.bn2.running_mean, backbone.layer3.4.bn2.running_var, backbone.layer3.4.bn2.num_batches_tracked, backbone.layer3.4.conv3.weight, backbone.layer3.4.bn3.weight, backbone.layer3.4.bn3.bias, backbone.layer3.4.bn3.running_mean, backbone.layer3.4.bn3.running_var, backbone.layer3.4.bn3.num_batches_tracked, backbone.layer3.5.conv1.weight, backbone.layer3.5.bn1.weight, backbone.layer3.5.bn1.bias, backbone.layer3.5.bn1.running_mean, backbone.layer3.5.bn1.running_var, backbone.layer3.5.bn1.num_batches_tracked, backbone.layer3.5.conv2.weight, backbone.layer3.5.bn2.weight, backbone.layer3.5.bn2.bias, backbone.layer3.5.bn2.running_mean, backbone.layer3.5.bn2.running_var, backbone.layer3.5.bn2.num_batches_tracked, backbone.layer3.5.conv3.weight, backbone.layer3.5.bn3.weight, backbone.layer3.5.bn3.bias, backbone.layer3.5.bn3.running_mean, backbone.layer3.5.bn3.running_var, backbone.layer3.5.bn3.num_batches_tracked, backbone.layer4.0.conv1.weight, backbone.layer4.0.bn1.weight, backbone.layer4.0.bn1.bias, backbone.layer4.0.bn1.running_mean, backbone.layer4.0.bn1.running_var, backbone.layer4.0.bn1.num_batches_tracked, backbone.layer4.0.conv2.weight, backbone.layer4.0.bn2.weight, backbone.layer4.0.bn2.bias, backbone.layer4.0.bn2.running_mean, backbone.layer4.0.bn2.running_var, backbone.layer4.0.bn2.num_batches_tracked, backbone.layer4.0.conv3.weight, backbone.layer4.0.bn3.weight, backbone.layer4.0.bn3.bias, backbone.layer4.0.bn3.running_mean, backbone.layer4.0.bn3.running_var, backbone.layer4.0.bn3.num_batches_tracked, backbone.layer4.0.downsample.0.weight, backbone.layer4.0.downsample.1.weight, backbone.layer4.0.downsample.1.bias, backbone.layer4.0.downsample.1.running_mean, backbone.layer4.0.downsample.1.running_var, backbone.layer4.0.downsample.1.num_batches_tracked, backbone.layer4.1.conv1.weight, backbone.layer4.1.bn1.weight, backbone.layer4.1.bn1.bias, backbone.layer4.1.bn1.running_mean, backbone.layer4.1.bn1.running_var, backbone.layer4.1.bn1.num_batches_tracked, backbone.layer4.1.conv2.weight, backbone.layer4.1.bn2.weight, backbone.layer4.1.bn2.bias, backbone.layer4.1.bn2.running_mean, backbone.layer4.1.bn2.running_var, backbone.layer4.1.bn2.num_batches_tracked, backbone.layer4.1.conv3.weight, backbone.layer4.1.bn3.weight, backbone.layer4.1.bn3.bias, backbone.layer4.1.bn3.running_mean, backbone.layer4.1.bn3.running_var, backbone.layer4.1.bn3.num_batches_tracked, backbone.layer4.2.conv1.weight, backbone.layer4.2.bn1.weight, backbone.layer4.2.bn1.bias, backbone.layer4.2.bn1.running_mean, backbone.layer4.2.bn1.running_var, backbone.layer4.2.bn1.num_batches_tracked, backbone.layer4.2.conv2.weight, backbone.layer4.2.bn2.weight, backbone.layer4.2.bn2.bias, backbone.layer4.2.bn2.running_mean, backbone.layer4.2.bn2.running_var, backbone.layer4.2.bn2.num_batches_tracked, backbone.layer4.2.conv3.weight, backbone.layer4.2.bn3.weight, backbone.layer4.2.bn3.bias, backbone.layer4.2.bn3.running_mean, backbone.layer4.2.bn3.running_var, backbone.layer4.2.bn3.num_batches_tracked, neck.lateral_convs.0.conv.weight, neck.lateral_convs.0.conv.bias, neck.lateral_convs.1.conv.weight, neck.lateral_convs.1.conv.bias, neck.lateral_convs.2.conv.weight, neck.lateral_convs.2.conv.bias, neck.lateral_convs.3.conv.weight, neck.lateral_convs.3.conv.bias, neck.fpn_convs.0.conv.weight, neck.fpn_convs.0.conv.bias, neck.fpn_convs.1.conv.weight, neck.fpn_convs.1.conv.bias, neck.fpn_convs.2.conv.weight, neck.fpn_convs.2.conv.bias, neck.fpn_convs.3.conv.weight, neck.fpn_convs.3.conv.bias, mask_feat_head.convs_all_levels.0.conv0.conv.weight, mask_feat_head.convs_all_levels.0.conv0.gn.weight, mask_feat_head.convs_all_levels.0.conv0.gn.bias, mask_feat_head.convs_all_levels.1.conv0.conv.weight, mask_feat_head.convs_all_levels.1.conv0.gn.weight, mask_feat_head.convs_all_levels.1.conv0.gn.bias, mask_feat_head.convs_all_levels.2.conv0.conv.weight, mask_feat_head.convs_all_levels.2.conv0.gn.weight, mask_feat_head.convs_all_levels.2.conv0.gn.bias, mask_feat_head.convs_all_levels.2.conv1.conv.weight, mask_feat_head.convs_all_levels.2.conv1.gn.weight, mask_feat_head.convs_all_levels.2.conv1.gn.bias, mask_feat_head.convs_all_levels.3.conv0.conv.weight, mask_feat_head.convs_all_levels.3.conv0.gn.weight, mask_feat_head.convs_all_levels.3.conv0.gn.bias, mask_feat_head.convs_all_levels.3.conv1.conv.weight, mask_feat_head.convs_all_levels.3.conv1.gn.weight, mask_feat_head.convs_all_levels.3.conv1.gn.bias, mask_feat_head.convs_all_levels.3.conv2.conv.weight, mask_feat_head.convs_all_levels.3.conv2.gn.weight, mask_feat_head.convs_all_levels.3.conv2.gn.bias, mask_feat_head.conv_pred.0.conv.weight, mask_feat_head.conv_pred.0.gn.weight, mask_feat_head.conv_pred.0.gn.bias, bbox_head.cate_convs.0.conv.weight, bbox_head.cate_convs.0.gn.weight, bbox_head.cate_convs.0.gn.bias, bbox_head.cate_convs.1.conv.weight, bbox_head.cate_convs.1.gn.weight, bbox_head.cate_convs.1.gn.bias, bbox_head.cate_convs.2.conv.weight, bbox_head.cate_convs.2.gn.weight, bbox_head.cate_convs.2.gn.bias, bbox_head.cate_convs.3.conv.weight, bbox_head.cate_convs.3.gn.weight, bbox_head.cate_convs.3.gn.bias, bbox_head.kernel_convs.0.conv.weight, bbox_head.kernel_convs.0.gn.weight, bbox_head.kernel_convs.0.gn.bias, bbox_head.kernel_convs.1.conv.weight, bbox_head.kernel_convs.1.gn.weight, bbox_head.kernel_convs.1.gn.bias, bbox_head.kernel_convs.2.conv.weight, bbox_head.kernel_convs.2.gn.weight, bbox_head.kernel_convs.2.gn.bias, bbox_head.kernel_convs.3.conv.weight, bbox_head.kernel_convs.3.gn.weight, bbox_head.kernel_convs.3.gn.bias, bbox_head.solo_cate.weight, bbox_head.solo_cate.bias, bbox_head.solo_kernel.weight, bbox_head.solo_kernel.bias

missing keys in source state_dict: conv1.weight, bn1.weight, bn1.bias, bn1.running_mean, bn1.running_var, layer1.0.conv1.weight, layer1.0.bn1.weight, layer1.0.bn1.bias, layer1.0.bn1.running_mean, layer1.0.bn1.running_var, layer1.0.conv2.weight, layer1.0.bn2.weight, layer1.0.bn2.bias, layer1.0.bn2.running_mean, layer1.0.bn2.running_var, layer1.0.conv3.weight, layer1.0.bn3.weight, layer1.0.bn3.bias, layer1.0.bn3.running_mean, layer1.0.bn3.running_var, layer1.0.downsample.0.weight, layer1.0.downsample.1.weight, layer1.0.downsample.1.bias, layer1.0.downsample.1.running_mean, layer1.0.downsample.1.running_var, layer1.1.conv1.weight, layer1.1.bn1.weight, layer1.1.bn1.bias, layer1.1.bn1.running_mean, layer1.1.bn1.running_var, layer1.1.conv2.weight, layer1.1.bn2.weight, layer1.1.bn2.bias, layer1.1.bn2.running_mean, layer1.1.bn2.running_var, layer1.1.conv3.weight, layer1.1.bn3.weight, layer1.1.bn3.bias, layer1.1.bn3.running_mean, layer1.1.bn3.running_var, layer1.2.conv1.weight, layer1.2.bn1.weight, layer1.2.bn1.bias, layer1.2.bn1.running_mean, layer1.2.bn1.running_var, layer1.2.conv2.weight, layer1.2.bn2.weight, layer1.2.bn2.bias, layer1.2.bn2.running_mean, layer1.2.bn2.running_var, layer1.2.conv3.weight, layer1.2.bn3.weight, layer1.2.bn3.bias, layer1.2.bn3.running_mean, layer1.2.bn3.running_var, layer2.0.conv1.weight, layer2.0.bn1.weight, layer2.0.bn1.bias, layer2.0.bn1.running_mean, layer2.0.bn1.running_var, layer2.0.conv2.weight, layer2.0.bn2.weight, layer2.0.bn2.bias, layer2.0.bn2.running_mean, layer2.0.bn2.running_var, layer2.0.conv3.weight, layer2.0.bn3.weight, layer2.0.bn3.bias, layer2.0.bn3.running_mean, layer2.0.bn3.running_var, layer2.0.downsample.0.weight, layer2.0.downsample.1.weight, layer2.0.downsample.1.bias, layer2.0.downsample.1.running_mean, layer2.0.downsample.1.running_var, layer2.1.conv1.weight, layer2.1.bn1.weight, layer2.1.bn1.bias, layer2.1.bn1.running_mean, layer2.1.bn1.running_var, layer2.1.conv2.weight, layer2.1.bn2.weight, layer2.1.bn2.bias, layer2.1.bn2.running_mean, layer2.1.bn2.running_var, layer2.1.conv3.weight, layer2.1.bn3.weight, layer2.1.bn3.bias, layer2.1.bn3.running_mean, layer2.1.bn3.running_var, layer2.2.conv1.weight, layer2.2.bn1.weight, layer2.2.bn1.bias, layer2.2.bn1.running_mean, layer2.2.bn1.running_var, layer2.2.conv2.weight, layer2.2.bn2.weight, layer2.2.bn2.bias, layer2.2.bn2.running_mean, layer2.2.bn2.running_var, layer2.2.conv3.weight, layer2.2.bn3.weight, layer2.2.bn3.bias, layer2.2.bn3.running_mean, layer2.2.bn3.running_var, layer2.3.conv1.weight, layer2.3.bn1.weight, layer2.3.bn1.bias, layer2.3.bn1.running_mean, layer2.3.bn1.running_var, layer2.3.conv2.weight, layer2.3.bn2.weight, layer2.3.bn2.bias, layer2.3.bn2.running_mean, layer2.3.bn2.running_var, layer2.3.conv3.weight, layer2.3.bn3.weight, layer2.3.bn3.bias, layer2.3.bn3.running_mean, layer2.3.bn3.running_var, layer3.0.conv1.weight, layer3.0.bn1.weight, layer3.0.bn1.bias, layer3.0.bn1.running_mean, layer3.0.bn1.running_var, layer3.0.conv2.weight, layer3.0.bn2.weight, layer3.0.bn2.bias, layer3.0.bn2.running_mean, layer3.0.bn2.running_var, layer3.0.conv3.weight, layer3.0.bn3.weight, layer3.0.bn3.bias, layer3.0.bn3.running_mean, layer3.0.bn3.running_var, layer3.0.downsample.0.weight, layer3.0.downsample.1.weight, layer3.0.downsample.1.bias, layer3.0.downsample.1.running_mean, layer3.0.downsample.1.running_var, layer3.1.conv1.weight, layer3.1.bn1.weight, layer3.1.bn1.bias, layer3.1.bn1.running_mean, layer3.1.bn1.running_var, layer3.1.conv2.weight, layer3.1.bn2.weight, layer3.1.bn2.bias, layer3.1.bn2.running_mean, layer3.1.bn2.running_var, layer3.1.conv3.weight, layer3.1.bn3.weight, layer3.1.bn3.bias, layer3.1.bn3.running_mean, layer3.1.bn3.running_var, layer3.2.conv1.weight, layer3.2.bn1.weight, layer3.2.bn1.bias, layer3.2.bn1.running_mean, layer3.2.bn1.running_var, layer3.2.conv2.weight, layer3.2.bn2.weight, layer3.2.bn2.bias, layer3.2.bn2.running_mean, layer3.2.bn2.running_var, layer3.2.conv3.weight, layer3.2.bn3.weight, layer3.2.bn3.bias, layer3.2.bn3.running_mean, layer3.2.bn3.running_var, layer3.3.conv1.weight, layer3.3.bn1.weight, layer3.3.bn1.bias, layer3.3.bn1.running_mean, layer3.3.bn1.running_var, layer3.3.conv2.weight, layer3.3.bn2.weight, layer3.3.bn2.bias, layer3.3.bn2.running_mean, layer3.3.bn2.running_var, layer3.3.conv3.weight, layer3.3.bn3.weight, layer3.3.bn3.bias, layer3.3.bn3.running_mean, layer3.3.bn3.running_var, layer3.4.conv1.weight, layer3.4.bn1.weight, layer3.4.bn1.bias, layer3.4.bn1.running_mean, layer3.4.bn1.running_var, layer3.4.conv2.weight, layer3.4.bn2.weight, layer3.4.bn2.bias, layer3.4.bn2.running_mean, layer3.4.bn2.running_var, layer3.4.conv3.weight, layer3.4.bn3.weight, layer3.4.bn3.bias, layer3.4.bn3.running_mean, layer3.4.bn3.running_var, layer3.5.conv1.weight, layer3.5.bn1.weight, layer3.5.bn1.bias, layer3.5.bn1.running_mean, layer3.5.bn1.running_var, layer3.5.conv2.weight, layer3.5.bn2.weight, layer3.5.bn2.bias, layer3.5.bn2.running_mean, layer3.5.bn2.running_var, layer3.5.conv3.weight, layer3.5.bn3.weight, layer3.5.bn3.bias, layer3.5.bn3.running_mean, layer3.5.bn3.running_var, layer4.0.conv1.weight, layer4.0.bn1.weight, layer4.0.bn1.bias, layer4.0.bn1.running_mean, layer4.0.bn1.running_var, layer4.0.conv2.weight, layer4.0.bn2.weight, layer4.0.bn2.bias, layer4.0.bn2.running_mean, layer4.0.bn2.running_var, layer4.0.conv3.weight, layer4.0.bn3.weight, layer4.0.bn3.bias, layer4.0.bn3.running_mean, layer4.0.bn3.running_var, layer4.0.downsample.0.weight, layer4.0.downsample.1.weight, layer4.0.downsample.1.bias, layer4.0.downsample.1.running_mean, layer4.0.downsample.1.running_var, layer4.1.conv1.weight, layer4.1.bn1.weight, layer4.1.bn1.bias, layer4.1.bn1.running_mean, layer4.1.bn1.running_var, layer4.1.conv2.weight, layer4.1.bn2.weight, layer4.1.bn2.bias, layer4.1.bn2.running_mean, layer4.1.bn2.running_var, layer4.1.conv3.weight, layer4.1.bn3.weight, layer4.1.bn3.bias, layer4.1.bn3.running_mean, layer4.1.bn3.running_var, layer4.2.conv1.weight, layer4.2.bn1.weight, layer4.2.bn1.bias, layer4.2.bn1.running_mean, layer4.2.bn1.running_var, layer4.2.conv2.weight, layer4.2.bn2.weight, layer4.2.bn2.bias, layer4.2.bn2.running_mean, layer4.2.bn2.running_var, layer4.2.conv3.weight, layer4.2.bn3.weight, layer4.2.bn3.bias, layer4.2.bn3.running_mean, layer4.2.bn3.running_var

2021-07-23 06:54:04,437 - mmdet - INFO - Start running, host: root@efe7fbebbac3, work_dir: /home/zq/work/SOLO/work_dirs/solov2_release_r50_fpn_8gpu_3x
2021-07-23 06:54:04,437 - mmdet - INFO - workflow: [('train', 1)], max: 36 epochs
loading annotations into memory...
Done (t=0.02s)
creating index...
index created!
{'type': 'CocoDataset', 'ann_file': 'data/annotation/merge/merge_train_coco.json', 'img_prefix': 'data/road/train/', 'pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'LoadAnnotations', 'with_bbox': True, 'with_mask': True}, {'type': 'Resize', 'img_scale': [(1333, 800), (1333, 768), (1333, 736), (1333, 704), (1333, 672), (1333, 640)], 'multiscale_mode': 'value', 'keep_ratio': True}, {'type': 'RandomFlip', 'flip_ratio': 0.5}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'DefaultFormatBundle'}, {'type': 'Collect', 'keys': ['img', 'gt_bboxes', 'gt_labels', 'gt_masks']}]}
/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:2494: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
2021-07-23 06:54:19,548 - mmdet - INFO - Epoch [1][50/673]	lr: 0.00107, eta: 2:01:46, time: 0.302, data_time: 0.017, memory: 4235, loss_ins: 0.8014, loss_cate: 0.4372, loss: 1.2386
2021-07-23 06:54:35,046 - mmdet - INFO - Epoch [1][100/673]	lr: 0.00206, eta: 2:03:04, time: 0.310, data_time: 0.013, memory: 4235, loss_ins: 0.6777, loss_cate: 0.4188, loss: 1.0965
2021-07-23 06:54:50,083 - mmdet - INFO - Epoch [1][150/673]	lr: 0.00305, eta: 2:02:06, time: 0.301, data_time: 0.012, memory: 4326, loss_ins: 0.7527, loss_cate: 0.6761, loss: 1.4289
2021-07-23 06:55:04,939 - mmdet - INFO - Epoch [1][200/673]	lr: 0.00404, eta: 2:01:08, time: 0.297, data_time: 0.012, memory: 4326, loss_ins: 0.6799, loss_cate: 0.5997, loss: 1.2796
2021-07-23 06:55:19,983 - mmdet - INFO - Epoch [1][250/673]	lr: 0.00503, eta: 2:00:45, time: 0.301, data_time: 0.012, memory: 4327, loss_ins: 0.6567, loss_cate: 0.4080, loss: 1.0647
2021-07-23 06:55:35,216 - mmdet - INFO - Epoch [1][300/673]	lr: 0.00602, eta: 2:00:40, time: 0.305, data_time: 0.012, memory: 4329, loss_ins: 0.6242, loss_cate: 0.6473, loss: 1.2715
2021-07-23 06:55:50,316 - mmdet - INFO - Epoch [1][350/673]	lr: 0.00701, eta: 2:00:23, time: 0.302, data_time: 0.012, memory: 4329, loss_ins: 0.5633, loss_cate: 0.4104, loss: 0.9738
2021-07-23 06:56:05,629 - mmdet - INFO - Epoch [1][400/673]	lr: 0.00800, eta: 2:00:19, time: 0.306, data_time: 0.013, memory: 4329, loss_ins: 0.7073, loss_cate: 0.5458, loss: 1.2531
Process Process-1:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.6/multiprocessing/process.py", line 261, in _bootstrap
    util._exit_function()
  File "/opt/conda/lib/python3.6/multiprocessing/util.py", line 322, in _exit_function
    _run_finalizers()
  File "/opt/conda/lib/python3.6/multiprocessing/util.py", line 262, in _run_finalizers
    finalizer()
  File "/opt/conda/lib/python3.6/multiprocessing/util.py", line 186, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/opt/conda/lib/python3.6/multiprocessing/queues.py", line 191, in _finalize_join
    thread.join()
  File "/opt/conda/lib/python3.6/threading.py", line 1056, in join
    self._wait_for_tstate_lock()
  File "/opt/conda/lib/python3.6/threading.py", line 1072, in _wait_for_tstate_lock
    elif lock.acquire(block, timeout):
KeyboardInterrupt
Process Process-2:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.6/multiprocessing/process.py", line 261, in _bootstrap
    util._exit_function()
  File "/opt/conda/lib/python3.6/multiprocessing/util.py", line 322, in _exit_function
    _run_finalizers()
  File "/opt/conda/lib/python3.6/multiprocessing/util.py", line 262, in _run_finalizers
    finalizer()
  File "/opt/conda/lib/python3.6/multiprocessing/util.py", line 186, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/opt/conda/lib/python3.6/multiprocessing/queues.py", line 191, in _finalize_join
    thread.join()
  File "/opt/conda/lib/python3.6/threading.py", line 1056, in join
    self._wait_for_tstate_lock()
  File "/opt/conda/lib/python3.6/threading.py", line 1072, in _wait_for_tstate_lock
    elif lock.acquire(block, timeout):
KeyboardInterrupt
Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f9f94843c50>>
Traceback (most recent call last):
  File "/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 926, in __del__
    self._shutdown_workers()
  File "/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 906, in _shutdown_workers
    w.join()
  File "/opt/conda/lib/python3.6/multiprocessing/process.py", line 124, in join
    res = self._popen.wait(timeout)
  File "/opt/conda/lib/python3.6/multiprocessing/popen_fork.py", line 50, in wait
    return self.poll(os.WNOHANG if timeout == 0.0 else 0)
  File "/opt/conda/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
KeyboardInterrupt: 
Traceback (most recent call last):
  File "tools/train.py", line 133, in <module>
    main()
  File "tools/train.py", line 129, in main
    timestamp=timestamp)
  File "/home/zq/work/SOLO/mmdet/apis/train.py", line 111, in train_detector
    timestamp=timestamp)
  File "/home/zq/work/SOLO/mmdet/apis/train.py", line 297, in _non_dist_train
    runner.run(data_loaders, cfg.workflow, cfg.total_epochs)
  File "/opt/conda/lib/python3.6/site-packages/mmcv/runner/runner.py", line 364, in run
    epoch_runner(data_loaders[i], **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/mmcv/runner/runner.py", line 275, in train
    self.call_hook('after_train_iter')
  File "/opt/conda/lib/python3.6/site-packages/mmcv/runner/runner.py", line 231, in call_hook
    getattr(hook, fn_name)(self)
  File "/opt/conda/lib/python3.6/site-packages/mmcv/runner/hooks/optimizer.py", line 20, in after_train_iter
    self.clip_grads(runner.model.parameters())
  File "/opt/conda/lib/python3.6/site-packages/mmcv/runner/hooks/optimizer.py", line 14, in clip_grads
    filter(lambda p: p.requires_grad, params), **self.grad_clip)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/utils/clip_grad.py", line 33, in clip_grad_norm_
    total_norm += param_norm.item() ** norm_type
KeyboardInterrupt
2021-07-23 06:57:27,892 - mmdet - INFO - Distributed training: False
2021-07-23 06:57:27,892 - mmdet - INFO - MMDetection Version: 1.0.0+c7b294a
2021-07-23 06:57:27,892 - mmdet - INFO - Config:
# model settings
model = dict(
    type='SOLOv2',
    pretrained='torchvision://resnet50',
    backbone=dict(
        type='ResNet',
        depth=50,
        num_stages=4,
        out_indices=(0, 1, 2, 3),  # C2, C3, C4, C5
        frozen_stages=1,
        style='pytorch'),
    neck=dict(
        type='FPN',
        in_channels=[256, 512, 1024, 2048],
        out_channels=256,
        start_level=0,
        num_outs=5),
    bbox_head=dict(
        type='SOLOv2Head',
        num_classes=2,
        in_channels=256,
        stacked_convs=4,
        seg_feat_channels=512,
        strides=[8, 8, 16, 32, 32],
        scale_ranges=((1, 96), (48, 192), (96, 384), (192, 768), (384, 2048)),
        # scale_ranges=((1, 250), (125, 500), (250, 1000), (500, 2000)),
        sigma=0.2,
        num_grids=[40, 36, 24, 16, 12],
        ins_out_channels=256,
        loss_ins=dict(
            type='DiceLoss',
            use_sigmoid=True,
            loss_weight=3.0),
        # loss_weight=10.0),
        loss_cate=dict(
            type='FocalLoss',
            use_sigmoid=True,
            gamma=2.0,
            alpha=0.25,
            loss_weight=1.0)),
    mask_feat_head=dict(
        type='MaskFeatHead',
        in_channels=256,
        out_channels=128,
        start_level=0,
        end_level=3,
        num_classes=256,
        norm_cfg=dict(type='GN', num_groups=32, requires_grad=True)),
)
# training and testing settings
train_cfg = dict()
test_cfg = dict(
    nms_pre=500,
    score_thr=0.1,
    mask_thr=0.5,
    update_thr=0.05,
    kernel='gaussian',  # gaussian/linear
    sigma=2.0,
    max_per_img=100)
# dataset settings
dataset_type = 'CocoDataset'
data_root = 'data/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),
    dict(type='Resize',
         img_scale=[(1333, 800), (1333, 768), (1333, 736),
                    (1333, 704), (1333, 672), (1333, 640)],
         multiscale_mode='value',
         keep_ratio=True),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(type='Normalize', **img_norm_cfg),
    dict(type='Pad', size_divisor=32),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks']),
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(1333, 800),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(type='Normalize', **img_norm_cfg),
            dict(type='Pad', size_divisor=32),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img']),
        ])
]
data = dict(
    imgs_per_gpu=2,
    workers_per_gpu=2,
    train=dict(
        type=dataset_type,
        ann_file=data_root + 'annotation/merge/merge_train_coco.json',
        img_prefix=data_root + 'road/train/',
        pipeline=train_pipeline),
    val=dict(
        type=dataset_type,
        ann_file=data_root + 'annotation/merge/merge_val_coco.json',
        img_prefix=data_root + 'road/val/',
        pipeline=test_pipeline),
    test=dict(
        type=dataset_type,
        ann_file=data_root + 'annotation/merge/merge_val_coco.json',
        img_prefix=data_root + 'road/val/',
        pipeline=test_pipeline))
# optimizer
optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0001)
optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))
# learning policy
lr_config = dict(
    policy='step',
    warmup='linear',
    warmup_iters=500,
    warmup_ratio=0.01,
    step=[27, 33])
checkpoint_config = dict(interval=1)
# yapf:disable
log_config = dict(
    interval=50,
    hooks=[
        dict(type='TextLoggerHook'),
        # dict(type='TensorboardLoggerHook')
    ])
# yapf:enable
# runtime settings
total_epochs = 36
device_ids = range(8)
dist_params = dict(backend='nccl')
log_level = 'INFO'
work_dir = './work_dirs/solov2_release_r50_fpn_8gpu_3x'
# work_dir = './work_dirs/solov2_release_r50_fpn_8gpu_3x_scale'
# work_dir = './work_dirs/solov2_release_r50_fpn_8gpu_3x_weight'
# work_dir = './work_dirs/solov2_release_r50_fpn_8gpu_3x_workflow'
# work_dir = './work_dirs/solov2_release_r50_fpn_8gpu_3x_validate'

load_from = None
resume_from = None
workflow = [('train', 1)]

2021-07-23 06:57:28,292 - mmdet - INFO - load model from: torchvision://resnet50
2021-07-23 06:57:30,591 - mmdet - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: backbone.conv1.weight, backbone.bn1.weight, backbone.bn1.bias, backbone.bn1.running_mean, backbone.bn1.running_var, backbone.bn1.num_batches_tracked, backbone.layer1.0.conv1.weight, backbone.layer1.0.bn1.weight, backbone.layer1.0.bn1.bias, backbone.layer1.0.bn1.running_mean, backbone.layer1.0.bn1.running_var, backbone.layer1.0.bn1.num_batches_tracked, backbone.layer1.0.conv2.weight, backbone.layer1.0.bn2.weight, backbone.layer1.0.bn2.bias, backbone.layer1.0.bn2.running_mean, backbone.layer1.0.bn2.running_var, backbone.layer1.0.bn2.num_batches_tracked, backbone.layer1.0.conv3.weight, backbone.layer1.0.bn3.weight, backbone.layer1.0.bn3.bias, backbone.layer1.0.bn3.running_mean, backbone.layer1.0.bn3.running_var, backbone.layer1.0.bn3.num_batches_tracked, backbone.layer1.0.downsample.0.weight, backbone.layer1.0.downsample.1.weight, backbone.layer1.0.downsample.1.bias, backbone.layer1.0.downsample.1.running_mean, backbone.layer1.0.downsample.1.running_var, backbone.layer1.0.downsample.1.num_batches_tracked, backbone.layer1.1.conv1.weight, backbone.layer1.1.bn1.weight, backbone.layer1.1.bn1.bias, backbone.layer1.1.bn1.running_mean, backbone.layer1.1.bn1.running_var, backbone.layer1.1.bn1.num_batches_tracked, backbone.layer1.1.conv2.weight, backbone.layer1.1.bn2.weight, backbone.layer1.1.bn2.bias, backbone.layer1.1.bn2.running_mean, backbone.layer1.1.bn2.running_var, backbone.layer1.1.bn2.num_batches_tracked, backbone.layer1.1.conv3.weight, backbone.layer1.1.bn3.weight, backbone.layer1.1.bn3.bias, backbone.layer1.1.bn3.running_mean, backbone.layer1.1.bn3.running_var, backbone.layer1.1.bn3.num_batches_tracked, backbone.layer1.2.conv1.weight, backbone.layer1.2.bn1.weight, backbone.layer1.2.bn1.bias, backbone.layer1.2.bn1.running_mean, backbone.layer1.2.bn1.running_var, backbone.layer1.2.bn1.num_batches_tracked, backbone.layer1.2.conv2.weight, backbone.layer1.2.bn2.weight, backbone.layer1.2.bn2.bias, backbone.layer1.2.bn2.running_mean, backbone.layer1.2.bn2.running_var, backbone.layer1.2.bn2.num_batches_tracked, backbone.layer1.2.conv3.weight, backbone.layer1.2.bn3.weight, backbone.layer1.2.bn3.bias, backbone.layer1.2.bn3.running_mean, backbone.layer1.2.bn3.running_var, backbone.layer1.2.bn3.num_batches_tracked, backbone.layer2.0.conv1.weight, backbone.layer2.0.bn1.weight, backbone.layer2.0.bn1.bias, backbone.layer2.0.bn1.running_mean, backbone.layer2.0.bn1.running_var, backbone.layer2.0.bn1.num_batches_tracked, backbone.layer2.0.conv2.weight, backbone.layer2.0.bn2.weight, backbone.layer2.0.bn2.bias, backbone.layer2.0.bn2.running_mean, backbone.layer2.0.bn2.running_var, backbone.layer2.0.bn2.num_batches_tracked, backbone.layer2.0.conv3.weight, backbone.layer2.0.bn3.weight, backbone.layer2.0.bn3.bias, backbone.layer2.0.bn3.running_mean, backbone.layer2.0.bn3.running_var, backbone.layer2.0.bn3.num_batches_tracked, backbone.layer2.0.downsample.0.weight, backbone.layer2.0.downsample.1.weight, backbone.layer2.0.downsample.1.bias, backbone.layer2.0.downsample.1.running_mean, backbone.layer2.0.downsample.1.running_var, backbone.layer2.0.downsample.1.num_batches_tracked, backbone.layer2.1.conv1.weight, backbone.layer2.1.bn1.weight, backbone.layer2.1.bn1.bias, backbone.layer2.1.bn1.running_mean, backbone.layer2.1.bn1.running_var, backbone.layer2.1.bn1.num_batches_tracked, backbone.layer2.1.conv2.weight, backbone.layer2.1.bn2.weight, backbone.layer2.1.bn2.bias, backbone.layer2.1.bn2.running_mean, backbone.layer2.1.bn2.running_var, backbone.layer2.1.bn2.num_batches_tracked, backbone.layer2.1.conv3.weight, backbone.layer2.1.bn3.weight, backbone.layer2.1.bn3.bias, backbone.layer2.1.bn3.running_mean, backbone.layer2.1.bn3.running_var, backbone.layer2.1.bn3.num_batches_tracked, backbone.layer2.2.conv1.weight, backbone.layer2.2.bn1.weight, backbone.layer2.2.bn1.bias, backbone.layer2.2.bn1.running_mean, backbone.layer2.2.bn1.running_var, backbone.layer2.2.bn1.num_batches_tracked, backbone.layer2.2.conv2.weight, backbone.layer2.2.bn2.weight, backbone.layer2.2.bn2.bias, backbone.layer2.2.bn2.running_mean, backbone.layer2.2.bn2.running_var, backbone.layer2.2.bn2.num_batches_tracked, backbone.layer2.2.conv3.weight, backbone.layer2.2.bn3.weight, backbone.layer2.2.bn3.bias, backbone.layer2.2.bn3.running_mean, backbone.layer2.2.bn3.running_var, backbone.layer2.2.bn3.num_batches_tracked, backbone.layer2.3.conv1.weight, backbone.layer2.3.bn1.weight, backbone.layer2.3.bn1.bias, backbone.layer2.3.bn1.running_mean, backbone.layer2.3.bn1.running_var, backbone.layer2.3.bn1.num_batches_tracked, backbone.layer2.3.conv2.weight, backbone.layer2.3.bn2.weight, backbone.layer2.3.bn2.bias, backbone.layer2.3.bn2.running_mean, backbone.layer2.3.bn2.running_var, backbone.layer2.3.bn2.num_batches_tracked, backbone.layer2.3.conv3.weight, backbone.layer2.3.bn3.weight, backbone.layer2.3.bn3.bias, backbone.layer2.3.bn3.running_mean, backbone.layer2.3.bn3.running_var, backbone.layer2.3.bn3.num_batches_tracked, backbone.layer3.0.conv1.weight, backbone.layer3.0.bn1.weight, backbone.layer3.0.bn1.bias, backbone.layer3.0.bn1.running_mean, backbone.layer3.0.bn1.running_var, backbone.layer3.0.bn1.num_batches_tracked, backbone.layer3.0.conv2.weight, backbone.layer3.0.bn2.weight, backbone.layer3.0.bn2.bias, backbone.layer3.0.bn2.running_mean, backbone.layer3.0.bn2.running_var, backbone.layer3.0.bn2.num_batches_tracked, backbone.layer3.0.conv3.weight, backbone.layer3.0.bn3.weight, backbone.layer3.0.bn3.bias, backbone.layer3.0.bn3.running_mean, backbone.layer3.0.bn3.running_var, backbone.layer3.0.bn3.num_batches_tracked, backbone.layer3.0.downsample.0.weight, backbone.layer3.0.downsample.1.weight, backbone.layer3.0.downsample.1.bias, backbone.layer3.0.downsample.1.running_mean, backbone.layer3.0.downsample.1.running_var, backbone.layer3.0.downsample.1.num_batches_tracked, backbone.layer3.1.conv1.weight, backbone.layer3.1.bn1.weight, backbone.layer3.1.bn1.bias, backbone.layer3.1.bn1.running_mean, backbone.layer3.1.bn1.running_var, backbone.layer3.1.bn1.num_batches_tracked, backbone.layer3.1.conv2.weight, backbone.layer3.1.bn2.weight, backbone.layer3.1.bn2.bias, backbone.layer3.1.bn2.running_mean, backbone.layer3.1.bn2.running_var, backbone.layer3.1.bn2.num_batches_tracked, backbone.layer3.1.conv3.weight, backbone.layer3.1.bn3.weight, backbone.layer3.1.bn3.bias, backbone.layer3.1.bn3.running_mean, backbone.layer3.1.bn3.running_var, backbone.layer3.1.bn3.num_batches_tracked, backbone.layer3.2.conv1.weight, backbone.layer3.2.bn1.weight, backbone.layer3.2.bn1.bias, backbone.layer3.2.bn1.running_mean, backbone.layer3.2.bn1.running_var, backbone.layer3.2.bn1.num_batches_tracked, backbone.layer3.2.conv2.weight, backbone.layer3.2.bn2.weight, backbone.layer3.2.bn2.bias, backbone.layer3.2.bn2.running_mean, backbone.layer3.2.bn2.running_var, backbone.layer3.2.bn2.num_batches_tracked, backbone.layer3.2.conv3.weight, backbone.layer3.2.bn3.weight, backbone.layer3.2.bn3.bias, backbone.layer3.2.bn3.running_mean, backbone.layer3.2.bn3.running_var, backbone.layer3.2.bn3.num_batches_tracked, backbone.layer3.3.conv1.weight, backbone.layer3.3.bn1.weight, backbone.layer3.3.bn1.bias, backbone.layer3.3.bn1.running_mean, backbone.layer3.3.bn1.running_var, backbone.layer3.3.bn1.num_batches_tracked, backbone.layer3.3.conv2.weight, backbone.layer3.3.bn2.weight, backbone.layer3.3.bn2.bias, backbone.layer3.3.bn2.running_mean, backbone.layer3.3.bn2.running_var, backbone.layer3.3.bn2.num_batches_tracked, backbone.layer3.3.conv3.weight, backbone.layer3.3.bn3.weight, backbone.layer3.3.bn3.bias, backbone.layer3.3.bn3.running_mean, backbone.layer3.3.bn3.running_var, backbone.layer3.3.bn3.num_batches_tracked, backbone.layer3.4.conv1.weight, backbone.layer3.4.bn1.weight, backbone.layer3.4.bn1.bias, backbone.layer3.4.bn1.running_mean, backbone.layer3.4.bn1.running_var, backbone.layer3.4.bn1.num_batches_tracked, backbone.layer3.4.conv2.weight, backbone.layer3.4.bn2.weight, backbone.layer3.4.bn2.bias, backbone.layer3.4.bn2.running_mean, backbone.layer3.4.bn2.running_var, backbone.layer3.4.bn2.num_batches_tracked, backbone.layer3.4.conv3.weight, backbone.layer3.4.bn3.weight, backbone.layer3.4.bn3.bias, backbone.layer3.4.bn3.running_mean, backbone.layer3.4.bn3.running_var, backbone.layer3.4.bn3.num_batches_tracked, backbone.layer3.5.conv1.weight, backbone.layer3.5.bn1.weight, backbone.layer3.5.bn1.bias, backbone.layer3.5.bn1.running_mean, backbone.layer3.5.bn1.running_var, backbone.layer3.5.bn1.num_batches_tracked, backbone.layer3.5.conv2.weight, backbone.layer3.5.bn2.weight, backbone.layer3.5.bn2.bias, backbone.layer3.5.bn2.running_mean, backbone.layer3.5.bn2.running_var, backbone.layer3.5.bn2.num_batches_tracked, backbone.layer3.5.conv3.weight, backbone.layer3.5.bn3.weight, backbone.layer3.5.bn3.bias, backbone.layer3.5.bn3.running_mean, backbone.layer3.5.bn3.running_var, backbone.layer3.5.bn3.num_batches_tracked, backbone.layer4.0.conv1.weight, backbone.layer4.0.bn1.weight, backbone.layer4.0.bn1.bias, backbone.layer4.0.bn1.running_mean, backbone.layer4.0.bn1.running_var, backbone.layer4.0.bn1.num_batches_tracked, backbone.layer4.0.conv2.weight, backbone.layer4.0.bn2.weight, backbone.layer4.0.bn2.bias, backbone.layer4.0.bn2.running_mean, backbone.layer4.0.bn2.running_var, backbone.layer4.0.bn2.num_batches_tracked, backbone.layer4.0.conv3.weight, backbone.layer4.0.bn3.weight, backbone.layer4.0.bn3.bias, backbone.layer4.0.bn3.running_mean, backbone.layer4.0.bn3.running_var, backbone.layer4.0.bn3.num_batches_tracked, backbone.layer4.0.downsample.0.weight, backbone.layer4.0.downsample.1.weight, backbone.layer4.0.downsample.1.bias, backbone.layer4.0.downsample.1.running_mean, backbone.layer4.0.downsample.1.running_var, backbone.layer4.0.downsample.1.num_batches_tracked, backbone.layer4.1.conv1.weight, backbone.layer4.1.bn1.weight, backbone.layer4.1.bn1.bias, backbone.layer4.1.bn1.running_mean, backbone.layer4.1.bn1.running_var, backbone.layer4.1.bn1.num_batches_tracked, backbone.layer4.1.conv2.weight, backbone.layer4.1.bn2.weight, backbone.layer4.1.bn2.bias, backbone.layer4.1.bn2.running_mean, backbone.layer4.1.bn2.running_var, backbone.layer4.1.bn2.num_batches_tracked, backbone.layer4.1.conv3.weight, backbone.layer4.1.bn3.weight, backbone.layer4.1.bn3.bias, backbone.layer4.1.bn3.running_mean, backbone.layer4.1.bn3.running_var, backbone.layer4.1.bn3.num_batches_tracked, backbone.layer4.2.conv1.weight, backbone.layer4.2.bn1.weight, backbone.layer4.2.bn1.bias, backbone.layer4.2.bn1.running_mean, backbone.layer4.2.bn1.running_var, backbone.layer4.2.bn1.num_batches_tracked, backbone.layer4.2.conv2.weight, backbone.layer4.2.bn2.weight, backbone.layer4.2.bn2.bias, backbone.layer4.2.bn2.running_mean, backbone.layer4.2.bn2.running_var, backbone.layer4.2.bn2.num_batches_tracked, backbone.layer4.2.conv3.weight, backbone.layer4.2.bn3.weight, backbone.layer4.2.bn3.bias, backbone.layer4.2.bn3.running_mean, backbone.layer4.2.bn3.running_var, backbone.layer4.2.bn3.num_batches_tracked, neck.lateral_convs.0.conv.weight, neck.lateral_convs.0.conv.bias, neck.lateral_convs.1.conv.weight, neck.lateral_convs.1.conv.bias, neck.lateral_convs.2.conv.weight, neck.lateral_convs.2.conv.bias, neck.lateral_convs.3.conv.weight, neck.lateral_convs.3.conv.bias, neck.fpn_convs.0.conv.weight, neck.fpn_convs.0.conv.bias, neck.fpn_convs.1.conv.weight, neck.fpn_convs.1.conv.bias, neck.fpn_convs.2.conv.weight, neck.fpn_convs.2.conv.bias, neck.fpn_convs.3.conv.weight, neck.fpn_convs.3.conv.bias, mask_feat_head.convs_all_levels.0.conv0.conv.weight, mask_feat_head.convs_all_levels.0.conv0.gn.weight, mask_feat_head.convs_all_levels.0.conv0.gn.bias, mask_feat_head.convs_all_levels.1.conv0.conv.weight, mask_feat_head.convs_all_levels.1.conv0.gn.weight, mask_feat_head.convs_all_levels.1.conv0.gn.bias, mask_feat_head.convs_all_levels.2.conv0.conv.weight, mask_feat_head.convs_all_levels.2.conv0.gn.weight, mask_feat_head.convs_all_levels.2.conv0.gn.bias, mask_feat_head.convs_all_levels.2.conv1.conv.weight, mask_feat_head.convs_all_levels.2.conv1.gn.weight, mask_feat_head.convs_all_levels.2.conv1.gn.bias, mask_feat_head.convs_all_levels.3.conv0.conv.weight, mask_feat_head.convs_all_levels.3.conv0.gn.weight, mask_feat_head.convs_all_levels.3.conv0.gn.bias, mask_feat_head.convs_all_levels.3.conv1.conv.weight, mask_feat_head.convs_all_levels.3.conv1.gn.weight, mask_feat_head.convs_all_levels.3.conv1.gn.bias, mask_feat_head.convs_all_levels.3.conv2.conv.weight, mask_feat_head.convs_all_levels.3.conv2.gn.weight, mask_feat_head.convs_all_levels.3.conv2.gn.bias, mask_feat_head.conv_pred.0.conv.weight, mask_feat_head.conv_pred.0.gn.weight, mask_feat_head.conv_pred.0.gn.bias, bbox_head.cate_convs.0.conv.weight, bbox_head.cate_convs.0.gn.weight, bbox_head.cate_convs.0.gn.bias, bbox_head.cate_convs.1.conv.weight, bbox_head.cate_convs.1.gn.weight, bbox_head.cate_convs.1.gn.bias, bbox_head.cate_convs.2.conv.weight, bbox_head.cate_convs.2.gn.weight, bbox_head.cate_convs.2.gn.bias, bbox_head.cate_convs.3.conv.weight, bbox_head.cate_convs.3.gn.weight, bbox_head.cate_convs.3.gn.bias, bbox_head.kernel_convs.0.conv.weight, bbox_head.kernel_convs.0.gn.weight, bbox_head.kernel_convs.0.gn.bias, bbox_head.kernel_convs.1.conv.weight, bbox_head.kernel_convs.1.gn.weight, bbox_head.kernel_convs.1.gn.bias, bbox_head.kernel_convs.2.conv.weight, bbox_head.kernel_convs.2.gn.weight, bbox_head.kernel_convs.2.gn.bias, bbox_head.kernel_convs.3.conv.weight, bbox_head.kernel_convs.3.gn.weight, bbox_head.kernel_convs.3.gn.bias, bbox_head.solo_cate.weight, bbox_head.solo_cate.bias, bbox_head.solo_kernel.weight, bbox_head.solo_kernel.bias

missing keys in source state_dict: conv1.weight, bn1.weight, bn1.bias, bn1.running_mean, bn1.running_var, layer1.0.conv1.weight, layer1.0.bn1.weight, layer1.0.bn1.bias, layer1.0.bn1.running_mean, layer1.0.bn1.running_var, layer1.0.conv2.weight, layer1.0.bn2.weight, layer1.0.bn2.bias, layer1.0.bn2.running_mean, layer1.0.bn2.running_var, layer1.0.conv3.weight, layer1.0.bn3.weight, layer1.0.bn3.bias, layer1.0.bn3.running_mean, layer1.0.bn3.running_var, layer1.0.downsample.0.weight, layer1.0.downsample.1.weight, layer1.0.downsample.1.bias, layer1.0.downsample.1.running_mean, layer1.0.downsample.1.running_var, layer1.1.conv1.weight, layer1.1.bn1.weight, layer1.1.bn1.bias, layer1.1.bn1.running_mean, layer1.1.bn1.running_var, layer1.1.conv2.weight, layer1.1.bn2.weight, layer1.1.bn2.bias, layer1.1.bn2.running_mean, layer1.1.bn2.running_var, layer1.1.conv3.weight, layer1.1.bn3.weight, layer1.1.bn3.bias, layer1.1.bn3.running_mean, layer1.1.bn3.running_var, layer1.2.conv1.weight, layer1.2.bn1.weight, layer1.2.bn1.bias, layer1.2.bn1.running_mean, layer1.2.bn1.running_var, layer1.2.conv2.weight, layer1.2.bn2.weight, layer1.2.bn2.bias, layer1.2.bn2.running_mean, layer1.2.bn2.running_var, layer1.2.conv3.weight, layer1.2.bn3.weight, layer1.2.bn3.bias, layer1.2.bn3.running_mean, layer1.2.bn3.running_var, layer2.0.conv1.weight, layer2.0.bn1.weight, layer2.0.bn1.bias, layer2.0.bn1.running_mean, layer2.0.bn1.running_var, layer2.0.conv2.weight, layer2.0.bn2.weight, layer2.0.bn2.bias, layer2.0.bn2.running_mean, layer2.0.bn2.running_var, layer2.0.conv3.weight, layer2.0.bn3.weight, layer2.0.bn3.bias, layer2.0.bn3.running_mean, layer2.0.bn3.running_var, layer2.0.downsample.0.weight, layer2.0.downsample.1.weight, layer2.0.downsample.1.bias, layer2.0.downsample.1.running_mean, layer2.0.downsample.1.running_var, layer2.1.conv1.weight, layer2.1.bn1.weight, layer2.1.bn1.bias, layer2.1.bn1.running_mean, layer2.1.bn1.running_var, layer2.1.conv2.weight, layer2.1.bn2.weight, layer2.1.bn2.bias, layer2.1.bn2.running_mean, layer2.1.bn2.running_var, layer2.1.conv3.weight, layer2.1.bn3.weight, layer2.1.bn3.bias, layer2.1.bn3.running_mean, layer2.1.bn3.running_var, layer2.2.conv1.weight, layer2.2.bn1.weight, layer2.2.bn1.bias, layer2.2.bn1.running_mean, layer2.2.bn1.running_var, layer2.2.conv2.weight, layer2.2.bn2.weight, layer2.2.bn2.bias, layer2.2.bn2.running_mean, layer2.2.bn2.running_var, layer2.2.conv3.weight, layer2.2.bn3.weight, layer2.2.bn3.bias, layer2.2.bn3.running_mean, layer2.2.bn3.running_var, layer2.3.conv1.weight, layer2.3.bn1.weight, layer2.3.bn1.bias, layer2.3.bn1.running_mean, layer2.3.bn1.running_var, layer2.3.conv2.weight, layer2.3.bn2.weight, layer2.3.bn2.bias, layer2.3.bn2.running_mean, layer2.3.bn2.running_var, layer2.3.conv3.weight, layer2.3.bn3.weight, layer2.3.bn3.bias, layer2.3.bn3.running_mean, layer2.3.bn3.running_var, layer3.0.conv1.weight, layer3.0.bn1.weight, layer3.0.bn1.bias, layer3.0.bn1.running_mean, layer3.0.bn1.running_var, layer3.0.conv2.weight, layer3.0.bn2.weight, layer3.0.bn2.bias, layer3.0.bn2.running_mean, layer3.0.bn2.running_var, layer3.0.conv3.weight, layer3.0.bn3.weight, layer3.0.bn3.bias, layer3.0.bn3.running_mean, layer3.0.bn3.running_var, layer3.0.downsample.0.weight, layer3.0.downsample.1.weight, layer3.0.downsample.1.bias, layer3.0.downsample.1.running_mean, layer3.0.downsample.1.running_var, layer3.1.conv1.weight, layer3.1.bn1.weight, layer3.1.bn1.bias, layer3.1.bn1.running_mean, layer3.1.bn1.running_var, layer3.1.conv2.weight, layer3.1.bn2.weight, layer3.1.bn2.bias, layer3.1.bn2.running_mean, layer3.1.bn2.running_var, layer3.1.conv3.weight, layer3.1.bn3.weight, layer3.1.bn3.bias, layer3.1.bn3.running_mean, layer3.1.bn3.running_var, layer3.2.conv1.weight, layer3.2.bn1.weight, layer3.2.bn1.bias, layer3.2.bn1.running_mean, layer3.2.bn1.running_var, layer3.2.conv2.weight, layer3.2.bn2.weight, layer3.2.bn2.bias, layer3.2.bn2.running_mean, layer3.2.bn2.running_var, layer3.2.conv3.weight, layer3.2.bn3.weight, layer3.2.bn3.bias, layer3.2.bn3.running_mean, layer3.2.bn3.running_var, layer3.3.conv1.weight, layer3.3.bn1.weight, layer3.3.bn1.bias, layer3.3.bn1.running_mean, layer3.3.bn1.running_var, layer3.3.conv2.weight, layer3.3.bn2.weight, layer3.3.bn2.bias, layer3.3.bn2.running_mean, layer3.3.bn2.running_var, layer3.3.conv3.weight, layer3.3.bn3.weight, layer3.3.bn3.bias, layer3.3.bn3.running_mean, layer3.3.bn3.running_var, layer3.4.conv1.weight, layer3.4.bn1.weight, layer3.4.bn1.bias, layer3.4.bn1.running_mean, layer3.4.bn1.running_var, layer3.4.conv2.weight, layer3.4.bn2.weight, layer3.4.bn2.bias, layer3.4.bn2.running_mean, layer3.4.bn2.running_var, layer3.4.conv3.weight, layer3.4.bn3.weight, layer3.4.bn3.bias, layer3.4.bn3.running_mean, layer3.4.bn3.running_var, layer3.5.conv1.weight, layer3.5.bn1.weight, layer3.5.bn1.bias, layer3.5.bn1.running_mean, layer3.5.bn1.running_var, layer3.5.conv2.weight, layer3.5.bn2.weight, layer3.5.bn2.bias, layer3.5.bn2.running_mean, layer3.5.bn2.running_var, layer3.5.conv3.weight, layer3.5.bn3.weight, layer3.5.bn3.bias, layer3.5.bn3.running_mean, layer3.5.bn3.running_var, layer4.0.conv1.weight, layer4.0.bn1.weight, layer4.0.bn1.bias, layer4.0.bn1.running_mean, layer4.0.bn1.running_var, layer4.0.conv2.weight, layer4.0.bn2.weight, layer4.0.bn2.bias, layer4.0.bn2.running_mean, layer4.0.bn2.running_var, layer4.0.conv3.weight, layer4.0.bn3.weight, layer4.0.bn3.bias, layer4.0.bn3.running_mean, layer4.0.bn3.running_var, layer4.0.downsample.0.weight, layer4.0.downsample.1.weight, layer4.0.downsample.1.bias, layer4.0.downsample.1.running_mean, layer4.0.downsample.1.running_var, layer4.1.conv1.weight, layer4.1.bn1.weight, layer4.1.bn1.bias, layer4.1.bn1.running_mean, layer4.1.bn1.running_var, layer4.1.conv2.weight, layer4.1.bn2.weight, layer4.1.bn2.bias, layer4.1.bn2.running_mean, layer4.1.bn2.running_var, layer4.1.conv3.weight, layer4.1.bn3.weight, layer4.1.bn3.bias, layer4.1.bn3.running_mean, layer4.1.bn3.running_var, layer4.2.conv1.weight, layer4.2.bn1.weight, layer4.2.bn1.bias, layer4.2.bn1.running_mean, layer4.2.bn1.running_var, layer4.2.conv2.weight, layer4.2.bn2.weight, layer4.2.bn2.bias, layer4.2.bn2.running_mean, layer4.2.bn2.running_var, layer4.2.conv3.weight, layer4.2.bn3.weight, layer4.2.bn3.bias, layer4.2.bn3.running_mean, layer4.2.bn3.running_var

2021-07-23 06:57:30,788 - mmdet - INFO - Start running, host: root@efe7fbebbac3, work_dir: /home/zq/work/SOLO/work_dirs/solov2_release_r50_fpn_8gpu_3x
2021-07-23 06:57:30,788 - mmdet - INFO - workflow: [('train', 1)], max: 36 epochs
loading annotations into memory...
Done (t=0.02s)
creating index...
index created!
{'type': 'CocoDataset', 'ann_file': 'data/annotation/merge/merge_train_coco.json', 'img_prefix': 'data/road/train/', 'pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'LoadAnnotations', 'with_bbox': True, 'with_mask': True}, {'type': 'Resize', 'img_scale': [(1333, 800), (1333, 768), (1333, 736), (1333, 704), (1333, 672), (1333, 640)], 'multiscale_mode': 'value', 'keep_ratio': True}, {'type': 'RandomFlip', 'flip_ratio': 0.5}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'DefaultFormatBundle'}, {'type': 'Collect', 'keys': ['img', 'gt_bboxes', 'gt_labels', 'gt_masks']}]}
/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:2494: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
2021-07-23 06:57:46,153 - mmdet - INFO - Epoch [1][50/673]	lr: 0.00107, eta: 2:03:48, time: 0.307, data_time: 0.018, memory: 4237, loss_ins: 0.9816, loss_cate: 0.4979, loss: 1.4795
2021-07-23 06:58:01,096 - mmdet - INFO - Epoch [1][100/673]	lr: 0.00206, eta: 2:01:51, time: 0.299, data_time: 0.013, memory: 4237, loss_ins: 0.7912, loss_cate: 0.4083, loss: 1.1995
2021-07-23 06:58:15,993 - mmdet - INFO - Epoch [1][150/673]	lr: 0.00305, eta: 2:00:55, time: 0.298, data_time: 0.012, memory: 4330, loss_ins: 0.6956, loss_cate: 0.6007, loss: 1.2963
2021-07-23 06:58:31,210 - mmdet - INFO - Epoch [1][200/673]	lr: 0.00404, eta: 2:00:58, time: 0.304, data_time: 0.013, memory: 4330, loss_ins: 0.6198, loss_cate: 0.6064, loss: 1.2261
2021-07-23 06:58:46,235 - mmdet - INFO - Epoch [1][250/673]	lr: 0.00503, eta: 2:00:35, time: 0.300, data_time: 0.012, memory: 4330, loss_ins: 0.7145, loss_cate: 0.3961, loss: 1.1105
2021-07-23 06:59:00,998 - mmdet - INFO - Epoch [1][300/673]	lr: 0.00602, eta: 1:59:54, time: 0.295, data_time: 0.011, memory: 4330, loss_ins: 0.4767, loss_cate: 0.2505, loss: 0.7272
2021-07-23 06:59:15,951 - mmdet - INFO - Epoch [1][350/673]	lr: 0.00701, eta: 1:59:34, time: 0.299, data_time: 0.012, memory: 4331, loss_ins: 0.4527, loss_cate: 0.2490, loss: 0.7017
2021-07-23 06:59:30,770 - mmdet - INFO - Epoch [1][400/673]	lr: 0.00800, eta: 1:59:07, time: 0.296, data_time: 0.012, memory: 4331, loss_ins: 0.5258, loss_cate: 0.2854, loss: 0.8111
2021-07-23 06:59:45,750 - mmdet - INFO - Epoch [1][450/673]	lr: 0.00899, eta: 1:58:51, time: 0.300, data_time: 0.012, memory: 4331, loss_ins: 0.5098, loss_cate: 0.3378, loss: 0.8476
2021-07-23 07:00:00,506 - mmdet - INFO - Epoch [1][500/673]	lr: 0.00998, eta: 1:58:24, time: 0.295, data_time: 0.012, memory: 4331, loss_ins: 0.5943, loss_cate: 0.3397, loss: 0.9340
2021-07-23 07:00:15,810 - mmdet - INFO - Epoch [1][550/673]	lr: 0.01000, eta: 1:58:24, time: 0.306, data_time: 0.012, memory: 4331, loss_ins: 0.5730, loss_cate: 0.2818, loss: 0.8548
2021-07-23 07:00:30,744 - mmdet - INFO - Epoch [1][600/673]	lr: 0.01000, eta: 1:58:06, time: 0.299, data_time: 0.012, memory: 4331, loss_ins: 0.5458, loss_cate: 0.2588, loss: 0.8045
2021-07-23 07:00:45,915 - mmdet - INFO - Epoch [1][650/673]	lr: 0.01000, eta: 1:57:57, time: 0.303, data_time: 0.012, memory: 4331, loss_ins: 0.6262, loss_cate: 0.2706, loss: 0.8968
2021-07-23 07:01:10,539 - mmdet - INFO - Epoch [2][50/673]	lr: 0.01000, eta: 1:54:09, time: 0.311, data_time: 0.018, memory: 4400, loss_ins: 0.5280, loss_cate: 0.2566, loss: 0.7846
2021-07-23 07:01:25,380 - mmdet - INFO - Epoch [2][100/673]	lr: 0.01000, eta: 1:54:03, time: 0.297, data_time: 0.012, memory: 4400, loss_ins: 0.5858, loss_cate: 0.2878, loss: 0.8736
2021-07-23 07:01:40,753 - mmdet - INFO - Epoch [2][150/673]	lr: 0.01000, eta: 1:54:10, time: 0.307, data_time: 0.012, memory: 4400, loss_ins: 0.4912, loss_cate: 0.2248, loss: 0.7159
2021-07-23 07:01:56,340 - mmdet - INFO - Epoch [2][200/673]	lr: 0.01000, eta: 1:54:21, time: 0.312, data_time: 0.012, memory: 4400, loss_ins: 0.4926, loss_cate: 0.2379, loss: 0.7305
2021-07-23 07:02:11,337 - mmdet - INFO - Epoch [2][250/673]	lr: 0.01000, eta: 1:54:14, time: 0.300, data_time: 0.011, memory: 4400, loss_ins: 0.4642, loss_cate: 0.2282, loss: 0.6925
2021-07-23 07:02:26,486 - mmdet - INFO - Epoch [2][300/673]	lr: 0.01000, eta: 1:54:10, time: 0.303, data_time: 0.012, memory: 4400, loss_ins: 0.5050, loss_cate: 0.2537, loss: 0.7586
2021-07-23 07:02:41,525 - mmdet - INFO - Epoch [2][350/673]	lr: 0.01000, eta: 1:54:02, time: 0.301, data_time: 0.012, memory: 4400, loss_ins: 0.3887, loss_cate: 0.2059, loss: 0.5946
2021-07-23 07:02:56,545 - mmdet - INFO - Epoch [2][400/673]	lr: 0.01000, eta: 1:53:54, time: 0.300, data_time: 0.012, memory: 4400, loss_ins: 0.4571, loss_cate: 0.2118, loss: 0.6689
2021-07-23 07:03:11,825 - mmdet - INFO - Epoch [2][450/673]	lr: 0.01000, eta: 1:53:50, time: 0.306, data_time: 0.013, memory: 4400, loss_ins: 0.5285, loss_cate: 0.2431, loss: 0.7716
2021-07-23 07:03:27,064 - mmdet - INFO - Epoch [2][500/673]	lr: 0.01000, eta: 1:53:44, time: 0.305, data_time: 0.012, memory: 4400, loss_ins: 0.4470, loss_cate: 0.1894, loss: 0.6364
2021-07-23 07:03:42,086 - mmdet - INFO - Epoch [2][550/673]	lr: 0.01000, eta: 1:53:33, time: 0.300, data_time: 0.012, memory: 4400, loss_ins: 0.4122, loss_cate: 0.1894, loss: 0.6017
2021-07-23 07:03:57,251 - mmdet - INFO - Epoch [2][600/673]	lr: 0.01000, eta: 1:53:25, time: 0.303, data_time: 0.012, memory: 4400, loss_ins: 0.5636, loss_cate: 0.2229, loss: 0.7865
2021-07-23 07:04:12,598 - mmdet - INFO - Epoch [2][650/673]	lr: 0.01000, eta: 1:53:19, time: 0.307, data_time: 0.012, memory: 4400, loss_ins: 0.5217, loss_cate: 0.2112, loss: 0.7329
2021-07-23 07:04:36,491 - mmdet - INFO - Epoch [3][50/673]	lr: 0.01000, eta: 1:51:10, time: 0.302, data_time: 0.018, memory: 4400, loss_ins: 0.4448, loss_cate: 0.1908, loss: 0.6356
2021-07-23 07:04:51,642 - mmdet - INFO - Epoch [3][100/673]	lr: 0.01000, eta: 1:51:04, time: 0.303, data_time: 0.012, memory: 4400, loss_ins: 0.4234, loss_cate: 0.1949, loss: 0.6183
2021-07-23 07:05:06,640 - mmdet - INFO - Epoch [3][150/673]	lr: 0.01000, eta: 1:50:55, time: 0.300, data_time: 0.012, memory: 4400, loss_ins: 0.3805, loss_cate: 0.1989, loss: 0.5794
2021-07-23 07:05:21,507 - mmdet - INFO - Epoch [3][200/673]	lr: 0.01000, eta: 1:50:44, time: 0.297, data_time: 0.012, memory: 4400, loss_ins: 0.5317, loss_cate: 0.2095, loss: 0.7412
2021-07-23 07:05:36,588 - mmdet - INFO - Epoch [3][250/673]	lr: 0.01000, eta: 1:50:35, time: 0.302, data_time: 0.012, memory: 4400, loss_ins: 0.4516, loss_cate: 0.2018, loss: 0.6533
2021-07-23 07:05:51,493 - mmdet - INFO - Epoch [3][300/673]	lr: 0.01000, eta: 1:50:24, time: 0.298, data_time: 0.012, memory: 4400, loss_ins: 0.4719, loss_cate: 0.2087, loss: 0.6805
2021-07-23 07:06:06,370 - mmdet - INFO - Epoch [3][350/673]	lr: 0.01000, eta: 1:50:12, time: 0.298, data_time: 0.011, memory: 4400, loss_ins: 0.4750, loss_cate: 0.2060, loss: 0.6809
2021-07-23 07:06:21,542 - mmdet - INFO - Epoch [3][400/673]	lr: 0.01000, eta: 1:50:04, time: 0.303, data_time: 0.011, memory: 4400, loss_ins: 0.5129, loss_cate: 0.2103, loss: 0.7232
2021-07-23 07:06:36,612 - mmdet - INFO - Epoch [3][450/673]	lr: 0.01000, eta: 1:49:54, time: 0.301, data_time: 0.010, memory: 4400, loss_ins: 0.4246, loss_cate: 0.2580, loss: 0.6825
2021-07-23 07:06:51,665 - mmdet - INFO - Epoch [3][500/673]	lr: 0.01000, eta: 1:49:43, time: 0.301, data_time: 0.011, memory: 4400, loss_ins: 0.4146, loss_cate: 0.2017, loss: 0.6164
2021-07-23 07:07:06,660 - mmdet - INFO - Epoch [3][550/673]	lr: 0.01000, eta: 1:49:32, time: 0.300, data_time: 0.012, memory: 4400, loss_ins: 0.3233, loss_cate: 0.1964, loss: 0.5197
2021-07-23 07:07:21,851 - mmdet - INFO - Epoch [3][600/673]	lr: 0.01000, eta: 1:49:23, time: 0.304, data_time: 0.012, memory: 4400, loss_ins: 0.4415, loss_cate: 0.1917, loss: 0.6332
2021-07-23 07:07:37,099 - mmdet - INFO - Epoch [3][650/673]	lr: 0.01000, eta: 1:49:14, time: 0.305, data_time: 0.013, memory: 4400, loss_ins: 0.4785, loss_cate: 0.2116, loss: 0.6901
2021-07-23 07:08:00,926 - mmdet - INFO - Epoch [4][50/673]	lr: 0.01000, eta: 1:47:43, time: 0.300, data_time: 0.018, memory: 4400, loss_ins: 0.4867, loss_cate: 0.2125, loss: 0.6992
2021-07-23 07:08:15,985 - mmdet - INFO - Epoch [4][100/673]	lr: 0.01000, eta: 1:47:33, time: 0.301, data_time: 0.013, memory: 4400, loss_ins: 0.3728, loss_cate: 0.1870, loss: 0.5598
2021-07-23 07:08:30,765 - mmdet - INFO - Epoch [4][150/673]	lr: 0.01000, eta: 1:47:20, time: 0.296, data_time: 0.012, memory: 4400, loss_ins: 0.3475, loss_cate: 0.1861, loss: 0.5336
2021-07-23 07:08:46,099 - mmdet - INFO - Epoch [4][200/673]	lr: 0.01000, eta: 1:47:13, time: 0.307, data_time: 0.013, memory: 4400, loss_ins: 0.3736, loss_cate: 0.1735, loss: 0.5471
2021-07-23 07:09:01,064 - mmdet - INFO - Epoch [4][250/673]	lr: 0.01000, eta: 1:47:02, time: 0.299, data_time: 0.013, memory: 4400, loss_ins: 0.4152, loss_cate: 0.1769, loss: 0.5921
2021-07-23 07:09:15,984 - mmdet - INFO - Epoch [4][300/673]	lr: 0.01000, eta: 1:46:50, time: 0.298, data_time: 0.012, memory: 4400, loss_ins: 0.3505, loss_cate: 0.1821, loss: 0.5326
2021-07-23 07:09:31,224 - mmdet - INFO - Epoch [4][350/673]	lr: 0.01000, eta: 1:46:41, time: 0.305, data_time: 0.013, memory: 4400, loss_ins: 0.4763, loss_cate: 0.2115, loss: 0.6878
2021-07-23 07:09:46,283 - mmdet - INFO - Epoch [4][400/673]	lr: 0.01000, eta: 1:46:30, time: 0.301, data_time: 0.013, memory: 4400, loss_ins: 0.2962, loss_cate: 0.1666, loss: 0.4628
2021-07-23 07:10:01,436 - mmdet - INFO - Epoch [4][450/673]	lr: 0.01000, eta: 1:46:20, time: 0.303, data_time: 0.013, memory: 4400, loss_ins: 0.4018, loss_cate: 0.1928, loss: 0.5946
2021-07-23 07:10:16,664 - mmdet - INFO - Epoch [4][500/673]	lr: 0.01000, eta: 1:46:10, time: 0.305, data_time: 0.013, memory: 4400, loss_ins: 0.4365, loss_cate: 0.1868, loss: 0.6233
2021-07-23 07:10:31,756 - mmdet - INFO - Epoch [4][550/673]	lr: 0.01000, eta: 1:45:59, time: 0.302, data_time: 0.013, memory: 4400, loss_ins: 0.3678, loss_cate: 0.1736, loss: 0.5414
2021-07-23 07:10:46,658 - mmdet - INFO - Epoch [4][600/673]	lr: 0.01000, eta: 1:45:46, time: 0.298, data_time: 0.012, memory: 4400, loss_ins: 0.3212, loss_cate: 0.1658, loss: 0.4870
2021-07-23 07:11:01,550 - mmdet - INFO - Epoch [4][650/673]	lr: 0.01000, eta: 1:45:33, time: 0.298, data_time: 0.013, memory: 4400, loss_ins: 0.3586, loss_cate: 0.1750, loss: 0.5336
2021-07-23 07:11:25,787 - mmdet - INFO - Epoch [5][50/673]	lr: 0.01000, eta: 1:44:20, time: 0.298, data_time: 0.018, memory: 4400, loss_ins: 0.3617, loss_cate: 0.1832, loss: 0.5449
2021-07-23 07:11:40,589 - mmdet - INFO - Epoch [5][100/673]	lr: 0.01000, eta: 1:44:08, time: 0.296, data_time: 0.011, memory: 4400, loss_ins: 0.3039, loss_cate: 0.1738, loss: 0.4777
2021-07-23 07:11:55,887 - mmdet - INFO - Epoch [5][150/673]	lr: 0.01000, eta: 1:43:59, time: 0.306, data_time: 0.012, memory: 4400, loss_ins: 0.3936, loss_cate: 0.1820, loss: 0.5756
2021-07-23 07:12:11,178 - mmdet - INFO - Epoch [5][200/673]	lr: 0.01000, eta: 1:43:49, time: 0.306, data_time: 0.012, memory: 4400, loss_ins: 0.3863, loss_cate: 0.1727, loss: 0.5590
2021-07-23 07:12:26,373 - mmdet - INFO - Epoch [5][250/673]	lr: 0.01000, eta: 1:43:39, time: 0.304, data_time: 0.011, memory: 4400, loss_ins: 0.3474, loss_cate: 0.1736, loss: 0.5210
2021-07-23 07:12:41,153 - mmdet - INFO - Epoch [5][300/673]	lr: 0.01000, eta: 1:43:25, time: 0.296, data_time: 0.012, memory: 4400, loss_ins: 0.3331, loss_cate: 0.1877, loss: 0.5208
2021-07-23 07:12:56,372 - mmdet - INFO - Epoch [5][350/673]	lr: 0.01000, eta: 1:43:15, time: 0.304, data_time: 0.012, memory: 4400, loss_ins: 0.3057, loss_cate: 0.1700, loss: 0.4758
2021-07-23 07:13:11,205 - mmdet - INFO - Epoch [5][400/673]	lr: 0.01000, eta: 1:43:02, time: 0.297, data_time: 0.013, memory: 4400, loss_ins: 0.3315, loss_cate: 0.1672, loss: 0.4987
2021-07-23 07:13:26,230 - mmdet - INFO - Epoch [5][450/673]	lr: 0.01000, eta: 1:42:50, time: 0.301, data_time: 0.013, memory: 4400, loss_ins: 0.3404, loss_cate: 0.1675, loss: 0.5079
2021-07-23 07:13:41,513 - mmdet - INFO - Epoch [5][500/673]	lr: 0.01000, eta: 1:42:40, time: 0.306, data_time: 0.013, memory: 4400, loss_ins: 0.3051, loss_cate: 0.1680, loss: 0.4731
2021-07-23 07:13:56,421 - mmdet - INFO - Epoch [5][550/673]	lr: 0.01000, eta: 1:42:27, time: 0.298, data_time: 0.013, memory: 4400, loss_ins: 0.3168, loss_cate: 0.1743, loss: 0.4911
2021-07-23 07:14:11,673 - mmdet - INFO - Epoch [5][600/673]	lr: 0.01000, eta: 1:42:16, time: 0.305, data_time: 0.013, memory: 4400, loss_ins: 0.3274, loss_cate: 0.1619, loss: 0.4893
2021-07-23 07:14:26,823 - mmdet - INFO - Epoch [5][650/673]	lr: 0.01000, eta: 1:42:04, time: 0.303, data_time: 0.012, memory: 4400, loss_ins: 0.3485, loss_cate: 0.1743, loss: 0.5229
2021-07-23 07:14:50,777 - mmdet - INFO - Epoch [6][50/673]	lr: 0.01000, eta: 1:41:06, time: 0.308, data_time: 0.019, memory: 4400, loss_ins: 0.3506, loss_cate: 0.1659, loss: 0.5165
2021-07-23 07:15:06,049 - mmdet - INFO - Epoch [6][100/673]	lr: 0.01000, eta: 1:40:56, time: 0.305, data_time: 0.016, memory: 4400, loss_ins: 0.3135, loss_cate: 0.1706, loss: 0.4841
2021-07-23 07:15:21,329 - mmdet - INFO - Epoch [6][150/673]	lr: 0.01000, eta: 1:40:45, time: 0.306, data_time: 0.015, memory: 4400, loss_ins: 0.2741, loss_cate: 0.1519, loss: 0.4260
2021-07-23 07:15:36,411 - mmdet - INFO - Epoch [6][200/673]	lr: 0.01000, eta: 1:40:34, time: 0.302, data_time: 0.014, memory: 4400, loss_ins: 0.3228, loss_cate: 0.1645, loss: 0.4873
2021-07-23 07:15:51,553 - mmdet - INFO - Epoch [6][250/673]	lr: 0.01000, eta: 1:40:22, time: 0.303, data_time: 0.014, memory: 4400, loss_ins: 0.3402, loss_cate: 0.1709, loss: 0.5111
2021-07-23 07:16:06,669 - mmdet - INFO - Epoch [6][300/673]	lr: 0.01000, eta: 1:40:10, time: 0.302, data_time: 0.014, memory: 4400, loss_ins: 0.2632, loss_cate: 0.1590, loss: 0.4222
2021-07-23 07:16:21,663 - mmdet - INFO - Epoch [6][350/673]	lr: 0.01000, eta: 1:39:58, time: 0.300, data_time: 0.013, memory: 4400, loss_ins: 0.2532, loss_cate: 0.1526, loss: 0.4059
2021-07-23 07:16:36,748 - mmdet - INFO - Epoch [6][400/673]	lr: 0.01000, eta: 1:39:46, time: 0.302, data_time: 0.014, memory: 4400, loss_ins: 0.2945, loss_cate: 0.1691, loss: 0.4636
2021-07-23 07:16:52,117 - mmdet - INFO - Epoch [6][450/673]	lr: 0.01000, eta: 1:39:35, time: 0.307, data_time: 0.015, memory: 4400, loss_ins: 0.2909, loss_cate: 0.1552, loss: 0.4461
2021-07-23 07:17:07,315 - mmdet - INFO - Epoch [6][500/673]	lr: 0.01000, eta: 1:39:23, time: 0.304, data_time: 0.015, memory: 4400, loss_ins: 0.3475, loss_cate: 0.1667, loss: 0.5143
2021-07-23 07:17:22,368 - mmdet - INFO - Epoch [6][550/673]	lr: 0.01000, eta: 1:39:11, time: 0.301, data_time: 0.015, memory: 4400, loss_ins: 0.3054, loss_cate: 0.1715, loss: 0.4769
2021-07-23 07:17:37,533 - mmdet - INFO - Epoch [6][600/673]	lr: 0.01000, eta: 1:38:59, time: 0.303, data_time: 0.015, memory: 4400, loss_ins: 0.2892, loss_cate: 0.1614, loss: 0.4505
2021-07-23 07:17:52,602 - mmdet - INFO - Epoch [6][650/673]	lr: 0.01000, eta: 1:38:46, time: 0.301, data_time: 0.014, memory: 4400, loss_ins: 0.3180, loss_cate: 0.1617, loss: 0.4797
2021-07-23 07:18:16,638 - mmdet - INFO - Epoch [7][50/673]	lr: 0.01000, eta: 1:37:55, time: 0.309, data_time: 0.021, memory: 4400, loss_ins: 0.2743, loss_cate: 0.1508, loss: 0.4251
2021-07-23 07:18:31,891 - mmdet - INFO - Epoch [7][100/673]	lr: 0.01000, eta: 1:37:44, time: 0.305, data_time: 0.016, memory: 4400, loss_ins: 0.2954, loss_cate: 0.1539, loss: 0.4494
2021-07-23 07:18:47,051 - mmdet - INFO - Epoch [7][150/673]	lr: 0.01000, eta: 1:37:32, time: 0.303, data_time: 0.015, memory: 4400, loss_ins: 0.2998, loss_cate: 0.1613, loss: 0.4611
2021-07-23 07:19:01,947 - mmdet - INFO - Epoch [7][200/673]	lr: 0.01000, eta: 1:37:19, time: 0.298, data_time: 0.014, memory: 4400, loss_ins: 0.2405, loss_cate: 0.1466, loss: 0.3872
2021-07-23 07:19:17,097 - mmdet - INFO - Epoch [7][250/673]	lr: 0.01000, eta: 1:37:07, time: 0.303, data_time: 0.015, memory: 4400, loss_ins: 0.2863, loss_cate: 0.1595, loss: 0.4458
2021-07-23 07:19:32,310 - mmdet - INFO - Epoch [7][300/673]	lr: 0.01000, eta: 1:36:55, time: 0.304, data_time: 0.014, memory: 4400, loss_ins: 0.2848, loss_cate: 0.1500, loss: 0.4347
2021-07-23 07:19:47,440 - mmdet - INFO - Epoch [7][350/673]	lr: 0.01000, eta: 1:36:43, time: 0.303, data_time: 0.014, memory: 4400, loss_ins: 0.2638, loss_cate: 0.1458, loss: 0.4097
2021-07-23 07:20:02,725 - mmdet - INFO - Epoch [7][400/673]	lr: 0.01000, eta: 1:36:31, time: 0.306, data_time: 0.014, memory: 4400, loss_ins: 0.2680, loss_cate: 0.1807, loss: 0.4486
2021-07-23 07:20:17,990 - mmdet - INFO - Epoch [7][450/673]	lr: 0.01000, eta: 1:36:19, time: 0.305, data_time: 0.014, memory: 4400, loss_ins: 0.3764, loss_cate: 0.1548, loss: 0.5313
2021-07-23 07:20:32,724 - mmdet - INFO - Epoch [7][500/673]	lr: 0.01000, eta: 1:36:05, time: 0.295, data_time: 0.013, memory: 4400, loss_ins: 0.2609, loss_cate: 0.1606, loss: 0.4215
2021-07-23 07:20:48,012 - mmdet - INFO - Epoch [7][550/673]	lr: 0.01000, eta: 1:35:53, time: 0.306, data_time: 0.015, memory: 4400, loss_ins: 0.2428, loss_cate: 0.1403, loss: 0.3831
2021-07-23 07:21:03,383 - mmdet - INFO - Epoch [7][600/673]	lr: 0.01000, eta: 1:35:41, time: 0.307, data_time: 0.015, memory: 4400, loss_ins: 0.3023, loss_cate: 0.1585, loss: 0.4608
2021-07-23 07:21:18,176 - mmdet - INFO - Epoch [7][650/673]	lr: 0.01000, eta: 1:35:27, time: 0.296, data_time: 0.012, memory: 4400, loss_ins: 0.2350, loss_cate: 0.1373, loss: 0.3724
2021-07-23 07:21:41,960 - mmdet - INFO - Epoch [8][50/673]	lr: 0.01000, eta: 1:34:40, time: 0.301, data_time: 0.018, memory: 4400, loss_ins: 0.2851, loss_cate: 0.1484, loss: 0.4335
2021-07-23 07:21:56,697 - mmdet - INFO - Epoch [8][100/673]	lr: 0.01000, eta: 1:34:26, time: 0.295, data_time: 0.013, memory: 4400, loss_ins: 0.2366, loss_cate: 0.1383, loss: 0.3750
2021-07-23 07:22:11,770 - mmdet - INFO - Epoch [8][150/673]	lr: 0.01000, eta: 1:34:13, time: 0.301, data_time: 0.013, memory: 4400, loss_ins: 0.2723, loss_cate: 0.1518, loss: 0.4241
2021-07-23 07:22:26,648 - mmdet - INFO - Epoch [8][200/673]	lr: 0.01000, eta: 1:34:00, time: 0.298, data_time: 0.013, memory: 4400, loss_ins: 0.2707, loss_cate: 0.1644, loss: 0.4351
2021-07-23 07:22:41,892 - mmdet - INFO - Epoch [8][250/673]	lr: 0.01000, eta: 1:33:48, time: 0.305, data_time: 0.013, memory: 4400, loss_ins: 0.3035, loss_cate: 0.1519, loss: 0.4554
2021-07-23 07:22:56,977 - mmdet - INFO - Epoch [8][300/673]	lr: 0.01000, eta: 1:33:35, time: 0.302, data_time: 0.013, memory: 4400, loss_ins: 0.2624, loss_cate: 0.1437, loss: 0.4061
2021-07-23 07:23:11,822 - mmdet - INFO - Epoch [8][350/673]	lr: 0.01000, eta: 1:33:21, time: 0.297, data_time: 0.012, memory: 4400, loss_ins: 0.3094, loss_cate: 0.1416, loss: 0.4510
2021-07-23 07:23:26,946 - mmdet - INFO - Epoch [8][400/673]	lr: 0.01000, eta: 1:33:09, time: 0.302, data_time: 0.013, memory: 4400, loss_ins: 0.3004, loss_cate: 0.1586, loss: 0.4590
2021-07-23 07:23:42,216 - mmdet - INFO - Epoch [8][450/673]	lr: 0.01000, eta: 1:32:56, time: 0.305, data_time: 0.013, memory: 4400, loss_ins: 0.2995, loss_cate: 0.1545, loss: 0.4540
2021-07-23 07:23:57,387 - mmdet - INFO - Epoch [8][500/673]	lr: 0.01000, eta: 1:32:44, time: 0.303, data_time: 0.013, memory: 4400, loss_ins: 0.3011, loss_cate: 0.1509, loss: 0.4520
2021-07-23 07:24:12,510 - mmdet - INFO - Epoch [8][550/673]	lr: 0.01000, eta: 1:32:31, time: 0.302, data_time: 0.013, memory: 4400, loss_ins: 0.2352, loss_cate: 0.1462, loss: 0.3814
2021-07-23 07:24:27,495 - mmdet - INFO - Epoch [8][600/673]	lr: 0.01000, eta: 1:32:18, time: 0.300, data_time: 0.013, memory: 4400, loss_ins: 0.2399, loss_cate: 0.1401, loss: 0.3800
2021-07-23 07:24:42,478 - mmdet - INFO - Epoch [8][650/673]	lr: 0.01000, eta: 1:32:04, time: 0.300, data_time: 0.013, memory: 4400, loss_ins: 0.2267, loss_cate: 0.1388, loss: 0.3655
2021-07-23 07:25:06,758 - mmdet - INFO - Epoch [9][50/673]	lr: 0.01000, eta: 1:31:22, time: 0.307, data_time: 0.018, memory: 4400, loss_ins: 0.2506, loss_cate: 0.1439, loss: 0.3945
2021-07-23 07:25:21,815 - mmdet - INFO - Epoch [9][100/673]	lr: 0.01000, eta: 1:31:09, time: 0.301, data_time: 0.013, memory: 4400, loss_ins: 0.2030, loss_cate: 0.1240, loss: 0.3270
2021-07-23 07:25:36,703 - mmdet - INFO - Epoch [9][150/673]	lr: 0.01000, eta: 1:30:55, time: 0.298, data_time: 0.014, memory: 4400, loss_ins: 0.1969, loss_cate: 0.1368, loss: 0.3337
2021-07-23 07:25:51,618 - mmdet - INFO - Epoch [9][200/673]	lr: 0.01000, eta: 1:30:42, time: 0.298, data_time: 0.013, memory: 4400, loss_ins: 0.2767, loss_cate: 0.1412, loss: 0.4178
2021-07-23 07:26:06,761 - mmdet - INFO - Epoch [9][250/673]	lr: 0.01000, eta: 1:30:29, time: 0.303, data_time: 0.013, memory: 4400, loss_ins: 0.2486, loss_cate: 0.1357, loss: 0.3844
2021-07-23 07:26:21,844 - mmdet - INFO - Epoch [9][300/673]	lr: 0.01000, eta: 1:30:16, time: 0.302, data_time: 0.013, memory: 4400, loss_ins: 0.2180, loss_cate: 0.1456, loss: 0.3636
2021-07-23 07:26:37,062 - mmdet - INFO - Epoch [9][350/673]	lr: 0.01000, eta: 1:30:03, time: 0.304, data_time: 0.013, memory: 4400, loss_ins: 0.2581, loss_cate: 0.1443, loss: 0.4024
2021-07-23 07:26:51,820 - mmdet - INFO - Epoch [9][400/673]	lr: 0.01000, eta: 1:29:49, time: 0.295, data_time: 0.013, memory: 4400, loss_ins: 0.2733, loss_cate: 0.1322, loss: 0.4055
2021-07-23 07:27:06,755 - mmdet - INFO - Epoch [9][450/673]	lr: 0.01000, eta: 1:29:36, time: 0.299, data_time: 0.012, memory: 4400, loss_ins: 0.3287, loss_cate: 0.1634, loss: 0.4920
2021-07-23 07:27:21,829 - mmdet - INFO - Epoch [9][500/673]	lr: 0.01000, eta: 1:29:22, time: 0.301, data_time: 0.013, memory: 4400, loss_ins: 0.2112, loss_cate: 0.1235, loss: 0.3347
2021-07-23 07:27:37,037 - mmdet - INFO - Epoch [9][550/673]	lr: 0.01000, eta: 1:29:10, time: 0.304, data_time: 0.013, memory: 4400, loss_ins: 0.2203, loss_cate: 0.1312, loss: 0.3515
2021-07-23 07:27:51,792 - mmdet - INFO - Epoch [9][600/673]	lr: 0.01000, eta: 1:28:55, time: 0.295, data_time: 0.012, memory: 4400, loss_ins: 0.2146, loss_cate: 0.1283, loss: 0.3428
2021-07-23 07:28:06,820 - mmdet - INFO - Epoch [9][650/673]	lr: 0.01000, eta: 1:28:42, time: 0.301, data_time: 0.013, memory: 4400, loss_ins: 0.3410, loss_cate: 0.1662, loss: 0.5072
2021-07-23 07:28:30,882 - mmdet - INFO - Epoch [10][50/673]	lr: 0.01000, eta: 1:28:02, time: 0.304, data_time: 0.018, memory: 4400, loss_ins: 0.2201, loss_cate: 0.1324, loss: 0.3525
2021-07-23 07:28:45,909 - mmdet - INFO - Epoch [10][100/673]	lr: 0.01000, eta: 1:27:49, time: 0.301, data_time: 0.013, memory: 4400, loss_ins: 0.2243, loss_cate: 0.1347, loss: 0.3590
2021-07-23 07:29:00,766 - mmdet - INFO - Epoch [10][150/673]	lr: 0.01000, eta: 1:27:35, time: 0.297, data_time: 0.013, memory: 4400, loss_ins: 0.2355, loss_cate: 0.1342, loss: 0.3697
2021-07-23 07:29:15,869 - mmdet - INFO - Epoch [10][200/673]	lr: 0.01000, eta: 1:27:22, time: 0.302, data_time: 0.013, memory: 4400, loss_ins: 0.2553, loss_cate: 0.1291, loss: 0.3843
2021-07-23 07:29:30,810 - mmdet - INFO - Epoch [10][250/673]	lr: 0.01000, eta: 1:27:09, time: 0.299, data_time: 0.013, memory: 4400, loss_ins: 0.2448, loss_cate: 0.1344, loss: 0.3792
2021-07-23 07:29:45,930 - mmdet - INFO - Epoch [10][300/673]	lr: 0.01000, eta: 1:26:55, time: 0.302, data_time: 0.013, memory: 4400, loss_ins: 0.2127, loss_cate: 0.1238, loss: 0.3365
2021-07-23 07:30:01,142 - mmdet - INFO - Epoch [10][350/673]	lr: 0.01000, eta: 1:26:43, time: 0.304, data_time: 0.013, memory: 4400, loss_ins: 0.2253, loss_cate: 0.1346, loss: 0.3599
2021-07-23 07:30:16,171 - mmdet - INFO - Epoch [10][400/673]	lr: 0.01000, eta: 1:26:29, time: 0.301, data_time: 0.013, memory: 4400, loss_ins: 0.2650, loss_cate: 0.1432, loss: 0.4082
2021-07-23 07:30:31,341 - mmdet - INFO - Epoch [10][450/673]	lr: 0.01000, eta: 1:26:16, time: 0.303, data_time: 0.013, memory: 4400, loss_ins: 0.2866, loss_cate: 0.1461, loss: 0.4327
2021-07-23 07:30:46,352 - mmdet - INFO - Epoch [10][500/673]	lr: 0.01000, eta: 1:26:03, time: 0.300, data_time: 0.013, memory: 4400, loss_ins: 0.2363, loss_cate: 0.1395, loss: 0.3758
2021-07-23 07:31:01,320 - mmdet - INFO - Epoch [10][550/673]	lr: 0.01000, eta: 1:25:49, time: 0.299, data_time: 0.012, memory: 4400, loss_ins: 0.2356, loss_cate: 0.1387, loss: 0.3744
2021-07-23 07:31:16,558 - mmdet - INFO - Epoch [10][600/673]	lr: 0.01000, eta: 1:25:36, time: 0.305, data_time: 0.013, memory: 4400, loss_ins: 0.2727, loss_cate: 0.1394, loss: 0.4121
2021-07-23 07:31:31,537 - mmdet - INFO - Epoch [10][650/673]	lr: 0.01000, eta: 1:25:22, time: 0.300, data_time: 0.013, memory: 4400, loss_ins: 0.2165, loss_cate: 0.1243, loss: 0.3408
2021-07-23 07:31:55,521 - mmdet - INFO - Epoch [11][50/673]	lr: 0.01000, eta: 1:24:45, time: 0.305, data_time: 0.016, memory: 4400, loss_ins: 0.2077, loss_cate: 0.1408, loss: 0.3485
2021-07-23 07:32:10,224 - mmdet - INFO - Epoch [11][100/673]	lr: 0.01000, eta: 1:24:31, time: 0.294, data_time: 0.011, memory: 4400, loss_ins: 0.2034, loss_cate: 0.1123, loss: 0.3158
2021-07-23 07:32:25,147 - mmdet - INFO - Epoch [11][150/673]	lr: 0.01000, eta: 1:24:17, time: 0.298, data_time: 0.011, memory: 4400, loss_ins: 0.2114, loss_cate: 0.1330, loss: 0.3444
2021-07-23 07:32:40,007 - mmdet - INFO - Epoch [11][200/673]	lr: 0.01000, eta: 1:24:04, time: 0.297, data_time: 0.012, memory: 4400, loss_ins: 0.2042, loss_cate: 0.1331, loss: 0.3373
2021-07-23 07:32:55,033 - mmdet - INFO - Epoch [11][250/673]	lr: 0.01000, eta: 1:23:50, time: 0.301, data_time: 0.012, memory: 4400, loss_ins: 0.2283, loss_cate: 0.1301, loss: 0.3583
2021-07-23 07:33:10,105 - mmdet - INFO - Epoch [11][300/673]	lr: 0.01000, eta: 1:23:37, time: 0.301, data_time: 0.013, memory: 4400, loss_ins: 0.2389, loss_cate: 0.1379, loss: 0.3768
2021-07-23 07:33:24,754 - mmdet - INFO - Epoch [11][350/673]	lr: 0.01000, eta: 1:23:22, time: 0.293, data_time: 0.011, memory: 4400, loss_ins: 0.2893, loss_cate: 0.1383, loss: 0.4276
2021-07-23 07:33:39,913 - mmdet - INFO - Epoch [11][400/673]	lr: 0.01000, eta: 1:23:09, time: 0.303, data_time: 0.012, memory: 4400, loss_ins: 0.2607, loss_cate: 0.1351, loss: 0.3958
2021-07-23 07:33:54,919 - mmdet - INFO - Epoch [11][450/673]	lr: 0.01000, eta: 1:22:55, time: 0.300, data_time: 0.012, memory: 4400, loss_ins: 0.2440, loss_cate: 0.1347, loss: 0.3786
2021-07-23 07:34:10,087 - mmdet - INFO - Epoch [11][500/673]	lr: 0.01000, eta: 1:22:42, time: 0.303, data_time: 0.012, memory: 4400, loss_ins: 0.2601, loss_cate: 0.1368, loss: 0.3969
2021-07-23 07:34:24,793 - mmdet - INFO - Epoch [11][550/673]	lr: 0.01000, eta: 1:22:28, time: 0.294, data_time: 0.011, memory: 4400, loss_ins: 0.2106, loss_cate: 0.1241, loss: 0.3346
2021-07-23 07:34:39,522 - mmdet - INFO - Epoch [11][600/673]	lr: 0.01000, eta: 1:22:14, time: 0.295, data_time: 0.012, memory: 4400, loss_ins: 0.2102, loss_cate: 0.1331, loss: 0.3432
2021-07-23 07:34:54,262 - mmdet - INFO - Epoch [11][650/673]	lr: 0.01000, eta: 1:21:59, time: 0.295, data_time: 0.012, memory: 4400, loss_ins: 0.1864, loss_cate: 0.1185, loss: 0.3049
2021-07-23 07:35:18,349 - mmdet - INFO - Epoch [12][50/673]	lr: 0.01000, eta: 1:21:24, time: 0.305, data_time: 0.018, memory: 4400, loss_ins: 0.2013, loss_cate: 0.1243, loss: 0.3256
2021-07-23 07:35:33,633 - mmdet - INFO - Epoch [12][100/673]	lr: 0.01000, eta: 1:21:11, time: 0.306, data_time: 0.013, memory: 4400, loss_ins: 0.2047, loss_cate: 0.1173, loss: 0.3220
2021-07-23 07:35:48,590 - mmdet - INFO - Epoch [12][150/673]	lr: 0.01000, eta: 1:20:58, time: 0.299, data_time: 0.013, memory: 4400, loss_ins: 0.2207, loss_cate: 0.1111, loss: 0.3318
2021-07-23 07:36:03,672 - mmdet - INFO - Epoch [12][200/673]	lr: 0.01000, eta: 1:20:44, time: 0.302, data_time: 0.014, memory: 4400, loss_ins: 0.2046, loss_cate: 0.1278, loss: 0.3323
2021-07-23 07:36:18,809 - mmdet - INFO - Epoch [12][250/673]	lr: 0.01000, eta: 1:20:31, time: 0.303, data_time: 0.013, memory: 4400, loss_ins: 0.2034, loss_cate: 0.1147, loss: 0.3181
2021-07-23 07:36:33,791 - mmdet - INFO - Epoch [12][300/673]	lr: 0.01000, eta: 1:20:17, time: 0.300, data_time: 0.012, memory: 4400, loss_ins: 0.2063, loss_cate: 0.1201, loss: 0.3263
2021-07-23 07:36:48,761 - mmdet - INFO - Epoch [12][350/673]	lr: 0.01000, eta: 1:20:03, time: 0.299, data_time: 0.013, memory: 4400, loss_ins: 0.2151, loss_cate: 0.1255, loss: 0.3406
2021-07-23 07:37:04,078 - mmdet - INFO - Epoch [12][400/673]	lr: 0.01000, eta: 1:19:50, time: 0.306, data_time: 0.014, memory: 4400, loss_ins: 0.2410, loss_cate: 0.1355, loss: 0.3766
2021-07-23 07:37:18,932 - mmdet - INFO - Epoch [12][450/673]	lr: 0.01000, eta: 1:19:36, time: 0.297, data_time: 0.012, memory: 4400, loss_ins: 0.2218, loss_cate: 0.1283, loss: 0.3500
2021-07-23 07:37:34,037 - mmdet - INFO - Epoch [12][500/673]	lr: 0.01000, eta: 1:19:23, time: 0.302, data_time: 0.012, memory: 4400, loss_ins: 0.2594, loss_cate: 0.1383, loss: 0.3976
2021-07-23 07:37:48,824 - mmdet - INFO - Epoch [12][550/673]	lr: 0.01000, eta: 1:19:09, time: 0.296, data_time: 0.013, memory: 4400, loss_ins: 0.2128, loss_cate: 0.1302, loss: 0.3429
2021-07-23 07:38:03,657 - mmdet - INFO - Epoch [12][600/673]	lr: 0.01000, eta: 1:18:55, time: 0.297, data_time: 0.013, memory: 4400, loss_ins: 0.1952, loss_cate: 0.1150, loss: 0.3102
2021-07-23 07:38:18,844 - mmdet - INFO - Epoch [12][650/673]	lr: 0.01000, eta: 1:18:41, time: 0.304, data_time: 0.013, memory: 4400, loss_ins: 0.2021, loss_cate: 0.1266, loss: 0.3286
2021-07-23 07:38:43,132 - mmdet - INFO - Epoch [13][50/673]	lr: 0.01000, eta: 1:18:08, time: 0.306, data_time: 0.019, memory: 4400, loss_ins: 0.2556, loss_cate: 0.1334, loss: 0.3890
2021-07-23 07:38:58,249 - mmdet - INFO - Epoch [13][100/673]	lr: 0.01000, eta: 1:17:54, time: 0.302, data_time: 0.013, memory: 4400, loss_ins: 0.2342, loss_cate: 0.1245, loss: 0.3587
2021-07-23 07:39:13,492 - mmdet - INFO - Epoch [13][150/673]	lr: 0.01000, eta: 1:17:41, time: 0.305, data_time: 0.013, memory: 4400, loss_ins: 0.2474, loss_cate: 0.1296, loss: 0.3770
2021-07-23 07:39:28,387 - mmdet - INFO - Epoch [13][200/673]	lr: 0.01000, eta: 1:17:27, time: 0.298, data_time: 0.014, memory: 4400, loss_ins: 0.1752, loss_cate: 0.1211, loss: 0.2962
2021-07-23 07:39:43,459 - mmdet - INFO - Epoch [13][250/673]	lr: 0.01000, eta: 1:17:14, time: 0.301, data_time: 0.013, memory: 4400, loss_ins: 0.1860, loss_cate: 0.1269, loss: 0.3129
2021-07-23 07:39:58,599 - mmdet - INFO - Epoch [13][300/673]	lr: 0.01000, eta: 1:17:00, time: 0.303, data_time: 0.014, memory: 4400, loss_ins: 0.2196, loss_cate: 0.1282, loss: 0.3478
2021-07-23 07:40:13,685 - mmdet - INFO - Epoch [13][350/673]	lr: 0.01000, eta: 1:16:47, time: 0.302, data_time: 0.014, memory: 4440, loss_ins: 0.1962, loss_cate: 0.1183, loss: 0.3145
2021-07-23 07:40:28,829 - mmdet - INFO - Epoch [13][400/673]	lr: 0.01000, eta: 1:16:33, time: 0.303, data_time: 0.014, memory: 4440, loss_ins: 0.2045, loss_cate: 0.1240, loss: 0.3285
2021-07-23 07:40:43,755 - mmdet - INFO - Epoch [13][450/673]	lr: 0.01000, eta: 1:16:19, time: 0.299, data_time: 0.013, memory: 4440, loss_ins: 0.1889, loss_cate: 0.1241, loss: 0.3131
2021-07-23 07:40:58,555 - mmdet - INFO - Epoch [13][500/673]	lr: 0.01000, eta: 1:16:05, time: 0.296, data_time: 0.013, memory: 4440, loss_ins: 0.1715, loss_cate: 0.1124, loss: 0.2840
2021-07-23 07:41:13,892 - mmdet - INFO - Epoch [13][550/673]	lr: 0.01000, eta: 1:15:52, time: 0.307, data_time: 0.014, memory: 4440, loss_ins: 0.1969, loss_cate: 0.1246, loss: 0.3216
2021-07-23 07:41:29,036 - mmdet - INFO - Epoch [13][600/673]	lr: 0.01000, eta: 1:15:38, time: 0.303, data_time: 0.014, memory: 4440, loss_ins: 0.1746, loss_cate: 0.1258, loss: 0.3004
2021-07-23 07:41:44,344 - mmdet - INFO - Epoch [13][650/673]	lr: 0.01000, eta: 1:15:25, time: 0.306, data_time: 0.014, memory: 4440, loss_ins: 0.2391, loss_cate: 0.1323, loss: 0.3714
2021-07-23 07:42:08,137 - mmdet - INFO - Epoch [14][50/673]	lr: 0.01000, eta: 1:14:53, time: 0.301, data_time: 0.017, memory: 4440, loss_ins: 0.2465, loss_cate: 0.1246, loss: 0.3711
2021-07-23 07:42:23,414 - mmdet - INFO - Epoch [14][100/673]	lr: 0.01000, eta: 1:14:39, time: 0.306, data_time: 0.014, memory: 4440, loss_ins: 0.2425, loss_cate: 0.1239, loss: 0.3664
2021-07-23 07:42:38,198 - mmdet - INFO - Epoch [14][150/673]	lr: 0.01000, eta: 1:14:25, time: 0.296, data_time: 0.013, memory: 4440, loss_ins: 0.2095, loss_cate: 0.1326, loss: 0.3420
2021-07-23 07:42:53,229 - mmdet - INFO - Epoch [14][200/673]	lr: 0.01000, eta: 1:14:11, time: 0.301, data_time: 0.013, memory: 4440, loss_ins: 0.1996, loss_cate: 0.1211, loss: 0.3207
2021-07-23 07:43:08,598 - mmdet - INFO - Epoch [14][250/673]	lr: 0.01000, eta: 1:13:58, time: 0.307, data_time: 0.014, memory: 4440, loss_ins: 0.2021, loss_cate: 0.1215, loss: 0.3236
2021-07-23 07:43:23,831 - mmdet - INFO - Epoch [14][300/673]	lr: 0.01000, eta: 1:13:45, time: 0.305, data_time: 0.013, memory: 4440, loss_ins: 0.1995, loss_cate: 0.1291, loss: 0.3287
2021-07-23 07:43:38,509 - mmdet - INFO - Epoch [14][350/673]	lr: 0.01000, eta: 1:13:30, time: 0.294, data_time: 0.011, memory: 4440, loss_ins: 0.2326, loss_cate: 0.1319, loss: 0.3646
2021-07-23 07:43:53,346 - mmdet - INFO - Epoch [14][400/673]	lr: 0.01000, eta: 1:13:16, time: 0.297, data_time: 0.012, memory: 4440, loss_ins: 0.2039, loss_cate: 0.1231, loss: 0.3270
2021-07-23 07:44:08,367 - mmdet - INFO - Epoch [14][450/673]	lr: 0.01000, eta: 1:13:02, time: 0.300, data_time: 0.012, memory: 4440, loss_ins: 0.2158, loss_cate: 0.1224, loss: 0.3381
2021-07-23 07:44:23,249 - mmdet - INFO - Epoch [14][500/673]	lr: 0.01000, eta: 1:12:48, time: 0.298, data_time: 0.012, memory: 4440, loss_ins: 0.1725, loss_cate: 0.1144, loss: 0.2869
2021-07-23 07:44:38,187 - mmdet - INFO - Epoch [14][550/673]	lr: 0.01000, eta: 1:12:34, time: 0.299, data_time: 0.012, memory: 4440, loss_ins: 0.1920, loss_cate: 0.1233, loss: 0.3153
2021-07-23 07:44:53,216 - mmdet - INFO - Epoch [14][600/673]	lr: 0.01000, eta: 1:12:20, time: 0.301, data_time: 0.013, memory: 4440, loss_ins: 0.1570, loss_cate: 0.1090, loss: 0.2659
2021-07-23 07:45:08,244 - mmdet - INFO - Epoch [14][650/673]	lr: 0.01000, eta: 1:12:06, time: 0.301, data_time: 0.013, memory: 4440, loss_ins: 0.1842, loss_cate: 0.1178, loss: 0.3020
2021-07-23 07:45:32,484 - mmdet - INFO - Epoch [15][50/673]	lr: 0.01000, eta: 1:11:36, time: 0.306, data_time: 0.020, memory: 4440, loss_ins: 0.2355, loss_cate: 0.1322, loss: 0.3677
2021-07-23 07:45:47,570 - mmdet - INFO - Epoch [15][100/673]	lr: 0.01000, eta: 1:11:22, time: 0.302, data_time: 0.014, memory: 4440, loss_ins: 0.2324, loss_cate: 0.1253, loss: 0.3577
2021-07-23 07:46:02,803 - mmdet - INFO - Epoch [15][150/673]	lr: 0.01000, eta: 1:11:08, time: 0.305, data_time: 0.013, memory: 4440, loss_ins: 0.2205, loss_cate: 0.1191, loss: 0.3396
2021-07-23 07:46:17,789 - mmdet - INFO - Epoch [15][200/673]	lr: 0.01000, eta: 1:10:54, time: 0.300, data_time: 0.015, memory: 4440, loss_ins: 0.2164, loss_cate: 0.1195, loss: 0.3360
2021-07-23 07:46:33,227 - mmdet - INFO - Epoch [15][250/673]	lr: 0.01000, eta: 1:10:41, time: 0.309, data_time: 0.015, memory: 4440, loss_ins: 0.2126, loss_cate: 0.1206, loss: 0.3332
2021-07-23 07:46:48,801 - mmdet - INFO - Epoch [15][300/673]	lr: 0.01000, eta: 1:10:28, time: 0.311, data_time: 0.016, memory: 4440, loss_ins: 0.1937, loss_cate: 0.1216, loss: 0.3152
2021-07-23 07:47:04,027 - mmdet - INFO - Epoch [15][350/673]	lr: 0.01000, eta: 1:10:15, time: 0.305, data_time: 0.015, memory: 4440, loss_ins: 0.1728, loss_cate: 0.1162, loss: 0.2890
2021-07-23 07:47:19,347 - mmdet - INFO - Epoch [15][400/673]	lr: 0.01000, eta: 1:10:01, time: 0.306, data_time: 0.015, memory: 4440, loss_ins: 0.1880, loss_cate: 0.1220, loss: 0.3100
2021-07-23 07:47:34,495 - mmdet - INFO - Epoch [15][450/673]	lr: 0.01000, eta: 1:09:47, time: 0.303, data_time: 0.016, memory: 4440, loss_ins: 0.1773, loss_cate: 0.1107, loss: 0.2881
2021-07-23 07:47:50,095 - mmdet - INFO - Epoch [15][500/673]	lr: 0.01000, eta: 1:09:34, time: 0.312, data_time: 0.015, memory: 4440, loss_ins: 0.1935, loss_cate: 0.1250, loss: 0.3184
2021-07-23 07:48:05,483 - mmdet - INFO - Epoch [15][550/673]	lr: 0.01000, eta: 1:09:21, time: 0.308, data_time: 0.015, memory: 4440, loss_ins: 0.1736, loss_cate: 0.1087, loss: 0.2824
2021-07-23 07:48:20,908 - mmdet - INFO - Epoch [15][600/673]	lr: 0.01000, eta: 1:09:07, time: 0.308, data_time: 0.015, memory: 4440, loss_ins: 0.1846, loss_cate: 0.1072, loss: 0.2917
2021-07-23 07:48:35,817 - mmdet - INFO - Epoch [15][650/673]	lr: 0.01000, eta: 1:08:53, time: 0.298, data_time: 0.014, memory: 4440, loss_ins: 0.1686, loss_cate: 0.1154, loss: 0.2840
2021-07-23 07:49:00,287 - mmdet - INFO - Epoch [16][50/673]	lr: 0.01000, eta: 1:08:24, time: 0.308, data_time: 0.018, memory: 4440, loss_ins: 0.1565, loss_cate: 0.1085, loss: 0.2650
2021-07-23 07:49:15,342 - mmdet - INFO - Epoch [16][100/673]	lr: 0.01000, eta: 1:08:10, time: 0.301, data_time: 0.013, memory: 4440, loss_ins: 0.1778, loss_cate: 0.1180, loss: 0.2958
2021-07-23 07:49:30,488 - mmdet - INFO - Epoch [16][150/673]	lr: 0.01000, eta: 1:07:56, time: 0.303, data_time: 0.013, memory: 4440, loss_ins: 0.1766, loss_cate: 0.1052, loss: 0.2818
2021-07-23 07:49:45,588 - mmdet - INFO - Epoch [16][200/673]	lr: 0.01000, eta: 1:07:42, time: 0.302, data_time: 0.013, memory: 4440, loss_ins: 0.2053, loss_cate: 0.1215, loss: 0.3268
2021-07-23 07:50:00,750 - mmdet - INFO - Epoch [16][250/673]	lr: 0.01000, eta: 1:07:28, time: 0.303, data_time: 0.012, memory: 4440, loss_ins: 0.1990, loss_cate: 0.1237, loss: 0.3228
2021-07-23 07:50:15,966 - mmdet - INFO - Epoch [16][300/673]	lr: 0.01000, eta: 1:07:15, time: 0.304, data_time: 0.013, memory: 4440, loss_ins: 0.2087, loss_cate: 0.1204, loss: 0.3291
2021-07-23 07:50:31,347 - mmdet - INFO - Epoch [16][350/673]	lr: 0.01000, eta: 1:07:01, time: 0.308, data_time: 0.013, memory: 4440, loss_ins: 0.1649, loss_cate: 0.1080, loss: 0.2729
2021-07-23 07:50:46,494 - mmdet - INFO - Epoch [16][400/673]	lr: 0.01000, eta: 1:06:47, time: 0.303, data_time: 0.013, memory: 4440, loss_ins: 0.1643, loss_cate: 0.1189, loss: 0.2832
2021-07-23 07:51:01,584 - mmdet - INFO - Epoch [16][450/673]	lr: 0.01000, eta: 1:06:33, time: 0.302, data_time: 0.013, memory: 4440, loss_ins: 0.1877, loss_cate: 0.1157, loss: 0.3034
2021-07-23 07:51:16,343 - mmdet - INFO - Epoch [16][500/673]	lr: 0.01000, eta: 1:06:19, time: 0.295, data_time: 0.012, memory: 4440, loss_ins: 0.2257, loss_cate: 0.1130, loss: 0.3387
2021-07-23 07:51:31,151 - mmdet - INFO - Epoch [16][550/673]	lr: 0.01000, eta: 1:06:04, time: 0.296, data_time: 0.012, memory: 4440, loss_ins: 0.1484, loss_cate: 0.1059, loss: 0.2543
2021-07-23 07:51:45,957 - mmdet - INFO - Epoch [16][600/673]	lr: 0.01000, eta: 1:05:50, time: 0.296, data_time: 0.012, memory: 4440, loss_ins: 0.1832, loss_cate: 0.1125, loss: 0.2957
2021-07-23 07:52:01,014 - mmdet - INFO - Epoch [16][650/673]	lr: 0.01000, eta: 1:05:36, time: 0.301, data_time: 0.013, memory: 4440, loss_ins: 0.2328, loss_cate: 0.1266, loss: 0.3594
2021-07-23 07:52:26,176 - mmdet - INFO - Epoch [17][50/673]	lr: 0.01000, eta: 1:05:09, time: 0.325, data_time: 0.019, memory: 4440, loss_ins: 0.1898, loss_cate: 0.1096, loss: 0.2995
2021-07-23 07:52:49,247 - mmdet - INFO - Epoch [17][100/673]	lr: 0.01000, eta: 1:05:04, time: 0.461, data_time: 0.014, memory: 4440, loss_ins: 0.1628, loss_cate: 0.1154, loss: 0.2783
2021-07-23 07:53:13,987 - mmdet - INFO - Epoch [17][150/673]	lr: 0.01000, eta: 1:05:02, time: 0.495, data_time: 0.013, memory: 4440, loss_ins: 0.1495, loss_cate: 0.1084, loss: 0.2579
2021-07-23 07:53:29,108 - mmdet - INFO - Epoch [17][200/673]	lr: 0.01000, eta: 1:04:48, time: 0.302, data_time: 0.014, memory: 4440, loss_ins: 0.1731, loss_cate: 0.1096, loss: 0.2826
2021-07-23 07:53:44,245 - mmdet - INFO - Epoch [17][250/673]	lr: 0.01000, eta: 1:04:34, time: 0.303, data_time: 0.014, memory: 4440, loss_ins: 0.1763, loss_cate: 0.1069, loss: 0.2832
2021-07-23 07:53:59,385 - mmdet - INFO - Epoch [17][300/673]	lr: 0.01000, eta: 1:04:20, time: 0.303, data_time: 0.013, memory: 4440, loss_ins: 0.2024, loss_cate: 0.1234, loss: 0.3259
2021-07-23 07:54:14,540 - mmdet - INFO - Epoch [17][350/673]	lr: 0.01000, eta: 1:04:06, time: 0.303, data_time: 0.014, memory: 4440, loss_ins: 0.1887, loss_cate: 0.1122, loss: 0.3009
2021-07-23 07:54:29,771 - mmdet - INFO - Epoch [17][400/673]	lr: 0.01000, eta: 1:03:52, time: 0.305, data_time: 0.013, memory: 4440, loss_ins: 0.1449, loss_cate: 0.0965, loss: 0.2414
2021-07-23 07:54:44,717 - mmdet - INFO - Epoch [17][450/673]	lr: 0.01000, eta: 1:03:37, time: 0.299, data_time: 0.013, memory: 4440, loss_ins: 0.1554, loss_cate: 0.1121, loss: 0.2675
2021-07-23 07:55:00,348 - mmdet - INFO - Epoch [17][500/673]	lr: 0.01000, eta: 1:03:24, time: 0.313, data_time: 0.013, memory: 4440, loss_ins: 0.1919, loss_cate: 0.1136, loss: 0.3055
2021-07-23 07:55:15,336 - mmdet - INFO - Epoch [17][550/673]	lr: 0.01000, eta: 1:03:10, time: 0.300, data_time: 0.013, memory: 4440, loss_ins: 0.1609, loss_cate: 0.1035, loss: 0.2644
2021-07-23 07:55:30,710 - mmdet - INFO - Epoch [17][600/673]	lr: 0.01000, eta: 1:02:56, time: 0.307, data_time: 0.013, memory: 4440, loss_ins: 0.1974, loss_cate: 0.1134, loss: 0.3109
2021-07-23 07:55:45,870 - mmdet - INFO - Epoch [17][650/673]	lr: 0.01000, eta: 1:02:41, time: 0.303, data_time: 0.013, memory: 4440, loss_ins: 0.1675, loss_cate: 0.1086, loss: 0.2761
2021-07-23 07:56:10,028 - mmdet - INFO - Epoch [18][50/673]	lr: 0.01000, eta: 1:02:13, time: 0.306, data_time: 0.019, memory: 4440, loss_ins: 0.1893, loss_cate: 0.1010, loss: 0.2903
2021-07-23 07:56:25,181 - mmdet - INFO - Epoch [18][100/673]	lr: 0.01000, eta: 1:01:59, time: 0.303, data_time: 0.013, memory: 4440, loss_ins: 0.1900, loss_cate: 0.1176, loss: 0.3076
2021-07-23 07:56:40,381 - mmdet - INFO - Epoch [18][150/673]	lr: 0.01000, eta: 1:01:45, time: 0.304, data_time: 0.013, memory: 4440, loss_ins: 0.1714, loss_cate: 0.1063, loss: 0.2777
2021-07-23 07:56:55,644 - mmdet - INFO - Epoch [18][200/673]	lr: 0.01000, eta: 1:01:31, time: 0.305, data_time: 0.012, memory: 4440, loss_ins: 0.1565, loss_cate: 0.1163, loss: 0.2728
2021-07-23 07:57:10,693 - mmdet - INFO - Epoch [18][250/673]	lr: 0.01000, eta: 1:01:17, time: 0.301, data_time: 0.011, memory: 4440, loss_ins: 0.1812, loss_cate: 0.1276, loss: 0.3088
2021-07-23 07:57:26,229 - mmdet - INFO - Epoch [18][300/673]	lr: 0.01000, eta: 1:01:03, time: 0.311, data_time: 0.012, memory: 4440, loss_ins: 0.1756, loss_cate: 0.0993, loss: 0.2749
2021-07-23 07:57:41,763 - mmdet - INFO - Epoch [18][350/673]	lr: 0.01000, eta: 1:00:49, time: 0.311, data_time: 0.012, memory: 4440, loss_ins: 0.2163, loss_cate: 0.1162, loss: 0.3325
2021-07-23 07:57:57,023 - mmdet - INFO - Epoch [18][400/673]	lr: 0.01000, eta: 1:00:35, time: 0.305, data_time: 0.012, memory: 4440, loss_ins: 0.1408, loss_cate: 0.1062, loss: 0.2470
2021-07-23 07:58:11,966 - mmdet - INFO - Epoch [18][450/673]	lr: 0.01000, eta: 1:00:21, time: 0.299, data_time: 0.012, memory: 4440, loss_ins: 0.1570, loss_cate: 0.1012, loss: 0.2582
2021-07-23 07:58:27,027 - mmdet - INFO - Epoch [18][500/673]	lr: 0.01000, eta: 1:00:07, time: 0.301, data_time: 0.012, memory: 4440, loss_ins: 0.1544, loss_cate: 0.1236, loss: 0.2780
2021-07-23 07:58:42,116 - mmdet - INFO - Epoch [18][550/673]	lr: 0.01000, eta: 0:59:52, time: 0.302, data_time: 0.012, memory: 4440, loss_ins: 0.1765, loss_cate: 0.1179, loss: 0.2944
2021-07-23 07:58:57,256 - mmdet - INFO - Epoch [18][600/673]	lr: 0.01000, eta: 0:59:38, time: 0.303, data_time: 0.012, memory: 4440, loss_ins: 0.1576, loss_cate: 0.1133, loss: 0.2708
2021-07-23 07:59:12,189 - mmdet - INFO - Epoch [18][650/673]	lr: 0.01000, eta: 0:59:24, time: 0.299, data_time: 0.013, memory: 4440, loss_ins: 0.1468, loss_cate: 0.1129, loss: 0.2597
2021-07-23 07:59:37,372 - mmdet - INFO - Epoch [19][50/673]	lr: 0.01000, eta: 0:58:57, time: 0.316, data_time: 0.018, memory: 4440, loss_ins: 0.1553, loss_cate: 0.0982, loss: 0.2535
2021-07-23 07:59:52,833 - mmdet - INFO - Epoch [19][100/673]	lr: 0.01000, eta: 0:58:43, time: 0.309, data_time: 0.012, memory: 4440, loss_ins: 0.1735, loss_cate: 0.1160, loss: 0.2895
2021-07-23 08:00:08,015 - mmdet - INFO - Epoch [19][150/673]	lr: 0.01000, eta: 0:58:29, time: 0.304, data_time: 0.012, memory: 4440, loss_ins: 0.1731, loss_cate: 0.1001, loss: 0.2732
2021-07-23 08:00:23,391 - mmdet - INFO - Epoch [19][200/673]	lr: 0.01000, eta: 0:58:15, time: 0.308, data_time: 0.012, memory: 4440, loss_ins: 0.1805, loss_cate: 0.1214, loss: 0.3019
2021-07-23 08:00:38,249 - mmdet - INFO - Epoch [19][250/673]	lr: 0.01000, eta: 0:58:00, time: 0.297, data_time: 0.012, memory: 4440, loss_ins: 0.1647, loss_cate: 0.1229, loss: 0.2876
2021-07-23 08:00:53,393 - mmdet - INFO - Epoch [19][300/673]	lr: 0.01000, eta: 0:57:46, time: 0.303, data_time: 0.012, memory: 4440, loss_ins: 0.1449, loss_cate: 0.0916, loss: 0.2365
2021-07-23 08:01:08,497 - mmdet - INFO - Epoch [19][350/673]	lr: 0.01000, eta: 0:57:32, time: 0.302, data_time: 0.012, memory: 4440, loss_ins: 0.1599, loss_cate: 0.1042, loss: 0.2640
2021-07-23 08:01:23,729 - mmdet - INFO - Epoch [19][400/673]	lr: 0.01000, eta: 0:57:17, time: 0.305, data_time: 0.012, memory: 4440, loss_ins: 0.1630, loss_cate: 0.1102, loss: 0.2732
2021-07-23 08:01:38,854 - mmdet - INFO - Epoch [19][450/673]	lr: 0.01000, eta: 0:57:03, time: 0.302, data_time: 0.012, memory: 4440, loss_ins: 0.1380, loss_cate: 0.0947, loss: 0.2327
2021-07-23 08:01:54,321 - mmdet - INFO - Epoch [19][500/673]	lr: 0.01000, eta: 0:56:49, time: 0.309, data_time: 0.013, memory: 4440, loss_ins: 0.1643, loss_cate: 0.0990, loss: 0.2633
2021-07-23 08:02:09,936 - mmdet - INFO - Epoch [19][550/673]	lr: 0.01000, eta: 0:56:35, time: 0.312, data_time: 0.012, memory: 4440, loss_ins: 0.1946, loss_cate: 0.1129, loss: 0.3075
2021-07-23 08:02:25,190 - mmdet - INFO - Epoch [19][600/673]	lr: 0.01000, eta: 0:56:21, time: 0.305, data_time: 0.012, memory: 4440, loss_ins: 0.1547, loss_cate: 0.1068, loss: 0.2615
2021-07-23 08:02:40,024 - mmdet - INFO - Epoch [19][650/673]	lr: 0.01000, eta: 0:56:07, time: 0.297, data_time: 0.011, memory: 4440, loss_ins: 0.1561, loss_cate: 0.1188, loss: 0.2750
2021-07-23 08:03:04,259 - mmdet - INFO - Epoch [20][50/673]	lr: 0.01000, eta: 0:55:40, time: 0.306, data_time: 0.017, memory: 4440, loss_ins: 0.1576, loss_cate: 0.1047, loss: 0.2623
2021-07-23 08:03:19,135 - mmdet - INFO - Epoch [20][100/673]	lr: 0.01000, eta: 0:55:25, time: 0.298, data_time: 0.012, memory: 4440, loss_ins: 0.1712, loss_cate: 0.1120, loss: 0.2832
2021-07-23 08:03:34,144 - mmdet - INFO - Epoch [20][150/673]	lr: 0.01000, eta: 0:55:11, time: 0.300, data_time: 0.012, memory: 4440, loss_ins: 0.1898, loss_cate: 0.1037, loss: 0.2935
2021-07-23 08:03:49,012 - mmdet - INFO - Epoch [20][200/673]	lr: 0.01000, eta: 0:54:57, time: 0.297, data_time: 0.012, memory: 4440, loss_ins: 0.1663, loss_cate: 0.1133, loss: 0.2796
2021-07-23 08:04:04,107 - mmdet - INFO - Epoch [20][250/673]	lr: 0.01000, eta: 0:54:42, time: 0.302, data_time: 0.012, memory: 4440, loss_ins: 0.1833, loss_cate: 0.1091, loss: 0.2924
2021-07-23 08:04:19,172 - mmdet - INFO - Epoch [20][300/673]	lr: 0.01000, eta: 0:54:28, time: 0.301, data_time: 0.012, memory: 4440, loss_ins: 0.1548, loss_cate: 0.1045, loss: 0.2593
2021-07-23 08:04:34,449 - mmdet - INFO - Epoch [20][350/673]	lr: 0.01000, eta: 0:54:14, time: 0.306, data_time: 0.012, memory: 4440, loss_ins: 0.1407, loss_cate: 0.0992, loss: 0.2399
2021-07-23 08:04:49,268 - mmdet - INFO - Epoch [20][400/673]	lr: 0.01000, eta: 0:53:59, time: 0.296, data_time: 0.012, memory: 4440, loss_ins: 0.1431, loss_cate: 0.1033, loss: 0.2464
2021-07-23 08:05:04,233 - mmdet - INFO - Epoch [20][450/673]	lr: 0.01000, eta: 0:53:45, time: 0.299, data_time: 0.012, memory: 4440, loss_ins: 0.1593, loss_cate: 0.1047, loss: 0.2640
2021-07-23 08:05:19,228 - mmdet - INFO - Epoch [20][500/673]	lr: 0.01000, eta: 0:53:30, time: 0.300, data_time: 0.012, memory: 4440, loss_ins: 0.1645, loss_cate: 0.1040, loss: 0.2685
2021-07-23 08:05:34,616 - mmdet - INFO - Epoch [20][550/673]	lr: 0.01000, eta: 0:53:16, time: 0.308, data_time: 0.012, memory: 4440, loss_ins: 0.1379, loss_cate: 0.1085, loss: 0.2463
2021-07-23 08:05:55,180 - mmdet - INFO - Epoch [20][600/673]	lr: 0.01000, eta: 0:53:06, time: 0.411, data_time: 0.012, memory: 4440, loss_ins: 0.1815, loss_cate: 0.1047, loss: 0.2863
2021-07-23 08:06:13,835 - mmdet - INFO - Epoch [20][650/673]	lr: 0.01000, eta: 0:52:55, time: 0.373, data_time: 0.012, memory: 4440, loss_ins: 0.1580, loss_cate: 0.0988, loss: 0.2568
2021-07-23 08:06:38,098 - mmdet - INFO - Epoch [21][50/673]	lr: 0.01000, eta: 0:52:28, time: 0.306, data_time: 0.016, memory: 4440, loss_ins: 0.1573, loss_cate: 0.1028, loss: 0.2601
2021-07-23 08:06:55,643 - mmdet - INFO - Epoch [21][100/673]	lr: 0.01000, eta: 0:52:16, time: 0.351, data_time: 0.012, memory: 4440, loss_ins: 0.1458, loss_cate: 0.0956, loss: 0.2414
2021-07-23 08:07:16,548 - mmdet - INFO - Epoch [21][150/673]	lr: 0.01000, eta: 0:52:06, time: 0.418, data_time: 0.013, memory: 4440, loss_ins: 0.2041, loss_cate: 0.1028, loss: 0.3069
2021-07-23 08:07:31,467 - mmdet - INFO - Epoch [21][200/673]	lr: 0.01000, eta: 0:51:52, time: 0.298, data_time: 0.012, memory: 4440, loss_ins: 0.1465, loss_cate: 0.1102, loss: 0.2568
2021-07-23 08:07:46,491 - mmdet - INFO - Epoch [21][250/673]	lr: 0.01000, eta: 0:51:37, time: 0.300, data_time: 0.012, memory: 4440, loss_ins: 0.1662, loss_cate: 0.1018, loss: 0.2680
2021-07-23 08:08:01,151 - mmdet - INFO - Epoch [21][300/673]	lr: 0.01000, eta: 0:51:22, time: 0.293, data_time: 0.012, memory: 4440, loss_ins: 0.1450, loss_cate: 0.1001, loss: 0.2452
2021-07-23 08:08:16,450 - mmdet - INFO - Epoch [21][350/673]	lr: 0.01000, eta: 0:51:08, time: 0.306, data_time: 0.013, memory: 4440, loss_ins: 0.1553, loss_cate: 0.1057, loss: 0.2610
2021-07-23 08:08:31,604 - mmdet - INFO - Epoch [21][400/673]	lr: 0.01000, eta: 0:50:54, time: 0.303, data_time: 0.012, memory: 4440, loss_ins: 0.1667, loss_cate: 0.1024, loss: 0.2691
2021-07-23 08:08:46,728 - mmdet - INFO - Epoch [21][450/673]	lr: 0.01000, eta: 0:50:39, time: 0.302, data_time: 0.012, memory: 4440, loss_ins: 0.1839, loss_cate: 0.1140, loss: 0.2979
2021-07-23 08:09:01,524 - mmdet - INFO - Epoch [21][500/673]	lr: 0.01000, eta: 0:50:25, time: 0.296, data_time: 0.012, memory: 4440, loss_ins: 0.1621, loss_cate: 0.1168, loss: 0.2790
2021-07-23 08:09:16,600 - mmdet - INFO - Epoch [21][550/673]	lr: 0.01000, eta: 0:50:10, time: 0.302, data_time: 0.012, memory: 4440, loss_ins: 0.1307, loss_cate: 0.1000, loss: 0.2307
2021-07-23 08:09:31,729 - mmdet - INFO - Epoch [21][600/673]	lr: 0.01000, eta: 0:49:56, time: 0.303, data_time: 0.011, memory: 4440, loss_ins: 0.1838, loss_cate: 0.1140, loss: 0.2978
2021-07-23 08:09:46,801 - mmdet - INFO - Epoch [21][650/673]	lr: 0.01000, eta: 0:49:41, time: 0.301, data_time: 0.012, memory: 4440, loss_ins: 0.1283, loss_cate: 0.0924, loss: 0.2206
2021-07-23 08:10:10,876 - mmdet - INFO - Epoch [22][50/673]	lr: 0.01000, eta: 0:49:15, time: 0.304, data_time: 0.018, memory: 4440, loss_ins: 0.1826, loss_cate: 0.1130, loss: 0.2956
2021-07-23 08:10:25,821 - mmdet - INFO - Epoch [22][100/673]	lr: 0.01000, eta: 0:49:01, time: 0.299, data_time: 0.013, memory: 4440, loss_ins: 0.1398, loss_cate: 0.0987, loss: 0.2386
2021-07-23 08:10:41,224 - mmdet - INFO - Epoch [22][150/673]	lr: 0.01000, eta: 0:48:46, time: 0.308, data_time: 0.014, memory: 4440, loss_ins: 0.1673, loss_cate: 0.1000, loss: 0.2673
2021-07-23 08:10:56,489 - mmdet - INFO - Epoch [22][200/673]	lr: 0.01000, eta: 0:48:32, time: 0.305, data_time: 0.013, memory: 4440, loss_ins: 0.1636, loss_cate: 0.1031, loss: 0.2666
2021-07-23 08:11:11,764 - mmdet - INFO - Epoch [22][250/673]	lr: 0.01000, eta: 0:48:18, time: 0.305, data_time: 0.013, memory: 4440, loss_ins: 0.1558, loss_cate: 0.1024, loss: 0.2581
2021-07-23 08:11:26,910 - mmdet - INFO - Epoch [22][300/673]	lr: 0.01000, eta: 0:48:03, time: 0.303, data_time: 0.012, memory: 4440, loss_ins: 0.1284, loss_cate: 0.0875, loss: 0.2159
2021-07-23 08:11:42,110 - mmdet - INFO - Epoch [22][350/673]	lr: 0.01000, eta: 0:47:49, time: 0.304, data_time: 0.012, memory: 4440, loss_ins: 0.1216, loss_cate: 0.0882, loss: 0.2098
2021-07-23 08:11:56,999 - mmdet - INFO - Epoch [22][400/673]	lr: 0.01000, eta: 0:47:34, time: 0.298, data_time: 0.011, memory: 4440, loss_ins: 0.1482, loss_cate: 0.1228, loss: 0.2710
2021-07-23 08:12:12,193 - mmdet - INFO - Epoch [22][450/673]	lr: 0.01000, eta: 0:47:20, time: 0.304, data_time: 0.011, memory: 4440, loss_ins: 0.1688, loss_cate: 0.1077, loss: 0.2765
2021-07-23 08:12:27,250 - mmdet - INFO - Epoch [22][500/673]	lr: 0.01000, eta: 0:47:05, time: 0.301, data_time: 0.012, memory: 4440, loss_ins: 0.1572, loss_cate: 0.1025, loss: 0.2597
2021-07-23 08:12:42,268 - mmdet - INFO - Epoch [22][550/673]	lr: 0.01000, eta: 0:46:51, time: 0.300, data_time: 0.012, memory: 4440, loss_ins: 0.1458, loss_cate: 0.1055, loss: 0.2513
2021-07-23 08:12:57,531 - mmdet - INFO - Epoch [22][600/673]	lr: 0.01000, eta: 0:46:36, time: 0.305, data_time: 0.013, memory: 4440, loss_ins: 0.1789, loss_cate: 0.1072, loss: 0.2861
2021-07-23 08:13:12,773 - mmdet - INFO - Epoch [22][650/673]	lr: 0.01000, eta: 0:46:22, time: 0.305, data_time: 0.013, memory: 4440, loss_ins: 0.1694, loss_cate: 0.1027, loss: 0.2721
2021-07-23 08:13:36,896 - mmdet - INFO - Epoch [23][50/673]	lr: 0.01000, eta: 0:45:56, time: 0.303, data_time: 0.018, memory: 4440, loss_ins: 0.1402, loss_cate: 0.0873, loss: 0.2275
2021-07-23 08:13:51,991 - mmdet - INFO - Epoch [23][100/673]	lr: 0.01000, eta: 0:45:42, time: 0.302, data_time: 0.014, memory: 4440, loss_ins: 0.1564, loss_cate: 0.0974, loss: 0.2538
2021-07-23 08:14:07,109 - mmdet - INFO - Epoch [23][150/673]	lr: 0.01000, eta: 0:45:28, time: 0.302, data_time: 0.014, memory: 4440, loss_ins: 0.1310, loss_cate: 0.0875, loss: 0.2185
2021-07-23 08:14:22,060 - mmdet - INFO - Epoch [23][200/673]	lr: 0.01000, eta: 0:45:13, time: 0.299, data_time: 0.013, memory: 4440, loss_ins: 0.1778, loss_cate: 0.1170, loss: 0.2949
2021-07-23 08:14:37,027 - mmdet - INFO - Epoch [23][250/673]	lr: 0.01000, eta: 0:44:58, time: 0.299, data_time: 0.013, memory: 4440, loss_ins: 0.1565, loss_cate: 0.1059, loss: 0.2624
2021-07-23 08:14:52,425 - mmdet - INFO - Epoch [23][300/673]	lr: 0.01000, eta: 0:44:44, time: 0.308, data_time: 0.014, memory: 4440, loss_ins: 0.1707, loss_cate: 0.1067, loss: 0.2774
2021-07-23 08:15:07,637 - mmdet - INFO - Epoch [23][350/673]	lr: 0.01000, eta: 0:44:30, time: 0.304, data_time: 0.013, memory: 4440, loss_ins: 0.1578, loss_cate: 0.1050, loss: 0.2629
2021-07-23 08:15:22,972 - mmdet - INFO - Epoch [23][400/673]	lr: 0.01000, eta: 0:44:15, time: 0.307, data_time: 0.013, memory: 4440, loss_ins: 0.1862, loss_cate: 0.1087, loss: 0.2950
2021-07-23 08:15:38,334 - mmdet - INFO - Epoch [23][450/673]	lr: 0.01000, eta: 0:44:01, time: 0.307, data_time: 0.013, memory: 4440, loss_ins: 0.1614, loss_cate: 0.1040, loss: 0.2653
2021-07-23 08:15:53,261 - mmdet - INFO - Epoch [23][500/673]	lr: 0.01000, eta: 0:43:46, time: 0.299, data_time: 0.012, memory: 4440, loss_ins: 0.2030, loss_cate: 0.1131, loss: 0.3161
2021-07-23 08:16:08,240 - mmdet - INFO - Epoch [23][550/673]	lr: 0.01000, eta: 0:43:32, time: 0.300, data_time: 0.012, memory: 4440, loss_ins: 0.1581, loss_cate: 0.1018, loss: 0.2599
2021-07-23 08:16:23,423 - mmdet - INFO - Epoch [23][600/673]	lr: 0.01000, eta: 0:43:17, time: 0.304, data_time: 0.011, memory: 4440, loss_ins: 0.1465, loss_cate: 0.0907, loss: 0.2372
2021-07-23 08:16:38,476 - mmdet - INFO - Epoch [23][650/673]	lr: 0.01000, eta: 0:43:03, time: 0.301, data_time: 0.012, memory: 4440, loss_ins: 0.1701, loss_cate: 0.0985, loss: 0.2686
2021-07-23 08:17:02,806 - mmdet - INFO - Epoch [24][50/673]	lr: 0.01000, eta: 0:42:38, time: 0.307, data_time: 0.018, memory: 4440, loss_ins: 0.1351, loss_cate: 0.0934, loss: 0.2285
2021-07-23 08:17:17,901 - mmdet - INFO - Epoch [24][100/673]	lr: 0.01000, eta: 0:42:23, time: 0.302, data_time: 0.013, memory: 4440, loss_ins: 0.1688, loss_cate: 0.0971, loss: 0.2659
2021-07-23 08:17:32,948 - mmdet - INFO - Epoch [24][150/673]	lr: 0.01000, eta: 0:42:09, time: 0.301, data_time: 0.012, memory: 4440, loss_ins: 0.1380, loss_cate: 0.0897, loss: 0.2276
2021-07-23 08:17:47,792 - mmdet - INFO - Epoch [24][200/673]	lr: 0.01000, eta: 0:41:54, time: 0.297, data_time: 0.012, memory: 4440, loss_ins: 0.1349, loss_cate: 0.0973, loss: 0.2322
2021-07-23 08:18:03,058 - mmdet - INFO - Epoch [24][250/673]	lr: 0.01000, eta: 0:41:40, time: 0.305, data_time: 0.013, memory: 4440, loss_ins: 0.1507, loss_cate: 0.0978, loss: 0.2485
2021-07-23 08:18:18,220 - mmdet - INFO - Epoch [24][300/673]	lr: 0.01000, eta: 0:41:25, time: 0.303, data_time: 0.013, memory: 4440, loss_ins: 0.1301, loss_cate: 0.0877, loss: 0.2179
2021-07-23 08:18:33,372 - mmdet - INFO - Epoch [24][350/673]	lr: 0.01000, eta: 0:41:11, time: 0.303, data_time: 0.012, memory: 4440, loss_ins: 0.1435, loss_cate: 0.0911, loss: 0.2346
2021-07-23 08:18:48,570 - mmdet - INFO - Epoch [24][400/673]	lr: 0.01000, eta: 0:40:56, time: 0.304, data_time: 0.013, memory: 4440, loss_ins: 0.1644, loss_cate: 0.0979, loss: 0.2623
2021-07-23 08:19:03,896 - mmdet - INFO - Epoch [24][450/673]	lr: 0.01000, eta: 0:40:42, time: 0.307, data_time: 0.013, memory: 4440, loss_ins: 0.1589, loss_cate: 0.1033, loss: 0.2623
2021-07-23 08:19:18,995 - mmdet - INFO - Epoch [24][500/673]	lr: 0.01000, eta: 0:40:28, time: 0.302, data_time: 0.013, memory: 4440, loss_ins: 0.1915, loss_cate: 0.1084, loss: 0.3000
2021-07-23 08:19:34,130 - mmdet - INFO - Epoch [24][550/673]	lr: 0.01000, eta: 0:40:13, time: 0.303, data_time: 0.013, memory: 4440, loss_ins: 0.1285, loss_cate: 0.0918, loss: 0.2203
2021-07-23 08:19:48,983 - mmdet - INFO - Epoch [24][600/673]	lr: 0.01000, eta: 0:39:58, time: 0.297, data_time: 0.012, memory: 4440, loss_ins: 0.1404, loss_cate: 0.0841, loss: 0.2245
2021-07-23 08:20:04,269 - mmdet - INFO - Epoch [24][650/673]	lr: 0.01000, eta: 0:39:44, time: 0.306, data_time: 0.012, memory: 4440, loss_ins: 0.1358, loss_cate: 0.0957, loss: 0.2315
2021-07-23 08:20:28,136 - mmdet - INFO - Epoch [25][50/673]	lr: 0.01000, eta: 0:39:19, time: 0.302, data_time: 0.017, memory: 4440, loss_ins: 0.1216, loss_cate: 0.0910, loss: 0.2126
2021-07-23 08:20:43,323 - mmdet - INFO - Epoch [25][100/673]	lr: 0.01000, eta: 0:39:05, time: 0.304, data_time: 0.013, memory: 4440, loss_ins: 0.1164, loss_cate: 0.0794, loss: 0.1957
2021-07-23 08:20:58,303 - mmdet - INFO - Epoch [25][150/673]	lr: 0.01000, eta: 0:38:50, time: 0.300, data_time: 0.013, memory: 4440, loss_ins: 0.1277, loss_cate: 0.0882, loss: 0.2160
2021-07-23 08:21:13,706 - mmdet - INFO - Epoch [25][200/673]	lr: 0.01000, eta: 0:38:36, time: 0.308, data_time: 0.013, memory: 4440, loss_ins: 0.1710, loss_cate: 0.1046, loss: 0.2755
2021-07-23 08:21:28,581 - mmdet - INFO - Epoch [25][250/673]	lr: 0.01000, eta: 0:38:21, time: 0.297, data_time: 0.011, memory: 4440, loss_ins: 0.1180, loss_cate: 0.0859, loss: 0.2039
2021-07-23 08:21:43,739 - mmdet - INFO - Epoch [25][300/673]	lr: 0.01000, eta: 0:38:07, time: 0.303, data_time: 0.012, memory: 4440, loss_ins: 0.1329, loss_cate: 0.0935, loss: 0.2264
2021-07-23 08:21:58,788 - mmdet - INFO - Epoch [25][350/673]	lr: 0.01000, eta: 0:37:52, time: 0.301, data_time: 0.012, memory: 4440, loss_ins: 0.1398, loss_cate: 0.0900, loss: 0.2298
2021-07-23 08:22:14,124 - mmdet - INFO - Epoch [25][400/673]	lr: 0.01000, eta: 0:37:38, time: 0.307, data_time: 0.013, memory: 4440, loss_ins: 0.1564, loss_cate: 0.0996, loss: 0.2561
2021-07-23 08:22:29,541 - mmdet - INFO - Epoch [25][450/673]	lr: 0.01000, eta: 0:37:23, time: 0.308, data_time: 0.013, memory: 4440, loss_ins: 0.1509, loss_cate: 0.0940, loss: 0.2449
2021-07-23 08:22:45,028 - mmdet - INFO - Epoch [25][500/673]	lr: 0.01000, eta: 0:37:09, time: 0.310, data_time: 0.014, memory: 4440, loss_ins: 0.1497, loss_cate: 0.0990, loss: 0.2488
2021-07-23 08:23:00,334 - mmdet - INFO - Epoch [25][550/673]	lr: 0.01000, eta: 0:36:55, time: 0.306, data_time: 0.012, memory: 4440, loss_ins: 0.1399, loss_cate: 0.0975, loss: 0.2374
2021-07-23 08:23:15,438 - mmdet - INFO - Epoch [25][600/673]	lr: 0.01000, eta: 0:36:40, time: 0.302, data_time: 0.013, memory: 4440, loss_ins: 0.1679, loss_cate: 0.0932, loss: 0.2612
2021-07-23 08:23:30,570 - mmdet - INFO - Epoch [25][650/673]	lr: 0.01000, eta: 0:36:26, time: 0.303, data_time: 0.013, memory: 4440, loss_ins: 0.1681, loss_cate: 0.1067, loss: 0.2748
2021-07-23 08:23:55,066 - mmdet - INFO - Epoch [26][50/673]	lr: 0.01000, eta: 0:36:01, time: 0.306, data_time: 0.018, memory: 4440, loss_ins: 0.1352, loss_cate: 0.0933, loss: 0.2284
2021-07-23 08:24:10,204 - mmdet - INFO - Epoch [26][100/673]	lr: 0.01000, eta: 0:35:47, time: 0.303, data_time: 0.012, memory: 4440, loss_ins: 0.1178, loss_cate: 0.0882, loss: 0.2059
2021-07-23 08:24:25,929 - mmdet - INFO - Epoch [26][150/673]	lr: 0.01000, eta: 0:35:33, time: 0.314, data_time: 0.014, memory: 4440, loss_ins: 0.1537, loss_cate: 0.1049, loss: 0.2586
2021-07-23 08:24:41,129 - mmdet - INFO - Epoch [26][200/673]	lr: 0.01000, eta: 0:35:18, time: 0.304, data_time: 0.014, memory: 4440, loss_ins: 0.1421, loss_cate: 0.0877, loss: 0.2298
2021-07-23 08:24:56,365 - mmdet - INFO - Epoch [26][250/673]	lr: 0.01000, eta: 0:35:04, time: 0.305, data_time: 0.013, memory: 4440, loss_ins: 0.1227, loss_cate: 0.0886, loss: 0.2113
2021-07-23 08:25:11,385 - mmdet - INFO - Epoch [26][300/673]	lr: 0.01000, eta: 0:34:49, time: 0.300, data_time: 0.013, memory: 4440, loss_ins: 0.1309, loss_cate: 0.0949, loss: 0.2259
2021-07-23 08:25:26,065 - mmdet - INFO - Epoch [26][350/673]	lr: 0.01000, eta: 0:34:34, time: 0.294, data_time: 0.011, memory: 4440, loss_ins: 0.1270, loss_cate: 0.0844, loss: 0.2114
2021-07-23 08:25:41,197 - mmdet - INFO - Epoch [26][400/673]	lr: 0.01000, eta: 0:34:20, time: 0.303, data_time: 0.012, memory: 4440, loss_ins: 0.1400, loss_cate: 0.1008, loss: 0.2408
2021-07-23 08:25:56,289 - mmdet - INFO - Epoch [26][450/673]	lr: 0.01000, eta: 0:34:05, time: 0.302, data_time: 0.013, memory: 4440, loss_ins: 0.1228, loss_cate: 0.0974, loss: 0.2201
2021-07-23 08:26:11,141 - mmdet - INFO - Epoch [26][500/673]	lr: 0.01000, eta: 0:33:51, time: 0.297, data_time: 0.013, memory: 4440, loss_ins: 0.1499, loss_cate: 0.1063, loss: 0.2561
2021-07-23 08:26:26,389 - mmdet - INFO - Epoch [26][550/673]	lr: 0.01000, eta: 0:33:36, time: 0.305, data_time: 0.014, memory: 4440, loss_ins: 0.1880, loss_cate: 0.1167, loss: 0.3047
2021-07-23 08:26:41,540 - mmdet - INFO - Epoch [26][600/673]	lr: 0.01000, eta: 0:33:22, time: 0.303, data_time: 0.013, memory: 4440, loss_ins: 0.1325, loss_cate: 0.1020, loss: 0.2345
2021-07-23 08:26:56,686 - mmdet - INFO - Epoch [26][650/673]	lr: 0.01000, eta: 0:33:07, time: 0.303, data_time: 0.013, memory: 4440, loss_ins: 0.1471, loss_cate: 0.1013, loss: 0.2484
2021-07-23 08:27:21,177 - mmdet - INFO - Epoch [27][50/673]	lr: 0.01000, eta: 0:32:43, time: 0.313, data_time: 0.019, memory: 4440, loss_ins: 0.1476, loss_cate: 0.0894, loss: 0.2370
2021-07-23 08:27:36,101 - mmdet - INFO - Epoch [27][100/673]	lr: 0.01000, eta: 0:32:29, time: 0.298, data_time: 0.012, memory: 4440, loss_ins: 0.1372, loss_cate: 0.0873, loss: 0.2245
2021-07-23 08:27:51,094 - mmdet - INFO - Epoch [27][150/673]	lr: 0.01000, eta: 0:32:14, time: 0.300, data_time: 0.013, memory: 4440, loss_ins: 0.1193, loss_cate: 0.0869, loss: 0.2062
2021-07-23 08:28:06,327 - mmdet - INFO - Epoch [27][200/673]	lr: 0.01000, eta: 0:32:00, time: 0.305, data_time: 0.012, memory: 4440, loss_ins: 0.1246, loss_cate: 0.0951, loss: 0.2197
2021-07-23 08:28:21,411 - mmdet - INFO - Epoch [27][250/673]	lr: 0.01000, eta: 0:31:45, time: 0.302, data_time: 0.013, memory: 4440, loss_ins: 0.1461, loss_cate: 0.0976, loss: 0.2437
2021-07-23 08:28:36,336 - mmdet - INFO - Epoch [27][300/673]	lr: 0.01000, eta: 0:31:30, time: 0.298, data_time: 0.012, memory: 4440, loss_ins: 0.1167, loss_cate: 0.0975, loss: 0.2142
2021-07-23 08:28:51,385 - mmdet - INFO - Epoch [27][350/673]	lr: 0.01000, eta: 0:31:16, time: 0.301, data_time: 0.012, memory: 4440, loss_ins: 0.1429, loss_cate: 0.0880, loss: 0.2309
2021-07-23 08:29:06,511 - mmdet - INFO - Epoch [27][400/673]	lr: 0.01000, eta: 0:31:01, time: 0.303, data_time: 0.012, memory: 4440, loss_ins: 0.1312, loss_cate: 0.0866, loss: 0.2178
2021-07-23 08:29:21,565 - mmdet - INFO - Epoch [27][450/673]	lr: 0.01000, eta: 0:30:47, time: 0.301, data_time: 0.012, memory: 4440, loss_ins: 0.1595, loss_cate: 0.1007, loss: 0.2603
2021-07-23 08:29:36,627 - mmdet - INFO - Epoch [27][500/673]	lr: 0.01000, eta: 0:30:32, time: 0.301, data_time: 0.012, memory: 4440, loss_ins: 0.1196, loss_cate: 0.0826, loss: 0.2022
2021-07-23 08:29:51,681 - mmdet - INFO - Epoch [27][550/673]	lr: 0.01000, eta: 0:30:17, time: 0.301, data_time: 0.012, memory: 4440, loss_ins: 0.1432, loss_cate: 0.0890, loss: 0.2323
2021-07-23 08:30:06,537 - mmdet - INFO - Epoch [27][600/673]	lr: 0.01000, eta: 0:30:03, time: 0.297, data_time: 0.012, memory: 4440, loss_ins: 0.1341, loss_cate: 0.0964, loss: 0.2305
2021-07-23 08:30:21,588 - mmdet - INFO - Epoch [27][650/673]	lr: 0.01000, eta: 0:29:48, time: 0.301, data_time: 0.012, memory: 4440, loss_ins: 0.1272, loss_cate: 0.0863, loss: 0.2135
2021-07-23 08:30:45,406 - mmdet - INFO - Epoch [28][50/673]	lr: 0.00100, eta: 0:29:25, time: 0.297, data_time: 0.016, memory: 4440, loss_ins: 0.1112, loss_cate: 0.0774, loss: 0.1886
2021-07-23 08:31:00,318 - mmdet - INFO - Epoch [28][100/673]	lr: 0.00100, eta: 0:29:10, time: 0.298, data_time: 0.011, memory: 4440, loss_ins: 0.1265, loss_cate: 0.0861, loss: 0.2126
2021-07-23 08:31:15,361 - mmdet - INFO - Epoch [28][150/673]	lr: 0.00100, eta: 0:28:55, time: 0.301, data_time: 0.013, memory: 4440, loss_ins: 0.1212, loss_cate: 0.0768, loss: 0.1979
2021-07-23 08:31:30,431 - mmdet - INFO - Epoch [28][200/673]	lr: 0.00100, eta: 0:28:41, time: 0.301, data_time: 0.013, memory: 4440, loss_ins: 0.1084, loss_cate: 0.0789, loss: 0.1873
2021-07-23 08:31:45,540 - mmdet - INFO - Epoch [28][250/673]	lr: 0.00100, eta: 0:28:26, time: 0.302, data_time: 0.013, memory: 4440, loss_ins: 0.1162, loss_cate: 0.0726, loss: 0.1889
2021-07-23 08:32:00,724 - mmdet - INFO - Epoch [28][300/673]	lr: 0.00100, eta: 0:28:12, time: 0.304, data_time: 0.012, memory: 4440, loss_ins: 0.1038, loss_cate: 0.0790, loss: 0.1828
2021-07-23 08:32:15,866 - mmdet - INFO - Epoch [28][350/673]	lr: 0.00100, eta: 0:27:57, time: 0.303, data_time: 0.012, memory: 4440, loss_ins: 0.1100, loss_cate: 0.0708, loss: 0.1809
2021-07-23 08:32:31,132 - mmdet - INFO - Epoch [28][400/673]	lr: 0.00100, eta: 0:27:43, time: 0.305, data_time: 0.012, memory: 4440, loss_ins: 0.1137, loss_cate: 0.0751, loss: 0.1888
2021-07-23 08:32:46,587 - mmdet - INFO - Epoch [28][450/673]	lr: 0.00100, eta: 0:27:28, time: 0.309, data_time: 0.011, memory: 4440, loss_ins: 0.1237, loss_cate: 0.0729, loss: 0.1965
2021-07-23 08:33:01,961 - mmdet - INFO - Epoch [28][500/673]	lr: 0.00100, eta: 0:27:14, time: 0.307, data_time: 0.012, memory: 4440, loss_ins: 0.1100, loss_cate: 0.0706, loss: 0.1806
2021-07-23 08:33:17,214 - mmdet - INFO - Epoch [28][550/673]	lr: 0.00100, eta: 0:26:59, time: 0.305, data_time: 0.011, memory: 4440, loss_ins: 0.1050, loss_cate: 0.0704, loss: 0.1754
2021-07-23 08:33:32,227 - mmdet - INFO - Epoch [28][600/673]	lr: 0.00100, eta: 0:26:44, time: 0.300, data_time: 0.013, memory: 4440, loss_ins: 0.1147, loss_cate: 0.0765, loss: 0.1911
2021-07-23 08:33:47,240 - mmdet - INFO - Epoch [28][650/673]	lr: 0.00100, eta: 0:26:30, time: 0.300, data_time: 0.013, memory: 4440, loss_ins: 0.1087, loss_cate: 0.0655, loss: 0.1742
2021-07-23 08:34:11,771 - mmdet - INFO - Epoch [29][50/673]	lr: 0.00100, eta: 0:26:07, time: 0.310, data_time: 0.019, memory: 4440, loss_ins: 0.0925, loss_cate: 0.0640, loss: 0.1565
2021-07-23 08:34:27,163 - mmdet - INFO - Epoch [29][100/673]	lr: 0.00100, eta: 0:25:52, time: 0.308, data_time: 0.015, memory: 4440, loss_ins: 0.1138, loss_cate: 0.0740, loss: 0.1878
2021-07-23 08:34:42,241 - mmdet - INFO - Epoch [29][150/673]	lr: 0.00100, eta: 0:25:38, time: 0.302, data_time: 0.014, memory: 4440, loss_ins: 0.1098, loss_cate: 0.0689, loss: 0.1788
2021-07-23 08:34:57,408 - mmdet - INFO - Epoch [29][200/673]	lr: 0.00100, eta: 0:25:23, time: 0.303, data_time: 0.014, memory: 4440, loss_ins: 0.0952, loss_cate: 0.0744, loss: 0.1697
2021-07-23 08:35:12,768 - mmdet - INFO - Epoch [29][250/673]	lr: 0.00100, eta: 0:25:09, time: 0.307, data_time: 0.015, memory: 4440, loss_ins: 0.1152, loss_cate: 0.0786, loss: 0.1938
2021-07-23 08:35:27,891 - mmdet - INFO - Epoch [29][300/673]	lr: 0.00100, eta: 0:24:54, time: 0.302, data_time: 0.014, memory: 4440, loss_ins: 0.1015, loss_cate: 0.0644, loss: 0.1659
2021-07-23 08:35:43,149 - mmdet - INFO - Epoch [29][350/673]	lr: 0.00100, eta: 0:24:39, time: 0.305, data_time: 0.013, memory: 4440, loss_ins: 0.1199, loss_cate: 0.0730, loss: 0.1929
2021-07-23 08:35:58,576 - mmdet - INFO - Epoch [29][400/673]	lr: 0.00100, eta: 0:24:25, time: 0.309, data_time: 0.015, memory: 4440, loss_ins: 0.1075, loss_cate: 0.0641, loss: 0.1716
2021-07-23 08:36:13,790 - mmdet - INFO - Epoch [29][450/673]	lr: 0.00100, eta: 0:24:10, time: 0.304, data_time: 0.014, memory: 4440, loss_ins: 0.1039, loss_cate: 0.0733, loss: 0.1772
2021-07-23 08:36:29,226 - mmdet - INFO - Epoch [29][500/673]	lr: 0.00100, eta: 0:23:56, time: 0.309, data_time: 0.014, memory: 4440, loss_ins: 0.1160, loss_cate: 0.0722, loss: 0.1882
2021-07-23 08:36:44,549 - mmdet - INFO - Epoch [29][550/673]	lr: 0.00100, eta: 0:23:41, time: 0.306, data_time: 0.013, memory: 4440, loss_ins: 0.1166, loss_cate: 0.0663, loss: 0.1829
2021-07-23 08:36:59,434 - mmdet - INFO - Epoch [29][600/673]	lr: 0.00100, eta: 0:23:27, time: 0.298, data_time: 0.013, memory: 4440, loss_ins: 0.0879, loss_cate: 0.0705, loss: 0.1584
2021-07-23 08:37:14,454 - mmdet - INFO - Epoch [29][650/673]	lr: 0.00100, eta: 0:23:12, time: 0.300, data_time: 0.013, memory: 4440, loss_ins: 0.1260, loss_cate: 0.0799, loss: 0.2058
2021-07-23 08:37:38,427 - mmdet - INFO - Epoch [30][50/673]	lr: 0.00100, eta: 0:22:49, time: 0.301, data_time: 0.018, memory: 4440, loss_ins: 0.1057, loss_cate: 0.0716, loss: 0.1774
2021-07-23 08:37:53,582 - mmdet - INFO - Epoch [30][100/673]	lr: 0.00100, eta: 0:22:34, time: 0.303, data_time: 0.013, memory: 4440, loss_ins: 0.1008, loss_cate: 0.0673, loss: 0.1681
2021-07-23 08:38:08,803 - mmdet - INFO - Epoch [30][150/673]	lr: 0.00100, eta: 0:22:20, time: 0.304, data_time: 0.014, memory: 4440, loss_ins: 0.0922, loss_cate: 0.0713, loss: 0.1635
2021-07-23 08:38:24,040 - mmdet - INFO - Epoch [30][200/673]	lr: 0.00100, eta: 0:22:05, time: 0.305, data_time: 0.014, memory: 4440, loss_ins: 0.1043, loss_cate: 0.0720, loss: 0.1764
2021-07-23 08:38:39,024 - mmdet - INFO - Epoch [30][250/673]	lr: 0.00100, eta: 0:21:51, time: 0.300, data_time: 0.013, memory: 4440, loss_ins: 0.1059, loss_cate: 0.0658, loss: 0.1717
2021-07-23 08:38:53,915 - mmdet - INFO - Epoch [30][300/673]	lr: 0.00100, eta: 0:21:36, time: 0.298, data_time: 0.013, memory: 4440, loss_ins: 0.0973, loss_cate: 0.0654, loss: 0.1627
2021-07-23 08:39:09,126 - mmdet - INFO - Epoch [30][350/673]	lr: 0.00100, eta: 0:21:21, time: 0.304, data_time: 0.013, memory: 4440, loss_ins: 0.1239, loss_cate: 0.0683, loss: 0.1922
2021-07-23 08:39:23,970 - mmdet - INFO - Epoch [30][400/673]	lr: 0.00100, eta: 0:21:07, time: 0.297, data_time: 0.012, memory: 4440, loss_ins: 0.0984, loss_cate: 0.0782, loss: 0.1766
2021-07-23 08:39:38,793 - mmdet - INFO - Epoch [30][450/673]	lr: 0.00100, eta: 0:20:52, time: 0.296, data_time: 0.012, memory: 4440, loss_ins: 0.0981, loss_cate: 0.0704, loss: 0.1686
2021-07-23 08:39:53,948 - mmdet - INFO - Epoch [30][500/673]	lr: 0.00100, eta: 0:20:37, time: 0.303, data_time: 0.013, memory: 4440, loss_ins: 0.0870, loss_cate: 0.0620, loss: 0.1490
2021-07-23 08:40:09,234 - mmdet - INFO - Epoch [30][550/673]	lr: 0.00100, eta: 0:20:23, time: 0.306, data_time: 0.013, memory: 4440, loss_ins: 0.1020, loss_cate: 0.0672, loss: 0.1691
2021-07-23 08:40:24,410 - mmdet - INFO - Epoch [30][600/673]	lr: 0.00100, eta: 0:20:08, time: 0.304, data_time: 0.011, memory: 4440, loss_ins: 0.1112, loss_cate: 0.0734, loss: 0.1846
2021-07-23 08:40:39,715 - mmdet - INFO - Epoch [30][650/673]	lr: 0.00100, eta: 0:19:54, time: 0.306, data_time: 0.013, memory: 4440, loss_ins: 0.1140, loss_cate: 0.0701, loss: 0.1842
2021-07-23 08:41:04,323 - mmdet - INFO - Epoch [31][50/673]	lr: 0.00100, eta: 0:19:31, time: 0.314, data_time: 0.018, memory: 4440, loss_ins: 0.1019, loss_cate: 0.0604, loss: 0.1623
2021-07-23 08:41:19,461 - mmdet - INFO - Epoch [31][100/673]	lr: 0.00100, eta: 0:19:16, time: 0.303, data_time: 0.013, memory: 4440, loss_ins: 0.0939, loss_cate: 0.0671, loss: 0.1610
2021-07-23 08:41:34,483 - mmdet - INFO - Epoch [31][150/673]	lr: 0.00100, eta: 0:19:02, time: 0.300, data_time: 0.012, memory: 4440, loss_ins: 0.1006, loss_cate: 0.0676, loss: 0.1682
2021-07-23 08:41:49,520 - mmdet - INFO - Epoch [31][200/673]	lr: 0.00100, eta: 0:18:47, time: 0.301, data_time: 0.012, memory: 4440, loss_ins: 0.1083, loss_cate: 0.0660, loss: 0.1743
2021-07-23 08:42:04,763 - mmdet - INFO - Epoch [31][250/673]	lr: 0.00100, eta: 0:18:33, time: 0.305, data_time: 0.013, memory: 4440, loss_ins: 0.1095, loss_cate: 0.0699, loss: 0.1794
2021-07-23 08:42:19,789 - mmdet - INFO - Epoch [31][300/673]	lr: 0.00100, eta: 0:18:18, time: 0.301, data_time: 0.012, memory: 4440, loss_ins: 0.1117, loss_cate: 0.0692, loss: 0.1809
2021-07-23 08:42:34,560 - mmdet - INFO - Epoch [31][350/673]	lr: 0.00100, eta: 0:18:03, time: 0.295, data_time: 0.012, memory: 4440, loss_ins: 0.0961, loss_cate: 0.0693, loss: 0.1654
2021-07-23 08:42:49,581 - mmdet - INFO - Epoch [31][400/673]	lr: 0.00100, eta: 0:17:49, time: 0.300, data_time: 0.012, memory: 4440, loss_ins: 0.1092, loss_cate: 0.0694, loss: 0.1786
2021-07-23 08:43:04,675 - mmdet - INFO - Epoch [31][450/673]	lr: 0.00100, eta: 0:17:34, time: 0.302, data_time: 0.012, memory: 4440, loss_ins: 0.0948, loss_cate: 0.0665, loss: 0.1612
2021-07-23 08:43:19,734 - mmdet - INFO - Epoch [31][500/673]	lr: 0.00100, eta: 0:17:19, time: 0.301, data_time: 0.012, memory: 4440, loss_ins: 0.1087, loss_cate: 0.0696, loss: 0.1784
2021-07-23 08:43:35,178 - mmdet - INFO - Epoch [31][550/673]	lr: 0.00100, eta: 0:17:05, time: 0.309, data_time: 0.012, memory: 4440, loss_ins: 0.1080, loss_cate: 0.0662, loss: 0.1742
2021-07-23 08:43:50,352 - mmdet - INFO - Epoch [31][600/673]	lr: 0.00100, eta: 0:16:50, time: 0.304, data_time: 0.012, memory: 4440, loss_ins: 0.0942, loss_cate: 0.0724, loss: 0.1666
2021-07-23 08:44:05,402 - mmdet - INFO - Epoch [31][650/673]	lr: 0.00100, eta: 0:16:36, time: 0.301, data_time: 0.012, memory: 4440, loss_ins: 0.1078, loss_cate: 0.0692, loss: 0.1770
2021-07-23 08:44:29,659 - mmdet - INFO - Epoch [32][50/673]	lr: 0.00100, eta: 0:16:13, time: 0.307, data_time: 0.018, memory: 4440, loss_ins: 0.0996, loss_cate: 0.0656, loss: 0.1651
2021-07-23 08:44:44,594 - mmdet - INFO - Epoch [32][100/673]	lr: 0.00100, eta: 0:15:59, time: 0.299, data_time: 0.012, memory: 4440, loss_ins: 0.1079, loss_cate: 0.0753, loss: 0.1832
2021-07-23 08:44:59,908 - mmdet - INFO - Epoch [32][150/673]	lr: 0.00100, eta: 0:15:44, time: 0.306, data_time: 0.014, memory: 4440, loss_ins: 0.0814, loss_cate: 0.0597, loss: 0.1412
2021-07-23 08:45:15,217 - mmdet - INFO - Epoch [32][200/673]	lr: 0.00100, eta: 0:15:29, time: 0.306, data_time: 0.014, memory: 4440, loss_ins: 0.0862, loss_cate: 0.0620, loss: 0.1482
2021-07-23 08:45:30,053 - mmdet - INFO - Epoch [32][250/673]	lr: 0.00100, eta: 0:15:15, time: 0.297, data_time: 0.013, memory: 4440, loss_ins: 0.0973, loss_cate: 0.0626, loss: 0.1599
2021-07-23 08:45:44,966 - mmdet - INFO - Epoch [32][300/673]	lr: 0.00100, eta: 0:15:00, time: 0.298, data_time: 0.013, memory: 4440, loss_ins: 0.1014, loss_cate: 0.0684, loss: 0.1697
2021-07-23 08:45:59,925 - mmdet - INFO - Epoch [32][350/673]	lr: 0.00100, eta: 0:14:45, time: 0.299, data_time: 0.013, memory: 4440, loss_ins: 0.1014, loss_cate: 0.0705, loss: 0.1719
2021-07-23 08:46:15,039 - mmdet - INFO - Epoch [32][400/673]	lr: 0.00100, eta: 0:14:31, time: 0.302, data_time: 0.013, memory: 4440, loss_ins: 0.0940, loss_cate: 0.0651, loss: 0.1591
2021-07-23 08:46:29,750 - mmdet - INFO - Epoch [32][450/673]	lr: 0.00100, eta: 0:14:16, time: 0.294, data_time: 0.012, memory: 4440, loss_ins: 0.1109, loss_cate: 0.0743, loss: 0.1852
2021-07-23 08:46:44,860 - mmdet - INFO - Epoch [32][500/673]	lr: 0.00100, eta: 0:14:01, time: 0.302, data_time: 0.012, memory: 4440, loss_ins: 0.0964, loss_cate: 0.0626, loss: 0.1589
2021-07-23 08:46:59,701 - mmdet - INFO - Epoch [32][550/673]	lr: 0.00100, eta: 0:13:47, time: 0.297, data_time: 0.012, memory: 4440, loss_ins: 0.0893, loss_cate: 0.0618, loss: 0.1511
2021-07-23 08:47:15,181 - mmdet - INFO - Epoch [32][600/673]	lr: 0.00100, eta: 0:13:32, time: 0.310, data_time: 0.014, memory: 4440, loss_ins: 0.1177, loss_cate: 0.0660, loss: 0.1837
2021-07-23 08:47:30,475 - mmdet - INFO - Epoch [32][650/673]	lr: 0.00100, eta: 0:13:18, time: 0.306, data_time: 0.013, memory: 4440, loss_ins: 0.1138, loss_cate: 0.0768, loss: 0.1906
2021-07-23 08:47:54,284 - mmdet - INFO - Epoch [33][50/673]	lr: 0.00100, eta: 0:12:55, time: 0.299, data_time: 0.018, memory: 4440, loss_ins: 0.0972, loss_cate: 0.0685, loss: 0.1656
2021-07-23 08:48:09,741 - mmdet - INFO - Epoch [33][100/673]	lr: 0.00100, eta: 0:12:41, time: 0.309, data_time: 0.014, memory: 4440, loss_ins: 0.1126, loss_cate: 0.0549, loss: 0.1674
2021-07-23 08:48:24,900 - mmdet - INFO - Epoch [33][150/673]	lr: 0.00100, eta: 0:12:26, time: 0.303, data_time: 0.014, memory: 4440, loss_ins: 0.1017, loss_cate: 0.0640, loss: 0.1658
2021-07-23 08:48:40,238 - mmdet - INFO - Epoch [33][200/673]	lr: 0.00100, eta: 0:12:11, time: 0.307, data_time: 0.014, memory: 4440, loss_ins: 0.0936, loss_cate: 0.0543, loss: 0.1478
2021-07-23 08:48:55,427 - mmdet - INFO - Epoch [33][250/673]	lr: 0.00100, eta: 0:11:57, time: 0.304, data_time: 0.013, memory: 4440, loss_ins: 0.0987, loss_cate: 0.0666, loss: 0.1653
2021-07-23 08:49:10,148 - mmdet - INFO - Epoch [33][300/673]	lr: 0.00100, eta: 0:11:42, time: 0.294, data_time: 0.013, memory: 4440, loss_ins: 0.0895, loss_cate: 0.0665, loss: 0.1560
2021-07-23 08:49:25,375 - mmdet - INFO - Epoch [33][350/673]	lr: 0.00100, eta: 0:11:27, time: 0.305, data_time: 0.013, memory: 4440, loss_ins: 0.1103, loss_cate: 0.0639, loss: 0.1742
2021-07-23 08:49:41,290 - mmdet - INFO - Epoch [33][400/673]	lr: 0.00100, eta: 0:11:13, time: 0.318, data_time: 0.013, memory: 4440, loss_ins: 0.1070, loss_cate: 0.0665, loss: 0.1735
2021-07-23 08:49:56,370 - mmdet - INFO - Epoch [33][450/673]	lr: 0.00100, eta: 0:10:58, time: 0.302, data_time: 0.014, memory: 4440, loss_ins: 0.1108, loss_cate: 0.0696, loss: 0.1804
2021-07-23 08:50:11,448 - mmdet - INFO - Epoch [33][500/673]	lr: 0.00100, eta: 0:10:44, time: 0.302, data_time: 0.013, memory: 4440, loss_ins: 0.0874, loss_cate: 0.0573, loss: 0.1447
2021-07-23 08:50:26,407 - mmdet - INFO - Epoch [33][550/673]	lr: 0.00100, eta: 0:10:29, time: 0.299, data_time: 0.012, memory: 4440, loss_ins: 0.0912, loss_cate: 0.0636, loss: 0.1549
2021-07-23 08:50:41,731 - mmdet - INFO - Epoch [33][600/673]	lr: 0.00100, eta: 0:10:14, time: 0.306, data_time: 0.013, memory: 4440, loss_ins: 0.1105, loss_cate: 0.0757, loss: 0.1862
2021-07-23 08:50:56,690 - mmdet - INFO - Epoch [33][650/673]	lr: 0.00100, eta: 0:10:00, time: 0.299, data_time: 0.012, memory: 4440, loss_ins: 0.1086, loss_cate: 0.0726, loss: 0.1812
2021-07-23 08:51:20,992 - mmdet - INFO - Epoch [34][50/673]	lr: 0.00010, eta: 0:09:38, time: 0.310, data_time: 0.018, memory: 4440, loss_ins: 0.0906, loss_cate: 0.0526, loss: 0.1432
2021-07-23 08:51:36,102 - mmdet - INFO - Epoch [34][100/673]	lr: 0.00010, eta: 0:09:23, time: 0.302, data_time: 0.013, memory: 4440, loss_ins: 0.1096, loss_cate: 0.0727, loss: 0.1822
2021-07-23 08:51:51,012 - mmdet - INFO - Epoch [34][150/673]	lr: 0.00010, eta: 0:09:08, time: 0.298, data_time: 0.013, memory: 4440, loss_ins: 0.0873, loss_cate: 0.0609, loss: 0.1482
2021-07-23 08:52:06,214 - mmdet - INFO - Epoch [34][200/673]	lr: 0.00010, eta: 0:08:54, time: 0.304, data_time: 0.014, memory: 4440, loss_ins: 0.1003, loss_cate: 0.0645, loss: 0.1649
2021-07-23 08:52:21,520 - mmdet - INFO - Epoch [34][250/673]	lr: 0.00010, eta: 0:08:39, time: 0.306, data_time: 0.014, memory: 4440, loss_ins: 0.1024, loss_cate: 0.0570, loss: 0.1595
2021-07-23 08:52:36,696 - mmdet - INFO - Epoch [34][300/673]	lr: 0.00010, eta: 0:08:24, time: 0.304, data_time: 0.014, memory: 4440, loss_ins: 0.0950, loss_cate: 0.0552, loss: 0.1502
2021-07-23 08:52:52,094 - mmdet - INFO - Epoch [34][350/673]	lr: 0.00010, eta: 0:08:10, time: 0.308, data_time: 0.014, memory: 4440, loss_ins: 0.1064, loss_cate: 0.0636, loss: 0.1700
2021-07-23 08:53:07,405 - mmdet - INFO - Epoch [34][400/673]	lr: 0.00010, eta: 0:07:55, time: 0.306, data_time: 0.014, memory: 4440, loss_ins: 0.0950, loss_cate: 0.0656, loss: 0.1606
2021-07-23 08:53:22,616 - mmdet - INFO - Epoch [34][450/673]	lr: 0.00010, eta: 0:07:41, time: 0.304, data_time: 0.014, memory: 4440, loss_ins: 0.1033, loss_cate: 0.0697, loss: 0.1729
2021-07-23 08:53:37,490 - mmdet - INFO - Epoch [34][500/673]	lr: 0.00010, eta: 0:07:26, time: 0.297, data_time: 0.013, memory: 4440, loss_ins: 0.1010, loss_cate: 0.0656, loss: 0.1665
2021-07-23 08:53:52,268 - mmdet - INFO - Epoch [34][550/673]	lr: 0.00010, eta: 0:07:11, time: 0.296, data_time: 0.013, memory: 4440, loss_ins: 0.0987, loss_cate: 0.0638, loss: 0.1625
2021-07-23 08:54:07,190 - mmdet - INFO - Epoch [34][600/673]	lr: 0.00010, eta: 0:06:56, time: 0.298, data_time: 0.013, memory: 4440, loss_ins: 0.0879, loss_cate: 0.0577, loss: 0.1456
2021-07-23 08:54:22,208 - mmdet - INFO - Epoch [34][650/673]	lr: 0.00010, eta: 0:06:42, time: 0.300, data_time: 0.012, memory: 4440, loss_ins: 0.1071, loss_cate: 0.0653, loss: 0.1723
2021-07-23 08:54:46,795 - mmdet - INFO - Epoch [35][50/673]	lr: 0.00010, eta: 0:06:20, time: 0.313, data_time: 0.019, memory: 4440, loss_ins: 0.0918, loss_cate: 0.0602, loss: 0.1519
2021-07-23 08:55:01,847 - mmdet - INFO - Epoch [35][100/673]	lr: 0.00010, eta: 0:06:05, time: 0.301, data_time: 0.012, memory: 4440, loss_ins: 0.0970, loss_cate: 0.0632, loss: 0.1602
2021-07-23 08:55:17,685 - mmdet - INFO - Epoch [35][150/673]	lr: 0.00010, eta: 0:05:51, time: 0.317, data_time: 0.012, memory: 4440, loss_ins: 0.0982, loss_cate: 0.0553, loss: 0.1535
2021-07-23 08:55:33,159 - mmdet - INFO - Epoch [35][200/673]	lr: 0.00010, eta: 0:05:36, time: 0.309, data_time: 0.012, memory: 4440, loss_ins: 0.0925, loss_cate: 0.0562, loss: 0.1487
2021-07-23 08:55:48,197 - mmdet - INFO - Epoch [35][250/673]	lr: 0.00010, eta: 0:05:21, time: 0.301, data_time: 0.012, memory: 4440, loss_ins: 0.0889, loss_cate: 0.0590, loss: 0.1479
2021-07-23 08:56:03,683 - mmdet - INFO - Epoch [35][300/673]	lr: 0.00010, eta: 0:05:07, time: 0.310, data_time: 0.013, memory: 4440, loss_ins: 0.1015, loss_cate: 0.0618, loss: 0.1634
2021-07-23 08:56:18,898 - mmdet - INFO - Epoch [35][350/673]	lr: 0.00010, eta: 0:04:52, time: 0.304, data_time: 0.013, memory: 4440, loss_ins: 0.0936, loss_cate: 0.0602, loss: 0.1538
2021-07-23 08:56:34,111 - mmdet - INFO - Epoch [35][400/673]	lr: 0.00010, eta: 0:04:37, time: 0.304, data_time: 0.013, memory: 4440, loss_ins: 0.0856, loss_cate: 0.0609, loss: 0.1465
2021-07-23 08:56:49,284 - mmdet - INFO - Epoch [35][450/673]	lr: 0.00010, eta: 0:04:23, time: 0.303, data_time: 0.013, memory: 4440, loss_ins: 0.0848, loss_cate: 0.0553, loss: 0.1401
2021-07-23 08:57:04,235 - mmdet - INFO - Epoch [35][500/673]	lr: 0.00010, eta: 0:04:08, time: 0.299, data_time: 0.013, memory: 4440, loss_ins: 0.0897, loss_cate: 0.0646, loss: 0.1542
2021-07-23 08:57:19,229 - mmdet - INFO - Epoch [35][550/673]	lr: 0.00010, eta: 0:03:53, time: 0.300, data_time: 0.013, memory: 4440, loss_ins: 0.1026, loss_cate: 0.0628, loss: 0.1654
2021-07-23 08:57:34,490 - mmdet - INFO - Epoch [35][600/673]	lr: 0.00010, eta: 0:03:39, time: 0.305, data_time: 0.013, memory: 4440, loss_ins: 0.0980, loss_cate: 0.0678, loss: 0.1658
2021-07-23 08:57:49,697 - mmdet - INFO - Epoch [35][650/673]	lr: 0.00010, eta: 0:03:24, time: 0.304, data_time: 0.013, memory: 4440, loss_ins: 0.1072, loss_cate: 0.0659, loss: 0.1731
2021-07-23 08:58:13,697 - mmdet - INFO - Epoch [36][50/673]	lr: 0.00010, eta: 0:03:02, time: 0.303, data_time: 0.018, memory: 4440, loss_ins: 0.0982, loss_cate: 0.0657, loss: 0.1639
2021-07-23 08:58:28,908 - mmdet - INFO - Epoch [36][100/673]	lr: 0.00010, eta: 0:02:48, time: 0.304, data_time: 0.016, memory: 4440, loss_ins: 0.1093, loss_cate: 0.0714, loss: 0.1807
2021-07-23 08:58:44,084 - mmdet - INFO - Epoch [36][150/673]	lr: 0.00010, eta: 0:02:33, time: 0.304, data_time: 0.016, memory: 4440, loss_ins: 0.0934, loss_cate: 0.0641, loss: 0.1576
2021-07-23 08:58:59,486 - mmdet - INFO - Epoch [36][200/673]	lr: 0.00010, eta: 0:02:18, time: 0.308, data_time: 0.015, memory: 4440, loss_ins: 0.0940, loss_cate: 0.0648, loss: 0.1588
2021-07-23 08:59:14,469 - mmdet - INFO - Epoch [36][250/673]	lr: 0.00010, eta: 0:02:04, time: 0.300, data_time: 0.014, memory: 4440, loss_ins: 0.0934, loss_cate: 0.0605, loss: 0.1539
2021-07-23 08:59:29,655 - mmdet - INFO - Epoch [36][300/673]	lr: 0.00010, eta: 0:01:49, time: 0.304, data_time: 0.014, memory: 4440, loss_ins: 0.0977, loss_cate: 0.0663, loss: 0.1640
2021-07-23 08:59:44,856 - mmdet - INFO - Epoch [36][350/673]	lr: 0.00010, eta: 0:01:34, time: 0.304, data_time: 0.014, memory: 4440, loss_ins: 0.0973, loss_cate: 0.0633, loss: 0.1606
2021-07-23 08:59:59,949 - mmdet - INFO - Epoch [36][400/673]	lr: 0.00010, eta: 0:01:20, time: 0.302, data_time: 0.014, memory: 4440, loss_ins: 0.1000, loss_cate: 0.0620, loss: 0.1619
2021-07-23 09:00:15,121 - mmdet - INFO - Epoch [36][450/673]	lr: 0.00010, eta: 0:01:05, time: 0.303, data_time: 0.014, memory: 4440, loss_ins: 0.0859, loss_cate: 0.0608, loss: 0.1467
2021-07-23 09:00:30,159 - mmdet - INFO - Epoch [36][500/673]	lr: 0.00010, eta: 0:00:50, time: 0.301, data_time: 0.013, memory: 4440, loss_ins: 0.0978, loss_cate: 0.0633, loss: 0.1611
2021-07-23 09:00:45,229 - mmdet - INFO - Epoch [36][550/673]	lr: 0.00010, eta: 0:00:36, time: 0.301, data_time: 0.013, memory: 4440, loss_ins: 0.1059, loss_cate: 0.0565, loss: 0.1624
2021-07-23 09:01:00,400 - mmdet - INFO - Epoch [36][600/673]	lr: 0.00010, eta: 0:00:21, time: 0.303, data_time: 0.014, memory: 4440, loss_ins: 0.0971, loss_cate: 0.0635, loss: 0.1606
2021-07-23 09:01:15,732 - mmdet - INFO - Epoch [36][650/673]	lr: 0.00010, eta: 0:00:06, time: 0.307, data_time: 0.014, memory: 4440, loss_ins: 0.0999, loss_cate: 0.0646, loss: 0.1644
